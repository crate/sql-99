{\rtf1\ansi\ansicpg1252\deff0\deflang4105\deflangfe4105{\fonttbl{\f0\fnil\fcharset0 Courier New;}}
{\*\generator Msftedit 5.41.21.2510;}\viewkind4\uc1\pard\nowidctlpar\lang9\kerning1\f0\fs21 SQL-99 Complete, Really\lang4105\par
\lang9 Copyright (c) 2005-2016 Trudy Pelzer & Peter Gulutzan.\lang4105\par
\lang9 All rights reserved.\lang4105\par
\par
\lang9 Redistribution and use in source and 'compiled' forms (PDF, PostScript, HTML, RTF, etc), with or without modification, are permitted provided that the following conditions are met:\lang4105\par
\par
\lang9 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer as the first lines of this file unmodified.\lang4105\par
\par
\lang9 2. Redistributions in compiled form (transformed to other DTDs, converted to PDF, PostScript, HTML, RTF, and other formats) must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\lang4105\par
\par
\lang9 3. The name of the author may not be used to endorse or promote products derived from this documentation without specific prior written permission.\lang4105\par
\par
\lang9 THIS DOCUMENTATION IS PROVIDED BY THE AUTHOR "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS DOCUMENTATION, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\lang4105\par
\pard\kerning0\par
\page\par
SQL-99 Complete, Really\par
\par
Peter Gulutzan and Trudy Pelzer\par
\par
Designations used by companies to\par
distinguish their products are often\par
claimed as trademarks. In all instances\par
where authors are aware of a trademark claim,\par
the product name appears in initial capital\par
letters, in all capital letters, or in\par
accordance with the vendor's capitalization\par
preference. Readers should contact the\par
appropriate companies for more complete\par
information on trademarks and trademark\par
registrations. All trademarks and registered\par
trademarks in this book are the property of\par
their respective holders.\par
\par
Copyright (c) 1999 by Ocelot Computer Services\par
Incorporated , except where noted otherwise. Published by\par
Ocelot Computer Services Incorporated. All rights reserved.\par
No part of this publication may reproduced or distributed\par
in any form or by any means, or stored in a database\par
or retrieval system, without the prior written permission\par
of the publisher; with the exception that the program\par
listings may be entered, stored, and executed in a\par
computer system, but they may not be reproduced for\par
publication.\par
\par
The programs in this book are presented for instructional\par
value. The programs have been carefully tested, but are\par
not guaranteed for any particular purpose. The publisher\par
does not offer any warranties and does not guarantee the\par
accuracy, adequacy, or completeness of any information\par
herein and is not responsible for any errors or omissions.\par
The publisher assumes no liability for damages resulting\par
from the use of the information in this book or for any\par
infringement of the intellectual property rights of third\par
parties that would result from the use of this information.\par
\par
\par
Trademarks:\par
Access: Microsoft Corp.\par
DB2: International Business Machines Corp.\par
dBASE IV: Inprise Corporation\par
Delphi: Inprise Corporation\par
Informix: Informix Corporation\par
Ingres: Computer Associates International Inc.\par
Java: Sun Microsystems Inc.\par
Ocelot, OCELOT DBMS: Ocelot Computer Services Inc.\par
Oracle: Oracle Corp.\par
Paradox: Inprise Corporation\par
SQL Server: Sybase, Inc.\par
SQL/DS: International Business Machines Corp.\par
Unicode: Unicode, Inc.\par
Windows, Windows95, WindowsNT, SQL Server: Microsoft Corp.\par
\par
All trademarks (those above and any others mentioned in this book) are the\par
property of their respective owners.\par
\par
\page\par
Table of Contents\par
\par
Table of Contents ...\par
\par
Preface ...\par
      Who Should Read this Book?\par
      What's In It?\par
\par
Chapter 1 -- Introduction ...\par
      How Ro Read This Book ...\par
      How To Read SQL Syntax ...\par
      What is SQL? ...\par
      SQL Conformance ...\par
      SQL Statement Classes ...\par
      SQL Rule Evaluation Order ...\par
\par
Chapter 2 -- General Concepts ...\par
      Set Theory ... \par
      Recap: Rhe Relational Model\par
      The SQL-environment ...\par
      SQL Objects ...\par
      SQL Data Types ...\par
      SQL Language Elements ...\par
\par
Chapter 3 -- Numbers ...\par
      Numeric <literal>s ...\par
      Numeric <data type>s ...\par
      IEEE Binary Floats ...\par
      Numeric Operations ...\par
      Choosing the Right <data type> ...\par
      Dialects ...\par
      The SQL Library ...\par
\par
Chapter 4 -- Bit Strings ...\par
      <bit string literal>s ...\par
      Bit string <data type>s ...\par
      Bit Operations ...\par
\par
Chapter 5 -- Binary Strings ...\par
      <BLOB literal>s ...\par
      BLOB <data type>s ...\par
      BLOB Operations ...\par
\par
Chapter 6 -- Characters ...\par
      What is a Character? ...\par
      What's In It for Me? ...\par
      Predefined Character sets ...\par
\par
Chapter 7 -- Character Strings ...\par
      Character String <literal>s ...\par
      Character String <data type>s ...\par
      Character String Operations ...\par
      Character Strings and Character Sets ...\par
      Character Strings and Collations ...\par
      Dialects ...\par
\par
Chapter 8 -- Temporal Values ...\par
      Some Preliminaries ...\par
      Temporal <literal>s ...\par
      Temporal <data type>s ...\par
      Temporal Operations ...\par
      Dialects ...\par
      The SQL Library ...\par
\par
Chapter 9 -- Boolean Values ...\par
      <Boolean literal>s ...\par
      Boolean <data type>s ...\par
      Boolean Operations ...\par
\par
Chapter 10 -- Collection Types ...\par
      Collection <data type>s ...\par
      Collection Operations ...\par
      Comprehensive Example ...\par
\par
Chapter 11 -- Row Types ...\par
      Row <data type>s ...\par
      Row Operations ...\par
      Comprehensive Example ...\par
\par
Chapter 12 -- Reference Types ...\par
      Reference <data type>s ...\par
      Reference Operations ...\par
\par
Chapter 13 -- NULLS ...\par
      Representing Missing Data with NULL ...\par
      The Meaning of NULL ...\par
      Three-Valued Logic ...\par
      Nullability ...\par
      The Duplicate Loophole ...\par
      Fun with NULLs ...\par
      Problems For Optimizers ...\par
      Nulloclasts vs. Nullodules ...\par
\par
Chapter 14 -- SQL Clusters ...\par
      Cluster ...\par
\par
Chapter 15-- AuthorizationIDs ...\par
      <AuthorizationID> ...\par
      CREATE ROLE Statement ...\par
      Privilege ...\par
      GRANT Statement ...\par
      Data Control ...\par
      REVOKE Statement ...\par
      DROP ROLE Statement ...\par
      What Privileges Do I Have? ...\par
      Violating the Security System ...\par
      User Functions ...\par
      Dialects ...\par
\par
Chapter 16 -- SQL Catalogs ...\par
      Catalog ...\par
      Catalog Names ...\par
      The Information Schema ...\par
\par
Chapter 17 -- SQL Schemas ...\par
      Schema ...\par
      CREATE SCHEMA Statement ...\par
      DROP SCHEMA Statement ...\par
\par
Chapter 18 -- SQL Tables and Views ...\par
      Base Table ...\par
      View ...\par
      Table Names ...\par
      Column ...\par
      CREATE TABLE Statement ...\par
      <Column definition> ...\par
      <default clause> ...\par
      ALTER TABLE Statement ...\par
      DROP TABLE Statement ...\par
      CREATE VIEW Statement ...\par
      Getting More Out Of Views ...\par
      DROP VIEW Statement ...\par
      DECLARE TABLE Statement ...\par
      Dialects ...\par
\par
Chapter 19 -- SQL Domains ...\par
      Domain ...\par
      CREATE DOMAIN Statement ...\par
      ALTER DOMAIN Statement ...\par
      DROP DOMAIN Statement ...\par
      Frequently-Used Numeric Domains ...\par
\par
Chapter 20 -- SQL Constraints and Assertions ...\par
      Constraint ...\par
      Constraint Descriptors ...\par
      Constraint Definition ...\par
      Constraint_type -- UNIQUE Constraint ...\par
      Constraint_type -- PRIMARY KEY Constraint ...\par
      Constraint_type -- FOREIGN KEY Constraint ...\par
      Constraint_type -- NOT NULL Constraint ...\par
      Constraint_type -- CHECK Constraint ...\par
      CREATE ASSERTION Statement ...\par
      Interlocking References ...\par
      Dropping Constraints ...\par
      DROP ASSERTION Statement ...\par
      Dialects ...\par
\par
Chapter 21 -- SQL Character Sets ...\par
      Character Set ...\par
      CREATE CHARACTER SET Statement ...\par
      DROP CHARACTER SET Statement ...\par
\par
Chapter 22 -- SQL Collations ...\par
      Collation ...\par
      CREATE COLLATION Statement ...\par
      DROP COLLATION Statement ...\par
\par
Chapter 23 -- SQL Translations ...\par
      Translation ...\par
      CREATE TRANSLATION Statement ...\par
      DROP TRANSLATION Statement ...\par
\par
Chapter 24 -- SQL Triggers ...\par
      Trigger ...\par
      CREATE TRIGGER Statement ...\par
      Activation of Triggers ...\par
      Trigger Examples ...\par
      Triggers versus Constraints ...\par
      DROP TRIGGER Statement ...\par
      Dialects ...\par
\par
Chapter 25 -- SQL-Invoked Routines ...\par
      Routine ...\par
      CREATE PROCEDURE/FUNCTION/METHOD Statement ...\par
      Routine Parameters ...\par
      Invoking Routines ...\par
      Routine Examples ...\par
      RETURN Statement ...\par
      External Routines ...\par
      ALTER ROUTINE/PROCEDURE/FUNCTION/METHOD Statement ...\par
      DROP ROUTINE/PROCEDURE/FUNCTION/METHOD Statement ...\par
      Dialects ...\par
\par
Chapter 26 -- PSM: Not Just Persistent Stored Modules ...\par
      Persistent Stored Modules ...\par
      CREATE MODULE Statement ...\par
      ALTER MODULE Statement ...\par
      DROP MODULE Statement ...\par
      BEGIN ... END: Compound Statement ...\par
      SIGNAL Statement ...\par
      RESIGNAL Statement ...\par
      Program Control ...\par
      Should Everything be in SQL? ...\par
      Dialects ...\par
\par
Chapter 27 -- User-Defined Types ...\par
      UDTs ...\par
      UDT Example ...\par
      Columns Based on UDTs ...\par
      Defining a Typed Table Based on a UDT ...\par
      CREATE TYPE Statement ...\par
      CREATE TABLE Statement ...\par
      CREATE CAST Statement ...\par
      CREATE ORDERING Statement ...\par
      Other Processes for Object/Relational Users ...\par
      Is Object/Relational Really Object-Oriented? ...\par
      Dialects ...\par
\par
Chapter 28 -- Introduction to SQL-Data Operations ...\par
      <value specification> ...\par
      <value expression> ...\par
      <row value constructor> ...\par
      <target specification> ...\par
\par
Chapter 29 -- Simple Search Conditions ...\par
      Truth Values ...\par
      SELECT Statement ...\par
      Predicates ...\par
      Search Conditions ...\par
      SQL's <case expression> ...\par
      Dialects ...\par
\par
Chapter 30 -- Searching with Joins ...\par
      Joined Tables ...\par
      Syntax Rules ...\par
      Dialects ...\par
\par
Chapter 31 -- Searching with Subqueries ...\par
      Subquery Syntax ...\par
      Scalar Subqueries ...\par
      Row Subqueries ...\par
      Table Subqueries ...\par
      Quantified Comparisons ...\par
      Predicates ...\par
      Joins versus Subqueries ...\par
      Subquery Examples ...\par
      Subquery Tips ...\par
      Dialects ...\par
\par
Chapter 32 -- Searching with Set Operators ...\par
      <query expression> ...\par
      Set Operation Syntax ...\par
      Result Names and ORDER BY ...\par
      Result <data type>s and Compatibility ...\par
      Set Operation Examples ...\par
      Updatability ...\par
      Recursive Unions ...\par
      Dialects ...\par
\par
Chapter 33 -- Searching with Groups ...\par
      GROUP BY Clause ...\par
      Set Functions ...\par
      HAVING Clause ...\par
      Views of Groups ...\par
      Dialects ...\par
\par
Chapter 34 -- Sorting Search Results ...\par
      ORDER BY Clause ...\par
      Dialects ...\par
\par
Chapter 35 -- Changing SQL-data ...\par
      The SQL-data Change Statements ...\par
      INSERT Statement ...\par
      UPDATE Statement ...\par
      DELETE Statement ...\par
      Data Change Operations ...\par
      Dialects ...\par
\par
Chapter 36 -- SQL Transactions ...\par
      Initiating Transactions ...\par
      Terminating Transactions ...\par
      Using Savepoints ...\par
      Transaction Tips ...\par
      See Also ...\par
      Dialects ...\par
\par
Chapter 37 -- SQL Transaction Concurrency ...\par
      Isolation Phenomena ...\par
      Pessimistic Concurrency: LOCKING ...\par
      Optimistic Concurrency: TIMESTAMPING ...\par
      SET TRANSACTION Statement ...\par
      START TRANSACTION Statement ...\par
      Special Problems ...\par
      Transactions and Constraint Checking ...\par
      Dialects ...\par
      Goodies ...\par
\par
Chapter 38 -- SQL Sessions ...\par
      SQL-Connections ...\par
      SQL-Session Management ...\par
\par
Chapter 39 -- Embedded SQL Binding Style ...\par
      What is Embedded SQL? ...\par
      Precompilers ...\par
      SQL Prefixes and Terminators ...\par
      Host Variables ...\par
      Cursors ...\par
      Embedded SQL Examples ...\par
      Diagnostics ...\par
      Dynamic SQL ...\par
      Summary ...\par
      Dialects ...\par
\par
Chapter 40 -- SQL/CLI Binding Style ...\par
      CHAP40_1.C ...\par
      SQLCHAR, SQLINTEGER and Other Typedefs ...\par
      SQLRETURN ...\par
      Handle Relationships ...\par
      How to Run Example Programs ...\par
      "Standard SQL CLI" equals "Core ODBC API" ...\par
      How each CLI Function will be Described ...\par
      CharacterStringRetrieval ...\par
\par
Chapter 41 -- SQL/CLI: env Functions ...\par
      Null Termination ...\par
      SQLAllocHandle(SQL_HANDLE_ENV,...) ...\par
      SQLAllocEnv ...\par
      SQLGetEnvAttr ...\par
      SQLSetEnvAttr ...\par
      SQLFreeHandle(SQL_HANDLE_ENV,...) ...\par
      SQLFreeEnv ...\par
\par
Chapter 42 -- SQL/CLI: dbc Functions ...\par
      SQLAllocHandle(SQL_HANDLE_DBC,...) ...\par
      SQLAllocConnect ...\par
      SQLConnect ...\par
      SQLDisconnect ...\par
      SQLGetConnectAttr ...\par
      SQLSetConnectAttr ...\par
      SQLFreeHandle(SQL_HANDLE_DBC,...) ...\par
      SQLFreeConnect ...\par
\par
Chapter 43 -- SQL/CLI: stmt Functions ...\par
      SQLAllocHandle(SQL_HANDLE_STMT,...) ...\par
      SQLAllocStmt ...\par
      SQLGetStmtAttr ...\par
      SQLSetStmtAttr ...\par
      SQLFreeHandle(SQL_HANDLE_STMT,...) ...\par
      SQLFreeStmt ...\par
\par
Chapter 44 -- SQL/CLI: Statement Functions ...\par
      Preparable SQL Statements ...\par
      SQLPrepare ...\par
      SQLExecute ...\par
      SQLExecDirect ...\par
      SQLEndTran ...\par
\par
Chapter 45 -- SQL/CLI Cursor Functions ...\par
      SQLFetch ...\par
      SQLFetchScroll ...\par
      SQLCloseCursor ...\par
      SQLGetCursorName ...\par
      SQLSetCursorName ...\par
      Embedded SQL versus CLI ...\par
      SQLMoreResults ...\par
\par
Chapter 46 -- SQL/CLI: desc Functions ...\par
      Descriptor Areas ...\par
      The desc Fields ...\par
      The desc Functions ...\par
\par
Chapter 47 -- SQL/CLI: Diagnostic Functions ...\par
      SQLGetDiagField ...\par
      SQLGetDiagRec ...\par
      SQLError ...\par
      SQLRowCount ...\par
      SQLSTATE Codes ...\par
\par
Chapter 48 -- SQL/CLI: General Functions ...\par
      SQLDataSources ...\par
      SQLGetFunctions ...\par
      SQLGetInfo ...\par
\par
Chapter 49 -- SQL/CLI: Deferred Parameter Functions ...\par
      How to Pass Deferred Parameters ...\par
      SQLParamData ...\par
      SQLPutData ...\par
      SQLCancel ...\par
\par
Chapter 50 -- SQL/CLI: Locator Functions ...\par
      What is a Locator? ...\par
      SQLGetLength ...\par
      SQLGetPosition ...\par
      SQLGetSubString ...\par
\par
Chapter 51 -- SQL/CLI: Catalog Functions ...\par
      Some Necessary Preliminaries ...\par
      SQLColumnPrivileges ...\par
      SQLColumns ...\par
      SQLForeignKeys ...\par
      SQLGetTypeInfo ...\par
      SQLParameters ...\par
      SQLPrimaryKeys ...\par
      SQLRoutinePrivileges ...\par
      SQLRoutines ...\par
      SQLSpecialColumns ...\par
      SQLTablePrivileges ...\par
      SQLTables ...\par
      The End ...\par
\par
Chapter 52 -- Module Binding Style ...\par
      SQL-client Modules ...\par
      MODULE Statement ...\par
      PROCEDURE Statement ...\par
\par
Chapter 53 -- Style ...\par
      Authority ...\par
      Layout Rules ...\par
      Naming Rules ...\par
      Examples of Statements in Formal Style ...\par
      Host Language Programs ...\par
      Summary ...\par
\par
Index ...\par
\par
Appendices on the CD-ROM\par
      Appendix A -- Remote Database Access ...\par
      Appendix B -- SQL Taxonomy ...\par
      Appendix C -- Non-portable SQL Features ...\par
      Appendix D -- Incompatibilities with SQL-92 ...\par
      Appendix E -- SQL Web Sites ...\par
      Appendix F -- Glossary ... \par
      Appendix G -- Errata ... \par
\par
\page\par
Preface\par
\par
If you've ever used a relational database product, chances are that you're\par
already familiar with SQL -- the internationally-accepted, standard\par
programming language for databases whic is supported by the vast majority of\par
relational database management system (DBMS) products available today. You may\par
also have noticed that, despite the large number of "reference" works that\par
claim to describe standard SQL, not a single one provides a complete, accurate\par
and example-filled description of the entire SQL Standard. This book was\par
written to fill that void.\par
\par
Who Should Read this Book?\par
\par
This book will be valuable to anyone who works with a DBMS that supports SQL.\par
While our emphasis is on programming with SQL, you do not need to be a\par
programmer to learn SQL from our examples. We do assume you know something\par
about Windows and something about C, but our main concern is that you are\par
interested in using "ANSI Standard SQL" in your projects. This is both a\par
beginner's and an advanced-user's book. Our hope is that a beginner will be\par
able to avoid the traditional "for beginners" books which, sadly, contain so much drivel\par
that it is impossible to advance from them without re-learning everything.\par
\par
Your Windows knowledge needn't be extensive, as we won't be getting into the\par
details of the Windows Application Programming Interface (API). We'll touch\par
only on things that occur in all versions of Windows, and occasionally\par
analogize with Windows concepts and terms.\par
\par
As for C, we assume you can read simple C programs, even if your favourite\par
programming language is something else. We want to show you examples of SQL\par
as it's used in programming projects -- that is, in company with a "host\par
language" -- and C seemed the convenient choice. All example programs shown\par
provided are short.\par
\par
What's In It?\par
\par
World's Longest SQL Poem (for obvious reasons)\par
\par
   All the snake-oil peddlers say, there's a fast and easy way,\par
   To get your SQL program up and running,\par
   But they're silent re the traps, that cause subtly buggy apps,\par
   For to catch the unaware a chasm's yawning!\par
\par
   Date-arithmetic exceptions, auto-rollbacked disconnections,\par
   Bit precisions, overflows, collate coercions,\par
   And how NULL affects your summing, for to keep your DB humming,\par
   You must know what happens in all vendors' versions!\par
\par
   Should this field be DOUBLE PRECISION?\par
   Will logic rules soon see revision?\par
   By the ANSI:Databases sub-committee?\par
   When you DROP should you CASCADE?\par
   How are NATURAL joins made?\par
   Re UNIQUE-keys matching check the nitty-gritty!\par
\par
   Yeah the true and standard facts, you'll avoid those later hacks\par
   That make Structured Query Language such a bore,\par
   You'll find tips and charts aplenty, in this one-thousand-and-twenty\par
   Four page volume (with an index), and yet more!\par
\par
                          Author anon (also for obvious reasons)\par
\par
This book describes the SQL syntax a DBMS must support to comply with the\par
International Organization for Standardization (ISO) document ISO/IEC\par
9075:1999 Database Language SQL, also adopted as the American National\par
Standards Institute (ANSI) document X3.135-1999 Database Language SQL --\par
familiarly known as SQL3, standard SQL or ANSI SQL. We will use the more\par
familiar terms "SQL" or "SQL3" to describe Standard-conforming SQL in this book,\par
rather than the formal term SQL-99.\par
\par
It's true that some features discussed in this book aren't in <fill in your\par
DBMS name here>. That's no reason to ignore them, because sooner or later they\par
will be there, due to pressure on serious vendors to adhere to the SQL\par
Standard.\par
\par
Why Read It?\par
\par
You need to know SQL so you've been looking for an accurate reference work\par
that describes the entire SQL Standard by way of examples. This is that book.\par
\par
How much of what you need to know is in this book? Well, it's impossible for a\par
single book to contain everything you need. We guarantee that the coverage is\par
complete for the SQL language itself, and is adequate for subjects that\par
closely relate to SQL. Let's express "what you will know" as a percentage of\par
"what you should know", with an assumption that you're an average person:\par
   ## SQL3 Standard "foundation"           90%\par
   ## Earlier ANSI and ISO Standards      100%\par
   ## SQL/CLI                             100%\par
   ## Embedded SQL and host languages      40%\par
   ## Object orientation (UDTs)            20%\par
   ## Relational database theory           10%\par
   ## Design                               10%\par
   ## Quirks of specific vendors' dialects  5%\par
"Complete" does not mean that everything which could be said about SQL\par
will be said here. SQL is big. More exactly, it means that we will\par
never refer you to further published material saying "the details are in the\par
official standard document" or "further discussion is outside the scope of\par
this book".\par
\par
Further Information\par
\par
When you look at our Table of Contents, you'll see that this book\par
includes several Appendices, but only on the accompanying CD-ROM,\par
to keep the book from becoming too unwieldy. Of the Appendix files,\par
we especially recommend Appendix F, the Glossary. It provides\par
definitions for all the SQL technical terms we use.\par
\par
\page\par
Chapter 1 -- Introduction\par
\par
SQL-99 (more commonly still called, "SQL3", the term we'll use\par
throughout this book) will soon be the current internationally accepted standard\par
for the database programming language called SQL. The SQL\par
Standard -- a complicated monster consisting of over 2,100 pages of\par
definitions, syntax and usage rules -- describes the required\par
syntax and the rules that must be followed to generate the\par
required result when the syntax is executed by a Standard-conforming\par
DBMS. (This compares to less than 150 pages required to describe\par
the Standard's earlier version, SQL-89.)\par
\par
This book was written to describe Standard-conforming SQL.\par
\par
How To Read This Book\par
\par
In this book, we've used the same descriptive terminology you'd\par
find in the SQL Standard. You can check the meaning of unfamiliar\par
terms in the glossary on the CD-ROM. To make it easier for you to\par
follow our discussion, we use these notation conventions throughout:\par
     ## Words with special meaning in SQL are shown capitalized, e.g., Table.\par
     ## Words within angle brackets have specific definitions in\par
SQL. See the appropriate syntax diagram for that definition.\par
     ## Direct SQL requires all SQL statements to be terminated\par
with a semicolon. This book does not include the terminator in\par
SQL syntax diagrams, but does include it in SQL statement examples.\par
\par
Everything we describe is as mandated by the SQL\par
Standard explicitly, unless the discussion starts with the notation: [OCELOT\par
Implementation]. We use this notation to describe the\par
conventions followed by THE OCELOT DBMS; the DBMS you'll\par
find on the CD-ROM that comes with the book. Despite this,\par
everything described as an [OCELOT Implementation] is legitimate\par
SQL; it does not contradict the SQL mandate. Rather, it describes\par
OCELOT's SQL implementation for the many areas where the SQL\par
Standard specifies the matter is "implementation-defined" or\par
"implementation-dependent". These are areas to note: because there is\par
no Standard-specified definition; requirements and responses will\par
vary from one DBMS to another. Discussion of these areas starts\par
with the notation: [NON-PORTABLE].\par
\par
You may initially skip over paragraphs which begin with the\par
notation: [Obscure Rule]. They describe details which will\par
probably be unclear on first reading and which are normally not\par
utilized in typical installations.\par
\par
How to Read SQL Syntax\par
\par
We have used the following common variant of BNF notation\par
for the SQL syntax diagrams in this book:\par
     ## < >\par
Angle brackets surround the names of syntactic elements. The\par
brackets are not part of the syntax; do not include them in your\par
SQL statement.\par
     ## ::=\par
The definition operator separates the syntactic element being\par
defined from its definition. Read the definition from left to right.\par
     ## [ ]\par
Square brackets surround optional syntax. You may choose whether\par
or not to omit such syntax when forming an SQL\par
statement. The brackets are not part of the syntax; do not include\par
them in your SQL statement.\par
     ## \{ \}\par
Braces surround mandatory syntax groupings. You must include the\par
entire grouping when forming an SQL statement. The braces are not\par
part of the syntax; do not include them in your SQL statement.\par
     ## |\par
The vertical bar separates groups of syntactic elements.\par
You must choose one of the elements when forming an SQL\par
statement. The vertical bar is not part of the syntax; do not\par
include it in your SQL statement.\par
     ## ...\par
An ellipsis following a syntactic element indicates that the\par
syntax is repeatable. You may include the element as often as you\par
wish when forming an SQL statement. The ellipsis is not part of\par
the syntax; do not include it in your SQL statement.\par
     ##\par
Blank spaces (whether single or multiple spaces and/or line breaks)\par
separate syntactic elements.\par
\par
All other characters in a definition stand for themselves.\par
\par
We also follow these notation conventions:\par
     ## Words written in uppercase letters are SQL <keyword>s.\par
You must write them exactly as shown when forming an SQL\par
statement, except that you have the choice of writing them in\par
either uppercase or lowercase letters.\par
     ## Words written in lowercase letters represent syntactic\par
categories. You must replace them with actual <identifier>s or\par
<literal>s when forming an SQL statement.\par
     ## Parentheses that appear in a syntax diagram are\par
part of the syntax. You must include them when forming an SQL statement.\par
\par
Thus, as in the following simplified example of an SQL syntax diagram:\par
\par
   CREATE TABLE <Table name> (\par
     <Column name> \{INTEGER | CHARACTER(5)\} )\par
\par
     ## The words CREATE and TABLE are SQL <keyword>s and\par
must be included, without changes, in a CREATE TABLE statement.\par
     ## The words <Table name> and <Column name> are\par
syntactic categories and must be replaced with an actual <Table\par
name> and <Column name>, respectively, in a CREATE TABLE\par
statement. The angle brackets around "Table name" and "Column\par
name" indicate that these terms are defined with a syntax diagram\par
somewhere in this book.\par
     ## The parentheses are part of the syntax and must be\par
included, exactly where shown, in a CREATE TABLE statement.\par
     ## The braces and vertical bar after the <Column\par
name> indicate that either one of the SQL <keyword>s "INTEGER" or\par
"CHARACTER(5)" must be included, without changes, in a CREATE TABLE statement.\par
\par
Based on this example, the following two SQL statements are the only\par
valid uses of the syntax:\par
\par
   CREATE TABLE A_Table_Name (\par
     a_column_name INTEGER);\par
\par
   CREATE TABLE A_Table_Name (\par
     a_column_name CHARACTER(5));\par
\par
What is SQL?\par
\par
SQL (originally: Structured Query Language) is an internationally-\par
recognized programming language for defining and maintaining\par
relational databases.\par
\par
Initially developed by IBM in the late 1970's, SQL caught on in\par
the database world as vendors, realizing the many advantages of\par
the relational approach to database management, began to develop\par
commercial products based on those principles. Because SQL was the\par
language most commonly supported by the new products, it soon\par
became the de facto standard for relational database products.\par
\par
The popularity of SQL further increased when the language\par
became an official standard in October of 1986, with ANSI's\par
(the American National Standards Institute) release of ANSI\par
document X3.135-1986 "Database Language - SQL". This first SQL\par
Standard, SQL-86, became internationally accepted in 1987, when\par
the International Organization for Standardization (ISO) -- a\par
worldwide federation of national standards bodies -- adopted the\par
ANSI document as well.\par
\par
SQL-86 was updated and enhanced in 1989. ANSI X3.168-1989\par
"Database Language - Embedded SQL" became official in April of\par
1989. ANSI X3.135-1989 "Database Language - SQL with Integrity\par
Enhancement" followed in October of 1989 and SQL-89 became the\par
new standard for DBMSs to follow. Then, in August of 1992,\par
another update, SQL-92, was released jointly by ISO and ANSI as\par
ISO/IEC 9075:1992 "Database Language SQL". (Soon after, SQL-92\par
was adopted as a [United States] Federal Information Processing\par
Standard. FIPS PUB 127-2, Database Language SQL also helpfully\par
specified what the US government required for some of the\par
features the SQL-92 Standard said were to be\par
"implementation-defined".) This will be followed by the next\par
version of the Standard, SQL3, expected to be released in early\par
1999 as ISO/IEC 9075:1999 "Information Technology - Database\par
Languages - SQL".\par
\par
This brings us to current times and the writing of this book.\par
\par
SQL Conformance\par
\par
The complete SQL Standard consists of five interrelated\par
documents. Additional parts, five in number so far,\par
describing related features will be added sometime in the future.\par
This book describes only the first five parts, Standard SQL3,\par
which consists of these documents.\par
\par
Part 1: SQL/Framework (ISO/IEC 9075-1, approximately 100\par
pages) defines the fundamental concepts on which SQL is\par
based, as well as specifying the general requirements for SQL\par
conformance. All parts of the Standard are dependent on\par
SQL/Framework.\par
\par
Part 2: SQL/Foundation (ISO/IEC 9075-2, approximately\par
1,050 pages) defines the fundamental syntax and operations of\par
SQL. All parts of the Standard, except for SQL/Framework, are\par
dependent on SQL/Foundation.\par
\par
Part 3: SQL/Call-Level Interface, or CLI (ISO/IEC 9075-3,\par
approximately 514 pages), defines an application programming\par
interface to SQL. No part of the Standard is dependent on\par
SQL/CLI.\par
\par
Part 4: SQL/Persistent Stored Modules, or PSM (ISO/IEC\par
9075-4, approximately 193 pages) defines both the control\par
structures that define SQL Routines and the Modules that may\par
contain SQL Routines. No part of the Standard is dependent on\par
SQL/PSM.\par
\par
Part 5: SQL/Host Language Bindings (ISO/IEC 9075-5,\par
approximately 270 pages) defines methods for embedding SQL\par
statements in application programs written in a standard\par
programming language. No part of the Standard is dependent on\par
SQL/Bindings.\par
\par
Minimal Conformance\par
The SQL3 Standard identifies two levels of SQL conformance which\par
a DBMS may claim: Core SQL support and enhanced SQL support.\par
(Conformance levels for SQL applications are also given; we\par
ignore these in this book.) In order to claim conformance with\par
the SQL Standard, a DBMS must support all of the following:\par
\par
     1. All features defined in SQL/Framework, including an SQL\par
Object Identifier that states the level of conformance being\par
claimed as well as all Core SQL features defined in\par
SQL/Foundation -- see Appendix B "SQL Taxonomy" for these\par
requirements. A Core SQL DBMS does not have to support any of\par
the features defined in the other parts of the Standard.\par
\par
     2. At least one of the following two binding styles:\par
          ## The SQL-client Module binding style (defined in\par
SQL/Foundation) for at least one host language.\par
          ## The Embedded SQL binding style (defined in\par
SQL/Bindings) for at least one host language.\par
\par
In order to claim conformance, a DBMS must state whether or not\par
the SQL-client Module binding style is supported and, if so,\par
which of the host languages (Ada, C, COBOL, Fortran, MUMPS,\par
Pascal, and PL/I) are supported. If applicable, the DBMS must also\par
state which of these <keyword>s (ADA, C, COBOL, FORTRAN, MUMPS,\par
PASCAL, PLI and SQL) may be specified for the LANGUAGE clause\par
in an <external body reference>. A DBMS which supports MUMPS goes\par
beyond Core SQL conformance.\par
\par
<SQL Object Identifier>\par
[Obscure Rule] applies for this section.\par
\par
The SQL Object Identifier identifies the characteristics of an\par
SQL DBMS to other entities in an open systems environment. (The\par
same information is available to SQL-data users in the\par
INFORMATION_SCHEMA.SQL_LANGUAGES View.) Listing 1.1 shows\par
the required syntax for the SQL Object Identifier.\par
\par
Listing 1.1 Required Syntax for the SQL Object Identifier\par
\par
<SQL Object Identifier> ::= <SQL provenance> <SQL variant>\par
\par
     <SQL provenance> ::= <arc1> <arc2> <arc3>\par
\par
          <arc1> ::= iso | 1 | iso(1)\par
\par
          <arc2> ::= standard | 0 | standard(0)\par
\par
          <arc3> ::= 9075\par
\par
     <SQL variant> ::= <SQL edition> <SQL conformance>\par
\par
          <SQL edition> ::= <1987> | <1989> | <1992> | <199x>\par
\par
               <1987> ::= 0 | edition1987(0)\par
\par
               <1989> ::= <1989 base> <1989 package>\par
\par
                    <1989 base> ::= 1 | edition1989(1)\par
\par
                    <1989 package> ::= <integrity no> | <integrity yes>\par
\par
                         <integrity no> ::= 0 | IntegrityNo(0)\par
\par
                         <integrity yes> ::= 1 | IntegrityYes(1)\par
\par
                    <1992> ::= 2 | edition1992(2)\par
\par
                    <199x> ::= 3 | edition199x(3)\par
\par
          <SQL conformance> ::= <level> | <parts>\par
\par
               <level> ::= <low> | <intermediate> | <high>\par
\par
                    <low> ::= 0 | Low(0)\par
\par
                    <intermediate> ::= 1 | Intermediate(1)\par
\par
                    <high> ::= 2 | High(2)\par
\par
               <parts> ::= <Part 3> <Part 4> <Part 5> <Part 6> <Part 7> <Part 8> <Part 9> <Part 10>\par
\par
                    <Part n> ::= <Part n no> | <Part n yes>\par
\par
                         <Part n no> ::= 0 | Part-nNo(0)\par
\par
                         <Part n yes> ::= !! per ISO/IEC 9075-n\par
\par
The SQL Object Identifier's <SQL provenance> identifies the\par
Standards document that governs the DBMS's SQL conformance, i.e.,\par
"iso standard 9075". The <SQL variant> identifies the version of\par
the SQL Standard that is supported.\par
\par
The SQL Object Identifier's <SQL conformance> identifies the\par
conformance level being claimed for that version of the Standard.\par
There are four options.\par
     1. If <SQL edition> is <1992>, the version of the Standard\par
supported is SQL-92 and the Object Identifier must state which\par
<level> of <SQL conformance> is claimed. A <level> of <low> means\par
Entry SQL is supported, a <level> of <intermediate> means\par
Intermediate SQL is supported, and a <level> of <high> means Full\par
SQL is supported. A DBMS may claim a <high> <SQL conformance>\par
only if SQL-92 is supported.\par
     2. If <SQL edition> is <1987>, the version of the Standard\par
supported is SQL-86. If <SQL edition> is <1989>, the version of\par
the Standard supported is SQL-89. In both of these cases, the Object\par
Identifier must state which <level> of <SQL conformance> is\par
claimed. A <level> of <low> means Level 1 SQL is supported and a\par
<level> of <intermediate> means Level 2 SQL is supported.\par
     3. If <SQL edition> is <1989>, an additional conformance claim must be made.\par
A <1989 package> value of <integrity yes> means that the features\par
defined in ANSI X3.135-1989 "Database Language - SQL with\par
Integrity Enhancement" are supported by the DBMS. A <1989\par
package> value of <integrity no> means that the integrity\par
enhancement features are not supported.\par
    4. If <SQL edition> is <199x>, the version of the Standard\par
supported is SQL3, with Core SQL conformance claimed. In this\par
case, the Object Identifier must also state the DBMS's <SQL\par
conformance> for each <part> of the Standard. A <Part n yes>\par
value for any part means that the DBMS fully supports that part\par
of the Standard. A <Part n no> value means that part of the\par
Standard is not fully supported.\par
\par
Enhanced Conformance\par
In order to claim enhanced conformance with the SQL Standard, a\par
DBMS must also (a) fully support one or more of parts 3 and up of\par
the Standard and/or one or more additional "packages" of SQL\par
features (identified below by their "Feature ID" values from\par
Appendix B, "SQL Taxonomy") and (b) provide an SQL Flagger.\par
\par
[Obscure Rule] applies for the rest of this section.\par
\par
SQL Packages\par
The SQL Standard specifies seven SQL packages which may be\par
supported by a DBMS claiming enhanced SQL conformance. They are\par
as follows:\par
\par
     1. Enhanced datetime facilities package --\par
To claim conformance with the "enhanced datetime facilities"\par
SQL package, a DBMS must also support:\par
          ## Feature ID F052 Interval data type.\par
          ## Feature ID F411 Time zone specification.\par
          ## Feature ID F551 Full datetime.\par
          ## Feature ID T161 Optional interval qualifier.\par
\par
     2. Enhanced integrity management package --\par
To claim conformance with the "enhanced integrity management" SQL\par
package, a DBMS must also support:\par
          ## Feature ID F521 Assertions.\par
          ## Feature ID E142 Referential delete actions.\par
          ## Feature ID F701 Referential update actions.\par
          ## Feature ID F491 Constraint management.\par
          ## Feature ID F671 Subqueries in CHECK constraints.\par
          ## Feature ID T211 Triggers.\par
          ## Feature ID T212 FOR EACH STATEMENT triggers.\par
          ## Feature ID T191 Referential action RESTRICT.\par
\par
     3. OLAP facilities package --\par
To claim conformance with the "OLAP facilities" SQL package, a\par
DBMS must also support:\par
          ## Feature ID T431 CUBE and ROLLUP.\par
          ## Feature ID F302 INTERSECT table operator.\par
          ## Feature ID F641 Row and table constructors.\par
          ## Feature ID F401 FULL OUTER JOIN.\par
          ## Feature ID F471 Scalar subquery values.\par
\par
     4. PSM package --\par
To claim conformance with the "PSM" SQL package, a DBMS must also\par
support:\par
          ## Feature ID P01 Stored Modules (<SQL-server Module definition>).\par
          ## Feature ID P02 Computational completeness.\par
          ## Feature ID P03 INFORMATION_SCHEMA views.\par
\par
     5. CLI package --\par
To claim conformance with the "CLI" SQL package, a DBMS must also\par
support:\par
          ## Feature ID C01 SQL/CLI.\par
\par
     6. Basic object support package --\par
To claim conformance with the "basic object support" SQL package,\par
a DBMS must also support:\par
          ## Feature ID T322 Overloading of SQL-invoked functions and SQL-invoked procedures.\par
          ## Feature ID O021 Basic user-defined types, including single inheritance.\par
          ## Feature ID O041 Reference types.\par
          ## Feature ID O051 CREATE TABLE of type.\par
          ## Feature ID O091 Basic array support.\par
          ## Feature ID O092 Arrays of UDTs.\par
          ## Feature ID O094 Arrays of reference types.\par
          ## Feature ID O121 Dereference operation.\par
          ## Feature ID O131 Reference operation.\par
          ## Feature ID O141 Attribute and field reference.\par
          ## Feature ID O171 Array expressions.\par
          ## Feature ID O191 Basic SQL routines on user-defined types, including dynamic dispatch.\par
          ## Feature ID O201 SQL routine on arrays.\par
          ## Feature ID O232 Array locators.\par
\par
     7. Enhanced object support package --\par
To claim conformance with the "enhanced object support" SQL\par
package, a DBMS must also support:\par
          ## Feature ID O022 Enhanced user-defined types, including constructor option, attribute defaults, multiple inheritance and ordering clause.\par
          ## Feature ID O061 ALTER TABLE, ADD named row type.\par
          ## Feature ID O071 SQL-paths in function and type name resolution.\par
          ## Feature ID O081 Subtables.\par
          ## Feature ID O111 ONLY in query expressions (to restrict subtable search).\par
          ## Feature ID O151 Type predicate.\par
          ## Feature ID O161 <subtype treatment>.\par
          ## Feature ID O192 SQL routines on user-defined types, including identity functions and generalized expressions.\par
          ## Feature ID O211 User-defined cast functions.\par
          ## Feature ID O231 UDT locators.\par
\par
SQL Flagger\par
An SQL Flagger is a facility that identifies SQL language\par
extensions or processing alternatives. It must be provided by a\par
DBMS claiming enhanced SQL conformance. The Flagger's purpose is\par
to help you produce portable SQL code. This is necessary\par
because the SQL Standard allows conforming DBMSs to provide\par
options for processing operations that the Standard doesn't\par
address (e.g., a CREATE INDEX statement). It also allows DBMSs to\par
provide options for processing Standard-defined SQL in a\par
non-conforming manner, provided that the non-conforming results\par
are returned only when you explicitly request them. Your DBMS's\par
Flagger must identify all the non-standard syntax, features and\par
options supported, but it only has to do a static check of SQL\par
syntax; the Standard doesn't require a Flagger to detect\par
extensions that cannot be determined until runtime.\par
\par
An SQL Flagger has to provide one or more of these "level of\par
flagging" options to identify SQL language that violates a given subset of SQL:\par
     ## Core SQL Flagging -- flags non-conforming Core SQL features.\par
     ## Part SQL Flagging -- flags non-conforming enhanced SQL features.\par
     ## Package SQL Flagging -- flags non-conforming package SQL features.\par
\par
A flagger also has to provide one or more of these "extent of checking" options:\par
     ## Syntax Only -- only the SQL language presented is\par
analyzed; the Flagger checks for syntax violations without\par
accessing INFORMATION_SCHEMA so it doesn't necessarily detect\par
violations that depend on the <data type> of syntactic elements.\par
     ## Catalog Lookup -- the SQL language and the metadata is\par
analyzed; the Flagger checks for both syntax and access violations (except\par
for access violations that deal with Privileges).\par
\par
Summary\par
In order to claim conformance with the SQL Standard, a DBMS must state four things:\par
     1. Level of conformance supported for a given version of the Standard.\par
     2. Binding style(s) supported.\par
     3. Host language(s) supported.\par
     4. The DBMS's definitions are for all "elements and\par
actions" the Standard specifies are implementation-defined.\par
(Decisions made for the Standard's implementation-dependent\par
features don't have to be documented.)\par
\par
SQL Statement Classes\par
\par
The SQL Standard groups the Core SQL statements into seven classes,\par
according to their function. These classes are as follows:\par
     1. SQL-Schema statements -- create, alter, and drop\par
Schemas and Schema Objects, so they may have a persistent effect\par
on Schemas. The SQL-Schema statements are: CREATE SCHEMA, DROP\par
SCHEMA, CREATE DOMAIN, ALTER DOMAIN, DROP DOMAIN, CREATE TABLE,\par
ALTER TABLE, DROP TABLE, CREATE VIEW, DROP VIEW, CREATE\par
ASSERTION, DROP ASSERTION, CREATE CHARACTER SET, DROP CHARACTER\par
SET, CREATE COLLATION, DROP COLLATION, CREATE TRANSLATION, DROP\par
TRANSLATION, CREATE TRIGGER, DROP TRIGGER, CREATE TYPE, DROP\par
TYPE, CREATE ORDERING, DROP ORDERING, CREATE TRANSFORM, DROP\par
TRANSFORM, CREATE PROCEDURE, CREATE FUNCTION, CREATE METHOD, DROP\par
SPECIFIC ROUTINE, DROP SPECIFIC FUNCTION, DROP SPECIFIC\par
PROCEDURE, CREATE ROLE, GRANT, REVOKE and DROP ROLE.\par
     2. SQL-data statements -- perform queries, insert, update,\par
and delete operations, so they may have a persistent effect on\par
SQL-data. The SQL-data statements are: DECLARE TABLE, DECLARE\par
CURSOR, OPEN, CLOSE, FETCH, SELECT, FREE LOCATOR, HOLD LOCATOR\par
and the SQL-data change statements INSERT, UPDATE and DELETE.\par
     3. SQL-transaction statements -- set parameters for\par
transactions, as well as starting and ending transactions, so\par
(except for the COMMIT statement) they have no effect that lasts\par
after the SQL-session ends. The SQL-transaction statements are:\par
START TRANSACTION, SET TRANSACTION, SET CONSTRAINTS, COMMIT,\par
ROLLBACK, SAVEPOINT and RELEASE SAVEPOINT.\par
     4. SQL-control statements -- control the execution of a\par
set of SQL statements and have no effect that lasts after the\par
SQL-session ends. The SQL-control statements are: CALL and RETURN.\par
     5. SQL-Connection statements -- start and end\par
Connections, and allow an SQL-client to switch from a session\par
with one SQL-server to a session with another, so they have no\par
effect that lasts after the SQL-session ends. The SQL-Connection\par
statements are: CONNECT, SET CONNECTION and DISCONNECT.\par
     6. SQL-session statements -- set certain default values\par
and other parameters for an SQL-session, so they have no effect\par
that lasts after the SQL-session ends. The SQL-session statements\par
are: SET TIME ZONE, SET ROLE, SET SESSION AUTHORIZATION and SET\par
SESSION CHARACTERISTICS.\par
     7. SQL-diagnostics statements -- get diagnostics from the\par
diagnostics area and signal exceptions in SQL routines, so they\par
have no effect that lasts after the SQL-session ends. The\par
SQL-diagnostics statement is: GET DIAGNOSTICS.\par
\par
Transaction-initiating SQL Statements\par
If there is no current transaction, these SQL statements will\par
begin one: (a) any SQL-Schema statement, (b) the SQL-transaction\par
statements COMMIT and ROLLBACK (if they specify AND CHAIN), (c)\par
the SQL-data statements OPEN, CLOSE, FETCH, SELECT, INSERT,\par
UPDATE, DELETE, FREE LOCATOR and HOLD LOCATOR or (d) START\par
TRANSACTION. The SQL-control statement RETURN will also begin a\par
transaction if it causes the evaluation of a <subquery> when\par
there is no current transaction. No other SQL statement will\par
begin a transaction.\par
\par
Which SQL statements Can You Use?\par
Even if it conforms to the SQL Standard, your DBMS may not\par
support all of the SQL statements described in this book because\par
different SQL statements may be prepared and executed in\par
different ways. Thus, the set of SQL statements supported by a\par
DBMS depends on the binding style it supports. The options are\par
as follows.\par
     ## SQL Module Language binding style -- where both static and\par
dynamic SQL statements are prepared when the Module is created\par
and executed when the procedure that contains them is called.\par
     ## Embedded SQL Syntax binding style -- where both static and\par
dynamic SQL statements are prepared when the host language\par
program is precompiled and executed when the host language program is run.\par
     ## Direct SQL Invocation binding style -- where static SQL\par
statements are effectively prepared immediately prior to execution.\par
\par
SQL Rule Evaluation Order\par
\par
The precedence of operators in an SQL statement is sometimes\par
specified explicitly by the SQL Standard. Where this is the case,\par
you'll find a note to that effect in our description of the\par
operator in question. It is also possible to force a specific\par
expression evaluation order by using parentheses in your SQL\par
statements. Where the precedence of an SQL statement's operators\par
is pre-determined (either by the Standard or by parentheses),\par
those operators are effectively performed in the order specified\par
by that precedence.\par
\par
Often, the Standard is silent on the subject of\par
precedence. In cases where\par
the precedence of operators in an SQL statement is not\par
specifically determined either by the rules stated in the\par
Standard, or by parentheses within the SQL statement, evaluation\par
of expressions is effectively performed from left to right.\par
\page\par
Chapter 2 -- General Concepts\par
\par
A database system can be described as essentially nothing more than a\par
computerized record-keeping system. A database, then, is simply a\par
collection of structured data files and any associated indexes.\par
The user of such a system must be able to add, insert, retrieve, update,\par
and delete data and files as necessary. Although the SQL Standard doesn't \par
actually define the nebulous concept "database", SQL provides all of these\par
functions and more.\par
\par
In this chapter, we'll briefly discuss SQL's fundamental concepts\par
-- how the language fits into its overall environment, the data\par
Objects you can expect to work with, and how SQL-data and SQL\par
statements are structured. Then, in subsequent chapters, we'll\par
revisit each of these areas in greater detail.\par
\par
Set Theory\par
\par
   Georg Cantor was a German.\par
   He invented Set Theory.\par
   He was committed to a mental institution.\par
   He died in 1918.\par
\par
We can explain the preceding statements using Georg Cantor's own\par
theory: a set is any collection of definite distinguishable\par
things. We can conceive of the set as a whole, and in fact we\par
often do: for example, we speak of "the Germans" (a set) and can\par
rephrase our first statement as "Georg Cantor was a member (or\par
element) of the set of Germans". By rephrasing, we emphasize the\par
collection of individual things over the individual things\par
themselves. That much is intuitive. But Cantor was careful in his\par
choice of words. By "distinguishable" (or distinct), he meant that\par
in looking at any two things which fit in the set, we must be able\par
to decide whether they are different. By "definite", he meant that if\par
we know what the set is and we know what the thing is, we can\par
decide whether the thing is a member of the set. Therefore, to\par
know what a set "is", it is sufficient to know what the members are.\par
\par
Here are a few examples. The "Germans" set also included Kaiser\par
Wilhelm. However, it can be proved from historical records that\par
Cantor was not a pseudonym or alias that the Kaiser used while\par
off duty -- therefore, the two members are distinguishable. At the\par
same time, we know that there were several million other Germans,\par
also distinguishable, and we could define the set by taking a\par
census of all the Germans. There might be some difficulty\par
deciding the individual question "What is a German?", but once\par
that was done there would be no difficulty deciding the\par
collective question "What are the Germans?". Therefore, the\par
members define the set, i.e., the members are definite. \par
\par
The census we spoke of is possible because the Germans were a\par
finite set (a fact which would have bored Cantor because he\par
developed his theory to explain various gradations of infinity).\par
We could enumerate the set thus:\par
   \{Georg Cantor, Kaiser Wilhelm, ...\}\par
\par
In this enumeration, we used braces to indicate "we are\par
enumerating a set" and an ellipsis to indicate "and so on" --\par
that is, the list could go on but we felt it unnecessary to\par
continue for the sake of our exposition. These are standard\par
conventions and we will use braces and ellipses again.\par
\par
Enumeration is unwieldy for large sets, so let us revisit the\par
question "What is a German?" by taking the bounds stated in the\par
song "Deutschland Ueber Alles" -- a German is a person living\par
between the Maas, the Memel, the Esch and the Belt (four bodies\par
of water which now lie respectively in Holland, Russia, Austria,\par
and Denmark). In Cantor's terms, that formula expresses a\par
defining property. It is either true or it is false. If it is\par
true, the person is in the set. If it is false, the person is outside the set.\par
\par
Without stating the defining property in advance, the German\par
census-takers would be unable to put together their forms and\par
plan their information collection. The objective, though, is to\par
produce an enumeration of all Germans. In computer terminology, we\par
call the definition the database design and the enumeration the \par
database itself. The "Germans" set can be broken up into several\par
subsets such as:\par
   \{Berliners, Frankfurters, Hamburgers, ...\}\par
\par
These subsets are also sets, with defining properties (city of\par
residence), and presumably, with members -- but that is not\par
necessary. For example, the set of Germans who live in the Rhine\par
River is an empty set, i.e., it has no members, but it is still a\par
set. The implicit breaking-up that happens when we ask "Among the\par
Germans which ones are Frankfurters?" is an example of a set\par
operation. A set operation is something we do with sets that\par
results in the production of more sets.\par
\par
Relations\par
First, let's consider first a binary relation -- that is, a relation\par
between two things. The things don't have to be of the same type;\par
all we are concerned with is that they have some type of bond,\par
and that they be in order. Getting back to our hero ... there is a\par
relationship between Georg Cantor and the concept Set Theory (he\par
invented it). There is also a relationship between Kaiser Wilhelm\par
and World War I (he started it). We could use our braces notation\par
to enumerate this:\par
   \{ (Georg Cantor, Set Theory), \{Kaiser Wilhelm, World War I) \}\par
but it looks clearer when diagrammed as a two-dimensional Table:\par
\par
NAME            ACTIVITY\par
Georg Cantor    Set Theory\par
Kaiser Wilhelm  World War I\par
\par
There are some points to note about this diagram.\par
   1. The Table shows ordered pairs -- we couldn't reverse\par
them because Set Theory didn't invent Georg Cantor and World War\par
I didn't cause Kaiser Wilhelm -- the relationship between the\par
"NAME" and "ACTIVITY" values is directional. Note, however, that\par
the word "ordered" refers only to the horizontal order in the\par
illustration -- across the relation. We don't care which member\par
of the set is listed first.\par
   2. The Table shows binary pairs -- there is no space\par
on the line for marking Georg Cantor's other achievements. Under\par
"What did he do?" we can only express one thing.\par
So: ordered means ordered, and pair means pair.\par
\par
So what, precisely, is the "relation" here? Well, it's the whole\par
thing. The relationship is the set of all the ordered pairs, and\par
the ordering itself (i.e., how part A relates to part B). What we\par
have in the preceding diagram is a picture of a relation and nothing\par
but a relation.\par
\par
This relation is a set. It has members. The members define the\par
set. However, the members are no longer "elements", but ordered\par
pairs. There's no reason to limit ourselves to ordered pairs,\par
though. That's just the simplest relation, the binary relation,\par
which is sometimes called "a relation of degree 2" (because there\par
are two columns). We could have relations of degree 3, degree 4,\par
degree 5, degree 6, degree 7, and so on, i.e., relations which are not\par
binary but triple, quadruple, pentuple, sextuple, septuple ...\par
Did you notice how after a while all the words ended in\par
"-tuple"? That's why the general term for a relation with n\par
elements is n-tuple. Here is a relation of degree 4 showing all\par
the information we have so far:\par
\par
NAME            ACTIVITY     RESIDENCE           DATE_OF_DEATH\par
Georg Cantor    Set Theory   Mental Institution  1918\par
Kaiser Wilhelm  World War I  Imperial Palace     ????\par
...\par
\par
Some differences now appear between the words Cantor used ("set\par
theory terminology") and the words we use ("database\par
terminology"). The line:\par
   \{Georg Cantor, Set Theory,Mental Institution,1918\}\par
would be one tuple to Cantor, but in SQL, we prefer the word row.\par
\par
Or, to be precise: the row value is the four-element:\par
   \{Georg Cantor,Set Theory,Mental Institution,1918)\par
and the row is the box that holds that information. (We don't\par
usually need to be so precise in ordinary discussion.) Meanwhile,\par
going down rather than across, Cantor would say that we have four\par
attributes, labelled NAME, ACTIVITY, RESIDENCE and\par
DATE_OF_DEATH. But in SQL, we prefer the word column instead\par
and we call each element going down (such as 'Georg Cantor' or\par
'Kaiser Wilhelm') a column value.\par
\par
Here's a quick summary. Moving across the relation are tuples\par
(but don't use that word) or rows. Moving up-and-down the relation\par
are attributes (but don't use that word) or columns. The\par
contents of a row is a row value. The intersection of a row and a\par
column is a column value. The column value is "atomic" -- it has\par
only one element. There is always exactly one column value in\par
each atomic box that's formed by the intersection of a row with a column.\par
\par
Incidentally, in the diagram we used an ellipsis once more, to\par
mean "and so on" -- there are more Germans in the set. We also used\par
the symbol "????" for the column value of "When did he die?" for\par
Kaiser Wilhelm. This is not a standard symbol -- there is no\par
standard way of expressing the fact that not only do we not know\par
when Kaiser Wilhelm died (i.e., "value is Unknown"), but we're not\par
even sure that he's dead (i.e., "category is Not Applicable").\par
This is not a problem for Set Theory, but it is a problem in\par
practice and we'll return to it later. When we do, we'll call the\par
"????" a NULL, or null value.\par
\par
And there we have it. A relation is an ordered n-tuple set, with\par
all members having the same degree, which is representable as a\par
table of rows and columns. It really does seem appropriate that\par
we should know what a relation is, because (we trust the following\par
is not an unpleasant surprise) SQL is a relational database\par
management system, and that means the database is made of\par
relations. To quote the Kellogg's Rice Krispies (tm) commercial,\par
"What the heck did you think they were made of?"\par
\par
Admittedly, when anything looks that obvious, it must be a lie.\par
And it is. Relational databases are actually made of tables,\par
rather than relations. What's the difference? Well, with a table\par
we can have two Georg Cantors. This clearly breaks Cantor's\par
"distinguishable" rule, and it's quite a big break; we all know\par
that the famous "Set Of Integers"  doesn't go\par
   \{1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,...\}\par
\par
By definition, a set has no duplicates. A relation is a set, so a\par
relation has no duplicates. But a table can have duplicates. This\par
is a concession to practicalities, since we know that duplicate\par
data happens in the "real world". However, if our database\par
contains two Georg Cantors who really are the same person, then\par
we have an error -- while if it contains two Georg Cantors whom\par
we can't distinguish from one another, then we have a design\par
flaw. The long and the short of it all is: (a) a relational\par
database consists of tables, (b) a table is not a relation, but\par
the only difference between them is that a table may have rows\par
with duplicate row values, (c) you should get rid of duplicates\par
regardless, therefore (d) therefore all relational databases should\par
consist of relations. (By the way, a table is sometimes called a\par
"multiset" to distinguish it from a regular set. You'll see the\par
word multiset in some Microsoft publications.)\par
\par
Set Operations\par
Since SQL operates on sets, there must be such things as "set\par
operations" that SQL can perform. In fact, SQL borrows all the\par
standard operations from Set Theory textbooks, along with the\par
terminology. Mercifully, it does not also borrow the notation. So\par
to describe the set operations in this book, we've been able to\par
use some English-looking terms which, in fact, have fairly precise\par
meanings in Set Theory, and some English-looking terms which, in\par
fact, are SQL words for our notation. In the following quick\par
introduction, we will describe a sequence of set\par
operations. A sequence, also known as a series, is an ordered\par
set. The order that we'll follow is the order of execution of the\par
clauses of the most famous of SQL statement types: the query, or \par
SELECT statement.\par
\par
IDENTITY\par
The easiest operation is take a copy of the table we started with:\par
\par
NAME            ACTIVITY\par
Georg Cantor    Set Theory\par
Kaiser Wilhelm  World War I\par
\par
The SQL for this is:\par
\par
   ... FROM Germans ...\par
\par
Because this is the first time we've said something "in SQL", we'll\par
regard it as our equivalent of the famous "hello world" -- so,\par
some introductions are in order. We've used the ellipsis before.\par
As usual, it means "and so on", so you can see that there's some\par
stuff both before and after "... FROM Germans ..." that we're not\par
going to spell out just here. We need the ellipsis to indicate\par
that we're not illustrating a whole statement, merely one clause,\par
called the FROM clause. The word FROM is an SQL keyword and the\par
word Germans is an SQL Table name. So: the FROM clause takes the\par
Germans table and ends up with a result table that is the same as\par
the Germans table.\par
\par
PRODUCT\par
In the history of the world, there have been four great Mathematicians:\par
   \{Al-Khwarezm, Georg Cantor, Leonhard Euler, Rene Descartes\}\par
\par
If we put that side-by-side with our original Germans set, we get:\par
\par
MATHEMATICIANS       GERMANS\par
Al-Khwarezm          Georg Cantor\par
Georg Cantor         Kaiser Wilhelm\par
Leonhard Euler\par
Rene Descartes\par
\par
The Cartesian product operation yields the set of all pairs (x,y)\par
such that x is a member of some set X and y is a member of some\par
set Y. The result of GERMANS [Cartesian Product] MATHEMATICIANS\par
is the following binary relation.\par
\par
CARTESIAN_PRODUCT\par
\par
GERMANS.NAME         MATHEMATICIANS.NAME\par
Al-Khwarezm          Georg Cantor\par
Georg Cantor         Georg Cantor\par
Leonhard Euler       Georg Cantor\par
Rene Descartes       Georg Cantor\par
Al-Khwarezm          Kaiser Wilhelm\par
Georg Cantor         Kaiser Wilhelm\par
Leonhard Euler       Kaiser Wilhelm\par
Rene Descartes       Kaiser Wilhelm\par
\par
You must not object that Al-Khwarezm is unrelated to Kaiser\par
Wilhelm, because the spirit of a Cartesian-product relation is\par
that everything relates to everything. The table above is a\par
relation -- it's mathematically valid (even if it doesn't seem to\par
make any sense!). There are several ways to express this\par
operation in SQL. The classic style is:\par
\par
   ... FROM Germans, Mathematicians ...\par
\par
That is, within a FROM clause the expression "table-name-1 ,\par
table-name-2" means "yield a table which is the Cartesian product\par
of table-name-1 and table-name-2".\par
\par
SEARCH CONDITION\par
In our Cartesian-product relation, there is something special about the row:\par
   (Georg Cantor,Georg Cantor)\par
\par
That row, and that row only, has two column values that are the\par
same. This is significant because the columns are defined in a\par
meaningful way: one 'Georg Cantor' is the name of a German, while\par
the other 'Georg Cantor' is the name of a mathematician.\par
Therefore, Georg Cantor must be the only person who is both a\par
German and a mathematician. (This assumes that names are unique.)\par
And again, there is an SQL way to say this:\par
\par
   ... FROM  Germans, Mathematicians\par
       WHERE Germans.name = Mathematicians.name ...\par
\par
We now have two clauses in our example. The FROM clause exploded\par
the tables into a Cartesian product relation. The WHERE clause\par
reduces the result to a subset of that relation. The result\par
subset is also a relation -- it contains only those rows where this\par
condition is true: "the name equals the name". (This is known as\par
a search condition in official-SQL vocabulary.) Now we have this result:\par
\par
CARTESIAN_PRODUCTS\par
\par
GERMANS.NAME         MATHEMATICIANS.NAME\par
Georg Cantor         Georg Cantor\par
\par
So: the WHERE clause contains a search condition, takes as input\par
the (table) result of the FROM clause, and produces as output a\par
table which contains only those rows where the search condition is TRUE.\par
\par
JOIN\par
In this example so far, the FROM clause contained two table names\par
and the WHERE clause contained a comparison between columns from\par
each table. This two-step process is usually called a join. In\par
modern SQL, there are several ways to ask for a join. We have\par
started with the oldest and best-known way, because it best\par
illustrates that a typical join is two separate operations.\par
\par
PROJECTION\par
Our result table now has one row with two columns, and the value\par
in each column is 'Georg Cantor' -- but we only need one column\par
to answer the question "Who is German and a mathematician?".\par
If you think of the earlier search condition as being an\par
operation which picks out certain rows, it's easy to get to the\par
next step. A projection is a complementary operation which picks\par
out certain columns. In SQL, we just list the columns we want:\par
\par
   SELECT Germans.name\par
   FROM   Germans, Mathematicians\par
   WHERE  Germans.name = Mathematicians.name ...\par
\par
The column reference after the keyword SELECT is called a select\par
list. We now have a result table that looks like this:\par
\par
CARTESIAN_PRODUCT\par
\par
GERMANS.NAME\par
Georg Cantor\par
\par
So, the select list does a projection on the table produced by\par
the WHERE clause. The result is (as always) a table. The words\par
"SELECT Germans.name FROM Germans, Mathematicians WHERE\par
Germans.name = Mathematicians.name" constitute a valid and\par
complete SQL statement. Specifically, this sort of statement is\par
called a query, presumably because it translates a question (in\par
this case, "What Germans are mathematicians?"). It's also commonly\par
called the SELECT statement.\par
\par
Other Set Operations\par
SQL also handles the standard set operations intersect, union, and\par
except. The following is an example of each: two example tables (the\par
"input"), one result table (the "output"), and the SQL statement\par
that makes it happen. To make the examples short, we've used\par
unrealistically small examples with one column per table and no\par
WHERE clauses, but don't worry about syntactical details or\par
the exact workings of the operations -- that comes later.\par
You understand enough so far if you grasp that some well-known\par
set operations can be expressed in SQL, and work on tables.\par
\par
Inputs                   SQL query           Output\par
\par
INTEGERS_1  INTEGERS_2   SELECT column_1     INTEGERS_3\par
                         FROM Integers_1\par
COLUMN_1    COLUMN_1     INTERSECT           COLUMN_1\par
5           33           SELECT column_1     4\par
4           14           FROM Integers_2\par
13           4\par
\par
STRINGS_1   STRINGS_2    SELECT column_1     STRINGS_3\par
                         FROM Strings_1\par
COLUMN_1    COLUMN_1     UNION               COLUMN_1\par
Spain       Italy        SELECT column_1     Spain\par
Greece      Denmark      FROM Strings_2      Greece\par
Yugoslavia  Belgium                          Italy\par
                                             Denmark\par
                                             Yugoslavia\par
                                             Belgium\par
\par
DECIMALS_1  DECIMALS_2   SELECT column_1     DECIMALS_3\par
                         FROM Decimals_1\par
COLUMN_1    COLUMN_1     EXCEPT              COLUMN_1\par
 5.32       33.08        SELECT column_1      5.32\par
 4.17       14.00        FROM Decimals_2     13.99\par
13.99        4.17\par
\par
Therefore God Exists\par
Leonhard Euler is famed for his remark that "(a+b)**n/n=X,\par
therefore God exists", which shows that any argument looks\par
imposing if you use lots of math symbols. SQL does the opposite.\par
It has a solid base on a mathematical theory, but the operations\par
of Set Theory are hidden behind a somewhat English-like sentence\par
structure. The result is, on balance, for the good. Most SQL\par
beginners have an easy time grasping the concepts behind "WHERE\par
clauses" or "select lists", while they might have a less easy\par
time with the dense polysymbolic notation of standard Set Theory.\par
Unfortunately, the SQL language hides the operations so well that\par
frequent delusions arise:\par
     1. SQL is a "nonprocedural" language. Perhaps people get\par
this idea from the fact that any operation on a set should affect\par
all set members simultaneously. But the set operations themselves\par
are ordered. One step follows another.\par
     2. A whole SQL query operates on the tables in the FROM\par
clause. This mode of thinking causes people to make certain\par
common errors which could be avoided if they kept in mind the\par
truth; that each set operation produces a new,\par
nameless, "virtual" table and passes it on. (Well, perhaps we\par
should add "conceptually" -- there will be hundreds of times in\par
this book that we could add "conceptually" because your DBMS may\par
do internal things in some out-of-order sequence, provided the\par
method doesn't affect the results. That is not our present\par
concern. What we must know from the outset is how a human being\par
is supposed to view the operations.)\par
\par
Coming away from this chapter, you only need to know that SQL has\par
a specialized vocabulary which to a large extent arises from Set\par
Theory; and that SQL operations happen on tables. You should\par
regard this as background information. This book takes a\par
bottom-up approach, starting with the smallest units (the column\par
and row values), so it will be several chapters before we reach\par
the top, and begin to emphasize the sets once more.\par
\par
Recap: the Relational Model\par
\par
A relational database is one which appears to be nothing more\par
than a collection of tables. The model it is based on has three\par
major aspects: the structure, the manipulation, and the integrity of data.\par
\par
In the relational model, data are logically presented in two-\par
dimensional tables made up of columns and rows. The rows of a\par
table consist of a collection of values that describe an entity;\par
for example, an employee. The columns of a table consist of a\par
collection of similar data among rows; e.g., employee surnames.\par
Operations on the data are simplified by the fact that a table's\par
rows are unordered. The intersection of a row and a column\par
contains individual data items called values. Values are always\par
atomic; that is, each position in a table may contain only one datum.\par
\par
Data manipulation is provided by a set of algebraic or calculus operators.\par
\par
Data integrity is provided by two rules. Entity integrity requires that every \par
value in the primary key of a table must be a unique, non-null data value. \par
Referential integrity requires that every value in a foreign key must either \par
equal some value of its related primary key, or it must be null.\par
\par
Design of a Relational Database\par
One of the main advantages of the relational model of database design is that \par
it is based on a foundation of formal mathematical theory that allows its \par
concepts to be defined and examined with great precision.\par
\par
Remember that a relation is (essentially) a two-dimensional table\par
consisting of horizontal rows and vertical columns. The advantage\par
of this form is that almost everyone is familiar with data\par
presented as a simple table. The relational model stipulates that\par
no two rows in the table (relation) may be identical; there must\par
be some combination of columns, called a key, whose values will\par
uniquely identify each row.\par
\par
As an example of the model's capabilities, we will design a\par
structure for a personnel database which contains the following\par
information: the name of each employee, the programming languages\par
the employee is familiar with, the number of years the employee\par
has used each language, the employee's title, the employee's\par
length of service with the company, the employee's hourly rate of\par
pay, the current projects to which the employee is assigned, and\par
the manager of each of these projects.\par
\par
The following PERSONNEL_1 table shown below shows a sample of the data that\par
might be stored in such a database, along with one possible structure.\par
\par
PERSONNEL_1 \par
NAME   LANG    YRS_USE TITLE     YRS_EXP PAY   PROJECT   MGR\par
Marvin Cobol   3       Sr. Prog. 4       25.00 Payroll   Smith\par
       Fortran 2                               A/R       Jones\par
Brown  Cobol   2       Sr. Prog. 3       24.00 Inventory Norman\par
       Basic   1         \par
       Ada     3 \par
Norman Cobol   4       Prj. Mgr. 2       35.00 Inventory Norman\par
       SQL     2 \par
James  SQL     1       Sys. Ana. 2       29.00 A/R       Jones\par
       Pascal  3                               Datcomm   Harvey\par
Jones  Cobol   1       Prj. Mgr. 8       42.00 A/R       Jones\par
       Pascal  5\par
       SQL     2\par
       Basic   9\par
\par
Each employee in this table has a unique name, so NAME may be\par
used as the table's key. In practice, of course, there may be\par
more than one way to construct a key - social security numbers or\par
employee numbers are other values that might be used to uniquely\par
identify an employee. Using this structure, any request of the\par
form, "Tell me something about employee E", is easily answered.\par
However, it isn't as simple to respond to such requests as\par
"Which employees can use language L?"; "Who is the manager of\par
project P?"; "Display all employees assigned to project P"; or\par
"Change the manager of project P to employee E". But\par
through a process known as normalization, the organization of the\par
data in PERSONNEL_1 can be changed so that it can be used more flexibly.\par
\par
The first step in normalizing the design is based on the\par
relational rule that each column of a table may take on only a\par
single, non-repeating (atomic) value for each row of the table.\par
Looking at PERSONNEL_1, it's easy to see that the columns LANG,\par
YRS_USE, PROJECT and MGR violate this rule, because an employee may\par
know more than one programming language and may be assigned to\par
more than one project at a time. By duplicating the non-repeating\par
values of NAME, TITLE, YRS_EXP, and PAY for each combination of\par
values for the repeating groups, the entire table can be\par
represented in first normal form. The PERSONNEL_2 table shown\par
below is in first normal form.\par
\par
PERSONNEL_2\par
NAME   LANG    YRS_USE TITLE     YRS_EXP PAY   PROJECT   MGR\par
Marvin Cobol   3       Sr. Prog. 4       25.00 Payroll   Smith\par
Marvin Fortran 2       Sr. Prog. 4       25.00 A/R       Jones\par
Brown  Cobol   2       Sr. Prog. 3       24.00 Inventory Norman\par
Brown  Basic   1       Sr. Prog. 3       24.00 Inventory Norman\par
Brown  Ada     3       Sr. Prog. 3       24.00 Inventory Norman\par
Norman Cobol   4       Prj. Mgr. 2       35.00 Inventory Norman\par
Norman SQL     2       Prj. Mgr. 2       35.00 Inventory Norman\par
James  SQL     1       Sys. Ani. 2       29.00 A/R       Jones\par
James  Pascal  3       Sys. Ani. 2       29.00 Datcomm   Harvey\par
Jones  Cobol   1       Prj. Mgr. 8       42.00 A/R       Jones\par
Jones  Pascal  5       Prj. Mgr. 8       42.00 A/R       Jones\par
Jones  SQL     2       Prj. Mgr. 8       42.00 A/R       Jones\par
Jones  Basic   9       Prj. Mgr. 8       42.00 A/R       Jones\par
\par
We can now see that NAME is no longer sufficient to uniquely\par
identify a row of PERSONNEL_2, because multiple rows may be present\par
for an employee who knows more than one language or is assigned\par
to more than one project. One solution is to create a new key\par
from a combination of columns. NAME, LANG, and PROJECT combined\par
would be such a key, as those three values together uniquely\par
identify a single row.\par
\par
PERSONNEL_2 appears to be a step backward in our design. Not only\par
does it require more space to present the data, but responding to\par
requests such as, "Change employee E's title to T"; "Add the\par
assignment of employee E to project P"; or "Make employee E\par
the manager of project P" is now more difficult. This problem\par
is addressed by the remaining normalization steps, which are\par
based on the concept of dependence and the relational rule that in\par
every row of a table, each column must be dependent on every part of the key.\par
\par
If, for each row, the value of a column C1 uniquely determines\par
the value of a column C2, then C2 is functionally dependent\par
on C1. If the value in C1 limits the possible values in C2\par
to a specific set, then C2 is set dependent on C1. For\par
example, because each employee has only one title, we may say that\par
NAME determines TITLE and that TITLE is functionally dependent on\par
NAME. PROJECT is set dependent on NAME, since each employee is\par
assigned to a specific set of projects.\par
\par
The columns TITLE, YRS_EXP and PAY are not dependent on the\par
entire key (NAME, LANG, PROJECT) of PERSONNEL_2 -- they are\par
dependent on NAME alone. To solve this, we must create a new\par
table containing only NAME, TITLE, YRS_EXP, and PAY. The key for\par
this table, called EMPLOYEES, will be NAME. Of the remaining\par
columns, YRS_USE is determined by both NAME and LANG and\par
therefore cannot be part of EMPLOYEES. Another table, called\par
LANGUAGES, must be formed by these three columns. LANGUAGES will\par
have a key formed by a combination of the columns NAME and LANG.\par
Because the table contains the NAME column as well, it is still\par
possible to associate an employee's language experience with his\par
employee data.\par
\par
Splitting a table in this way prevents the experience part of the\par
database from having columns that are dependent on only part of\par
the table's key. A first normal form relation (atomic values in\par
each portion of the table) that also has no partial key\par
dependence is said to be in second normal form. The following\par
tables, EMPLOYEES and LANGUAGES, are in second normal form.\par
\par
EMPLOYEES\par
NAME   TITLE     YRS_EXP PAY\par
Marvin Sr. Prog. 4       25.00\par
Brown  Sr. Prog. 3       24.00\par
Norman Prj. Mgr. 2       35.00\par
James  Sys. Ani. 2       29.00\par
Jones  Prj. Mgr. 8       42.00\par
\par
LANGUAGES\par
NAME   LANG    YRS_USE\par
Marvin Cobol   3\par
Marvin Fortran 2\par
Brown  Cobol   2\par
Brown  Basic   1\par
Brown  Ada     3\par
Norman Cobol   4\par
Norman SQL     2\par
James  SQL     1\par
James  Pascal  3\par
Jones  Cobol   1\par
Jones  Pascal  5\par
Jones  SQL     2\par
Jones  Basic   9\par
\par
The situation with project assignments is slightly different. We\par
have already noted that an employee name determines the set of\par
projects on which that employee works. This is independent of the\par
languages used by the employee. This means that a table\par
containing PROJECT should not have LANG in its key. However, the\par
project name uniquely determines the project manager. MGR is\par
transitively dependent on NAME, because NAME determines a set of\par
values for PROJECT, and PROJECT functionally determines MGR. To\par
complete our design, we should remove any transitive\par
dependencies, according to the relational rule that in every row\par
of a table, all columns must depend directly on the key, without\par
any transitive dependencies through other columns. A second\par
normal form relation that has no transitive dependence is said to\par
be in third normal form.\par
\par
Because each project has only one manager, we can form a PROJECTS\par
table with the columns PROJECT and MGR. PROJECTS' key will be\par
PROJECT. Note that MGR could also be a key, if each employee\par
managed only one project. Finally, since each employee works on\par
one or more projects, we will create a fourth table, called\par
ASSIGNMENTS, using the columns NAME and PROJECT. This table forms\par
the association between the EMPLOYEES and PROJECTS tables and is\par
"all key" - i.e., it has no additional dependent columns, because\par
the only thing dependent on both NAME and PROJECT is the fact\par
that they are associated. Here are the third normal form tables.\par
\par
PROJECTS\par
PROJECT   MGR\par
Payroll   Smith\par
A/R       Jones\par
Inventory Norman\par
Datcomm   Harvey\par
\par
ASSIGNMENTS\par
NAME   PROJECT\par
Marvin Payroll\par
Marvin A/R\par
Brown  Inventory\par
Norman Inventory\par
James  A/R\par
James  Datcomm\par
Jones  A/R\par
\par
At this point, our design is complete. All tables are in third normal form, \par
and requests such as those listed earlier can easily be dealt with.\par
\par
Here are some tips for good database design:\par
     ## Don't use an existing database as the basis for a new\par
database structure -- you don't want to inadvertently duplicate\par
awkward or inconsistent table definitions.\par
     ## Make sure that each table represents just one subject --\par
that is, either one object or one event. This avoids unnecessary\par
duplication of data.\par
     ## Define a primary key for every table -- not only will it\par
uniquely identify a row value, you'll use it to join tables. A\par
primary key should have these characteristics: its value must be\par
unique and "known not nullable", and its value should consist of\par
the minimum number of columns to guarantee uniqueness.\par
     ## Don't define any multi-value columns -- that is, don't\par
use the ROW or ARRAY <data type>s.\par
     ## Implement data integrity; define unique keys and foreign\par
keys for your tables.\par
\par
The SQL-environment\par
\par
The SQL Standard says that all SQL operations are executed within\par
an SQL-environment. An SQL-environment has six components.\par
     1. One SQL-agent responsible for causing\par
the execution of SQL statements. It is usually an application\par
program that calls one or more externally-invoked procedures in\par
an SQL-client Module.\par
     2. One SQL-implementation; a\par
database management system (DBMS) that executes SQL statements.\par
Your SQL-agent considers your DBMS to have two components:\par
(a) one SQL-client, to which the SQL-agent is bound, and (b) one or more\par
SQL-servers to manage your SQL-data. (SQL-data consists of the\par
descriptions of all the SQL Objects, plus all the data values you\par
can access with your DBMS.) The SQL-client is the part of your\par
DBMS that establishes connections to the SQL-servers; it\par
maintains a diagnostics area and other state data that relate to\par
the interactions between the DBMS and the SQL-agent. Each SQL-\par
server has three responsibilities: (a) it manages the SQL-session\par
taking place over the SQL-Connection between itself and the\par
SQL-client, (b) it executes SQL statements received from the\par
SQL-client, receiving and sending data as required, and (c) it\par
maintains the state of the SQL-session, including the\par
<AuthorizationID> and certain session defaults. The method of\par
communication between the SQL-client and the SQL-server(s) is\par
implementation-defined, but the Standard does specify how an SQL-\par
agent will communicate with your DBMS (see SQL Binding Styles).\par
     3. Zero or more SQL-client Modules, each containing zero or\par
more externally-invoked procedures. SQL-client Modules are\par
programming modules -- exactly one is associated with an SQL-agent\par
at any time.\par
     4. Zero or more <AuthorizationID>s. An SQL <AuthorizationID>, or \par
authorization identifier, represents a user of SQL-data.\par
     5. Zero or more Catalogs.\par
     6. Zero or more sites (e.g., Base tables) that contain SQL-data.\par
\par
In short, an SQL-environment can be thought of as a specific\par
operation of a DBMS on the collection of Catalogs (that contain\par
SQL-data) within a specified SQL-server by all the users (that\par
is, all persons and programs) that have authority to access the\par
SQL-server during the time the DBMS is operating.\par
\par
SQL Objects\par
\par
The SQL Standard describes the concepts on which SQL is based in\par
terms of Objects, such as Tables. Each SQL Object is defined in\par
terms of the characteristics (e.g., its name) that describe it --\par
the Standard calls this the Object's descriptor. Some Objects are\par
dependent on other Objects, e.g., a Column is dependent on the\par
Table it belongs to. If an Object is dropped (i.e., destroyed),\par
then every Object dependent on it is also dropped.\par
\par
Cluster\par
An SQL Cluster is the group of Catalogs available to an\par
SQL-session at any point in time; that is, it contains all the\par
SQL-data you may access through a given SQL-server. Clusters are\par
created and dropped using implementation-defined methods. The\par
Objects that belong to a Cluster are known as Cluster Objects;\par
that is, they depend on some Cluster. Every Cluster Object has a\par
name that must be unique (among Objects of its name class) within\par
the Cluster it belongs to. The Cluster Object name classes are:\par
     ## <AuthorizationID>s\par
     ## Catalogs\par
\par
<AuthorizationID>\par
An SQL <AuthorizationID> is a character string which identifies a\par
user and the set of Privileges belonging to that user. (A user\par
is either an actual person or an application program that has\par
access to SQL-data.) An SQL Role is a\par
set of zero or more role authorizations. A role authorization\par
allows a given <AuthorizationID> to use every Privilege granted\par
to that Role. <AuthorizationID>s are dependent on some\par
Cluster; they are created, dropped and mapped to real users\par
using implementation-defined methods. Roles are dependent on\par
some schema and are created and dropped with the CREATE ROLE\par
and DROP ROLE statements.\par
\par
Privilege\par
An SQL Privilege authorizes a particular <AuthorizationID>\par
to execute a given operation -- either DELETE, EXECUTE,\par
INSERT, REFERENCES, SELECT, TRIGGER, UNDER, UPDATE, or USAGE on\par
a given Schema Object. It may also allow the grantee to pass the\par
Privilege on to others. Privileges, dependent on some\par
<AuthorizationID>, are created and assigned to\par
<AuthorizationID>s with the GRANT statement and are\par
dropped and removed with the REVOKE statement.\par
\par
Catalog\par
An SQL Catalog is a named group of Schemas, one of which must be\par
an Ur-Schema named INFORMATION_SCHEMA. (The INFORMATION_SCHEMA\par
Schema is a set of Views and Domains that contain the\par
descriptions of all the SQL-data belonging to that Catalog.)\par
Catalogs are dependent on some Cluster and are created and\par
dropped using implementation-defined methods.\par
\par
Schema\par
An SQL Schema is a named group of SQL-data that is owned by a\par
particular <AuthorizationID>. Schemas are dependent on some\par
Catalog and are created, altered, and dropped using the SQL-Schema\par
statements. The Objects that may belong to a Schema are known as\par
Schema Objects; that is, they depend on some Schema. Every Schema\par
Object has a name that must be unique (among Objects of its name\par
class) within the Schema it belongs to. The Schema Object name\par
classes are:\par
     ## Base tables and Views\par
     ## Domains and UDTs\par
     ## Constraints and Assertions\par
     ## Character sets\par
     ## Collations\par
     ## Translations\par
     ## Triggers\par
     ## SQL-server Modules\par
     ## SQL-invoked routines\par
\par
Table\par
An SQL Table is a named set of rows -- an ordered row of one or\par
more <Column name>s together with zero or more unordered rows of\par
data values. Tables store data about a specific entity; each row\par
of the Table describes a single occurrence of that entity. The\par
SQL Standard defines three types of Tables: Base tables, Views,\par
and derived tables. Tables are dependent on some Schema or some\par
Module. Base tables are created, altered, and dropped with the CREATE\par
TABLE, ALTER TABLE, and DROP TABLE statements, Views are created\par
and dropped with the CREATE VIEW and DROP VIEW statements, and\par
derived tables are created when you execute a query.\par
\par
Column\par
An SQL Column is a named component of a Table -- a set of similar\par
data values that describe the same attribute of an entity. A\par
Column's values all belong to the same <data type>, or to the\par
same Domain, and may vary over time. A Column value is the\par
smallest unit of data that can be selected from, or updated for,\par
a Table. Columns are dependent on some Table and are created,\par
altered, and dropped with Column definition clauses in the CREATE\par
TABLE and ALTER TABLE statements.\par
\par
Domain and UDT\par
An SQL Domain and an SQL UDT, or user-defined type, are both\par
named <data type>s that identify a set of valid data values.\par
Their characteristics are defined by users and their purpose is\par
to constrain the values that can be stored as SQL-data. Domains\par
are dependent on some Schema and are created, altered, and dropped\par
with the CREATE DOMAIN, ALTER DOMAIN and DROP DOMAIN statements.\par
UDTs are dependent on some Schema or some Module and are created.\par
altered, and dropped with the CREATE TYPE, ALTER TYPE,\par
and DROP TYPE statements.\par
\par
Constraint and Assertion\par
An SQL Constraint and an SQL Assertion are both named rules that\par
identify sets of valid data values. They constrain the allowable\par
data values for Columns, Domains, and Tables and are defined with\par
two checking characteristics: a deferral mode (either DEFERRABLE\par
or NOT DEFERRABLE) and a constraint check time (either DEFERRED\par
or IMMEDIATE). Constraints are dependent on some Table or some\par
Domain and are created and dropped with Constraint clauses in the\par
CREATE TABLE, ALTER TABLE, CREATE DOMAIN and ALTER DOMAIN\par
statements. Assertions are dependent on some Schema and are\par
created and dropped with the CREATE ASSERTION and DROP ASSERTION statements. \par
\par
Character Set\par
An SQL Character set is a named group of characters (the\par
character repertoire) combined with that repertoire's\par
Form-of-use, or coding scheme -- the (usually one-to-one) mapping\par
scheme between each character in the repertoire and a set of\par
internal codes (usually 8-bit values) that give the characters'\par
order in the repertoire and define how the characters are encoded\par
as numbers. Every Character set must contain a space character\par
that is equivalent to the Unicode character U+0020. Character\par
sets are dependent on some Schema and are created and dropped\par
with the CREATE CHARACTER SET and DROP CHARACTER SET statements.\par
Every Character set has a default Collation.\par
\par
Collation\par
An SQL Collation is a named set of rules that describes a\par
collating sequence. Each Collation is defined for exactly one\par
Character set and is used to determine the results of comparisons\par
between character strings based on that Character set. All\par
Character sets have a default Collation. Additional Collations\par
may also be created for any Character set, so for any character\par
string comparison, there are one or more Collations that may be\par
invoked by the COLLATE function. Collations are dependent on some\par
Schema and are created and dropped with the CREATE COLLATION and\par
DROP COLLATION statements.\par
\par
Translation\par
An SQL Translation is a named set of rules that maps characters\par
from a source Character set to characters in a target Character\par
set for conversion purposes. For any pair of Character sets,\par
there are zero or more Translations that may be invoked by the\par
TRANSLATE function. Translations are dependent on some Schema and\par
are created and dropped with the CREATE TRANSLATION and DROP\par
TRANSLATION statements.\par
\par
Trigger\par
An SQL Trigger is a named rule that is associated with a single\par
Base table. Each Trigger defines a trigger event specifying\par
which action -- either INSERT, DELETE, or UPDATE -- on the Table\par
will cause the triggered actions, a trigger action time specifying\par
whether the triggered action is to be taken before or\par
after the trigger event, and one or more triggered actions (the\par
action to take when the Trigger is fired, or invoked). Triggers\par
are dependent on some Schema and are created and dropped with the\par
CREATE TRIGGER and DROP TRIGGER statements.\par
\par
Module\par
An SQL Module is an optionally-named group of SQL statements that\par
is treated as a unit of an application program. Such programs use\par
SQL statements to carry out database operations instead of\par
routines written in the host language. There are three kinds of\par
SQL Modules: (a) an SQL-client Module contains SQL procedures that\par
are invoked by a host language and is defined with the MODULE\par
statement, (b) an SQL-session Module contains only SQL statements\par
prepared in that SQL-session and is usually an implicit Module\par
(that is, its presence isn't obvious to the user), and (c) an\par
SQL-server Module -- the SQL/PSM type -- is dependent on some\par
Schema, contains only SQL-invoked routines and is created,\par
altered, and dropped with the CREATE MODULE, ALTER MODULE, and DROP\par
MODULE statements.\par
\par
SQL-invoked Routine\par
An SQL-invoked routine is a function or a procedure that can be\par
invoked from SQL. An SQL-invoked function is invoked by a routine\par
invocation in some value expression, while an SQL-invoked\par
procedure is a procedure invoked with the CALL statement. SQL-\par
invoked routines are dependent either directly on some Schema or\par
on some Module and are created and dropped with the CREATE\par
PROCEDURE, DECLARE PROCEDURE, CREATE FUNCTION, CREATE METHOD,\par
DROP SPECIFIC ROUTINE, DROP SPECIFIC FUNCTION, and DROP SPECIFIC\par
PROCEDURE statements.\par
\par
SQL Data Types\par
\par
Every data value belongs to some SQL <data type>. The logical\par
representation of a data value is known as a <literal>. SQL\par
supports three sorts of <data type>s -- predefined <data type>s,\par
constructed <data type>s, and <user-defined data type>s, or UDTs\par
-- all of which may be used to define a set of valid data values.\par
The predefined <data type>s are all scalar types; they contain\par
atomic values (i.e., values that are not composed of sets of\par
values of other <data type>s). The constructed <data type>s are\par
mostly composite types; they contain array values (i.e., values\par
that are composed of sets of values, each of a declared\par
predefined <data type>). The UDTs are composite types. Their\par
values and attributes are totally user-defined.\par
\par
Each host language supported by the SQL Standard has its own data\par
types. These are distinct from SQL <data type>s, though they\par
often have similar names. The Standard includes instructions on\par
how to map SQL <data type>s to host language data types.\par
\par
SQL-data values are either non-null values or the null value. The\par
null value is a special implementation-dependent value that can\par
be assigned to any SQL <data type>. It is used to represent\par
"value unknown" or "value inapplicable" and is distinct from all\par
non-null values. The null value is often denoted by the <keyword> NULL.\par
\par
Predefined <data type>s\par
SQL's predefined scalar <data type>s are identified by these\par
<keyword>s: INTEGER, SMALLINT, NUMERIC, DECIMAL, FLOAT, REAL,\par
DOUBLE PRECISION, BIT, BIT VARYING, BINARY LARGE OBJECT,\par
CHARACTER, CHARACTER VARYING, NATIONAL CHARACTER, NATIONAL\par
CHARACTER VARYING, CHARACTER LARGE OBJECT, NATIONAL CHARACTER\par
LARGE OBJECT, DATE, TIME, TIME WITH TIME ZONE, TIMESTAMP,\par
TIMESTAMP WITH TIME ZONE, INTERVAL, and BOOLEAN.\par
\par
Number <data type>s\par
A numeric value is either an exact numeric (integer or decimal)\par
number or an approximate numeric (floating point) number. The\par
numeric <data type>s INTEGER (or INT), SMALLINT, NUMERIC, DECIMAL\par
(or DEC), FLOAT, REAL, and DOUBLE PRECISION store numbers inserted\par
in either exact numeric form (e.g., 75, -6.2) or approximate\par
numeric form (e.g., 1.256E-4, -1.03E+5). INT and SMALLINT are\par
exact numeric types with a predefined precision and a scale of\par
zero; NUMERIC and DECIMAL are exact numeric types with definable\par
precisions and scales; FLOAT is an approximate numeric type with\par
a definable precision; and REAL and DOUBLE PRECISION are approximate\par
numeric types with predefined precisions. All numbers are\par
mutually assignable and mutually comparable. Assignment and\par
comparison are performed in the familiar, algebraic manner. The\par
following SQL operations involve numbers: addition and unary\par
plus, subtraction and unary minus, multiplication, division,\par
assignment, comparison, ABS, BETWEEN, BIT_LENGTH, CARDINALITY,\par
CHAR_LENGTH, DISTINCT, EXISTS, EXTRACT, FOR ALL, FOR SOME, IN, IS\par
NULL, MATCH, MOD, OCTET_LENGTH, POSITION, and UNIQUE.\par
\par
Bit String <data types>s\par
A bit string value is any sequence of bits or hexits. The bit\par
string <data type>s BIT and BIT VARYING store bit string values\par
inserted in either binary form (any sequence of zero or more 0-\par
bits or 1-bits) or hexadecimal form (any sequence of zero or more\par
0-hexits, 1-hexits, 2-hexits, 3-hexits, 4-hexits, 5-hexits, 6-\par
hexits, 7-hexits, 8-hexits, 9-hexits, A-hexits, B-hexits, C-\par
hexits, D-hexits, E-hexits, or F-hexits). BIT has a definable\par
fixed length; BIT VARYING has a definable variable length. All\par
bit strings are mutually assignable and mutually comparable.\par
Assignment of a bit string is performed bit-by-bit beginning\par
with the source's most significant bit. For comparison purposes,\par
a 0-bit is less than a 1-bit. The following SQL operations\par
involve bit strings: concatenation, assignment, comparison,\par
BETWEEN, BIT_LENGTH, CHAR_LENGTH, DISTINCT, EXISTS, FOR ALL, FOR\par
SOME, IN, IS NULL, MATCH, OCTET_LENGTH, POSITION, SUBSTRING, and UNIQUE.\par
\par
Binary String <data types>s\par
A binary string value is any sequence of octets that aren't\par
associated with a Character set. The binary string <data type>\par
BINARY LARGE OBJECT (BLOB) stores binary string values\par
inserted in hexadecimal form. BLOB has a definable variable\par
length. All binary strings are mutually assignable and mutually\par
comparable. Assignment of a binary string is performed octet-by-octet\par
beginning with the source's most significant octet.\par
Comparison is supported only for equality. The following SQL\par
operations involve binary strings: concatenation, assignment,\par
comparison, BIT_LENGTH, CHAR_LENGTH, EXISTS, FOR ALL, FOR SOME,\par
IS NULL, LIKE, OCTET_LENGTH, OVERLAY, POSITION, SUBSTRING, and TRIM.\par
\par
Character String <data type>s\par
A character string value is any sequence of characters that\par
belong to a given Character set. The character string <data\par
type>s CHARACTER (CHAR), CHARACTER VARYING (VARCHAR),\par
NATIONAL CHARACTER (NCHAR) and NATIONAL CHARACTER VARYING\par
(NCHAR VARYING) store character strings, while the character\par
string <data type>s CHARACTER LARGE OBJECT (CLOB) and NATIONAL\par
CHARACTER LARGE OBJECT (NCLOB) store large object character\par
strings. CHAR and NCHAR have a definable fixed length; VARCHAR,\par
NCHAR VARYING, CLOB and NCLOB have a definable variable length.\par
CHAR, VARCHAR, and CLOB have a definable Character set; NCHAR,\par
NCHAR VARYING, and NCLOB have a predefined Character set. All of\par
the character string <data type>s have a definable Collation or\par
collating sequence. All character strings that belong to the same\par
Character set are mutually assignable and mutually comparable if\par
they have the same Collation. Assignment of a character string is\par
performed character-by-character beginning with the source's\par
first character. The result of a character string comparison is\par
determined by the rules of the Collation used for the comparison.\par
The following SQL operations involve character strings:\par
concatenation, assignment, comparison, BETWEEN, BIT_LENGTH,\par
CHAR_LENGTH, CONVERT, DISTINCT, EXISTS, FOR ALL, FOR SOME, IN, IS\par
NULL, LIKE, LOWER, MATCH, OCTET_LENGTH, OVERLAY, POSITION,\par
SIMILAR, SUBSTRING, TRANSLATE, TRIM, UNIQUE, and UPPER.\par
\par
Temporal <data type>s\par
A temporal value is a date, a time, a timestamp, or an interval of\par
time. The temporal <data type> DATE stores dates, TIME and TIME\par
WITH TIME ZONE store times, TIMESTAMP and TIMESTAMP WITH TIME\par
ZONE store timestamps, and INTERVAL stores intervals. DATE has a\par
predefined precision; TIME, TIME WITH TIME ZONE, TIMESTAMP and\par
TIMESTAMP WITH TIME ZONE have definable fractional seconds\par
precisions. There are two classes of INTERVAL. The first,\par
year-month intervals, has a definable precision that includes\par
some contiguous combination of the YEAR and MONTH datetime\par
fields. The second, day-time intervals, has a definable precision\par
that includes some contiguous combination of the DAY, HOUR,\par
MINUTE, and SECOND datetime fields. TIME WITH TIME ZONE values\par
are (and TIMESTAMP WITH TIME ZONE values include) times that are\par
maintained in Universal Coordinated Time (UTC) -- with a portion\par
of the value representing a time zone offset. The time zone\par
offset is an interval that specifies the difference between UTC\par
and the actual date and time in the value's time zone. All\par
temporal values of the same type are mutually assignable and\par
mutually comparable; the results must follow the usual rules for\par
temporal values according to the Gregorian calendar and the\par
24-hour clock. The\par
following SQL operations involve temporal values: addition,\par
subtraction, multiplication, division, assignment, comparison,\par
ABS, BETWEEN, CURRENT_DATE, CURRENT_TIME, CURRENT_TIMESTAMP,\par
DISTINCT, EXISTS, EXTRACT, FOR ALL, FOR SOME, IN, IS NULL,\par
LOCALTIME, LOCALTIMESTAMP, MATCH, OVERLAPS, and UNIQUE.\par
\par
Boolean <data type>s\par
A boolean value is a truth value; either TRUE, FALSE, or UNKNOWN.\par
(The truth value UNKNOWN is sometimes represented by the null\par
value.) The boolean <data type> BOOLEAN stores truth values. All\par
truth values are mutually assignable and mutually comparable.\par
TRUE and FALSE may be assigned to any boolean target; UNKNOWN may\par
only be assigned if the boolean target allows NULLs. For\par
comparison purposes, TRUE is greater than FALSE. The following\par
SQL operations involve boolean values: AND, IS, NOT, OR, and the\par
results of any predicate or search condition.\par
\par
Constructed <data types>:\par
An SQL constructed <data type> is either a <reference type>, a\par
<row type>, or a <collection type>. A <reference type> is a scalar\par
constructed <data type> identified by the <keyword> REF. A\par
<row type> is a composite constructed <data type> identified by\par
the <keyword> ROW. A <collection type> is a composite\par
constructed <data type>, identified by the <keyword> ARRAY.\par
\par
<reference type>s\par
A reference value points to some row of a referenceable Base\par
table (that is, a Base table that has a "with REF value" property).\par
\par
<row type>s\par
A <row type> is a sequence of one or more (Field, <data type>)\par
pairs. A value of a <row type> consists of one value for each of its Fields.\par
\par
<collection type>s\par
A <collection type> is a composite data value that consists of\par
zero or more elements of a specified <data type>, known as the\par
element type -- that is, in SQL3, a <collection type> is an array.\par
\par
User-defined Types\par
The SQL user-defined types (UDTs) are Schema Objects that can\par
be defined by a standard, by a DBMS, or by an SQL application.\par
UDTs have no corresponding <literal>s.\par
\par
Data Type Conversions\par
SQL allows for implicit <data type> conversion in expressions and\par
in FETCH, SELECT, INSERT, DELETE, and UPDATE operations. Explicit\par
<data type> conversions may be performed with the CAST operator.\par
\par
Sites\par
As defined in the SQL Standard, a site is "a place that holds an\par
instance of a value of a specified <data type>". A site has a\par
defined degree of persistence -- if it exists until deliberately\par
destroyed, it is a persistent site; if it ceases to exist at the\par
end of an SQL statement, SQL transaction, or SQL-session, it is a\par
temporary site; if it exists only to hold an argument or returned\par
value, it is a transient site. The principal kind of persistent\par
or temporary site is a Base table. Some sites may be referenced\par
by their names (e.g., Base tables and SQL variables) or by a REF\par
value. A site occupied by an element of an array may be\par
referenced by its element number.\par
\par
The instance at a site can be changed in two ways: by assignment\par
or by mutation. Assignment is an operation that replaces the\par
value at a site (the "target") with a new value (the "source").\par
Mutation is an operation that changes the value of some attribute\par
of an instance at a site whose <data type> is a UDT. Neither\par
assignment nor mutation has any effect on the reference value of\par
a site, if any.\par
\par
Every site has a nullability characteristic, which indicates\par
whether it may contain the null value (is "possibly nullable") or\par
not (is "known not nullable"). Only the Columns of Base tables\par
may be constrained to be "known not nullable", but the\par
characteristic is inheritable.\par
\par
Locators\par
An embedded host language variable, host parameter, SQL parameter,\par
or external routine, or the value returned by an external\par
function may all be specified to be a Locator. The purpose of a\par
Locator is to allow very large data values to be operated on\par
without transferring the entire value to and from your\par
application program. \par
\par
A Locator is not SQL-data; instead, it is an SQL-session Object\par
that can be used to reference a specific value. The SQL Standard\par
defines three types of Locators: the large object (LOB) Locator,\par
the UDT Locator and the array Locator. A LOB Locator is either\par
(a) a BLOB Locator (its value identifies a binary large object),\par
(b) a CLOB Locator (its value identifies a character large\par
object) or (c) an NCLOB Locator (its value identifies a national\par
character large object). A UDT Locator identifies a value of a\par
given user-defined type. An array Locator identifies a value of a\par
given array.\par
\par
SQL Language Elements\par
\par
The SQL Standard has numerous rules for such basic issues as what\par
makes a legal name and how to put together SQL syntax. The\par
starting point for these rules is knowing what the basic scalar\par
language elements are. The SQL basic scalar language elements are\par
defined in the set of <SQL language character>s.\par
\par
<SQL language character>\par
According to the SQL Standard, the syntactic element <SQL\par
language character> defines "the terminal symbols of the SQL\par
language and the elements of strings". In other words, you'll use\par
<SQL language character>s to write SQL syntax or <token>s. <SQL\par
language character>s are case insensitive; that is, uppercase\par
and lowercase simple Latin letters are interchangeable so that,\par
to an SQL parser, these three words are exactly alike:\par
\par
   SELECT\par
\par
   select\par
\par
   Select\par
   \par
The set of <SQL language character>s contains:\par
     ## The uppercase simple Latin letters A to Z.\par
     ## The lowercase simple Latin letters a to z.\par
     ## The digits 0 to 9.\par
     ## The set of <SQL special character>s.\par
\par
<SQL special character>\par
The set of <SQL special character>s is part of the set of <SQL\par
language character>s and contains:\par
     ##        -- The space character\par
     ## (      -- The left parenthesis\par
     ## )      -- The right parenthesis\par
     ## "      -- The double quote mark\par
     ## '      -- The single quote mark\par
     ## %      -- The percent sign\par
     ## &      -- The ampersand\par
     ## *      -- The asterisk or multiplication sign\par
     ## /      -- The solidus or division sign\par
     ## +      -- The plus sign\par
     ## -      -- The minus sign or dash\par
     ## ,      -- The comma\par
     ## .      -- The period\par
     ## :      -- The colon\par
     ## ;      -- The semicolon\par
     ## <      -- The less than operator\par
     ## >      -- The greater than operator\par
     ## ?      -- The question mark\par
     ## [      -- The left bracket\par
     ## ]      -- The right bracket\par
     ## _      -- The underline character\par
     ## |      -- The vertical bar\par
     ## =      -- The equals operator\par
     ## \{      -- The left brace\par
     ## \}      -- The right brace\par
     ## ^      -- The circumflex\par
\par
<token>\par
A <token> is either a <literal>, a <keyword>, an <identifier> or\par
an <SQL special character> or symbol -- that is, a <token> is a\par
group of characters that is recognized as a single unit by an SQL\par
parser. For example, there are a total of 7 <token>s\par
("SELECT", "a", "+", "5", "FROM", "t", and ";") in the\par
following SQL statement.\par
\par
   SELECT a+5 FROM t;\par
\par
In SQL, <token>s are grouped into two types: <nondelimiter\par
token>s and <delimiter token>s. The difference between them lies\par
in the fact that, while any <token> may be followed by a\par
<separator>, a <nondelimiter token> must be followed either by a\par
<separator> or a <delimiter token>.\par
\par
A <nondelimiter token> is an <unsigned numeric literal>, a\par
<national character string literal>, a <bit string literal>, a\par
<hex string literal>, a <keyword>, or a <regular identifier>. A\par
<delimiter token> is a <character string literal>, a <date\par
literal>, a <time literal>, a <timestamp literal>, an <interval\par
literal>, a <delimited identifier>, an <SQL special character>, or\par
one of these symbols:\par
     ## <>     -- The not equals operator\par
     ## >=     -- The greater than or equals operator\par
     ## <=     -- The less than or equals operator\par
     ## ||     -- The concatenation operator\par
     ## ??(    -- The left trigraph\par
     ## ??)    -- The right trigraph\par
     ## ->     -- The right arrow\par
     ## =>     -- The keyword parameter tag\par
\par
For example, the <keyword> <token> "SELECT" may be followed\par
either by a <separator> (usually a space) or by an <SQL special\par
character>. Thus, both of the following are examples of legal SQL syntax:\par
\par
   SELECT column_1 \par
is legal syntax because a space separates the <token> "SELECT" from the <token> "column_1"\par
\par
   SELECT*\par
is legal syntax because, although no space separates the <token> "SELECT" from the <token> "*",\par
the asterisk is identified as a separate <token> because it is a <SQL special character>.\par
   \par
A <token> may not include any <separator>s unless it is a <character string \par
literal>, a <bit string literal>, a <hex string literal>, a <timestamp \par
literal>, an <interval literal>, or a <delimited identifier>.\par
\par
## <separator>\par
[Obscure Rule] applies to this entire section.\par
\par
Your SQL parser must know where one <token> ends and another\par
begins. To do so, it recognizes white space, a newline character,\par
a simple comment, and a bracketed comment as <separator>s.\par
\par
White space is usually just one or more spaces, but it can also\par
consist of any consecutive sequence of these Unicode characters:\par
     ## U+0009, Horizontal Tab\par
     ## U+000A, Line Feed\par
     ## U+000B, Vertical Tabulation\par
     ## U+000C, Form Feed\par
     ## U+000D, Carriage Return\par
     ## U+0020, Space\par
     ## U+00A0, No-Break Space\par
     ## U+2000, En Quad\par
     ## U+2001, Em Quad\par
     ## U+2002, En Space\par
     ## U+2003, Em Space\par
     ## U+2004, Three-Per-Em Space\par
     ## U+2005, Four-Per-Em Space\par
     ## U+2006, Six-Per-Em Space\par
     ## U+2007, Figure Space\par
     ## U+2008, Punctuation Space\par
     ## U+2009, Thin Space\par
     ## U+200A, Hair Space\par
     ## U+200B, Zero Width Space\par
     ## U+200C, Zero Width Non-Joiner\par
     ## U+200D, Zero Width Joiner\par
     ## U+200E, Left-To-Right Mark\par
     ## U+200F, Right-To-Left Mark\par
     ## U+3000, Ideographic Space\par
     ## U+2028, Line Separator\par
     ## U+2029, Paragraph Separator\par
     ## U+FEFF, Zero Width No-Break Space\par
\par
[NON-PORTABLE] A newline character marks the end of a line. It is\par
non-standard because the SQL Standard requires implementors to\par
define which white space character(s) will be recognized as end-\par
of-line indicators by their parsers. [OCELOT Implementation] The\par
OCELOT DBMS that comes with this book recognizes carriage returns\par
and line feeds as newline characters.\par
\par
A simple comment begins with two or more consecutive dashes,\par
contains any number of characters (including spaces and more\par
dashes), and ends with a newline character. For example, these two\par
SQL statements are both followed by a simple comment.\par
\par
   SELECT a+5 FROM t;     -- this is a simple comment\par
\par
   SELECT a+5 FROM t;     --- this is a simple comment too\par
\par
A bracketed comment is a C-style comment. It begins with "/*",\par
ends with "*/" and contains any number of characters, including\par
zero or more <separator>s. For example, this SQL statement is\par
followed by a bracketed comment.\par
\par
   SELECT a+5 FROM t;    /* this is a bracketed comment \par
that contains a carriage return */ \par
\par
If you want to restrict your code to Core SQL, don't use bracketed comments.\par
\par
<literal>\par
A <literal> is a <token> that represents a non-null data value.\par
SQL values are normally atomic -- they cannot be subdivided --\par
and are either non-null values or the null value. The null value\par
isn't represented by a <literal>. Instead, the <keyword> NULL is\par
used whenever it's necessary to indicate that the null value is represented.\par
     [NON-PORTABLE] The logical representation of the null value\par
is non-standard because the SQL Standard requires implementors to\par
define that character used to display the null value. [OCELOT Implementation]\par
The OCELOT DBMS that comes with\par
this book displays a question mark to represent the null value.\par
\par
In SQL, a <literal> is either a signed <numeric literal> (for\par
example: +52.6), an unsigned <numeric literal> (for example: 15)\par
or a general literal. (An unsigned literal is thus either an\par
unsigned <numeric literal> or a general literal. A general\par
literal is one of the following:\par
     ## A <bit string literal>, for example,\par
B'1011'\par
     ## A <hex string literal>, for example,\par
X'4A'\par
     ## A <binary string literal>, for example,\par
X'44AF'\par
     ## A <character string literal>, for example,\par
'hello'\par
     ## A <national character string literal>, for example,\par
N'hello'\par
     ## A <date literal>, for example,\par
DATE '1997-07-15'\par
     ## A <time literal>, for example,\par
TIME '19:30:20'\par
TIME '19:30:20.05'\par
TIME '19:30:20+03:00'\par
     ## A <timestamp literal>, for example,\par
TIMESTAMP '1997-07-15 19:30:20'\par
TIMESTAMP '1997-07-15 19:30:20.05'\par
TIMESTAMP '1997-07-15 19:30:20.05-10:30'\par
     ## A <year-month literal>, for example,\par
INTERVAL '20' YEAR\par
INTERVAL '10' MONTH\par
INTERVAL '20-10' YEAR TO MONTH\par
     ## A <day-time literal>, for example,\par
INTERVAL -'20' DAY\par
INTERVAL '-10' HOUR\par
INTERVAL '15' MINUTE\par
INTERVAL '10' SECOND\par
INTERVAL '20 10:15:10' DAY TO SECOND\par
     ## A <boolean literal>, either\par
 TRUE, FALSE or UNKNOWN.\par
\par
<keyword>\par
A <keyword> is a word that has a special meaning for the SQL\par
parser. There are two types of SQL <keyword>s: reserved\par
<keyword>s and non-reserved <keyword>s. Reserved <keyword>s may\par
not be used as <regular identifier>s. Non-reserved <keyword>s are\par
not so restricted, but it's probably not a good idea to use them\par
as <regular identifier>s anyway.\par
\par
A <keyword> is case insensitive because all its characters are part\par
of the set of <SQL language character>s. That is, uppercase and\par
lowercase letters within a <keyword> are interchangeable; so\par
that, for example, these three <keyword>s are exactly alike to an\par
SQL parser:\par
   \par
   SELECT\par
\par
   select\par
\par
   Select\par
\par
The Set of Reserved <keyword>s\par
ABSOLUTE\par
ACTION\par
ADD\par
ADMIN\par
AFTER\par
AGGREGATE\par
ALIAS\par
ALL\par
ALLOCATE\par
ALTER\par
AND\par
ANY\par
ARE\par
ARRAY\par
AS\par
ASC\par
ASSERTION\par
AT\par
AUTHORIZATION\par
BEFORE\par
BEGIN\par
BINARY\par
BIT\par
BLOB\par
BOOLEAN\par
BOTH\par
BREADTH\par
BY\par
CALL\par
CASCADE\par
CASCADED\par
CASE\par
CAST\par
CATALOG\par
CHAR\par
CHARACTER\par
CHECK\par
CLASS\par
CLOB\par
CLOSE\par
COLLATE\par
COLLATION\par
COLUMN\par
COMMIT\par
COMPLETION\par
CONDITION\par
CONNECT\par
CONNECTION\par
CONSTRAINT\par
CONSTRAINTS\par
CONSTRUCTOR\par
CONTAINS\par
CONTINUE\par
CORRESPONDING\par
CREATE\par
CROSS\par
CUBE\par
CURRENT\par
CURRENT_DATE\par
CURRENT_PATH\par
CURRENT_ROLE\par
CURRENT_TIME\par
CURRENT_TIMESTAMP\par
CURRENT_USER\par
CURSOR\par
CYCLE\par
DATA\par
DATALINK\par
DATE\par
DAY\par
DEALLOCATE\par
DEC\par
DECIMAL\par
DECLARE\par
DEFAULT\par
DEFERRABLE\par
DEFERRED\par
DELETE\par
DEPTH\par
DEREF\par
DESC\par
DESCRIBE\par
DESCRIPTOR\par
DESTROY\par
DESTRUCTOR\par
DETERMINISTIC\par
DIAGNOSTICS\par
DICTIONARY\par
DISCONNECT\par
DISTINCT\par
DO\par
DOMAIN\par
DOUBLE\par
DROP\par
DYNAMIC\par
EACH\par
ELSE\par
ELSEIF\par
END\par
END-EXEC\par
EQUALS\par
ESCAPE\par
EVERY\par
EXCEPT\par
EXCEPTION\par
EXEC\par
EXECUTE\par
EXIT\par
EXPAND\par
EXPANDING\par
EXTERNAL\par
FALSE\par
FETCH\par
FIRST\par
FLOAT\par
FOR\par
FOREIGN\par
FOUND\par
FROM\par
FREE\par
FULL\par
FUNCTION\par
GENERAL\par
GET\par
GLOBAL\par
GO\par
GOTO\par
GRANT\par
GROUP\par
GROUPING\par
HANDLER\par
HAVING\par
HASH\par
HOST\par
HOUR\par
IDENTITY\par
IF\par
IGNORE\par
IMMEDIATE\par
IN\par
INDICATOR\par
INITIALIZE\par
INITIALLY\par
INNER\par
INOUT\par
INPUT\par
INSERT\par
INT\par
INTEGER\par
INTERSECT\par
INTERVAL\par
INTO\par
IS\par
ISOLATION\par
ITERATE\par
JOIN\par
KEY\par
LANGUAGE\par
LARGE\par
LAST\par
LATERAL\par
LEADING\par
LEAVE\par
LEFT\par
LESS\par
LEVEL\par
LIKE\par
LIMIT\par
LOCAL\par
LOCALTIME\par
LOCALTIMESTAMP\par
LOCATOR\par
LOOP\par
MATCH\par
MEETS\par
MINUTE\par
MODIFIES\par
MODIFY\par
MODULE\par
MONTH\par
NAMES\par
NATIONAL\par
NATURAL\par
NCHAR\par
NCLOB\par
NEW\par
NEXT\par
NO\par
NONE\par
NORMALIZE\par
NOT\par
NULL\par
NUMERIC\par
OBJECT\par
OF\par
OFF\par
OLD\par
ON\par
ONLY\par
OPEN\par
OPERATION\par
OPTION\par
OR\par
ORDER\par
ORDINALITY\par
OUT\par
OUTER\par
OUTPUT\par
PAD\par
PARAMETER\par
PARAMETERS\par
PARTIAL\par
PATH\par
PERIOD\par
POSTFIX\par
PRECEDES\par
PRECISION\par
PREFIX\par
PREORDER\par
PREPARE\par
PRESERVE\par
PRIMARY\par
PRIOR\par
PRIVILEGES\par
PROCEDURE\par
PUBLIC\par
READ\par
READS\par
REAL\par
RECURSIVE\par
REDO\par
REF\par
REFERENCES\par
REFERENCING\par
RELATIVE\par
REPEAT\par
RESIGNAL\par
RESTRICT\par
RESULT\par
RETURN\par
RETURNS\par
REVOKE\par
RIGHT\par
ROLE\par
ROLLBACK\par
ROLLUP\par
ROUTINE\par
ROW\par
ROWS\par
SAVEPOINT\par
SCHEMA\par
SCROLL\par
SEARCH\par
SECOND\par
SECTION\par
SELECT\par
SEQUENCE\par
SESSION\par
SESSION_USER\par
SET\par
SETS\par
SIGNAL\par
SIZE\par
SMALLINT\par
SOME\par
SPACE\par
SPECIFIC\par
SPECIFICTYPE\par
SQL\par
SQLEXCEPTION\par
SQLSTATE\par
SQLWARNING\par
START\par
STATE\par
STATIC\par
STRUCTURE\par
SUCCEEDS\par
SYSTEM_USER\par
TABLE\par
TEMPORARY\par
TERMINATE\par
THAN\par
THEN\par
TIME\par
TIMESTAMP\par
TIMEZONE_HOUR\par
TIMEZONE_MINUTE\par
TO\par
TRAILING\par
TRANSACTION\par
TRANSLATION\par
TREAT\par
TRIGGER\par
TRUE\par
UNDER\par
UNDO\par
UNION\par
UNIQUE\par
UNKNOWN\par
UNTIL\par
UPDATE\par
USAGE\par
USER\par
USING\par
VALUE\par
VALUES\par
VARCHAR\par
VARIABLE\par
VARYING\par
VIEW\par
WHEN\par
WHENEVER\par
WHERE\par
WHILE\par
WITH\par
WITHOUT\par
WORK\par
WRITE\par
YEAR\par
ZONE\par
Note: SQL-92 and SQL3 both added a considerable number of words\par
to the set of SQL reserved <keyword>s. The Standard acknowledges\par
this and -- as an aid to users -- suggests that you include\par
either a digit or an underline character in your <regular\par
identifier>s, and avoid names that begin with CURRENT_, SESSION_,\par
SYSTEM_ or TIMEZONE_ and those that end with _LENGTH, to avoid\par
conflicts with reserved <keyword>s added in future revisions.\par
\par
The set of non-reserved <keyword>s\par
ABS\par
ADA\par
ASENSITIVE\par
ASSIGNMENT\par
ASYMMETRIC\par
ATOMIC\par
AVG\par
BETWEEN\par
BIT_LENGTH\par
BITVAR\par
BLOCKED\par
C\par
CARDINALITY\par
CATALOG_NAME\par
CHAIN\par
CHAR_LENGTH\par
CHARACTER_LENGTH\par
CHARACTER_SET_CATALOG\par
CHARACTER_SET_NAME\par
CHARACTER_SET_SCHEMA\par
CHECKED\par
CLASS_ORIGIN\par
COALESCE\par
COBOL\par
COLLATION_CATALOG\par
COLLATION_NAME\par
COLLATION_SCHEMA\par
COLUMN_NAME\par
COMMAND_FUNCTION\par
COMMAND_FUNCTION_CODE\par
COMMITTED\par
CONCATENATE\par
CONDITION_NUMBER\par
CONNECTION_NAME\par
CONSTRAINT_CATALOG\par
CONSTRAINT_NAME\par
CONSTRAINT_SCHEMA\par
CONTAINS\par
CONTROL\par
CONVERT\par
COUNT\par
CURSOR_NAME\par
DATETIME_INTERVAL_CODE\par
DATETIME_INTERVAL_PRECISION\par
DB\par
DISPATCH\par
DLCOMMENT\par
DLFILESIZE\par
DLFILESIZEEXACT\par
DLLINKTYPE\par
DLURLCOMPLETE\par
DLURLPATH\par
DLURLPATHONLY\par
DLURLSCHEMA\par
DLURLSERVER\par
DLVALUE\par
DYNAMIC_FUNCTION\par
DYNAMIC_FUNCTION_CODE\par
EXISTING\par
EXISTS\par
EXTRACT\par
FILE\par
FINAL\par
FORTRAN\par
GENERATED\par
HOLD\par
INFIX\par
INSENSITIVE\par
INSTANTIABLE\par
INTEGRITY\par
KEY_MEMBER\par
KEY_TYPE\par
LENGTH\par
LINK\par
LOWER\par
MAX\par
MIN\par
MESSAGE_LENGTH\par
MESSAGE_OCTET_LENGTH\par
MESSAGE_TEXT\par
METHOD\par
MOD\par
MORE\par
MUMPS\par
NAME\par
NULLABLE\par
NUMBER\par
NULLIF\par
OCTET_LENGTH\par
OPTIONS\par
OVERLAPS\par
OVERLAY\par
OVERRIDING\par
PASCAL\par
PARAMETER_MODE\par
PARAMETER_ORDINAL_POSITION\par
PARAMETER_SPECIFIC_CATALOG\par
PARAMETER_SPECIFIC_NAME\par
PARAMETER_SPECIFIC_SCHEMA\par
PERMISSION\par
PLI\par
POSITION\par
RECOVERY\par
REPEATABLE\par
RESTORE\par
RETURNED_LENGTH\par
RETURNED_OCTET_LENGTH\par
RETURNED_SQLSTATE\par
ROUTINE_CATALOG\par
ROUTINE_NAME\par
ROUTINE_SCHEMA\par
ROW_COUNT\par
ROW_TYPE_CATALOG\par
ROW_TYPE_SCHEMA\par
ROW_TYPE_NAME\par
SCALE\par
SCHEMA_NAME\par
SELECTIVE\par
SELF\par
SENSITIVE\par
SERIALIZABLE\par
SERVER_NAME\par
SIMPLE\par
SOURCE\par
SPECIFIC_NAME\par
SIMILAR\par
STRUCTURE\par
STYLE\par
SUBCLASS_ORIGIN\par
SUBLIST\par
SUBSTRING\par
SUM\par
SYMMETRIC\par
SYSTEM\par
TABLE_NAME\par
TRANSACTIONS_COMMITTED\par
TRANSACTIONS_ROLLED_BACK\par
TRANSACTION_ACTIVE\par
TRANSFORM\par
TRANSLATE\par
TRIGGER_CATALOG\par
TRIGGER_SCHEMA\par
TRIGGER_NAME\par
TRIM\par
TYPE\par
UNCOMMITTED\par
UNLINK\par
UNNAMED\par
UPPER\par
USER_DEFINED_TYPE_CATALOG\par
USER_DEFINED_TYPE_NAME\par
USER_DEFINED_TYPE_SCHEMA\par
YES\par
\par
The SQL Standard allows implementations to define more reserved\par
words for their own DBMSs. Here are some words that are reserved\par
in some dialect of one of the major vendors (e.g., Oracle,\par
Sybase, Microsoft). You may be able to use these words as\par
<regular identifier>s, but if you do so, you will lose portability.\par
ABORT\par
ACCEPT\par
ANALYZE\par
ARCHIVELOG\par
ARRAY\par
ASSIGN\par
ASYNCH\par
ATTRIBUTES\par
AUDIT\par
BACKUP\par
BINARY_INTEGER\par
BODY\par
CACHE\par
CHAR_BASE\par
CLUSTER\par
CLUSTERS\par
COLAUTH\par
COLUMNS\par
COMPRESS\par
CONSTANT\par
CRASH\par
CURVAL\par
DATA_BASE\par
DATABASE\par
DBA\par
DEBUGOFF\par
DEBUGON\par
DEFINITION\par
DELAY\par
DELTA\par
DICTIONARY\par
DIGITS\par
DISPLACEMENT\par
DISPOSE\par
ELEMENT\par
ENTRY\par
EXCEPTION_INIT\par
FACTOR\par
FORM\par
FREELISTS\par
GENERIC\par
IDENTIFIED\par
IGNORE\par
INCLUDE\par
INDEX\par
INDEXES\par
INFILE\par
INSTEAD\par
INSTANCE\par
LIMITED\par
LIST\par
MAXEXTENTS\par
MINUS\par
MLSLABEL\par
MODE\par
NEW\par
NEW_TABLE\par
NEXTVAL\par
NOCOMPRESS\par
NONE\par
NUMBER\par
NUMBER_BASE\par
OFF\par
OID\par
OLD_TABLE\par
OPERATOR\par
OPERATORS\par
OTHERS\par
PACKAGE\par
PARTITION\par
PCTFREE\par
PENDANT\par
POSITIVE\par
PRAGMA\par
PREORDERED\par
PRIVATE\par
PROTECTED\par
RAISE\par
RANGE\par
RAW\par
RECORD\par
RELEASE\par
REM\par
RENAME\par
REPLACE\par
RESOURCE\par
REUSE\par
REVERSE\par
ROWID\par
ROWLABEL\par
ROWNUM\par
ROWTYPE\par
RUN\par
SEPARATE\par
SEQUENCE\par
SQLCA\par
SQLCODE\par
SQLERRM\par
SQLWARNING\par
STATEMENT\par
STDDEV\par
SUBTYPE\par
SYMBOL\par
TABAUTH\par
TABLES\par
TASK\par
TERM\par
TEST\par
THERE\par
TUPLE\par
USE\par
VARCHAR2\par
VARIANCE\par
VIEWS\par
VIRTUAL\par
VISIBLE\par
WAIT\par
XOR\par
\par
<identifier>\par
An <identifier> (a <token> that names an SQL Object) is a\par
character string, up to 128 characters long, from one Character\par
set. Within a CREATE SCHEMA statement, an <identifier> that\par
doesn't include an explicit <Schema name> names an Object that\par
belongs to the Schema you're creating. In any other SQL\par
statement, an <identifier> that doesn't include an explicit\par
<Schema name> names an Object that belongs to the Schema named in\par
the SCHEMA clause (or, if there is no SCHEMA clause, in the\par
AUTHORIZATION clause) of the MODULE statement that defines the\par
Module you're running. SQL recognizes three types of\par
<identifier>s: the <regular identifier>, the <SQL language\par
identifier>, and the <delimited identifier>.\par
\par
<regular identifier>\par
The required syntax for a <regular identifier> is:\par
\par
<regular identifier> ::=\par
Object name\par
\par
A <regular identifier> is a character string, up to 128\par
characters long, that consists only of letters, digits, and\par
underscore characters. It must begin with a letter.\par
\par
[Obscure Rule] We usually think of a "letter" as one of the\par
simple Latin letters, but in fact -- depending on the Character\par
set being used -- a "letter" can also be an accented character, a\par
character in a non-Latin alphabet, or a syllable or ideograph;\par
i.e., it can be any character with the Unicode alphabetic\par
property or ideographic property. The "letter" that begins a\par
<regular identifier> may not have the Unicode combining property;\par
the letters following it may, with the proviso that these\par
characters are not legal anywhere in a <regular identifier>:\par
     ## U+06DD, Arabic End of Ayah.\par
     ## U+06DE, Arabic Start of Rub El Hizb.\par
     ## U+20DD, Combining Enclosing Circle.\par
     ## U+20DE, Combining Enclosing Square.\par
     ## U+20DF, Combining Enclosing Diamond.\par
     ## U+20E0, Combining Enclosing Circle Backslash.\par
Depending on the Character set in use, you may also use these\par
characters in a <regular identifier>, as long as they're not used\par
as the <identifier>'s first character:\par
     ## U+00B7, Middle Dot\par
     ## U+02D0, Modifier Letter Triangular Colon\par
     ## U+20D1, Modifier Letter Half Triangular Colon\par
     ## U+0640, Arabic Tatweel\par
     ## U+0E46, Thai Character Maiyamok\par
     ## U+0EC6, Lao Ko La\par
     ## U+3005, Ideographic Iteration Mark\par
     ## U+3031 to U+3035 inclusive, variations of Vertical Kana Repeat Mark\par
     ## U+309B to U+309E inclusive, variations of Combining Katakana-Hiragana Sound Mark and Hiragana Iteration Mark\par
     ## U+30FC to U+30FE inclusive, variations of Katakana-Hiragana Prolonged Sound Mark and Katakana Iteration Mark\par
     ## U+FF70, Halfwidth Katakana-Hiragana Prolonged Sound Mark\par
     ## U+FF9E, Halfwidth Katakana Voiced Sound Mark\par
     ## U+FF9F, Halfwidth Katakana Semi-voiced Sound Mark\par
     ## U+200C, Zero Width Non-Joiner\par
     ## U+200D, Zero Width Joiner\par
     ## U+200E, Left-To-Right Mark\par
     ## U+200F, Right-To-Left Mark\par
     ## U+202A, Left-To-Right Embedding\par
     ## U+202B, Right-To-Left Embedding\par
     ## U+202C, Pop Directional Formatting\par
     ## U+202D, Left-To-Right Override\par
     ## U+202E, Right-To-Left Override.\par
     ## U+206A, Inhibit Symmetric Swapping\par
     ## U+206B, Activate Symmetric Swapping\par
     ## U+206C, Inhibit Arabic Form Shaping\par
     ## U+206D, Activate Arabic Form Shaping\par
     ## U+206E, National Digit Shapes\par
     ## U+206F, Nominal Digit Shapes\par
     ## U+FEFF, Zero-Width No-Break Space\par
     ## U+203F, Undertie\par
     ## U+2040, Character Tie\par
     ## U+FE33, Presentation Form for Vertical Low Line\par
     ## U+FE34, Presentation Form for Vertical Wavy Low Line\par
     ## U+FE4D, Dashed Low Line\par
     ## U+FE4E, Centreline Low Line\par
     ## U+FE4F, Wavy Low Line\par
     ## U+FF3F, Fullwidth Low Line\par
\par
A <regular identifier> is case insensitive. That is, uppercase\par
and lowercase letters within a <regular identifier> are\par
interchangeable; for example, these\par
three <regular identifier>s are exactly alike to an SQL parser:\par
\par
   SAMS_TABLE\par
\par
   sams_table\par
\par
   Sams_Table\par
\par
SQL doesn't allow a reserved <keyword> to be used as a <regular\par
identifier>. When comparing a <regular identifier> and a reserved\par
<keyword> to check for equality, your DBMS will replace the lowercase\par
letters in each with their uppercase equivalents and assume\par
that both belong to the SQL_TEXT Character set. In fact, your\par
DBMS will replace all lowercase letters in a <regular\par
identifier> with their uppercase equivalents prior to any\par
comparison and prior to storing the <identifier> either in a\par
Catalog's INFORMATION_SCHEMA or a diagnostics area.\par
\par
Here are some examples of <regular identifier>s:\par
\par
   TABLE_1   a <regular identifier>\par
\par
   OCELOT_COMPUTER_SERVICES   another <regular identifier>\par
\par
   DATE_   a <regular identifier> that looks like a reserved <keyword>\par
\par
   M\'dcLLER_DATEI   a <regular identifier> that doesn't exclusively use simple Latin letters\par
\par
If you want to restrict your code to Core SQL, make sure your\par
<regular identifier>s are no more than 18 characters long.\par
\par
<SQL language identifier>\par
The required syntax for an <SQL language identifier> is:\par
\par
<SQL language identifier> ::=\par
Object name\par
\par
An <SQL language identifier> is a <regular identifier> that\par
consists only of simple Latin letters, digits, and underscore\par
characters. It must begin with a simple Latin letter. Here are two\par
examples of <SQL language identifier>s:\par
\par
   TABLE_1\par
\par
   BOB_SCHEMA\par
\par
<delimited identifier>\par
The required syntax for a <delimited identifier> is:\par
\par
<delimited identifier> ::=\par
"Object name"\par
\par
A <delimited identifier> is a character string, up to 128\par
characters long, surrounded by a pair of double quote\par
marks. (The delimiting double quotes aren't part of the\par
<identifier>, so they're not included in the calculation of its\par
size.) Two consecutive double quotes within the character string\par
(i.e., "") represent one double quote mark; together, they count\par
as one character when calculating the size of the <identifier>.\par
\par
A <delimited identifier> is case sensitive. That is, uppercase\par
and lowercase letters within a <delimited identifier> are not\par
interchangeable; for example, to an SQL parser, these\par
three <delimited identifier>s\par
\par
   "SAMS_TABLE" \par
\par
   "sams_table"\par
\par
   "Sams_Table"\par
\par
represent three different names. Your DBMS will not replace lowercase\par
letters in a <delimited identifier> with their uppercase\par
equivalents prior to any comparison or storage operation.\par
\par
Here are some examples of <delimited identifier>s:\par
\par
   "table#1"   a <delimited identifier> that uses lowercase letters and a special character\par
\par
   "OCELOT Computer Services"   a <delimited identifier> that includes spaces\par
\par
   "DATE"   a <delimited identifier> that looks like a reserved <keyword>\par
\par
If you want to restrict your code to Core SQL, make sure your\par
<delimited identifier>s are no more than 18 characters long.\par
\par
<identifier> Equivalence\par
Two <regular identifier>s are the same if they consist of the\par
same characters. Your DBMS assumes the relevant Character set is\par
SQL_TEXT when comparing them.\par
\par
A <regular identifier> and a <delimited identifier> are the same\par
if the <regular identifier> consists of the same characters that\par
make up the body (i.e., the string of characters inside the\par
double quote marks) of the <delimited identifier>. Two\par
<delimited identifier>s are the same if their bodies consist of\par
the same characters. Your DBMS assumes the relevant Character set\par
is SQL_TEXT with a case sensitive Collation when comparing\par
<regular identifier>s to <delimited identifier>s and <delimited\par
identifier>s to one another.\par
\par
Because of the difference in case sensitivity between <regular\par
identifier>s and <delimited identifier>s, these two <regular\par
identifier>s are the same:\par
\par
   P_TABLE \par
\par
   p_table\par
\par
and both are equal to this <delimited identifier>:\par
\par
   "P_TABLE"\par
\par
but neither are equal to this <delimited identifier>:\par
\par
   "p_table"\par
\par
For another example, consider this group of <identifier>s:\par
     1. "E"   A <delimited (uppercase) identifier>.\par
     2. "e"   A <delimited (lowercase) identifier>.\par
     3. E     A <regular identifier>.\par
     4. e     A <regular identifier>.\par
     5. \'eb     A <regular identifier>.\par
\par
Because delimiting double quotes are not themselves part of an\par
<identifier>, the <delimited identifier> "E" is the same as the\par
<regular identifier> E, i.e., examples #1 and #3 are the same\par
name. Because lowercase letters in a <regular identifier> are\par
mapped to uppercase letters before comparison and storage,\par
examples #3 and #4 are the same name -- and they're also the same\par
name as example #1. Because lowercase letters in a <delimited\par
identifier> are not mapped to uppercase letters at any time,\par
example #2 is not the same name as example #4. Because there is no\par
mapping of accented characters in an <identifier>, example #5 is\par
not the same name as any of the others -- but \'eb is a letter, and\par
so qualifies as a <regular identifier>. (This example assumes\par
that the MS-Windows encoding scheme -- the one that Microsoft\par
calls "ANSI" -- is in use. This is not always the case; the\par
choice of possible Character sets is broad.)\par
\par
qualification of <identifier>s\par
All SQL Objects have names which are some combination of <regular\par
identifier>s, <delimited identifier>s, or <SQL language\par
identifier>s in an appropriate hierarchy of qualification. The\par
top of the hierarchy is [SQL-server name.], an implicit\par
name, therefore never specified. Then comes [<Catalog\par
name>.], which is the first level of the hierarchy that can be\par
explicitly stated. The next level is [<Schema name>.], then comes\par
[the name of an Object], and (if the Object is a Table) the final\par
level of the hierarchy is <.Column name>. The entire\par
qualification hierarchy always exists but is not necessarily\par
visible; the Standard contains rules by which high-level parts of\par
the combination may be omitted and their values assumed by default.\par
\page\par
Chapter 3 -- Numbers\par
\par
In SQL, a number -- i.e.: any signed, or unsigned, combination of\par
the digits 0 to 9 -- is either an exact numeric value or an\par
approximate numeric value. A numeric value may be a <literal>,\par
the value of a parameter or a host language variable or the\par
result of any expression or argument (including a possibly\par
qualified <Column name>) that evaluates to a number.\par
\par
Exact numeric values have a precision and a scale. The precision\par
is a positive integer that determines the number of significant\par
digits in the radix. The scale is a non-negative integer that\par
specifies the number of digits to the right of the value's\par
decimal point. Exact numeric values are stored in one of the four\par
exact numeric <data type>s: INTEGER, SMALLINT, NUMERIC or DECIMAL.\par
\par
Approximate numeric values, or floating point numbers, have two\par
parts: a signed decimal number (the mantissa) and a signed\par
integer (the exponent). The exponent specifies the magnitude of\par
the mantissa, so the value of such a number is the mantissa\par
raised to the power of the exponent. Approximate numeric values\par
also have a precision: a positive integer that specifies the\par
number of significant bits in the mantissa. Approximate numeric\par
values are stored in one of the three approximate numeric <data\par
type>s: FLOAT, REAL or DOUBLE PRECISION.\par
\par
Numeric <literal>s\par
\par
A <numeric literal> is any number in one of two categories: the\par
exact numeric integers and decimal numbers, and the approximate\par
numeric floating point numbers.\par
\par
<exact numeric literal>:\par
An <exact numeric literal> is either an integer or a decimal\par
number and its <data type> is exact numeric DECIMAL, though it is\par
compatible with the INTEGER, SMALLINT, DECIMAL, NUMERIC, REAL,\par
FLOAT and DOUBLE PRECISION <data type>s. The <literal>'s\par
precision is the number of digits it contains and its scale is\par
the number of digits to the right of its decimal point. A valid\par
integer <literal> is a signed or unsigned decimal integer with an\par
implicit scale of zero, e.g.:\par
   -65\par
   476\par
\par
A valid decimal <literal> is a signed or unsigned decimal integer\par
with an explicit scale (that can nevertheless default to zero), e.g.:\par
   65\par
   -819.3\par
   .67\par
   -.02\par
\par
<approximate numeric literal>:\par
An <approximate numeric literal> is a floating point number and\par
its <data type> is approximate numeric FLOAT, though it is\par
compatible with the INTEGER, SMALLINT, DECIMAL, NUMERIC, REAL,\par
FLOAT and DOUBLE PRECISION <data type>s. The <literal>'s\par
precision is the precision of its mantissa and its numeric value\par
is the product of its mantissa raised to the power of its\par
exponent. A valid <approximate numeric literal> is a floating\par
point number consisting of a possibly signed decimal number (the\par
mantissa) and a signed integer (the exponent), separated by the\par
upper case letter "E", e.g.:\par
   -1.27982E+5\par
   .465E-7\par
\par
Here are some equivalent <literal>s in "exact" and in "exponential" notation:\par
\par
Exact                  REAL                DOUBLE PRECISION\par
 .0000000000000001      1.0000000E-15       1.00000000000000E-015\par
-0.1                   -1.0000000E-01      -1.00000000000000E-001\par
1                       1.0000000E+00       1.00000000000000E+000\par
+10                     1.0000000E+01       1.00000000000000E+001\par
1000000000000000        1.0000000E+15       1.00000000000000E+015\par
\par
In this example, we've shown the real and double precision\par
numbers in a "normalized" form -- with one digit before the\par
decimal point. This is not mandatory, but strongly recommended.\par
We also show a fixed number of digits after the decimal point so\par
that maximum sizes will be apparent; in fact leading zeroes and\par
signs, as well as post-decimal zeros are all optional. The one\par
thing that is not optional is the letter "E" -- always upper-case.\par
\par
Numeric <data type>s\par
\par
A numeric <data type> is defined by a descriptor that contains four pieces of information:\par
     ## The <data type>'s name: either INTEGER, SMALLINT, NUMERIC, DECIMAL, FLOAT, REAL or DOUBLE PRECISION.\par
     ## The <data type>'s precision.\par
     ## The <data type>'s scale (for exact numeric types).\par
     ## Whether the <data type>'s precision and scale are expressed in decimal or binary terms.\par
\par
INTEGER:\par
The required syntax for an INTEGER <data type> specification is:\par
\par
INTEGER <data type> ::=\par
INTEGER\par
\par
INTEGER may be abbreviated as INT; it defines a set of possibly\par
signed whole numbers that have a scale of zero.\par
\par
[NON-PORTABLE] INT's precision must be greater than or equal to\par
the precision of SMALLINT but is non-standard because the SQL\par
Standard requires implementors to define INT's precision. FIPS\par
says that INT should have a precision of at least 9 digits.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book defines INT as a 32-bit, signed binary numeric, i.e.: INT\par
corresponds to the C long int data type. Thus, INT defines a set\par
of values that are possibly signed whole numbers with a precision\par
of 31 bits and a scale of zero, e.g.:\par
   -6500\par
   476673\par
\par
[NON-PORTABLE] INT's radix must be the same as the radix chosen\par
for SMALLINT but is non-standard because the SQL Standard\par
requires implementors to define whether INT and SMALLINT have a\par
binary radix or a decimal radix.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book defines INT and SMALLINT with a binary radix, i.e.: 2. This\par
gives INT a valid range of -2,147,483,647 to +2,147,483,647.\par
\par
SMALLINT:\par
The required syntax for a SMALLINT <data type> specification is:\par
\par
SMALLINT <data type> ::=\par
SMALLINT\par
\par
SMALLINT defines a set of possibly signed whole numbers that have\par
a scale of zero.\par
\par
[NON-PORTABLE] SMALLINT's precision must be less than or equal to\par
the precision of INT but is non-standard because the SQL Standard\par
requires implementors to define SMALLINT's precision. FIPS says\par
that SMALLINT should have a precision of at least 4 digits.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book defines SMALLINT as a 16-bit signed binary numeric, i.e.:\par
SMALLINT corresponds to the C int data type. Thus, SMALLINT\par
defines a set of values that are possibly signed whole numbers\par
with a precision of 15 bits and a scale of zero, e.g.:\par
   -65\par
   476\par
\par
[NON-PORTABLE] SMALLINT's radix must be the same as the radix\par
chosen for INT but is non-standard because the SQL Standard\par
requires implementors to define whether SMALLINT and INT have a\par
binary radix or a decimal radix.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book defines SMALLINT and INT with a binary radix, i.e.: 2. This\par
gives SMALLINT a range of -32,767 to +32,767.\par
\par
NUMERIC:\par
The required syntax for a NUMERIC <data type> specification is:\par
\par
NUMERIC <data type> ::=\par
NUMERIC [ (precision[,scale]) ]\par
\par
NUMERIC is a fixed-point numeric with a decimal precision and\par
decimal scale that are equal to the explicit precision and the\par
explicit scale given; it defines a set of values that are\par
possibly signed decimal numbers with an optionally defined\par
precision and optionally defined scale, e.g.:\par
   65.73\par
   .6\par
   -819.3\par
   -.25\par
\par
The optional precision, if specified, is an unsigned integer that\par
defines the maximum precision of acceptable values. The minimum precision is 1.\par
     ## [NON-PORTABLE] The default precision and the maximum\par
precision for NUMERIC are non-standard because the SQL Standard\par
requires implementors to define NUMERIC's default and maximum\par
precisions. Typically, the maximum precision is 15 (the FIPS\par
requirement); it may be as high as 38 (the DB2 maximum).\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows the precision of NUMERIC to range from 1 to 38,\par
with a default precision of 1. For example, this <data type> specification\par
defines a set of values that may range from -9999 to +9999 (4 digits defined):\par
\par
   NUMERIC(4)\par
\par
and these two equivalent <data type> specifications define a set\par
of values that may range from -9 to +9 (1 digit defined or default):\par
\par
   NUMERIC(1)\par
\par
   NUMERIC\par
\par
The optional scale, if specified, is an unsigned integer, greater\par
than zero, that defines the maximum number of digits in the scale\par
of acceptable values. It must be less than the precision and\par
defaults to zero if omitted. You may define a scale for NUMERIC\par
only if you also define a precision: if no precision is defined,\par
the scale must default to zero.\par
     ## [NON-PORTABLE] The maximum scale for NUMERIC must always\par
be less than the defined precision but is non-standard because\par
the SQL Standard requires implementors to define NUMERIC's\par
maximum scale.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows you to define a scale ranging from 1 to 38 for\par
NUMERIC. For example, this <data type> specification defines a set of\par
values that may range from -999.9 to +999.9 (3 digits before the\par
decimal point and 1 digit after the decimal point, for a total of 4 digits):\par
\par
   NUMERIC(4,1)\par
\par
DECIMAL:\par
The required syntax for a DECIMAL <data type> specification is:\par
\par
DECIMAL <data type> ::=\par
DECIMAL [ (precision[,scale]) ]\par
\par
DECIMAL may be abbreviated as DEC and is a fixed-point numeric\par
with a decimal scale that is equal to the explicit scale given;\par
it defines a set of values that are possibly signed decimal\par
numbers with an optionally defined precision and optionally defined scale, e.g.:\par
   65.73\par
   .6\par
   -819.3\par
   -.25\par
\par
The optional precision, if specified, is an unsigned integer that\par
defines the maximum precision of acceptable values. DEC's decimal\par
precision must be at least equal to the precision you define --\par
compare COBOL, which allows "PIC S9(3) COMP-1" but might allot a\par
full-word "PIC S9(5)" for internal storage. The minimum precision is 1.\par
     ## [NON-PORTABLE] The default precision, maximum precision\par
and exact precision for DEC are non-standard because the SQL\par
Standard requires implementors to define DEC's default, maximum\par
and exact precisions. Typically, the maximum precision is 15 (the\par
FIPS requirement); it may be as high as 38 (the DB2 maximum).\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows the precision of DEC to range from 1 to 38, with\par
a default precision of 1. DEC's decimal precision is equal to the\par
precision you define, i.e.: OCELOT treats DEC and NUMERIC as\par
synonyms. For example, this <data type> specification defines a set of values\par
that may range from -9999 to +9999 (4 digits defined):\par
\par
   DEC(4)\par
\par
and these two equivalent <data type> specifications define a set\par
of values that may range from -9 to +9 (1 digit defined or default):\par
\par
   DEC(1)\par
\par
   DECIMAL\par
\par
The optional scale, if specified, is an unsigned integer, greater\par
than zero, that defines the maximum number of digits in the scale\par
of acceptable values. It must be less than the precision and\par
defaults to zero if omitted. You may define a scale for DEC only\par
if you also define a precision: if no precision is defined, the scale must default to zero.\par
     ## [NON-PORTABLE] The maximum scale for DEC must always be\par
less than the defined precision but is non-standard because the\par
SQL Standard requires implementors to define DEC's maximum scale.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows you to define a scale ranging from 1 to 38 for\par
DEC. For example, this <data type> specification defines a set of\par
values that may range from -999.9 to +999.9 (3 digits before the\par
decimal point and 1 digit after the decimal point, for a total of 4 digits):\par
\par
   DEC(4,1)\par
\par
FLOAT:\par
The required syntax for a FLOAT <data type> specification is:\par
\par
FLOAT <data type> ::=\par
FLOAT [ (precision) ]\par
\par
FLOAT is a floating-point numeric with a binary precision; it\par
defines a set of values that are possibly signed floating point numbers.\par
\par
The optional precision, if specified, is an unsigned integer that\par
defines the maximum number of bits (including the hidden bit) in\par
the mantissa of acceptable values. FLOAT's binary precision must\par
be at least equal to the precision you define. The minimum precision is 1.\par
     ## [NON-PORTABLE] The default precision, maximum precision\par
and binary precision for FLOAT are non-standard because the SQL\par
Standard requires implementors to define FLOAT's default, maximum\par
and exact precisions. FIPS says that FLOAT should have a binary\par
precision of at least 20 digits.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows the precision of FLOAT to range from 1 to 53,\par
with a default precision of 53. Thus, FLOAT defines a set of\par
values that are possibly signed floating point numbers with this format:\par
[sign]+digit+period+ up to 14 digits+E+[sign]+ up to 3 digits\par
For example:\par
   -1.27982E+015\par
   .465E-007\par
The IEEE Standard for Binary Floating-Point Arithmetic (IEEE\par
Standard 754-1985) specifies two usual mantissa sizes: 24 and 53.\par
OCELOT supports both: regardless of the actual precision\par
specified for FLOAT, there are really only two possible results.\par
If you define FLOAT with a precision that is less than or equal\par
to 24, the actual binary precision will equal 24 bits in the\par
mantissa. For example, these two <data type> specifications are\par
equivalent: they both define a set of floating point values whose\par
mantissa may range up to a precision of 24 bits:\par
\par
   FLOAT(12)\par
\par
   FLOAT(24)\par
\par
If you define FLOAT with a precision between 25 and 53, the\par
actual binary precision will equal 53 bits in the mantissa. For\par
example, these three <data type> specifications are equivalent:\par
they all define a set of floating point values whose mantissa may\par
range up to a precision of 53 bits:\par
\par
   FLOAT\par
\par
   FLOAT(27)\par
\par
   FLOAT(53)\par
\par
[NON-PORTABLE] The minimum exponent and the maximum exponent for\par
FLOAT are non-standard because the SQL Standard requires\par
implementors to define FLOAT's minimum and maximum exponents.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book allows you to define an exponent ranging from -038 to +038 for FLOAT.\par
\par
REAL:\par
The required syntax for a REAL <data type> specification is:\par
\par
REAL <data type> ::=\par
REAL\par
\par
REAL is a floating-point numeric with a binary precision, i.e.:\par
REAL defines a set of values that are possibly signed floating point numbers.\par
\par
[NON-PORTABLE] The binary precision of REAL must be less than the\par
precision defined for DOUBLE PRECISION but is non-standard\par
because the SQL Standard requires implementors to define REAL's exact precision.\par
     [OCELOT Implementation]  The OCELOT DBMS that comes with\par
this book treats REAL as a synonym for FLOAT(24). Thus, REAL\par
defines a set of values that are possibly signed floating point\par
numbers with this format:\par
[sign]+digit+period+up to 6 digits+E+[sign]+ up to 2 digits\par
For example:\par
   -1.27982E+15\par
   .465E-07\par
\par
[NON-PORTABLE] The minimum exponent and the maximum exponent for\par
REAL are non-standard because the SQL Standard requires\par
implementors to define REAL's minimum and maximum exponents.\par
     [OCELOT Implementation]  The OCELOT DBMS that comes with\par
this book allows you to define an exponent ranging from -38 to +38 for REAL.\par
\par
DOUBLE PRECISION:\par
The required syntax for a DOUBLE PRECISION <data type> specification is:\par
\par
DOUBLE PRECISION <data type> ::=\par
DOUBLE PRECISION\par
\par
DOUBLE PRECISION is a floating-point numeric with a binary\par
precision, i.e.: DOUBLE PRECISION defines a set of values that\par
are possibly signed floating point numbers.\par
\par
[NON-PORTABLE] The binary precision of DOUBLE PRECISION must be\par
greater than the precision defined for REAL but is non-standard\par
because the SQL Standard requires implementors to define DOUBLE\par
PRECISION's exact precision. FIPS says that DOUBLE PRECISION\par
should have a binary precision of at least 30 digits.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book treats DOUBLE PRECISION as a synonym for FLOAT(53). Thus,\par
DOUBLE PRECISION defines a set of values that are possibly signed\par
floating point numbers with this format:\par
[sign]+digit+period+up to 14 digits+E+[sign]+up to 3 digits\par
For example:\par
   -1.27982E+015\par
   .465E-007\par
\par
[NON-PORTABLE] The minimum exponent and the maximum exponent for\par
DOUBLE PRECISION are non-standard because the SQL Standard\par
requires implementors to define DOUBLE PRECISION's minimum and maximum exponents.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows you to define an exponent ranging from -038 to\par
+038 for DOUBLE PRECISION.\par
\par
Now that we've described SQL's numeric <data type>s, let's look\par
at some example SQL statements that put them to use.\par
\par
These SQL statements make a Table with four exact numeric\par
Columns, insert a row, then search for any number less than -1.\par
\par
CREATE TABLE Exact_Examples (\par
     occurrence_decimal DECIMAL(5),\par
     occurrence_numeric NUMERIC(7,2),\par
     occurrence_integer INTEGER,\par
     occurrence_smallint SMALLINT);\par
\par
INSERT INTO Exact_Examples (\par
     occurrence_decimal,\par
     occurrence_numeric,\par
     occurrence_integer,\par
     occurrence_smallint)\par
     VALUES (12345, 12345, 12345, 12345);\par
\par
SELECT occurrence_decimal,\par
       occurrence_numeric,\par
       occurrence_integer,\par
       occurrence_smallint\par
FROM   Exact_Examples\par
WHERE  occurrence_decimal < -1;\par
\par
These SQL statements make a Table with three approximate numeric\par
Columns, insert a row, then search for any number less than 50000.\par
\par
CREATE TABLE Approximate_Examples (\par
     occurrence_float FLOAT(53),\par
     occurrence_real REAL,\par
     occurrence_double DOUBLE PRECISION);\par
\par
INSERT INTO Approximate_Examples (\par
     occurrence_float,\par
     occurrence_real,\par
     occurrence_double)\par
     VALUES (5E+2, 5E+2, 5E+2);\par
\par
SELECT occurrence_float,\par
       occurrence_real,\par
       occurrence_double\par
FROM   Approximate_Examples\par
WHERE  occurrence_float < 5E+4;\par
\par
IEEE Binary Floats\par
\par
According to the IEEE Standard for Binary Floating-Point\par
Arithmetic, "single-" and "double-precision" numbers are defined as follows:\par
\par
            SIGN     EXPONENT    MANTISSA    EXPONENT         RANGE\par
PRECISION   [BITS]   [BITS]      [BITS]*     [DECIMAL]        [DECIMAL]\par
Single      1         8          24           -38 to +35       7 digits\par
Double      1        11          53          -304 to +308     15 digits\par
(* The most significant mantissa bit is assumed to be 1. It is not stored.)\par
\par
You'd find the same specification in, say, an Intel FPU reference\par
text or a C++ manual. But we found discrepancies when looking\par
through documents for Java (where the exponent range is between\par
-35 and +38), Delphi (where the exponent range is between -45 and\par
+38 for single-precision and between -324 and -308 for double-\par
precision), FIPS SQL (where the FLOAT exponent+size are 9+47 and\par
the REAL exponent+size are 7+23). So, for portability reasons, it\par
would be a good idea to avoid the extremes of the IEEE range.\par
\par
Most DBMSs support IEEE float formats because FIPS requires that\par
the decimal ranges be supported and because the DBMS code itself\par
is written in a language that supports IEEE floats. But never\par
does an official SQL standard tell vendors "how to store the\par
data". So it might be that your DBMS actually uses the IEEE sizes\par
or it might be that your DBMS actually stores float decimal\par
literals (as xBase does) and processes with base-10 arithmetic.\par
If so, the following information doesn't apply to you.\par
\par
[Obscure Information] applies for the rest of this section.\par
\par
Binary Floats are not exact. The danger with these numbers is\par
easy to observe in a simple arithmetic exercise:\par
     ## Represent the number one-third (1/3) in decimal. The maximum number\par
of post-decimal digits (the scale) is large but not infinite. Result: 0.333333\par
     ## Take the sum of three occurrences of this number. Result:\par
0.333333 + 0.333333 + 0.333333 = 0.999999\par
     ## Note that the number is wrong (three thirds should equal\par
1). Increase the scale. Try again. You'll never get the correct\par
result because you can't accurately represent 1/3 as a decimal fraction.\par
\par
Now consider what would happen if your number was decimal, e.g.:\par
one-hundredth (1/100). Try to represent that number as a binary\par
fraction. If you have 16 binary digits (a 16-bit "word"), there\par
are only 2^16 discrete values you can represent, so you are dealing\par
in dividends which are sixty-five-thousand-five-hundred-and-thirty-sixths.\par
The closest number to 1/100 is thus 655/65536 -- i.e.: you have to store\par
655 in your word. This is a bit small. (Actually 655/65536 is closer\par
to 0.09945, so our error is about one part in a thousand.) In\par
other words: you cannot represent 1/100 as a binary fraction.\par
Worse, if you now convert back to decimal, you will probably get\par
1/100 again (the smart computer rounds up) so you won't see the\par
inaccuracy. Now consider the result of this SQL code:\par
\par
   SUM(column_containing_the_fractional_value_one_hundredth)\par
\par
If your Table has 1000 rows, then the conversion to binary\par
happens 1000 times -- cumulating the inaccuracy each time -- and\par
the conversion back to decimal happens only once, when the final\par
SUM is returned. Rounding won't save you, because the result --\par
99.45 -- is good to the nearest hundredth. And you won't check\par
the result in your head. Yet the result is "wrong".\par
\par
In theory, this arithmetic exercise is not a "floating point"\par
problem. We introduced the inaccuracy by converting a decimal\par
fraction to binary. Both fixed-point and floating-point binary\par
fractions have the same danger of inaccuracy, because the danger\par
lies in the fact that we're dealing with binary numbers -- not in\par
the fact that we're dealing with floating-point numbers. So, in\par
theory, the same "wrong" result could be returned for a DECIMAL\par
Column or a NUMERIC Column. In practice, though, the better SQL\par
DBMSs won't use binary fractions for DECIMAL or NUMERIC values.\par
Instead, like COBOL with "PIC 9V99", they actually store an\par
integer with an implied decimal point -- so the number 1/100 is,\par
internally, 1. No conversion occurs because an integral number of\par
hundredths are being stored, rather than a fraction.\par
\par
** TIP: Because of this, for all financial transactions, both\par
money and interest ought to be DECIMAL or NUMERIC. The frequency\par
of definitions like:\par
\par
   CREATE TABLE Table_1 (salary FLOAT);\par
\par
is a mistake, justified only by the fact that, in C or Pascal,\par
it's normal to define big or non-integer variables as floating-point.\par
\par
Numeric Operations\par
\par
A number is compatible with, and comparable to, all other numbers\par
-- that is, all numbers are mutually comparable and mutually\par
assignable. Numbers may not be directly compared with, or\par
directly assigned to, any other <data type> class, though\par
implicit type conversions can occur in expressions, SELECTs,\par
INSERTs, DELETEs and UPDATEs. Explicit numeric type conversions\par
can be forced with the CAST operator.\par
\par
CAST:\par
In SQL, CAST is a scalar operator that converts a given scalar\par
value to a given scalar <data type>. The required syntax for the CAST operator is:\par
\par
CAST (<cast operand> AS <cast target>)\par
\par
   <cast operand> ::= scalar_expression\par
\par
   <cast target> ::= <Domain name> | <data type>\par
\par
The CAST operator converts values of a source <data type> into\par
values of a target <data type>, where each <data type> is an SQL\par
pre-defined <data type> (data conversions between UDTs are done\par
with a user-defined cast). The source <data type>, or <cast\par
operand>, can be any expression that evaluates to a single value.\par
The target <data type>, or <cast target>, is either an SQL\par
predefined <data type> specification or the name of a Domain\par
whose defined <data type> is the SQL predefined <data type> that\par
you want to convert the value of "scalar_expression" into. (If\par
you use CAST (... AS <Domain name>), your current <AuthorizationID>\par
must have the USAGE Privilege on that Domain.)\par
\par
It isn't, of course, possible to convert the values of every\par
<data type> into the values of every other <data type>. For\par
numbers, the rules are:\par
     ## CAST (NULL AS <data type>) and CAST (numeric_source_is_a_null_value AS <data type>)\par
both result in a CAST result of NULL.\par
     ## You can CAST an exact numeric source to these targets:\par
exact numeric, approximate numeric, fixed length character\par
string, variable length character string, CLOB and NCLOB. You can\par
also CAST an exact numeric source to an interval target, provided\par
the target contains only one datetime field -- that is, you can\par
CAST an integer to INTERVAL YEAR or to INTERVAL MONTH, but you\par
can't CAST it to INTERVAL YEAR TO MONTH. You can CAST an exact\par
numeric source to a UDT target or a <reference type> target if a\par
user-defined cast exists for this purpose and your current\par
<AuthorizationID> has the EXECUTE Privilege on that user-defined cast.\par
     ## You can CAST an approximate numeric source to these\par
targets: exact numeric, approximate numeric, fixed length\par
character string, variable length character string, CLOB and\par
NCLOB. You can also CAST an approximate numeric source to a UDT\par
target or a <reference type> target if a user-defined cast exists\par
for this purpose and your current <AuthorizationID> has the\par
EXECUTE Privilege on that user-defined cast.\par
\par
When you CAST an exact numeric value or an approximate numeric\par
value to an exact numeric target -- for example: "CAST (25 AS\par
INTEGER)", "CAST (1.47E-5 AS DECIMAL(9,7))" -- or when you CAST an\par
exact numeric value or an approximate numeric value to an\par
approximate numeric target (for example: "CAST (25 AS FLOAT)",\par
"CAST (1.47E-5 AS DOUBLE PRECISION)" -- your DBMS checks whether\par
the source is a valid value for the target's <data type> (or if a\par
valid value -- one that doesn't lose any leading significant\par
digits -- can be obtained from the source by rounding or\par
truncation). If so, then the source is converted to that target\par
value. If neither of these are true, the CAST will fail: your\par
DBMS will return the SQLSTATE error 22003 "data exception-numeric\par
value out of range".\par
     [NON-PORTABLE] If your source value is not a valid value for\par
your target <data type>, then the value CAST is non-standard\par
because the SQL Standard requires implementors to define whether\par
the DBMS will round or will truncate the source to obtain a valid target value.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book truncates the source to obtain a valid target value.\par
\par
When you CAST an exact numeric value or an approximate numeric\par
value to a fixed length character string target, your DBMS\par
converts the number to the shortest string that represents that\par
number (that is, "CAST (25 AS CHAR(2))" results in the character\par
string '25', "CAST (1.47E-5 AS CHAR(8))" results in the character\par
string '.0000147', "CAST (-25 AS CHAR(3))" results in the\par
character string '-25', "CAST (+25 AS CHAR(3))" results in the\par
character string '25 ', "CAST (025 AS CHAR(3))" results in the\par
character string '25 ', "CAST (25. AS CHAR(3))" results in the\par
character string '25 ', "CAST (25.0 AS CHAR(4))" results in the\par
character string '25  ', and so on). If the length of the result\par
equals the fixed length of the target, then the source is CAST to\par
that result. If the length of the result is shorter than the\par
fixed length of the target, then the source is CAST to that\par
result, padded on the right with however many spaces is required\par
to make the lengths the same. If the length of the result is\par
longer than the fixed length of the target, the CAST will fail:\par
your DBMS will return the SQLSTATE error 22001 "data\par
exception-string data, right truncation". And if the result\par
contains any characters that don't belong to the target's\par
Character set, the CAST will also fail: your DBMS will return the\par
SQLSTATE error 22018 "data  exception-invalid character value for\par
cast". (Note: if your approximate numeric source value is zero,\par
the CAST result is this character string: '0E0'.)\par
\par
When you CAST an exact numeric value or an approximate numeric\par
value to a variable length character string target or a CLOB or\par
NCLOB target, your DBMS converts the number to the shortest\par
string that represents that number -- as with fixed length\par
target, it strips off leading plus signs, leading zeros, and any\par
insignificant decimal signs and trailing zeros. If the length of\par
the result is less than or equals the maximum length of the\par
target, then the source is CAST to that result. If the length of\par
the result is longer than the maximum length of the target, the\par
CAST will fail: your DBMS will return the SQLSTATE error 22001\par
"data exception-string data, right truncation". And if the result\par
contains any characters that don't belong to the target's\par
Character set, the CAST will also fail: your DBMS will return the\par
SQLSTATE error 22018 "data exception-invalid character value for cast".\par
\par
[Obscure Rule] The result of a CAST to a character string target\par
has the COERCIBLE coercibility attribute; its Collation is the\par
default Collation for the target's Character set.\par
\par
When you CAST an exact numeric value to an interval target, your\par
DBMS converts it to the value of the interval's single datetime\par
field represented by that number -- for example, "CAST (25 AS\par
INTERVAL YEAR)" results in an interval of 25 years. If the number\par
you're casting is too large for the precision of the target -- as\par
in "CAST (500 AS INTERVAL HOUR(2)" -- the CAST will fail: your DBMS\par
will return the SQLSTATE error 22015 "data exception-interval field overflow".\par
\par
When you CAST an exact numeric value or an approximate numeric\par
value to a UDT or a <reference type> target, your DBMS invokes\par
the user defined cast routine, with the source value as the\par
routine's argument. The CAST result is the value returned by the user defined cast.\par
\par
If you want to restrict your code to Core SQL, don't use <Domain\par
name> as a CAST target: CAST only to a <data type>.\par
\par
Assignment:\par
In SQL, when an exact numeric or an approximate numeric value is\par
assigned to an exact numeric target, the source is first\par
converted to an exact numeric value with the precision and scale\par
of the target. When an exact numeric or an approximate numeric\par
value is assigned to an approximate numeric target, the source is\par
first converted to an approximate numeric value with the\par
precision of the target. In either case, if the assignment would\par
result in the loss of any of the source value's most significant\par
digits, the assignment will fail: your DBMS will return the\par
SQLSTATE error 22003 "data exception-numeric value out of range".\par
     [NON-PORTABLE] If the assignment of a numeric value would\par
result in the loss of any of the source value's least significant\par
digits, the result is non-standard because the SQL Standard\par
requires implementors to define the result using either of two\par
options: (a) your DBMS may truncate the source to fit the target\par
and then make the assignment or (b) your DBMS may round the\par
source to fit the target and then make the assignment.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book truncates the source value to fit the target.\par
\par
[Obscure Rule] Since only SQL accepts null values, when a null\par
value is taken from SQL-data to be assigned to a numeric target,\par
your target's value is not changed. Instead, your DBMS will set\par
the target's indicator parameter to -1, to indicate that an\par
assignment of the null value was attempted. If your target\par
doesn't have an indicator parameter, the assignment will fail:\par
your DBMS will return the SQLSTATE error 22002 "data\par
exception-null value, no indicator parameter". Going the other\par
way, there are two ways to assign a null value to an SQL-data\par
target. Within SQL, you can use the <keyword> NULL in an INSERT\par
or an UPDATE statement to indicate that the target should be set\par
to NULL; that is, if your source is NULL, your DBMS will set your\par
target to NULL. Outside of SQL, if your source has an indicator\par
parameter that is set to -1, your DBMS will set your target to\par
NULL (regardless of the value of the source). (An indicator\par
parameter with a value less than -1 will cause an error: your\par
DBMS will return the SQLSTATE error 22010 "data exception-invalid\par
indicator parameter value".) We'll talk more about indicator\par
parameters in our chapters on SQL binding styles.\par
\par
As an example, assume that you have an INTEGER Column and need to\par
assign a non-integer value to it. The result will depend not only\par
on what the source value is, but also on whether your DBMS uses\par
rounding or truncation to turn it into an integer. Here are the\par
choices (note that "rounding toward zero" is really truncating):\par
\par
           Rounding     Rounding      Rounding     Rounding\par
Source     toward       toward        toward       toward\par
value      +infinity    -infinity     zero         nearest\par
 1.5       2             1             1            2\par
-1.5       1            -2            -1           -2\par
etc.\par
\par
Most DBMSs use truncation, but these SQL statements show how to force the rounding method you prefer:\par
\par
   -- rounding toward positive infinity\par
   CASE numeric_expression - CAST (numeric_expression AS INTEGER)\par
       WHEN > 0 numeric_expression+1\par
       WHEN < 0 numeric_expression-1\par
       ELSE numeric_expression\par
   END\par
\par
   -- rounding toward negative infinity\par
   CASE numeric_expression\par
        WHEN > 0 CAST (numeric_expression AS INTEGER)\par
        WHEN < 0 CAST (0 - (ABS(numeric_expression) + 0.5) AS INTEGER))\par
        ELSE numeric_expression\par
   END\par
\par
   -- rounding toward zero\par
   CAST (numeric_expression AS INTEGER)\par
\par
   -- rounding toward nearest\par
   CAST (numeric_expression + 0.5 AS INTEGER)\par
\par
Comparison:\par
SQL provides the usual scalar comparison operators -- = and <>\par
and < and <= and > and >= -- to perform operations on numbers.\par
All of them will be familiar; there are equivalent operators in\par
other computer languages. Numbers are compared in the usual\par
manner. If any of the comparands are NULL, the result of the\par
operation is UNKNOWN. For example:\par
\par
   97 = 105.2\par
\par
returns FALSE.\par
\par
   97 <> \{result is NULL\}\par
\par
returns UNKNOWN.\par
\par
SQL also provides three quantifiers -- ALL, SOME, ANY -- which\par
you can use along with a comparison operator to compare a value\par
with the collection of values returned by a <table subquery>.\par
Place the quantifier after the comparison operator, immediately\par
before the <table subquery>. For example:\par
\par
   SELECT decimal_column\par
   FROM   Table_1\par
   WHERE  decimal_column < ALL (\par
      SELECT integer_column\par
      FROM   Table_2);\par
\par
ALL returns TRUE either (a) if the collection is an empty set\par
(i.e.: if it contains zero rows) or (b) if the comparison\par
operator returns TRUE for every value in the collection. ALL\par
returns FALSE if the comparison operator returns FALSE for at\par
least one value in the collection.\par
\par
SOME and ANY are synonyms. They return TRUE if the comparison\par
operator returns TRUE for at least one value in the collection.\par
They return FALSE either (a) if the collection is an empty set or\par
(b) if the comparison operator returns FALSE for every value in\par
the collection. (The search condition "= ANY (collection)" is\par
equivalent to "IN (collection)".)\par
\par
Other Operations:\par
With SQL, you have several other operations that you can perform\par
on numbers, or on other values to get a numeric result.\par
\par
## Arithmetic\par
SQL provides the usual scalar arithmetic operators -- + and - and\par
* and / -- to perform operations on numbers. All of them will be\par
familiar; there are equivalent operators in other computer\par
languages. If any of the operands are NULL, the result of the\par
operation is also NULL.\par
\par
monadic + and monadic -\par
When used alone, + and - change the sign of an operand (e.g.: a\par
<literal> or a Column instance or a host variable). For example:\par
\par
   SELECT -5, -(-occurrence_decimal)\par
   FROM   Exact_Examples\par
   WHERE  occurrence_integer = +5;\par
\par
** TRAP: Since two dashes (i.e.: --) means "comment start" in\par
SQL, our example of a double negative has to be\par
"-(-occurrence_decimal)" rather than "--occurrence_decimal".\par
\par
dyadic + and dyadic - and dyadic * and dyadic /\par
When used between two operands, + and - and * and / stand for add\par
and subtract and multiply and divide, respectively, and return\par
results according to the usual rules. For example:\par
\par
   SELECT occurrence_integer + 5, (occurrence_integer * 7) / 2\par
   FROM   Exact_Examples\par
   WHERE  occurrence_integer < (:host_variable - 7);\par
\par
precedence\par
Dyadic * and / have priority over dyadic + and -, but monadic +\par
and - have top priority. It's good style to use parentheses for\par
any expressions with different operators.\par
\par
errors\par
The two common arithmetic exception conditions are:\par
SQLSTATE 22003 -- data exception - numeric value out of range\par
SQLSTATE 22012 -- data exception - division by zero\par
\par
Here is a snippet of an embedded SQL program that checks for\par
overflow after executing a statement that contains addition:\par
\par
   EXEC SQL UPDATE Exact_Examples\par
            SET    occurrence_smallint = occurrence_decimal + 1;\par
   if (strcmp(sqlstate,"22003") printf("Overflow! Operation cancelled ...\\n");\par
\par
Error checks should follow every execution of an SQL statement,\par
but imagine that the EXACT_EXAMPLES Table has a million rows. To\par
avoid the situation where, after chugging through 999,999 rows,\par
your application collapses on the last one with "Overflow! Operation cancelled ...",\par
try this code:\par
\par
   EXEC SQL UPDATE Exact_Examples\par
            SET    occurrence_smallint =\par
            CASE\par
              WHEN occurrence_smallint = 32767 THEN 0\par
              ELSE occurrence_smallint = occurrence_smallint + 1\par
            END;\par
\par
** TIP: CASE expressions are good for taking error-abating actions in advance.\par
\par
** TIP: SQL has no low-level debugging features, so sometimes you\par
will need to force an error somewhere in a complex expression, to\par
be sure it is actually being executed. For this purpose, insert\par
code that would cause a numeric overflow.\par
\par
Mixing numeric <data type>s --\par
As we said earlier, all numbers -- any <data type>, exact or\par
approximate -- are compatible. That means that you can mix them\par
together in any numeric expression -- which leads to the\par
question: what comes out when you do mix them, i.e.: what is the\par
<data type>, precision and scale of the result? The SQL Standard\par
says these are the results you will get:\par
\par
[NON-PORTABLE] An exact numeric value added to, subtracted from,\par
multiplied by or divided by an exact numeric value yields an\par
exact numeric value with a precision that is non-standard because\par
the SQL Standard requires implementors to define the precision of\par
the result. For all these operations, if the result of the\par
operation can't be exactly represented with the correct precision\par
and scale, the operation will fail: your DBMS will return the\par
SQLSTATE error 22003 "data exception-numeric value out of range".\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book gives the result of an arithmetic operation between exact\par
numeric operands a <data type> and precision that matches the\par
<data type> and precision of the operand with the most exact\par
precision, e.g.: for an operation with SMALLINT and INT operands,\par
the result is an INT type.\par
\par
An exact numeric value added to or subtracted from an exact\par
numeric value yields a result with a scale size that matches the\par
size of scale of the operand with the largest scale, e.g.: for an\par
operation with DECIMAL(6,2) and INT operands, the result has a\par
scale of 2.\par
\par
An exact numeric value multiplied by an exact numeric value\par
yields a result with a scale size that is the sum of the scale\par
sizes of the operands, e.g.: for an operation with DECIMAL(6,2)\par
and NUMERIC(10,4) operands, the result has a scale of 6.\par
\par
[NON-PORTABLE] An exact numeric value divided by an exact numeric\par
value yields a result with a scale size that is non-standard\par
because the SQL Standard requires implementors to define the\par
scale size of the result.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book gives the result of a division operation between exact\par
numeric operands a scale size that matches the size of scale of\par
the operand with the largest scale, e.g.: for an operation with\par
DECIMAL(6,2) and NUMERIC(10,4) operands, the result has a scale\par
of 4.\par
\par
[NON-PORTABLE] An approximate numeric value added to, subtracted\par
from, multiplied by or divided by an approximate numeric value\par
yields an approximate numeric value with a precision and scale\par
that are non-standard because the SQL Standard requires\par
implementors to define the precision and scale of the result. If\par
the exponent of the result doesn't fall within the DBMS's\par
supported exponent range, the operation will fail: your DBMS will\par
return the SQLSTATE error 22003 "data exception-numeric value out of range.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book gives the result of an arithmetic operation between\par
approximate numeric operands a <data type> and precision that\par
matches the <data type> and precision of the operand with the\par
most exact precision, e.g.: for an operation with REAL and DOUBLE\par
PRECISION operands, the result is a DOUBLE PRECISION type.\par
\par
[NON-PORTABLE] An approximate numeric value added to, subtracted\par
from, multiplied by or divided by an exact numeric value (or vice\par
versa) yields an approximate numeric value with a precision and\par
scale that are non-standard because the SQL Standard requires\par
implementors to define the precision and scale of the result.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book gives the result of an arithmetic operation between\par
approximate numeric and exact numeric operands a <data type> and\par
precision that matches the <data type> and precision of the\par
operand with the most exact precision, e.g.: for an operation\par
with INT and DOUBLE PRECISION operands, the result is a DOUBLE PRECISION type.\par
\par
In other words, the Standard always evades the big question:\par
what's the result precision? To put this into perspective,\par
consider a DBMS faced with a tough operation: "add 1 to a Column\par
which is defined as DECIMAL(5)". Since the Column might already\par
contain the value 99999, adding 1 might yield 100000 -- a\par
DECIMAL(6) value. For such cases, the DBMS must decide what to do\par
before executing, because the application program, which will\par
receive the result, must know the size in advance. The DBMS has two choices:\par
     ## Let it grow. The result is DECIMAL(6) if the operation is\par
addition and slightly more if the operation is multiplication.\par
This choice has the advantage that it eliminates "overflow"\par
errors. But there are still undefined areas: What happens if the\par
DECIMAL precision is already at the maximum? What happens if the\par
operation adds 1 to a SMALLINT -- does the <data type> upgrade to\par
INTEGER so that the increased precision is valid?\par
     ## Chop it. The result is DECIMAL(5), regardless. This risks\par
failure on even the most innocuous operations, but it's a simple\par
rule to follow: output precision = input precision. Programmers\par
can understand it.\par
These choices are not mutually exclusive and your DBMS might make\par
different decisions for different operations.\par
\par
** TIP: Before you divide, decide how many digits should follow\par
the decimal point in the result. The number will almost certainly\par
be greater than the number you start with; for instance, "12/5"\par
(dividing scale-0 integers) yields "2.4" (a scale-1 decimal\par
number) -- you hope. Your DBMS may increase the scale\par
automatically, but the Standard doesn't say it must. To force the\par
result, use this SQL code:\par
\par
   CAST (12 AS DECIMAL(3,1))/5    -- yields 2.4\par
\par
Incidentally, there are several bad ways to cast. This SQL code:\par
\par
   CAST ((12/5) AS DECIMAL(3,1))\par
\par
will yield 2.0 if your DBMS doesn't increase the scale\par
automatically -- be sure to CAST the source, not the result. This SQL code:\par
\par
   CAST (12 AS DECIMAL(2,1))/5\par
\par
will cause an error -- be sure your source value fits in the CAST target.\par
\par
Floating-point arithmetic --\par
If you want fast and complex floating-point arithmetic, buy a\par
good Fortran compiler: SQL can't handle the fancy stuff. In particular:\par
     ## SQL lacks useful functions which in other languages are\par
built-in, e.g.: the ability to detect NaN (Not a Number).\par
     ## SQL vendors are only obliged to define and to accept IEEE\par
numbers. They can do arithmetic without paying any attention to\par
the IEEE standard at all. In particular, some vendors may use the\par
same routines for approximate numerics as they use for exact\par
numerics, and exact is slower.\par
\par
Still, you can do the basic arithmetic functions -- add, subtract, divide,\par
multiply, compare -- provided you take sensible precautions.\par
\par
comparing two floating-point numbers for equality\par
Think of the inexact result produced when 1/100 was converted to\par
a binary fraction. Because of this, the following SQL code:\par
\par
   ... WHERE float_column = 1.0E+1\par
\par
will fail if, e.g.: the value of FLOAT_COLUMN was originally\par
produced by summing 1/100 one hundred times. To get the\par
"approximately right" answer, compare the absolute difference\par
between the two numbers against a constant, e.g.: with this SQL code:\par
\par
   ... WHERE ABS(float_column - 1.0E+1) < :epsilon\par
\par
To choose a value for epsilon, remember that the accuracy of\par
floating point numbers varies -- by definition -- according to\par
magnitude. For example, between 1.0 and 2.0 there are about 8\par
million numbers, but between 1023.0 and 1024.0 there are only\par
about 8 thousand numbers (assuming IEEE single-precision\par
standards). In this example, since the comparison is for\par
equality, we know that FLOAT_COLUMN must be about the same\par
magnitude as the <literal> 1.0E+1, therefore a reasonable value\par
for epsilon is 1/8000000 or 1.25E-7. When you don't know one of\par
the comparands in advance, start with a value for epsilon that's\par
half as large, multiply it by the sum of the comparands (thus\par
changing its magnitude to the comparands' magnitude) and then\par
compare with this SQL code:\par
\par
   ... WHERE ABS(float_column_1 - float_column_2) <\par
             (ABS(float_column_1 + float_column_2) * :epsilon/2)\par
\par
subtraction\par
We did this operation with an IEEE-compatible compiler:\par
   1234.567 - 1234.000\par
The result was: 0.5670166\par
\par
Both inputs are single-precision floating point numbers (7 digits\par
precision), accurate to the third decimal place. Unfortunately,\par
so is the output. Although the subtraction decreased the\par
magnitude, causing the decimal place to shift right, the accuracy\par
was unaffected: the extra digits after 0.567 are spurious\par
precision. If a subtraction causes a drop in magnitude, spurious\par
precision is likely. (This is often called the "insignificant\par
digits" problem and applies to addition too, if operands can have negative signs.)\par
\par
** TIP: Eliminate insignificant digits using two CASTs. In this\par
example, we know what the input is, so we could clear everything\par
after the result's third decimal place with this SQL code:\par
\par
   CAST (CAST ((1.234567E+04 - 1.234000E+04) AS DEC(8,3)) AS REAL)\par
\par
Here, by casting to DEC(8,3) we first change the result 0.5670166\par
to 0.567. The second CAST casts this back to REAL, with a\par
subsequent result of 0.5670000. Casting is a straightforward way\par
to strip -- unfortunately, it's only useful if you know a lot about the data.\par
\par
** TIP: If an SQL statement does both addition and subtraction,\par
parenthesize so that the addition happens first -- this makes a\par
drop in magnitude less likely to occur. For example, change this SQL statement:\par
\par
   UPDATE Approximate_Examples\par
   SET    occurrence_real = occurrence_real - :host_variable + 1.1E+01;\par
\par
to this SQL statement:\par
\par
   UPDATE Approximate_Examples\par
   SET    occurrence_real = occurrence_real - (:host_variable + 1.1E+01);\par
\par
By the way, don't just transpose the operands. Order of expression evaluation varies.\par
\par
division\par
When doing floating-point division, keep in mind that there is\par
such a thing as "negative zero" and there are floating-point\par
numbers which are so small that you'll get an exception when you\par
divide by them, even though they don't exactly equal zero. This\par
makes it a little harder to test for "division by zero" errors in advance.\par
\par
## Scalar functions\par
SQL provides ten scalar functions that return a number: the <case\par
expression>, the <cast specification>, the <position expression>,\par
the three <length expression>s, the <extract expression>, the\par
<cardinality expression>, the <absolute value expression> and the\par
<modulus expression>. Only the last two also operate exclusively\par
on numbers; these are described below. We'll discuss the rest in\par
other chapters; for now, just remember that they evaluate to a\par
number and can therefore be used anywhere in an SQL statement\par
that a number could be used.\par
\par
<absolute value expression> --\par
The required syntax for an <absolute value expression> is:\par
\par
<absolute value expression> ::=\par
ABS(numeric_argument)\par
\par
ABS operates on an argument that evaluates to a number. It strips\par
a negative sign (if it's present) from the argument and returns a\par
non-negative number whose <data type> is the same as the\par
argument's <data type>, e.g.: ABS(-17) returns 17, ABS(17)\par
returns 17 and ABS(0) returns 0. If the argument is NULL, ABS returns NULL.\par
\par
If the result of ABS is a number that doesn't fit into the\par
argument's <data type> range, the function will fail: your DBMS\par
will return the SQLSTATE error 22003 "data exception-numeric value out of range".\par
\par
ABS is new to SQL with SQL3 and is also supported by ODBC. If\par
your DBMS doesn't support ABS, you can simulate it with this SQL statement:\par
\par
   CASE\par
      WHEN ...<0 THEN ...*-1\par
      ELSE ...\par
   END\par
\par
If your DBMS doesn't support CASE, you can still get an absolute\par
value of a number with this arithmetic expression:\par
   (number * number) / number\par
\par
[Obscure Rule] ABS can also operate on an interval. We've ignored\par
this option for now -- look for it in our chapter on temporal values.\par
\par
<modulus expression> --\par
The required syntax for a <modulus expression> is:\par
\par
<modulus expression> ::=\par
MOD(dividend_argument,divisor_argument)\par
\par
MOD operates on two arguments, both of which must evaluate to an\par
exact numeric integer. It divides the first number by the second\par
number and returns the operation's remainder as a non-negative\par
exact numeric integer whose <data type> is the same as the\par
divisor_argument's <data type>, e.g.: MOD(35,4) returns 3 and\par
MOD(32,4) returns 0. If either argument is NULL, MOD returns\par
NULL. If the divisor_argument is zero, the function will fail:\par
your DBMS will return the SQLSTATE error 22012 "data exception-division by zero".\par
\par
MOD is new to SQL with SQL3. In the Standard, MOD stands for\par
"modulus" but the result of this function is not actually a\par
modulus -- it is a remainder achieved "by means of a modulus".\par
\par
## Set functions\par
SQL provides five set functions that return a number: COUNT(*),\par
COUNT, AVG, SUM and GROUPING, all of which also operate on\par
numbers. In addition to these, the set functions MAX and MIN also\par
operate on numbers. Since none of these operate exclusively with\par
numeric arguments, we won't discuss them here; look for them in\par
our chapter on set functions.\par
\par
## Predicates\par
In addition to the comparison operators, SQL provides eight other\par
predicates that operate on numbers: the <between predicate>, the\par
<in predicate>, the <null predicate>, the <exists predicate>, the\par
<unique predicate>, the <match predicate>, the <quantified\par
predicate> and the <distinct predicate>. Each will return a\par
boolean value: either TRUE, FALSE or UNKNOWN. None of these\par
operate strictly on numbers, so we won't discuss them here. Look\par
for them in our chapter on search conditions.\par
\par
Choosing the right <data type>\par
\par
When you're defining a <data type> specification, think about\par
whether you really need a numeric <data type> for the expected\par
data. Don't just ask: are the values always bunches of digits?\par
For example, phone numbers are digits but if you define a DECIMAL\par
<data type> for them you might lose a valuable piece of\par
information -- whether a leading zero is significant.\par
Identification numbers are digits but if you define a DECIMAL\par
<data type> for them you might have trouble calculating the check\par
digit, which is usually based on a substring extraction. Instead,\par
consider the question: will I ever need to do standard arithmetic\par
operations on the data? If the answer is "no", use a string <data\par
type> rather than a numeric type.\par
\par
If the answer is "yes", then consider which numeric type to\par
choose by answering the question: are the values going to be seen\par
by users or by programs written in other computer languages? If\par
the former: it's a lot easier to explain to a user looking at a\par
blank six-position field on a screen: "you can type in a number\par
between -99999 and +9999" instead of "you can type in a number\par
between -32767 and +32767". If the latter: pick the numeric type\par
that's closest to the variable type that the other computer\par
language will use. You can also follow this short decision tree:\par
\par
IF (numeric values might be huge (> 1 quadrillion) or tiny (< 1 quadrillionth)\par
  /* you need an approximate numeric <data type> */\par
  IF (your host program uses C "float" or Delphi "Single")\par
  AND(7 digit precision is satisfactory)\par
    /* you need a REAL <data type> */\par
  IF (your host program uses C or Delphi "double")\par
  AND(15 digit precision is satisfactory)\par
    /* you need a DOUBLE PRECISION <data type> */\par
ELSE (if values are not huge or tiny)\par
  /* you need an exact numeric <data type> -- the usual case */\par
  IF (your host program uses C "short int" or Delphi "SmallInt" */\par
    /* you need a SMALLINT <data type> */\par
  IF (your host program uses C "int" or Delphi "Longint" */\par
    /* you need an INTEGER <data type> */\par
  ELSE\par
    /* you don't need an exact match with host-language variables */\par
    IF (you are accustomed to the word NUMERIC because Oracle uses it)\par
      /* you need a NUMERIC <data type> */\par
    ELSE\par
      /* you need a DECIMAL <data type> */\par
\par
Once you've gone through the decision tree, calculate the\par
required precision and scale by looking at all expected values.\par
\par
Dialects\par
\par
The "typical" SQL DBMS supports most of the standard numeric data\par
types, but often uses preferred local names. Here are some lists\par
of local types derived from vendor manuals. The correlation with\par
the leftmost ("Standard") column is sometimes imprecise. "ODBC"\par
is not a DBMS but a spec.\par
\par
Standard           Oracle   DB2                Sybase     ODBC\par
SMALLINT           NUMBER   SMALLINT           SMALLINT   SMALLINT\par
INTEGER            NUMBER   INTEGER            INT        INTEGER\par
DECIMAL            NUMBER   DECIMAL            MONEY      DECIMAL\par
NUMERIC            NUMBER   NUMERIC            MONEY      NUMERIC\par
REAL               NUMBER   REAL               FLOAT      REAL\par
FLOAT              NUMBER   FLOAT              FLOAT      FLOAT\par
DOUBLE PRECISION   NUMBER   DOUBLE PRECISION   FLOAT      DOUBLE PRECISION\par
\par
Other commonly-seen numeric data types include TINYINT (8-bit signed integer),\par
BIGINT (64-bit signed integer) and SERIAL (integer that goes up by 1 for each new inserted row).\par
\par
The SQL Library\par
\par
Before we finish discussing numbers, it's time to add something\par
to our "SQL library". To be worthy of addition to the SQL\par
library, a routine must (a) be good clean SQL, (b) be callable\par
from C and Delphi, (c) be actually useful in C and Delphi because\par
it does something that those languages can't and (d) have nothing\par
at all do with "databases" -- it should be available for use just\par
like any general function library.\par
\par
Our addition to the SQL library for this chapter will be a\par
calculator. It won't match C and Delphi for floating-point\par
arithmetic, but it will give more exact answers. Here it is.\par
\par
Function: SQL_calculator (lp_calculation, lp_result, lp_error)\par
\par
Pass: An arithmetic expression in the string lp_calculation. The\par
string may contain any combination of numeric <literal>s (in\par
valid SQL form), the operators * + * / MOD ABS and parentheses.\par
\par
Return:  lp_result: Result of expression (a string containing a number).\par
         lp_error:  SQLSTATE and error message, if expression was invalid.\par
\par
Example: Try passing the expression:\par
   (1.000001 + 1.999990) * 11000\par
to our calculator. Our proc gives the correct result:\par
"33000.0000000". The compilers we tested gave the wrong result:\par
"32999.9901000". (Remember that in SQL all the <literal>s in this\par
expression are DECIMAL, not floating-point, <literal>s.)\par
\page\par
CHAPTER THREE -- Numbers\par
\par
In SQL, a number -- i.e.: any signed, or unsigned, combination of\par
the digits 0 to 9 -- is either an exact numeric value or an\par
approximate numeric value. A numeric value may be a <literal>,\par
the value of a parameter or a host language variable or the\par
result of any expression or argument (including a possibly\par
qualified <Column name>) that evaluates to a number.\par
\par
Exact numeric values have a precision and a scale. The precision\par
is a positive integer that determines the number of significant\par
digits in the radix. The scale is a non-negative integer that\par
specifies the number of digits to the right of the value's\par
decimal point. Exact numeric values are stored in one of the four\par
exact numeric <data type>s: INTEGER, SMALLINT, NUMERIC or DECIMAL.\par
\par
Approximate numeric values, or floating point numbers, have two\par
parts: a signed decimal number (the mantissa) and a signed\par
integer (the exponent). The exponent specifies the magnitude of\par
the mantissa, so the value of such a number is the mantissa\par
raised to the power of the exponent. Approximate numeric values\par
also have a precision: a positive integer that specifies the\par
number of significant bits in the mantissa. Approximate numeric\par
values are stored in one of the three approximate numeric <data\par
type>s: FLOAT, REAL or DOUBLE PRECISION.\par
\par
Numeric <literal>s\par
\par
A <numeric literal> is any number in one of two categories: the\par
exact numeric integers and decimal numbers, and the approximate\par
numeric floating point numbers.\par
\par
<exact numeric literal>:\par
An <exact numeric literal> is either an integer or a decimal\par
number and its <data type> is exact numeric DECIMAL, though it is\par
compatible with the INTEGER, SMALLINT, DECIMAL, NUMERIC, REAL,\par
FLOAT and DOUBLE PRECISION <data type>s. The <literal>'s\par
precision is the number of digits it contains and its scale is\par
the number of digits to the right of its decimal point. A valid\par
integer <literal> is a signed or unsigned decimal integer with an\par
implicit scale of zero, e.g.:\par
   -65\par
   476\par
\par
A valid decimal <literal> is a signed or unsigned decimal integer\par
with an explicit scale (that can nevertheless default to zero), e.g.:\par
   65\par
   -819.3\par
   .67\par
   -.02\par
\par
<approximate numeric literal>:\par
An <approximate numeric literal> is a floating point number and\par
its <data type> is approximate numeric FLOAT, though it is\par
compatible with the INTEGER, SMALLINT, DECIMAL, NUMERIC, REAL,\par
FLOAT and DOUBLE PRECISION <data type>s. The <literal>'s\par
precision is the precision of its mantissa and its numeric value\par
is the product of its mantissa raised to the power of its\par
exponent. A valid <approximate numeric literal> is a floating\par
point number consisting of a possibly signed decimal number (the\par
mantissa) and a signed integer (the exponent), separated by the\par
upper case letter "E", e.g.:\par
   -1.27982E+5\par
   .465E-7\par
\par
Here are some equivalent <literal>s in "exact" and in "exponential" notation:\par
\par
Exact                  REAL                DOUBLE PRECISION\par
 .0000000000000001      1.0000000E-15       1.00000000000000E-015\par
-0.1                   -1.0000000E-01      -1.00000000000000E-001\par
1                       1.0000000E+00       1.00000000000000E+000\par
+10                     1.0000000E+01       1.00000000000000E+001\par
1000000000000000        1.0000000E+15       1.00000000000000E+015\par
\par
In this example, we've shown the real and double precision\par
numbers in a "normalized" form -- with one digit before the\par
decimal point. This is not mandatory, but strongly recommended.\par
We also show a fixed number of digits after the decimal point so\par
that maximum sizes will be apparent; in fact leading zeroes and\par
signs, as well as post-decimal zeros are all optional. The one\par
thing that is not optional is the letter "E" -- always upper-case.\par
\par
Numeric <data type>s\par
\par
A numeric <data type> is defined by a descriptor that contains four pieces of information:\par
     ## The <data type>'s name: either INTEGER, SMALLINT, NUMERIC, DECIMAL, FLOAT, REAL or DOUBLE PRECISION.\par
     ## The <data type>'s precision.\par
     ## The <data type>'s scale (for exact numeric types).\par
     ## Whether the <data type>'s precision and scale are expressed in decimal or binary terms.\par
\par
INTEGER:\par
The required syntax for an INTEGER <data type> specification is:\par
\par
INTEGER <data type> ::=\par
INTEGER\par
\par
INTEGER may be abbreviated as INT; it defines a set of possibly\par
signed whole numbers that have a scale of zero.\par
\par
[NON-PORTABLE] INT's precision must be greater than or equal to\par
the precision of SMALLINT but is non-standard because the SQL\par
Standard requires implementors to define INT's precision. FIPS\par
says that INT should have a precision of at least 9 digits.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book defines INT as a 32-bit, signed binary numeric, i.e.: INT\par
corresponds to the C long int data type. Thus, INT defines a set\par
of values that are possibly signed whole numbers with a precision\par
of 31 bits and a scale of zero, e.g.:\par
   -6500\par
   476673\par
\par
[NON-PORTABLE] INT's radix must be the same as the radix chosen\par
for SMALLINT but is non-standard because the SQL Standard\par
requires implementors to define whether INT and SMALLINT have a\par
binary radix or a decimal radix.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book defines INT and SMALLINT with a binary radix, i.e.: 2. This\par
gives INT a valid range of -2,147,483,647 to +2,147,483,647.\par
\par
SMALLINT:\par
The required syntax for a SMALLINT <data type> specification is:\par
\par
SMALLINT <data type> ::=\par
SMALLINT\par
\par
SMALLINT defines a set of possibly signed whole numbers that have\par
a scale of zero.\par
\par
[NON-PORTABLE] SMALLINT's precision must be less than or equal to\par
the precision of INT but is non-standard because the SQL Standard\par
requires implementors to define SMALLINT's precision. FIPS says\par
that SMALLINT should have a precision of at least 4 digits.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book defines SMALLINT as a 16-bit signed binary numeric, i.e.:\par
SMALLINT corresponds to the C int data type. Thus, SMALLINT\par
defines a set of values that are possibly signed whole numbers\par
with a precision of 15 bits and a scale of zero, e.g.:\par
   -65\par
   476\par
\par
[NON-PORTABLE] SMALLINT's radix must be the same as the radix\par
chosen for INT but is non-standard because the SQL Standard\par
requires implementors to define whether SMALLINT and INT have a\par
binary radix or a decimal radix.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book defines SMALLINT and INT with a binary radix, i.e.: 2. This\par
gives SMALLINT a range of -32,767 to +32,767.\par
\par
NUMERIC:\par
The required syntax for a NUMERIC <data type> specification is:\par
\par
NUMERIC <data type> ::=\par
NUMERIC [ (precision[,scale]) ]\par
\par
NUMERIC is a fixed-point numeric with a decimal precision and\par
decimal scale that are equal to the explicit precision and the\par
explicit scale given; it defines a set of values that are\par
possibly signed decimal numbers with an optionally defined\par
precision and optionally defined scale, e.g.:\par
   65.73\par
   .6\par
   -819.3\par
   -.25\par
\par
The optional precision, if specified, is an unsigned integer that\par
defines the maximum precision of acceptable values. The minimum precision is 1.\par
     ## [NON-PORTABLE] The default precision and the maximum\par
precision for NUMERIC are non-standard because the SQL Standard\par
requires implementors to define NUMERIC's default and maximum\par
precisions. Typically, the maximum precision is 15 (the FIPS\par
requirement); it may be as high as 38 (the DB2 maximum).\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows the precision of NUMERIC to range from 1 to 38,\par
with a default precision of 1. For example, this <data type> specification\par
defines a set of values that may range from -9999 to +9999 (4 digits defined):\par
\par
   NUMERIC(4)\par
\par
and these two equivalent <data type> specifications define a set\par
of values that may range from -9 to +9 (1 digit defined or default):\par
\par
   NUMERIC(1)\par
\par
   NUMERIC\par
\par
The optional scale, if specified, is an unsigned integer, greater\par
than zero, that defines the maximum number of digits in the scale\par
of acceptable values. It must be less than the precision and\par
defaults to zero if omitted. You may define a scale for NUMERIC\par
only if you also define a precision: if no precision is defined,\par
the scale must default to zero.\par
     ## [NON-PORTABLE] The maximum scale for NUMERIC must always\par
be less than the defined precision but is non-standard because\par
the SQL Standard requires implementors to define NUMERIC's\par
maximum scale.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows you to define a scale ranging from 1 to 38 for\par
NUMERIC. For example, this <data type> specification defines a set of\par
values that may range from -999.9 to +999.9 (3 digits before the\par
decimal point and 1 digit after the decimal point, for a total of 4 digits):\par
\par
   NUMERIC(4,1)\par
\par
DECIMAL:\par
The required syntax for a DECIMAL <data type> specification is:\par
\par
DECIMAL <data type> ::=\par
DECIMAL [ (precision[,scale]) ]\par
\par
DECIMAL may be abbreviated as DEC and is a fixed-point numeric\par
with a decimal scale that is equal to the explicit scale given;\par
it defines a set of values that are possibly signed decimal\par
numbers with an optionally defined precision and optionally defined scale, e.g.:\par
   65.73\par
   .6\par
   -819.3\par
   -.25\par
\par
The optional precision, if specified, is an unsigned integer that\par
defines the maximum precision of acceptable values. DEC's decimal\par
precision must be at least equal to the precision you define --\par
compare COBOL, which allows "PIC S9(3) COMP-1" but might allot a\par
full-word "PIC S9(5)" for internal storage. The minimum precision is 1.\par
     ## [NON-PORTABLE] The default precision, maximum precision\par
and exact precision for DEC are non-standard because the SQL\par
Standard requires implementors to define DEC's default, maximum\par
and exact precisions. Typically, the maximum precision is 15 (the\par
FIPS requirement); it may be as high as 38 (the DB2 maximum).\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows the precision of DEC to range from 1 to 38, with\par
a default precision of 1. DEC's decimal precision is equal to the\par
precision you define, i.e.: OCELOT treats DEC and NUMERIC as\par
synonyms. For example, this <data type> specification defines a set of values\par
that may range from -9999 to +9999 (4 digits defined):\par
\par
   DEC(4)\par
\par
and these two equivalent <data type> specifications define a set\par
of values that may range from -9 to +9 (1 digit defined or default):\par
\par
   DEC(1)\par
\par
   DECIMAL\par
\par
The optional scale, if specified, is an unsigned integer, greater\par
than zero, that defines the maximum number of digits in the scale\par
of acceptable values. It must be less than the precision and\par
defaults to zero if omitted. You may define a scale for DEC only\par
if you also define a precision: if no precision is defined, the scale must default to zero.\par
     ## [NON-PORTABLE] The maximum scale for DEC must always be\par
less than the defined precision but is non-standard because the\par
SQL Standard requires implementors to define DEC's maximum scale.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows you to define a scale ranging from 1 to 38 for\par
DEC. For example, this <data type> specification defines a set of\par
values that may range from -999.9 to +999.9 (3 digits before the\par
decimal point and 1 digit after the decimal point, for a total of 4 digits):\par
\par
   DEC(4,1)\par
\par
FLOAT:\par
The required syntax for a FLOAT <data type> specification is:\par
\par
FLOAT <data type> ::=\par
FLOAT [ (precision) ]\par
\par
FLOAT is a floating-point numeric with a binary precision; it\par
defines a set of values that are possibly signed floating point numbers.\par
\par
The optional precision, if specified, is an unsigned integer that\par
defines the maximum number of bits (including the hidden bit) in\par
the mantissa of acceptable values. FLOAT's binary precision must\par
be at least equal to the precision you define. The minimum precision is 1.\par
     ## [NON-PORTABLE] The default precision, maximum precision\par
and binary precision for FLOAT are non-standard because the SQL\par
Standard requires implementors to define FLOAT's default, maximum\par
and exact precisions. FIPS says that FLOAT should have a binary\par
precision of at least 20 digits.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows the precision of FLOAT to range from 1 to 53,\par
with a default precision of 53. Thus, FLOAT defines a set of\par
values that are possibly signed floating point numbers with this format:\par
[sign]+digit+period+ up to 14 digits+E+[sign]+ up to 3 digits\par
For example:\par
   -1.27982E+015\par
   .465E-007\par
The IEEE Standard for Binary Floating-Point Arithmetic (IEEE\par
Standard 754-1985) specifies two usual mantissa sizes: 24 and 53.\par
OCELOT supports both: regardless of the actual precision\par
specified for FLOAT, there are really only two possible results.\par
If you define FLOAT with a precision that is less than or equal\par
to 24, the actual binary precision will equal 24 bits in the\par
mantissa. For example, these two <data type> specifications are\par
equivalent: they both define a set of floating point values whose\par
mantissa may range up to a precision of 24 bits:\par
\par
   FLOAT(12)\par
\par
   FLOAT(24)\par
\par
If you define FLOAT with a precision between 25 and 53, the\par
actual binary precision will equal 53 bits in the mantissa. For\par
example, these three <data type> specifications are equivalent:\par
they all define a set of floating point values whose mantissa may\par
range up to a precision of 53 bits:\par
\par
   FLOAT\par
\par
   FLOAT(27)\par
\par
   FLOAT(53)\par
\par
[NON-PORTABLE] The minimum exponent and the maximum exponent for\par
FLOAT are non-standard because the SQL Standard requires\par
implementors to define FLOAT's minimum and maximum exponents.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book allows you to define an exponent ranging from -038 to +038 for FLOAT.\par
\par
REAL:\par
The required syntax for a REAL <data type> specification is:\par
\par
REAL <data type> ::=\par
REAL\par
\par
REAL is a floating-point numeric with a binary precision, i.e.:\par
REAL defines a set of values that are possibly signed floating point numbers.\par
\par
[NON-PORTABLE] The binary precision of REAL must be less than the\par
precision defined for DOUBLE PRECISION but is non-standard\par
because the SQL Standard requires implementors to define REAL's exact precision.\par
     [OCELOT Implementation]  The OCELOT DBMS that comes with\par
this book treats REAL as a synonym for FLOAT(24). Thus, REAL\par
defines a set of values that are possibly signed floating point\par
numbers with this format:\par
[sign]+digit+period+up to 6 digits+E+[sign]+ up to 2 digits\par
For example:\par
   -1.27982E+15\par
   .465E-07\par
\par
[NON-PORTABLE] The minimum exponent and the maximum exponent for\par
REAL are non-standard because the SQL Standard requires\par
implementors to define REAL's minimum and maximum exponents.\par
     [OCELOT Implementation]  The OCELOT DBMS that comes with\par
this book allows you to define an exponent ranging from -38 to +38 for REAL.\par
\par
DOUBLE PRECISION:\par
The required syntax for a DOUBLE PRECISION <data type> specification is:\par
\par
DOUBLE PRECISION <data type> ::=\par
DOUBLE PRECISION\par
\par
DOUBLE PRECISION is a floating-point numeric with a binary\par
precision, i.e.: DOUBLE PRECISION defines a set of values that\par
are possibly signed floating point numbers.\par
\par
[NON-PORTABLE] The binary precision of DOUBLE PRECISION must be\par
greater than the precision defined for REAL but is non-standard\par
because the SQL Standard requires implementors to define DOUBLE\par
PRECISION's exact precision. FIPS says that DOUBLE PRECISION\par
should have a binary precision of at least 30 digits.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book treats DOUBLE PRECISION as a synonym for FLOAT(53). Thus,\par
DOUBLE PRECISION defines a set of values that are possibly signed\par
floating point numbers with this format:\par
[sign]+digit+period+up to 14 digits+E+[sign]+up to 3 digits\par
For example:\par
   -1.27982E+015\par
   .465E-007\par
\par
[NON-PORTABLE] The minimum exponent and the maximum exponent for\par
DOUBLE PRECISION are non-standard because the SQL Standard\par
requires implementors to define DOUBLE PRECISION's minimum and maximum exponents.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book allows you to define an exponent ranging from -038 to\par
+038 for DOUBLE PRECISION.\par
\par
Now that we've described SQL's numeric <data type>s, let's look\par
at some example SQL statements that put them to use.\par
\par
These SQL statements make a Table with four exact numeric\par
Columns, insert a row, then search for any number less than -1.\par
\par
CREATE TABLE Exact_Examples (\par
     occurrence_decimal DECIMAL(5),\par
     occurrence_numeric NUMERIC(7,2),\par
     occurrence_integer INTEGER,\par
     occurrence_smallint SMALLINT);\par
\par
INSERT INTO Exact_Examples (\par
     occurrence_decimal,\par
     occurrence_numeric,\par
     occurrence_integer,\par
     occurrence_smallint)\par
     VALUES (12345, 12345, 12345, 12345);\par
\par
SELECT occurrence_decimal,\par
       occurrence_numeric,\par
       occurrence_integer,\par
       occurrence_smallint\par
FROM   Exact_Examples\par
WHERE  occurrence_decimal < -1;\par
\par
These SQL statements make a Table with three approximate numeric\par
Columns, insert a row, then search for any number less than 50000.\par
\par
CREATE TABLE Approximate_Examples (\par
     occurrence_float FLOAT(53),\par
     occurrence_real REAL,\par
     occurrence_double DOUBLE PRECISION);\par
\par
INSERT INTO Approximate_Examples (\par
     occurrence_float,\par
     occurrence_real,\par
     occurrence_double)\par
     VALUES (5E+2, 5E+2, 5E+2);\par
\par
SELECT occurrence_float,\par
       occurrence_real,\par
       occurrence_double\par
FROM   Approximate_Examples\par
WHERE  occurrence_float < 5E+4;\par
\par
IEEE Binary Floats\par
\par
According to the IEEE Standard for Binary Floating-Point\par
Arithmetic, "single-" and "double-precision" numbers are defined as follows:\par
\par
            SIGN     EXPONENT    MANTISSA    EXPONENT         RANGE\par
PRECISION   [BITS]   [BITS]      [BITS]*     [DECIMAL]        [DECIMAL]\par
Single      1         8          24           -38 to +35       7 digits\par
Double      1        11          53          -304 to +308     15 digits\par
(* The most significant mantissa bit is assumed to be 1. It is not stored.)\par
\par
You'd find the same specification in, say, an Intel FPU reference\par
text or a C++ manual. But we found discrepancies when looking\par
through documents for Java (where the exponent range is between\par
-35 and +38), Delphi (where the exponent range is between -45 and\par
+38 for single-precision and between -324 and -308 for double-\par
precision), FIPS SQL (where the FLOAT exponent+size are 9+47 and\par
the REAL exponent+size are 7+23). So, for portability reasons, it\par
would be a good idea to avoid the extremes of the IEEE range.\par
\par
Most DBMSs support IEEE float formats because FIPS requires that\par
the decimal ranges be supported and because the DBMS code itself\par
is written in a language that supports IEEE floats. But never\par
does an official SQL standard tell vendors "how to store the\par
data". So it might be that your DBMS actually uses the IEEE sizes\par
or it might be that your DBMS actually stores float decimal\par
literals (as xBase does) and processes with base-10 arithmetic.\par
If so, the following information doesn't apply to you.\par
\par
[Obscure Information] applies for the rest of this section.\par
\par
Binary Floats are not exact. The danger with these numbers is\par
easy to observe in a simple arithmetic exercise:\par
     ## Represent the number one-third (1/3) in decimal. The maximum number\par
of post-decimal digits (the scale) is large but not infinite. Result: 0.333333\par
     ## Take the sum of three occurrences of this number. Result:\par
0.333333 + 0.333333 + 0.333333 = 0.999999\par
     ## Note that the number is wrong (three thirds should equal\par
1). Increase the scale. Try again. You'll never get the correct\par
result because you can't accurately represent 1/3 as a decimal fraction.\par
\par
Now consider what would happen if your number was decimal, e.g.:\par
one-hundredth (1/100). Try to represent that number as a binary\par
fraction. If you have 16 binary digits (a 16-bit "word"), there\par
are only 2^16 discrete values you can represent, so you are dealing\par
in dividends which are sixty-five-thousand-five-hundred-and-thirty-sixths.\par
The closest number to 1/100 is thus 655/65536 -- i.e.: you have to store\par
655 in your word. This is a bit small. (Actually 655/65536 is closer\par
to 0.09945, so our error is about one part in a thousand.) In\par
other words: you cannot represent 1/100 as a binary fraction.\par
Worse, if you now convert back to decimal, you will probably get\par
1/100 again (the smart computer rounds up) so you won't see the\par
inaccuracy. Now consider the result of this SQL code:\par
\par
   SUM(column_containing_the_fractional_value_one_hundredth)\par
\par
If your Table has 1000 rows, then the conversion to binary\par
happens 1000 times -- cumulating the inaccuracy each time -- and\par
the conversion back to decimal happens only once, when the final\par
SUM is returned. Rounding won't save you, because the result --\par
99.45 -- is good to the nearest hundredth. And you won't check\par
the result in your head. Yet the result is "wrong".\par
\par
In theory, this arithmetic exercise is not a "floating point"\par
problem. We introduced the inaccuracy by converting a decimal\par
fraction to binary. Both fixed-point and floating-point binary\par
fractions have the same danger of inaccuracy, because the danger\par
lies in the fact that we're dealing with binary numbers -- not in\par
the fact that we're dealing with floating-point numbers. So, in\par
theory, the same "wrong" result could be returned for a DECIMAL\par
Column or a NUMERIC Column. In practice, though, the better SQL\par
DBMSs won't use binary fractions for DECIMAL or NUMERIC values.\par
Instead, like COBOL with "PIC 9V99", they actually store an\par
integer with an implied decimal point -- so the number 1/100 is,\par
internally, 1. No conversion occurs because an integral number of\par
hundredths are being stored, rather than a fraction.\par
\par
** TIP: Because of this, for all financial transactions, both\par
money and interest ought to be DECIMAL or NUMERIC. The frequency\par
of definitions like:\par
\par
   CREATE TABLE Table_1 (salary FLOAT);\par
\par
is a mistake, justified only by the fact that, in C or Pascal,\par
it's normal to define big or non-integer variables as floating-point.\par
\par
Numeric Operations\par
\par
A number is compatible with, and comparable to, all other numbers\par
-- that is, all numbers are mutually comparable and mutually\par
assignable. Numbers may not be directly compared with, or\par
directly assigned to, any other <data type> class, though\par
implicit type conversions can occur in expressions, SELECTs,\par
INSERTs, DELETEs and UPDATEs. Explicit numeric type conversions\par
can be forced with the CAST operator.\par
\par
CAST:\par
In SQL, CAST is a scalar operator that converts a given scalar\par
value to a given scalar <data type>. The required syntax for the CAST operator is:\par
\par
CAST (<cast operand> AS <cast target>)\par
\par
   <cast operand> ::= scalar_expression\par
\par
   <cast target> ::= <Domain name> | <data type>\par
\par
The CAST operator converts values of a source <data type> into\par
values of a target <data type>, where each <data type> is an SQL\par
pre-defined <data type> (data conversions between UDTs are done\par
with a user-defined cast). The source <data type>, or <cast\par
operand>, can be any expression that evaluates to a single value.\par
The target <data type>, or <cast target>, is either an SQL\par
predefined <data type> specification or the name of a Domain\par
whose defined <data type> is the SQL predefined <data type> that\par
you want to convert the value of "scalar_expression" into. (If\par
you use CAST (... AS <Domain name>), your current <AuthorizationID>\par
must have the USAGE Privilege on that Domain.)\par
\par
It isn't, of course, possible to convert the values of every\par
<data type> into the values of every other <data type>. For\par
numbers, the rules are:\par
     ## CAST (NULL AS <data type>) and CAST (numeric_source_is_a_null_value AS <data type>)\par
both result in a CAST result of NULL.\par
     ## You can CAST an exact numeric source to these targets:\par
exact numeric, approximate numeric, fixed length character\par
string, variable length character string, CLOB and NCLOB. You can\par
also CAST an exact numeric source to an interval target, provided\par
the target contains only one datetime field -- that is, you can\par
CAST an integer to INTERVAL YEAR or to INTERVAL MONTH, but you\par
can't CAST it to INTERVAL YEAR TO MONTH. You can CAST an exact\par
numeric source to a UDT target or a <reference type> target if a\par
user-defined cast exists for this purpose and your current\par
<AuthorizationID> has the EXECUTE Privilege on that user-defined cast.\par
     ## You can CAST an approximate numeric source to these\par
targets: exact numeric, approximate numeric, fixed length\par
character string, variable length character string, CLOB and\par
NCLOB. You can also CAST an approximate numeric source to a UDT\par
target or a <reference type> target if a user-defined cast exists\par
for this purpose and your current <AuthorizationID> has the\par
EXECUTE Privilege on that user-defined cast.\par
\par
When you CAST an exact numeric value or an approximate numeric\par
value to an exact numeric target -- for example: "CAST (25 AS\par
INTEGER)", "CAST (1.47E-5 AS DECIMAL(9,7))" -- or when you CAST an\par
exact numeric value or an approximate numeric value to an\par
approximate numeric target (for example: "CAST (25 AS FLOAT)",\par
"CAST (1.47E-5 AS DOUBLE PRECISION)" -- your DBMS checks whether\par
the source is a valid value for the target's <data type> (or if a\par
valid value -- one that doesn't lose any leading significant\par
digits -- can be obtained from the source by rounding or\par
truncation). If so, then the source is converted to that target\par
value. If neither of these are true, the CAST will fail: your\par
DBMS will return the SQLSTATE error 22003 "data exception-numeric\par
value out of range".\par
     [NON-PORTABLE] If your source value is not a valid value for\par
your target <data type>, then the value CAST is non-standard\par
because the SQL Standard requires implementors to define whether\par
the DBMS will round or will truncate the source to obtain a valid target value.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book truncates the source to obtain a valid target value.\par
\par
When you CAST an exact numeric value or an approximate numeric\par
value to a fixed length character string target, your DBMS\par
converts the number to the shortest string that represents that\par
number (that is, "CAST (25 AS CHAR(2))" results in the character\par
string '25', "CAST (1.47E-5 AS CHAR(8))" results in the character\par
string '.0000147', "CAST (-25 AS CHAR(3))" results in the\par
character string '-25', "CAST (+25 AS CHAR(3))" results in the\par
character string '25 ', "CAST (025 AS CHAR(3))" results in the\par
character string '25 ', "CAST (25. AS CHAR(3))" results in the\par
character string '25 ', "CAST (25.0 AS CHAR(4))" results in the\par
character string '25  ', and so on). If the length of the result\par
equals the fixed length of the target, then the source is CAST to\par
that result. If the length of the result is shorter than the\par
fixed length of the target, then the source is CAST to that\par
result, padded on the right with however many spaces is required\par
to make the lengths the same. If the length of the result is\par
longer than the fixed length of the target, the CAST will fail:\par
your DBMS will return the SQLSTATE error 22001 "data\par
exception-string data, right truncation". And if the result\par
contains any characters that don't belong to the target's\par
Character set, the CAST will also fail: your DBMS will return the\par
SQLSTATE error 22018 "data  exception-invalid character value for\par
cast". (Note: if your approximate numeric source value is zero,\par
the CAST result is this character string: '0E0'.)\par
\par
When you CAST an exact numeric value or an approximate numeric\par
value to a variable length character string target or a CLOB or\par
NCLOB target, your DBMS converts the number to the shortest\par
string that represents that number -- as with fixed length\par
target, it strips off leading plus signs, leading zeros, and any\par
insignificant decimal signs and trailing zeros. If the length of\par
the result is less than or equals the maximum length of the\par
target, then the source is CAST to that result. If the length of\par
the result is longer than the maximum length of the target, the\par
CAST will fail: your DBMS will return the SQLSTATE error 22001\par
"data exception-string data, right truncation". And if the result\par
contains any characters that don't belong to the target's\par
Character set, the CAST will also fail: your DBMS will return the\par
SQLSTATE error 22018 "data exception-invalid character value for cast".\par
\par
[Obscure Rule] The result of a CAST to a character string target\par
has the COERCIBLE coercibility attribute; its Collation is the\par
default Collation for the target's Character set.\par
\par
When you CAST an exact numeric value to an interval target, your\par
DBMS converts it to the value of the interval's single datetime\par
field represented by that number -- for example, "CAST (25 AS\par
INTERVAL YEAR)" results in an interval of 25 years. If the number\par
you're casting is too large for the precision of the target -- as\par
in "CAST (500 AS INTERVAL HOUR(2)" -- the CAST will fail: your DBMS\par
will return the SQLSTATE error 22015 "data exception-interval field overflow".\par
\par
When you CAST an exact numeric value or an approximate numeric\par
value to a UDT or a <reference type> target, your DBMS invokes\par
the user defined cast routine, with the source value as the\par
routine's argument. The CAST result is the value returned by the user defined cast.\par
\par
If you want to restrict your code to Core SQL, don't use <Domain\par
name> as a CAST target: CAST only to a <data type>.\par
\par
Assignment:\par
In SQL, when an exact numeric or an approximate numeric value is\par
assigned to an exact numeric target, the source is first\par
converted to an exact numeric value with the precision and scale\par
of the target. When an exact numeric or an approximate numeric\par
value is assigned to an approximate numeric target, the source is\par
first converted to an approximate numeric value with the\par
precision of the target. In either case, if the assignment would\par
result in the loss of any of the source value's most significant\par
digits, the assignment will fail: your DBMS will return the\par
SQLSTATE error 22003 "data exception-numeric value out of range".\par
     [NON-PORTABLE] If the assignment of a numeric value would\par
result in the loss of any of the source value's least significant\par
digits, the result is non-standard because the SQL Standard\par
requires implementors to define the result using either of two\par
options: (a) your DBMS may truncate the source to fit the target\par
and then make the assignment or (b) your DBMS may round the\par
source to fit the target and then make the assignment.\par
          [OCELOT Implementation] The OCELOT DBMS that comes with\par
this book truncates the source value to fit the target.\par
\par
[Obscure Rule] Since only SQL accepts null values, when a null\par
value is taken from SQL-data to be assigned to a numeric target,\par
your target's value is not changed. Instead, your DBMS will set\par
the target's indicator parameter to -1, to indicate that an\par
assignment of the null value was attempted. If your target\par
doesn't have an indicator parameter, the assignment will fail:\par
your DBMS will return the SQLSTATE error 22002 "data\par
exception-null value, no indicator parameter". Going the other\par
way, there are two ways to assign a null value to an SQL-data\par
target. Within SQL, you can use the <keyword> NULL in an INSERT\par
or an UPDATE statement to indicate that the target should be set\par
to NULL; that is, if your source is NULL, your DBMS will set your\par
target to NULL. Outside of SQL, if your source has an indicator\par
parameter that is set to -1, your DBMS will set your target to\par
NULL (regardless of the value of the source). (An indicator\par
parameter with a value less than -1 will cause an error: your\par
DBMS will return the SQLSTATE error 22010 "data exception-invalid\par
indicator parameter value".) We'll talk more about indicator\par
parameters in our chapters on SQL binding styles.\par
\par
As an example, assume that you have an INTEGER Column and need to\par
assign a non-integer value to it. The result will depend not only\par
on what the source value is, but also on whether your DBMS uses\par
rounding or truncation to turn it into an integer. Here are the\par
choices (note that "rounding toward zero" is really truncating):\par
\par
           Rounding     Rounding      Rounding     Rounding\par
Source     toward       toward        toward       toward\par
value      +infinity    -infinity     zero         nearest\par
 1.5       2             1             1            2\par
-1.5       1            -2            -1           -2\par
etc.\par
\par
Most DBMSs use truncation, but these SQL statements show how to force the rounding method you prefer:\par
\par
   -- rounding toward positive infinity\par
   CASE numeric_expression - CAST (numeric_expression AS INTEGER)\par
       WHEN > 0 numeric_expression+1\par
       WHEN < 0 numeric_expression-1\par
       ELSE numeric_expression\par
   END\par
\par
   -- rounding toward negative infinity\par
   CASE numeric_expression\par
        WHEN > 0 CAST (numeric_expression AS INTEGER)\par
        WHEN < 0 CAST (0 - (ABS(numeric_expression) + 0.5) AS INTEGER))\par
        ELSE numeric_expression\par
   END\par
\par
   -- rounding toward zero\par
   CAST (numeric_expression AS INTEGER)\par
\par
   -- rounding toward nearest\par
   CAST (numeric_expression + 0.5 AS INTEGER)\par
\par
Comparison:\par
SQL provides the usual scalar comparison operators -- = and <>\par
and < and <= and > and >= -- to perform operations on numbers.\par
All of them will be familiar; there are equivalent operators in\par
other computer languages. Numbers are compared in the usual\par
manner. If any of the comparands are NULL, the result of the\par
operation is UNKNOWN. For example:\par
\par
   97 = 105.2\par
\par
returns FALSE.\par
\par
   97 <> \{result is NULL\}\par
\par
returns UNKNOWN.\par
\par
SQL also provides three quantifiers -- ALL, SOME, ANY -- which\par
you can use along with a comparison operator to compare a value\par
with the collection of values returned by a <table subquery>.\par
Place the quantifier after the comparison operator, immediately\par
before the <table subquery>. For example:\par
\par
   SELECT decimal_column\par
   FROM   Table_1\par
   WHERE  decimal_column < ALL (\par
      SELECT integer_column\par
      FROM   Table_2);\par
\par
ALL returns TRUE either (a) if the collection is an empty set\par
(i.e.: if it contains zero rows) or (b) if the comparison\par
operator returns TRUE for every value in the collection. ALL\par
returns FALSE if the comparison operator returns FALSE for at\par
least one value in the collection.\par
\par
SOME and ANY are synonyms. They return TRUE if the comparison\par
operator returns TRUE for at least one value in the collection.\par
They return FALSE either (a) if the collection is an empty set or\par
(b) if the comparison operator returns FALSE for every value in\par
the collection. (The search condition "= ANY (collection)" is\par
equivalent to "IN (collection)".)\par
\par
Other Operations:\par
With SQL, you have several other operations that you can perform\par
on numbers, or on other values to get a numeric result.\par
\par
## Arithmetic\par
SQL provides the usual scalar arithmetic operators -- + and - and\par
* and / -- to perform operations on numbers. All of them will be\par
familiar; there are equivalent operators in other computer\par
languages. If any of the operands are NULL, the result of the\par
operation is also NULL.\par
\par
monadic + and monadic -\par
When used alone, + and - change the sign of an operand (e.g.: a\par
<literal> or a Column instance or a host variable). For example:\par
\par
   SELECT -5, -(-occurrence_decimal)\par
   FROM   Exact_Examples\par
   WHERE  occurrence_integer = +5;\par
\par
** TRAP: Since two dashes (i.e.: --) means "comment start" in\par
SQL, our example of a double negative has to be\par
"-(-occurrence_decimal)" rather than "--occurrence_decimal".\par
\par
dyadic + and dyadic - and dyadic * and dyadic /\par
When used between two operands, + and - and * and / stand for add\par
and subtract and multiply and divide, respectively, and return\par
results according to the usual rules. For example:\par
\par
   SELECT occurrence_integer + 5, (occurrence_integer * 7) / 2\par
   FROM   Exact_Examples\par
   WHERE  occurrence_integer < (:host_variable - 7);\par
\par
precedence\par
Dyadic * and / have priority over dyadic + and -, but monadic +\par
and - have top priority. It's good style to use parentheses for\par
any expressions with different operators.\par
\par
errors\par
The two common arithmetic exception conditions are:\par
SQLSTATE 22003 -- data exception - numeric value out of range\par
SQLSTATE 22012 -- data exception - division by zero\par
\par
Here is a snippet of an embedded SQL program that checks for\par
overflow after executing a statement that contains addition:\par
\par
   EXEC SQL UPDATE Exact_Examples\par
            SET    occurrence_smallint = occurrence_decimal + 1;\par
   if (strcmp(sqlstate,"22003") printf("Overflow! Operation cancelled ...\\n");\par
\par
Error checks should follow every execution of an SQL statement,\par
but imagine that the EXACT_EXAMPLES Table has a million rows. To\par
avoid the situation where, after chugging through 999,999 rows,\par
your application collapses on the last one with "Overflow! Operation cancelled ...",\par
try this code:\par
\par
   EXEC SQL UPDATE Exact_Examples\par
            SET    occurrence_smallint =\par
            CASE\par
              WHEN occurrence_smallint = 32767 THEN 0\par
              ELSE occurrence_smallint = occurrence_smallint + 1\par
            END;\par
\par
** TIP: CASE expressions are good for taking error-abating actions in advance.\par
\par
** TIP: SQL has no low-level debugging features, so sometimes you\par
will need to force an error somewhere in a complex expression, to\par
be sure it is actually being executed. For this purpose, insert\par
code that would cause a numeric overflow.\par
\par
Mixing numeric <data type>s --\par
As we said earlier, all numbers -- any <data type>, exact or\par
approximate -- are compatible. That means that you can mix them\par
together in any numeric expression -- which leads to the\par
question: what comes out when you do mix them, i.e.: what is the\par
<data type>, precision and scale of the result? The SQL Standard\par
says these are the results you will get:\par
\par
[NON-PORTABLE] An exact numeric value added to, subtracted from,\par
multiplied by or divided by an exact numeric value yields an\par
exact numeric value with a precision that is non-standard because\par
the SQL Standard requires implementors to define the precision of\par
the result. For all these operations, if the result of the\par
operation can't be exactly represented with the correct precision\par
and scale, the operation will fail: your DBMS will return the\par
SQLSTATE error 22003 "data exception-numeric value out of range".\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book gives the result of an arithmetic operation between exact\par
numeric operands a <data type> and precision that matches the\par
<data type> and precision of the operand with the most exact\par
precision, e.g.: for an operation with SMALLINT and INT operands,\par
the result is an INT type.\par
\par
An exact numeric value added to or subtracted from an exact\par
numeric value yields a result with a scale size that matches the\par
size of scale of the operand with the largest scale, e.g.: for an\par
operation with DECIMAL(6,2) and INT operands, the result has a\par
scale of 2.\par
\par
An exact numeric value multiplied by an exact numeric value\par
yields a result with a scale size that is the sum of the scale\par
sizes of the operands, e.g.: for an operation with DECIMAL(6,2)\par
and NUMERIC(10,4) operands, the result has a scale of 6.\par
\par
[NON-PORTABLE] An exact numeric value divided by an exact numeric\par
value yields a result with a scale size that is non-standard\par
because the SQL Standard requires implementors to define the\par
scale size of the result.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book gives the result of a division operation between exact\par
numeric operands a scale size that matches the size of scale of\par
the operand with the largest scale, e.g.: for an operation with\par
DECIMAL(6,2) and NUMERIC(10,4) operands, the result has a scale\par
of 4.\par
\par
[NON-PORTABLE] An approximate numeric value added to, subtracted\par
from, multiplied by or divided by an approximate numeric value\par
yields an approximate numeric value with a precision and scale\par
that are non-standard because the SQL Standard requires\par
implementors to define the precision and scale of the result. If\par
the exponent of the result doesn't fall within the DBMS's\par
supported exponent range, the operation will fail: your DBMS will\par
return the SQLSTATE error 22003 "data exception-numeric value out of range.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book gives the result of an arithmetic operation between\par
approximate numeric operands a <data type> and precision that\par
matches the <data type> and precision of the operand with the\par
most exact precision, e.g.: for an operation with REAL and DOUBLE\par
PRECISION operands, the result is a DOUBLE PRECISION type.\par
\par
[NON-PORTABLE] An approximate numeric value added to, subtracted\par
from, multiplied by or divided by an exact numeric value (or vice\par
versa) yields an approximate numeric value with a precision and\par
scale that are non-standard because the SQL Standard requires\par
implementors to define the precision and scale of the result.\par
     [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book gives the result of an arithmetic operation between\par
approximate numeric and exact numeric operands a <data type> and\par
precision that matches the <data type> and precision of the\par
operand with the most exact precision, e.g.: for an operation\par
with INT and DOUBLE PRECISION operands, the result is a DOUBLE PRECISION type.\par
\par
In other words, the Standard always evades the big question:\par
what's the result precision? To put this into perspective,\par
consider a DBMS faced with a tough operation: "add 1 to a Column\par
which is defined as DECIMAL(5)". Since the Column might already\par
contain the value 99999, adding 1 might yield 100000 -- a\par
DECIMAL(6) value. For such cases, the DBMS must decide what to do\par
before executing, because the application program, which will\par
receive the result, must know the size in advance. The DBMS has two choices:\par
     ## Let it grow. The result is DECIMAL(6) if the operation is\par
addition and slightly more if the operation is multiplication.\par
This choice has the advantage that it eliminates "overflow"\par
errors. But there are still undefined areas: What happens if the\par
DECIMAL precision is already at the maximum? What happens if the\par
operation adds 1 to a SMALLINT -- does the <data type> upgrade to\par
INTEGER so that the increased precision is valid?\par
     ## Chop it. The result is DECIMAL(5), regardless. This risks\par
failure on even the most innocuous operations, but it's a simple\par
rule to follow: output precision = input precision. Programmers\par
can understand it.\par
These choices are not mutually exclusive and your DBMS might make\par
different decisions for different operations.\par
\par
** TIP: Before you divide, decide how many digits should follow\par
the decimal point in the result. The number will almost certainly\par
be greater than the number you start with; for instance, "12/5"\par
(dividing scale-0 integers) yields "2.4" (a scale-1 decimal\par
number) -- you hope. Your DBMS may increase the scale\par
automatically, but the Standard doesn't say it must. To force the\par
result, use this SQL code:\par
\par
   CAST (12 AS DECIMAL(3,1))/5    -- yields 2.4\par
\par
Incidentally, there are several bad ways to cast. This SQL code:\par
\par
   CAST ((12/5) AS DECIMAL(3,1))\par
\par
will yield 2.0 if your DBMS doesn't increase the scale\par
automatically -- be sure to CAST the source, not the result. This SQL code:\par
\par
   CAST (12 AS DECIMAL(2,1))/5\par
\par
will cause an error -- be sure your source value fits in the CAST target.\par
\par
Floating-point arithmetic --\par
If you want fast and complex floating-point arithmetic, buy a\par
good Fortran compiler: SQL can't handle the fancy stuff. In particular:\par
     ## SQL lacks useful functions which in other languages are\par
built-in, e.g.: the ability to detect NaN (Not a Number).\par
     ## SQL vendors are only obliged to define and to accept IEEE\par
numbers. They can do arithmetic without paying any attention to\par
the IEEE standard at all. In particular, some vendors may use the\par
same routines for approximate numerics as they use for exact\par
numerics, and exact is slower.\par
\par
Still, you can do the basic arithmetic functions -- add, subtract, divide,\par
multiply, compare -- provided you take sensible precautions.\par
\par
comparing two floating-point numbers for equality\par
Think of the inexact result produced when 1/100 was converted to\par
a binary fraction. Because of this, the following SQL code:\par
\par
   ... WHERE float_column = 1.0E+1\par
\par
will fail if, e.g.: the value of FLOAT_COLUMN was originally\par
produced by summing 1/100 one hundred times. To get the\par
"approximately right" answer, compare the absolute difference\par
between the two numbers against a constant, e.g.: with this SQL code:\par
\par
   ... WHERE ABS(float_column - 1.0E+1) < :epsilon\par
\par
To choose a value for epsilon, remember that the accuracy of\par
floating point numbers varies -- by definition -- according to\par
magnitude. For example, between 1.0 and 2.0 there are about 8\par
million numbers, but between 1023.0 and 1024.0 there are only\par
about 8 thousand numbers (assuming IEEE single-precision\par
standards). In this example, since the comparison is for\par
equality, we know that FLOAT_COLUMN must be about the same\par
magnitude as the <literal> 1.0E+1, therefore a reasonable value\par
for epsilon is 1/8000000 or 1.25E-7. When you don't know one of\par
the comparands in advance, start with a value for epsilon that's\par
half as large, multiply it by the sum of the comparands (thus\par
changing its magnitude to the comparands' magnitude) and then\par
compare with this SQL code:\par
\par
   ... WHERE ABS(float_column_1 - float_column_2) <\par
             (ABS(float_column_1 + float_column_2) * :epsilon/2)\par
\par
subtraction\par
We did this operation with an IEEE-compatible compiler:\par
   1234.567 - 1234.000\par
The result was: 0.5670166\par
\par
Both inputs are single-precision floating point numbers (7 digits\par
precision), accurate to the third decimal place. Unfortunately,\par
so is the output. Although the subtraction decreased the\par
magnitude, causing the decimal place to shift right, the accuracy\par
was unaffected: the extra digits after 0.567 are spurious\par
precision. If a subtraction causes a drop in magnitude, spurious\par
precision is likely. (This is often called the "insignificant\par
digits" problem and applies to addition too, if operands can have negative signs.)\par
\par
** TIP: Eliminate insignificant digits using two CASTs. In this\par
example, we know what the input is, so we could clear everything\par
after the result's third decimal place with this SQL code:\par
\par
   CAST (CAST ((1.234567E+04 - 1.234000E+04) AS DEC(8,3)) AS REAL)\par
\par
Here, by casting to DEC(8,3) we first change the result 0.5670166\par
to 0.567. The second CAST casts this back to REAL, with a\par
subsequent result of 0.5670000. Casting is a straightforward way\par
to strip -- unfortunately, it's only useful if you know a lot about the data.\par
\par
** TIP: If an SQL statement does both addition and subtraction,\par
parenthesize so that the addition happens first -- this makes a\par
drop in magnitude less likely to occur. For example, change this SQL statement:\par
\par
   UPDATE Approximate_Examples\par
   SET    occurrence_real = occurrence_real - :host_variable + 1.1E+01;\par
\par
to this SQL statement:\par
\par
   UPDATE Approximate_Examples\par
   SET    occurrence_real = occurrence_real - (:host_variable + 1.1E+01);\par
\par
By the way, don't just transpose the operands. Order of expression evaluation varies.\par
\par
division\par
When doing floating-point division, keep in mind that there is\par
such a thing as "negative zero" and there are floating-point\par
numbers which are so small that you'll get an exception when you\par
divide by them, even though they don't exactly equal zero. This\par
makes it a little harder to test for "division by zero" errors in advance.\par
\par
## Scalar functions\par
SQL provides ten scalar functions that return a number: the <case\par
expression>, the <cast specification>, the <position expression>,\par
the three <length expression>s, the <extract expression>, the\par
<cardinality expression>, the <absolute value expression> and the\par
<modulus expression>. Only the last two also operate exclusively\par
on numbers; these are described below. We'll discuss the rest in\par
other chapters; for now, just remember that they evaluate to a\par
number and can therefore be used anywhere in an SQL statement\par
that a number could be used.\par
\par
<absolute value expression> --\par
The required syntax for an <absolute value expression> is:\par
\par
<absolute value expression> ::=\par
ABS(numeric_argument)\par
\par
ABS operates on an argument that evaluates to a number. It strips\par
a negative sign (if it's present) from the argument and returns a\par
non-negative number whose <data type> is the same as the\par
argument's <data type>, e.g.: ABS(-17) returns 17, ABS(17)\par
returns 17 and ABS(0) returns 0. If the argument is NULL, ABS returns NULL.\par
\par
If the result of ABS is a number that doesn't fit into the\par
argument's <data type> range, the function will fail: your DBMS\par
will return the SQLSTATE error 22003 "data exception-numeric value out of range".\par
\par
ABS is new to SQL with SQL3 and is also supported by ODBC. If\par
your DBMS doesn't support ABS, you can simulate it with this SQL statement:\par
\par
   CASE\par
      WHEN ...<0 THEN ...*-1\par
      ELSE ...\par
   END\par
\par
If your DBMS doesn't support CASE, you can still get an absolute\par
value of a number with this arithmetic expression:\par
   (number * number) / number\par
\par
[Obscure Rule] ABS can also operate on an interval. We've ignored\par
this option for now -- look for it in our chapter on temporal values.\par
\par
<modulus expression> --\par
The required syntax for a <modulus expression> is:\par
\par
<modulus expression> ::=\par
MOD(dividend_argument,divisor_argument)\par
\par
MOD operates on two arguments, both of which must evaluate to an\par
exact numeric integer. It divides the first number by the second\par
number and returns the operation's remainder as a non-negative\par
exact numeric integer whose <data type> is the same as the\par
divisor_argument's <data type>, e.g.: MOD(35,4) returns 3 and\par
MOD(32,4) returns 0. If either argument is NULL, MOD returns\par
NULL. If the divisor_argument is zero, the function will fail:\par
your DBMS will return the SQLSTATE error 22012 "data exception-division by zero".\par
\par
MOD is new to SQL with SQL3. In the Standard, MOD stands for\par
"modulus" but the result of this function is not actually a\par
modulus -- it is a remainder achieved "by means of a modulus".\par
\par
## Set functions\par
SQL provides five set functions that return a number: COUNT(*),\par
COUNT, AVG, SUM and GROUPING, all of which also operate on\par
numbers. In addition to these, the set functions MAX and MIN also\par
operate on numbers. Since none of these operate exclusively with\par
numeric arguments, we won't discuss them here; look for them in\par
our chapter on set functions.\par
\par
## Predicates\par
In addition to the comparison operators, SQL provides eight other\par
predicates that operate on numbers: the <between predicate>, the\par
<in predicate>, the <null predicate>, the <exists predicate>, the\par
<unique predicate>, the <match predicate>, the <quantified\par
predicate> and the <distinct predicate>. Each will return a\par
boolean value: either TRUE, FALSE or UNKNOWN. None of these\par
operate strictly on numbers, so we won't discuss them here. Look\par
for them in our chapter on search conditions.\par
\par
Choosing the right <data type>\par
\par
When you're defining a <data type> specification, think about\par
whether you really need a numeric <data type> for the expected\par
data. Don't just ask: are the values always bunches of digits?\par
For example, phone numbers are digits but if you define a DECIMAL\par
<data type> for them you might lose a valuable piece of\par
information -- whether a leading zero is significant.\par
Identification numbers are digits but if you define a DECIMAL\par
<data type> for them you might have trouble calculating the check\par
digit, which is usually based on a substring extraction. Instead,\par
consider the question: will I ever need to do standard arithmetic\par
operations on the data? If the answer is "no", use a string <data\par
type> rather than a numeric type.\par
\par
If the answer is "yes", then consider which numeric type to\par
choose by answering the question: are the values going to be seen\par
by users or by programs written in other computer languages? If\par
the former: it's a lot easier to explain to a user looking at a\par
blank six-position field on a screen: "you can type in a number\par
between -99999 and +9999" instead of "you can type in a number\par
between -32767 and +32767". If the latter: pick the numeric type\par
that's closest to the variable type that the other computer\par
language will use. You can also follow this short decision tree:\par
\par
IF (numeric values might be huge (> 1 quadrillion) or tiny (< 1 quadrillionth)\par
  /* you need an approximate numeric <data type> */\par
  IF (your host program uses C "float" or Delphi "Single")\par
  AND(7 digit precision is satisfactory)\par
    /* you need a REAL <data type> */\par
  IF (your host program uses C or Delphi "double")\par
  AND(15 digit precision is satisfactory)\par
    /* you need a DOUBLE PRECISION <data type> */\par
ELSE (if values are not huge or tiny)\par
  /* you need an exact numeric <data type> -- the usual case */\par
  IF (your host program uses C "short int" or Delphi "SmallInt" */\par
    /* you need a SMALLINT <data type> */\par
  IF (your host program uses C "int" or Delphi "Longint" */\par
    /* you need an INTEGER <data type> */\par
  ELSE\par
    /* you don't need an exact match with host-language variables */\par
    IF (you are accustomed to the word NUMERIC because Oracle uses it)\par
      /* you need a NUMERIC <data type> */\par
    ELSE\par
      /* you need a DECIMAL <data type> */\par
\par
Once you've gone through the decision tree, calculate the\par
required precision and scale by looking at all expected values.\par
\par
Dialects\par
\par
The "typical" SQL DBMS supports most of the standard numeric data\par
types, but often uses preferred local names. Here are some lists\par
of local types derived from vendor manuals. The correlation with\par
the leftmost ("Standard") column is sometimes imprecise. "ODBC"\par
is not a DBMS but a spec.\par
\par
Standard           Oracle   DB2                Sybase     ODBC\par
SMALLINT           NUMBER   SMALLINT           SMALLINT   SMALLINT\par
INTEGER            NUMBER   INTEGER            INT        INTEGER\par
DECIMAL            NUMBER   DECIMAL            MONEY      DECIMAL\par
NUMERIC            NUMBER   NUMERIC            MONEY      NUMERIC\par
REAL               NUMBER   REAL               FLOAT      REAL\par
FLOAT              NUMBER   FLOAT              FLOAT      FLOAT\par
DOUBLE PRECISION   NUMBER   DOUBLE PRECISION   FLOAT      DOUBLE PRECISION\par
\par
Other commonly-seen numeric data types include TINYINT (8-bit signed integer),\par
BIGINT (64-bit signed integer) and SERIAL (integer that goes up by 1 for each new inserted row).\par
\par
The SQL Library\par
\par
Before we finish discussing numbers, it's time to add something\par
to our "SQL library". To be worthy of addition to the SQL\par
library, a routine must (a) be good clean SQL, (b) be callable\par
from C and Delphi, (c) be actually useful in C and Delphi because\par
it does something that those languages can't and (d) have nothing\par
at all do with "databases" -- it should be available for use just\par
like any general function library.\par
\par
Our addition to the SQL library for this chapter will be a\par
calculator. It won't match C and Delphi for floating-point\par
arithmetic, but it will give more exact answers. Here it is.\par
\par
Function: SQL_calculator (lp_calculation, lp_result, lp_error)\par
\par
Pass: An arithmetic expression in the string lp_calculation. The\par
string may contain any combination of numeric <literal>s (in\par
valid SQL form), the operators * + * / MOD ABS and parentheses.\par
\par
Return:  lp_result: Result of expression (a string containing a number).\par
         lp_error:  SQLSTATE and error message, if expression was invalid.\par
\par
Example: Try passing the expression:\par
   (1.000001 + 1.999990) * 11000\par
to our calculator. Our proc gives the correct result:\par
"33000.0000000". The compilers we tested gave the wrong result:\par
"32999.9901000". (Remember that in SQL all the <literal>s in this\par
expression are DECIMAL, not floating-point, <literal>s.)\par
\page\par
Chapter 4 -- Bit strings\par
\par
In SQL, a bit string is either a binary bit string or a hexadecimal bit\par
string. Binary bit strings are arbitrary sequences of zero or more binary\par
digits (bits), each having a value of 0 or 1 and a length of 1 bit.\par
Hexadecimal bit strings are arbitrary sequences of zero or more hexadecimal\par
digits (hexits). A hexit is either (a) any of the digits 0 through 9 or (b)\par
any of the letters A through F (upper case or lower case allowed) and is four\par
bits long (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E and F are interpreted\par
as 0000, 0001, 0010, 0011, 0100, 0101, 0110, 0111, 1000, 1001, 1010, 1011,\par
1100, 1101, 1110 and 1111, respectively). A bit string value may be a\par
<literal>, the value of a parameter or a host language variable or the result\par
of any expression or argument (including a possibly qualified <Column name>)\par
that evaluates to a bit string.\par
\par
A bit string has a length: a non-negative integer equal to the number of bits\par
in the string. Bits in a bit string are numbered (from left to right),\par
beginning with 1 (the most significant bit). Bit strings are stored in either\par
of the two bit string <data type>s: BIT or BIT VARYING.\par
\par
<bit string literal>s\par
\par
A <bit string literal> is either a binary <bit string literal> or a\par
hexadecimal <bit string literal>.\par
\par
binary <bit string literal>:\par
A binary <bit string literal> is the letter "B" (upper case mandatory)\par
followed by a string of zero or more bits inside a pair of single quote marks.\par
Its <data type> is fixed length BIT, though it is compatible with both the BIT\par
and the BIT VARYING <data type>s. The <literal>'s length is the number of bits\par
inside the quote marks; the delimiting single quotes aren't part of the\par
<literal>, so they're not included in the calculation of the <bit string\par
literal>'s size. Here are some examples of binary <bit string literal>s:\par
\par
   B'00010110'\par
\par
   B'1101'\par
\par
hexadecimal <bit string literal>:\par
A hexadecimal <bit string literal> is the letter "X" (upper case mandatory)\par
followed by a string of zero or more hexits inside a pair of single quote\par
marks. Its <data type> is fixed length BIT, though it is compatible with both\par
the BIT and the BIT VARYING <data type>s. The <literal>'s length is four times\par
the number of hexits inside the quote marks; the delimiting single quotes are\par
not part of the <literal>, therefore they are not included in the calculation\par
of the <bit string literal>'s size. Here are some examples of hexadecimal <bit\par
string literal>s:\par
\par
   X'49FE'\par
\par
   X'a31d'\par
\par
[Obscure Rule] SQL allows you to break a long <bit string literal> up into two\par
or more smaller <bit string literal>s, split by a <separator> that includes a\par
newline character. When it sees such a <literal>, your DBMS will ignore the\par
<separator> and treat the multiple strings as a single <literal>. For example,\par
these two <bit string literal>s are equivalent:\par
\par
   B'00001111'\par
'01101100'\par
\par
   B'0000111101101100'\par
\par
(In the first example, there is a carriage return newline <separator> between\par
"1111'" and "'0110".)\par
\par
These two <bit string literal>s are also equivalent:\par
\par
   X'09AF'\par
'ab42'\par
\par
   X'09afAB42'\par
\par
If you want to restrict your code to Core SQL, do not use either binary or\par
hexadecimal <bit string literal>s.\par
\par
Bit string <data type>s\par
\par
A bit string <data type> is defined by a descriptor that contains two pieces of information:\par
      ## The <data type>'s name: either BIT or BIT VARYING.\par
      ## The <data type>'s length in bits.\par
\par
BIT:\par
The required syntax for a BIT <data type> specification is:\par
\par
BIT <data type> ::=\par
BIT [ (length) ]\par
\par
BIT is a fixed length bit string, exactly "length" bits long; it defines a set\par
of bit string values that are any correctly sized string of bits, e.g.:\par
   10110001\par
\par
The optional length, if specified, is an unsigned integer that defines the\par
fixed length of acceptable values. The minimum length and the default length\par
are both 1. For example, these two <data type> specifications are equivalent:\par
both define a set of bit string values that must be exactly 1 bit long:\par
\par
   BIT\par
\par
   BIT(1)\par
\par
[NON-PORTABLE] The maximum length for BIT is non-standard because the SQL\par
Standard requires implementors to define BIT's maximum length.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the length of BIT to range from 1 to 32768 (i.e.: 4096*8 bits).\par
\par
** TIP: Always specify a bit length which is divisible by 8.\par
\par
When operating on a BIT <data type>, you can use either binary <bit string\par
literal>s or hexadecimal <bit string literal>s. For example, these two\par
<literal>s represent the same bit value:\par
\par
   X'44'\par
\par
   B'01000100'\par
\par
** TIP: Use hexadecimal <bit string literal>s rather than binary <bit string\par
literal>s whenever bit length is divisible by 4.\par
\par
If you want to restrict your code to Core SQL, don't define any BIT <data type>s.\par
\par
BIT VARYING:\par
The required syntax for a BIT VARYING <data type> specification is:\par
\par
BIT VARYING <data type> ::=\par
BIT VARYING (length)\par
\par
BIT VARYING is a variable length bit string, up to "length" bits long; it\par
defines a set of bit string values that are any correctly sized string of bits, e.g.:\par
   10110001\par
\par
The mandatory length is an unsigned integer that defines the maximum length of\par
acceptable values. The minimum length is 1. For example, this <data type>\par
specification defines a set of bit string values that may be anywhere from 0 to 16 bits long:\par
\par
   BIT VARYING(16)\par
\par
(Zero length bit strings can be stored in a BIT VARYING field.)\par
\par
NON-PORTABLE] The maximum length for BIT VARYING is non-standard because the\par
SQL Standard requires implementors to define BIT VARYING's maximum length.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the length of BIT VARYING to range from 1 to 32768 (i.e.: 4096*8 bits).\par
\par
When operating on a BIT VARYING <data type>, you can use either binary <bit\par
string literal>s or hexadecimal <bit string literal>s. For example, these two\par
<literal>s represent the same bit value:\par
\par
   X'44'\par
\par
   B'01000100'\par
\par
** TIP: Use hexadecimal <bit string literal>s rather than binary <bit string\par
literal>s whenever bit length is divisible by 4.\par
\par
If you want to restrict your code to Core SQL, don't define any BIT VARYING <data type>s.\par
\par
Now that we've described SQL's bit <data type>s, let's look at some example\par
SQL statements that put them to use.\par
\par
These SQL statements make a Table with two bit Columns, insert two rows, then\par
search for any bit string equal to 01000100.\par
\par
CREATE TABLE Bit_Examples (\par
      occurrence_bit BIT(8),\par
      occurrence_bitvarying BIT VARYING(8));\par
\par
INSERT INTO Bit_Examples (\par
      occurrence_bit,\par
      occurrence_bitvarying)\par
      VALUES (B'11110000',X'4D');\par
\par
INSERT INTO Bit_Examples (\par
      occurrence_bit,\par
      occurrence_bitvarying)\par
      VALUES (X'a9',B'01011010');\par
\par
SELECT occurrence_bit,\par
       occurrence_bitvarying\par
FROM   Bit_Examples\par
WHERE  occurrence_bitvarying = X'44';\par
\par
SELECT occurrence_bit,\par
       occurrence_bitvarying\par
FROM   Bit_Examples\par
WHERE  occurrence_bit = B'01000100';\par
\par
Bit Operations\par
\par
A bit string is compatible with, and comparable to, all other bit strings --\par
that is, all bit strings are mutually comparable and mutually assignable. Bit\par
strings may not be directly compared with, or directly assigned to, any other\par
<data type> class, though implicit type conversions can occur in expressions,\par
SELECTs, INSERTs, DELETEs and UPDATEs. Explicit bit string type conversions\par
can be forced with the CAST operator.\par
\par
CAST:\par
In SQL, CAST is a scalar operator that converts a given scalar value to a\par
given scalar <data type>. The required syntax for the CAST operator is:\par
\par
CAST (<cast operand> AS <cast target>)\par
\par
   <cast operand> ::= scalar_expression\par
\par
   <cast target> ::= <Domain name> | <data type>\par
\par
The CAST operator converts values of a source <data type> into values of a\par
target <data type>, where each <data type> is an SQL pre-defined <data type>\par
(data conversions between UDTs are done with a user-defined cast). The source\par
<data type>, or <cast operand>, can be any expression that evaluates to a\par
single value. The target <data type>, or <cast target>, is either an SQL\par
predefined <data type> specification or the name of a Domain whose defined\par
<data type> is the SQL predefined <data type> that you want to convert the\par
value of "scalar_expression" into. (If you use CAST (... AS <Domain name>),\par
your current <AuthorizationID> must have the USAGE Privilege on that Domain.)\par
\par
It isn't, of course, possible to convert the values of every <data type> into\par
the values of every other <data type>. For bit strings, the rules are:\par
      ## CAST (NULL AS <data type>) and CAST (bit_string_source_is_a_null_value AS <data type>)\par
both result in a CAST of NULL.\par
      ## You can CAST a fixed length or variable length bit string source to\par
these targets: fixed length character string, variable length character\par
string, CLOB, NCLOB, fixed length bit string and variable length bit string.\par
You can also CAST a fixed length or variable length bit string source to a UDT\par
target or a <reference type> target if a user-defined cast exists for this\par
purpose and your current <AuthorizationID> has the EXECUTE Privilege on that\par
user-defined cast.\par
\par
When you CAST a bit string to a UDT or a <reference type> target, your DBMS\par
invokes the user defined cast routine, with the source value as the routine's\par
argument. The CAST result is the value returned by the user defined cast.\par
\par
When you CAST a fixed length bit string or a variable length bit string to a\par
fixed length bit string target and the bit length of the source value equals\par
the fixed bit length of the target, the CAST result is the source bit string.\par
When you CAST a fixed length bit string or a variable length bit string to a\par
fixed length bit string target and the bit length of the source value is less\par
than the fixed bit length of the target, the CAST result is the source bit\par
string, padded on the least significant end with as many zero-bits as required\par
to make the lengths match. When you CAST a fixed length bit string or a\par
variable length bit string to a fixed length bit string target and the bit\par
length of the source value is greater than the fixed bit length of the target,\par
the CAST result is as much of the source bit string as will fit into the\par
target -- in this case, your DBMS will return the SQLSTATE warning 01004\par
"warning-string data, right truncation".\par
\par
When you CAST a fixed length bit string or a variable length bit string to a\par
variable length bit string target and the bit length of the source value is\par
less than or equals the maximum bit length of the target, the CAST result is\par
the source bit string. When you CAST a fixed length bit string or a variable\par
length bit string to a variable length bit string target and the bit length of\par
the source value is greater than the maximum bit length of the target, the\par
CAST result is as much of the source bit string as will fit into the target --\par
in this case, your DBMS will return the SQLSTATE warning 01004 "warning-string\par
data, right truncation".\par
\par
When you CAST a fixed length or a variable length bit string to a fixed length\par
character string target, a variable length character string target, a CLOB\par
target or an NCLOB target, your DBMS first determines whether the source value\par
needs to be padded: if the remainder from the result of the source's bit\par
length divided by the smallest bit length of any character in the target's\par
character set is not zero, then your DBMS will append a number of zero-bits to\par
the least significant end of the source value -- the number of zero-bits to\par
append is determined by calculating the difference between the bit length of\par
the smallest character and the remainder -- and then return the SQLSTATE\par
warning 01008 "warning-implicit zero-bit padding". The result of the CAST is\par
the string of characters that results from the conversion of the bit string's\par
bits into characters that belong to the target's Character set. (Note: if the\par
length of the CAST result is less than the length of the (possibly padded)\par
source string, your DBMS will return the SQLSTATE warning 01004\par
"warning-string data, right truncation" and if the length of the CAST result\par
is greater than the length of the source string, your DBMS will return the\par
SQLSTATE warning 01008 "warning-implicit zero-bit padding".)\par
\par
Let's look more closely at what happens when you CAST a bit string to a\par
character string. First of all, it's important to remember that character\par
strings have a "form-of-use encoding": it comes from the string's Character\par
set. As an example, assume that the Character set for a CAST target <data\par
type> is UNICODE, where every character is 16 bits long. According to the\par
Unicode standard, the code for the letter 'C' is 0043 hexadecimal (that is,\par
the binary number 0000000001000011) and the code for the letter 'D' is 0044\par
hexadecimal (that is, the binary number 0000000001000100). Now, when you CAST\par
from a bit string to a UNICODE character string, you're instructing your DBMS\par
to take the binary numbers that make up your bit string and convert them into\par
the UNICODE coded character values -- so "CAST(X'00430044' AS CHAR(2)\par
CHARACTER SET UNICODE)" will result in 'CD' and "CAST(B'0000000001000011' AS\par
CHAR(1) CHARACTER SET UNICODE)" will result in 'C'. If your CAST is of a short\par
bit string to a longer fixed length character string, zero bits are padded on\par
the right of the source to bring it to the proper length -- so\par
"CAST(B'00000000010001' AS CHAR(2) CHARACTER SET UNICODE)" will result in\par
'D\\0' (we use the symbol \\0 here to represent a 16-bit character with all bits zero).\par
\par
[Obscure Rule] The result of a CAST to a character string target has the\par
COERCIBLE coercibility attribute; its Collation is the default Collation for\par
the target's Character set.\par
\par
If you want to restrict your code to Core SQL, don't use <Domain name> as a\par
CAST target: CAST only to a <data type>.\par
\par
Assignment:\par
In SQL, when a bit string is assigned to a bit string target, the assignment\par
is done one bit at a time, from left to right -- that is, the source value's\par
most significant bit is assigned to the target's most significant bit, then\par
the source's next bit is assigned to the target's next bit, and so on.\par
\par
When a bit string is taken from SQL-data to be assigned to a fixed length bit\par
string target and the source is shorter than the target, the source is padded\par
(on the right) with 0-bits until it matches the target's size. In this case,\par
your DBMS will return the SQLSTATE warning 01008 "warning-implicit zero-bit\par
padding". If the source is longer than the target, the source is truncated to\par
fit the target. In this case, your DBMS will return the SQLSTATE warning 01004\par
"warning-string data, right truncation". When a bit string is taken from\par
SQL-data to be assigned to a variable length bit string target, the size of\par
the target is first set either to the size of the source or to its own maximum\par
length, whichever is less. The source may then be truncated, if necessary, to\par
match the size of the target. In this case, your DBMS will return the SQLSTATE\par
warning 01004 "warning-string data, right truncation".\par
\par
[Obscure Rule] Since only SQL accepts null values, if your source is NULL,\par
then your target's value is not changed. Instead, your DBMS will set its\par
indicator parameter to -1, to indicate that an assignment of the null value\par
was attempted. If your target doesn't have an indicator parameter, the\par
assignment will fail: your DBMS will return the SQLSTATE error 22002 "data\par
exception-null value, no indicator parameter". If your source is a non-null\par
value that fits into your target, your DBMS will set the target's indicator\par
parameter (if any) to zero. If your source is longer than your target, your\par
DBMS will set your target's indicator parameter to the length of the source;\par
that is, if your source is 12 bits long and your target can accept only 10\par
bits, your DBMS will set the target's indicator parameter to 12, to indicate\par
that 2 bits were lost on assignment. If the source's length is too big to be\par
assigned to the indicator, the assignment will fail: your DBMS will return the\par
SQLSTATE error 22022 "data exception-indicator overflow". We'll talk more\par
about indicator parameters in our chapters on SQL binding styles.\par
\par
When a bit string is assigned to a fixed length SQL-data bit string target and\par
the source is shorter than the target, the assignment will fail: your DBMS\par
will return the SQLSTATE error 22026 "data exception-string data, length\par
mismatch". If the source is larger than the target, the assignment will also\par
fail: your DBMS will return the SQLSTATE error 22001 "data exception-string\par
data, right truncation". When a bit string is assigned to a variable length\par
SQL-data bit string target, the size of the target is first set either to the\par
size of the source or to its own maximum length, whichever is less. If the\par
source is larger than the target, the assignment will fail: your DBMS will\par
return the SQLSTATE error 22001 "data exception-string data, right truncation".\par
\par
[Obscure Rule] There are two ways to assign a null value to an SQL-data\par
target. Within SQL, you can use the <keyword> NULL in an INSERT or an UPDATE\par
statement to indicate that the target should be set to NULL; that is, if your\par
source is NULL, your DBMS will set your target to NULL. Outside of SQL, if\par
your source has an indicator parameter that is set to -1, your DBMS will set\par
your target to NULL (regardless of the value of the source). (An indicator\par
parameter with a value less than -1 will cause an error: your DBMS will return\par
the SQLSTATE error 22010 "data exception-invalid indicator parameter value".)\par
\par
Comparison:\par
SQL provides the usual scalar comparison operators -- = and <> and < and <=\par
and > and >= -- to perform operations on bit strings. All of them will be\par
familiar; there are equivalent operators in other computer languages. If any\par
of the comparands are NULL, the result of the operation is UNKNOWN. For example:\par
\par
   B'0011' = B'0011'\par
\par
returns TRUE.\par
\par
   B'0011' = \{result is NULL\}\par
\par
returns UNKNOWN.\par
\par
SQL also provides three quantifiers -- ALL, SOME, ANY -- which you can use\par
along with a comparison operator to compare a value with the collection of\par
values returned by a <table subquery>. Place the quantifier after the\par
comparison operator, immediately before the <table subquery>. For example:\par
\par
   SELECT bit_column\par
   FROM   Table_1\par
   WHERE  bit_column < ALL (\par
      SELECT bit_column\par
      FROM   Table_2);\par
\par
ALL returns TRUE either (a) if the collection is an empty set (i.e.: if it\par
contains zero rows) or (b) if the comparison operator returns TRUE for every\par
value in the collection. ALL returns FALSE if the comparison operator returns\par
FALSE for at least one value in the collection.\par
\par
SOME and ANY are synonyms. They return TRUE if the comparison operator returns\par
TRUE for at least one value in the collection. They return FALSE either (a) if\par
the collection is an empty set or (b) if the comparison operator returns FALSE\par
for every value in the collection. (The search condition "= ANY (collection)"\par
is equivalent to "IN (collection)".)\par
\par
When a bit string is compared to another bit string, the comparison is done\par
one bit at a time, from left to right -- that is, the first comparand's most\par
significant bit is compared to the second comparand's most significant bit,\par
then the next two bits are compared, and so on. A 0-bit is considered to be\par
less than a 1-bit.\par
\par
Bit strings of equal length are compared, bit by bit, until equality is either\par
determined or not. Two bit strings, BIT_ARGUMENT_1 and BIT_ARGUMENT_2, are\par
equal if (a) they have the same length and (b) each bit within BIT_ARGUMENT_1\par
compares as equal to the corresponding bit in BIT_ARGUMENT_2.\par
\par
Bit strings of unequal length are compared, bit by bit, only after the longer\par
comparand has been truncated to the length of the shorter comparand.\par
Equivalence is determined as usual except that if the shorter comparand\par
compares as equal to the substring of the longer comparand that matches its\par
size, then the shorter bit string is considered to be less than the longer bit\par
string -- even if the remainder of the longer comparand consists only of\par
0-bits. That is, BIT_ARGUMENT_1 is less than BIT_ARGUMENT_2 if (a) the length\par
of BIT_ARGUMENT_1 is less than the length of BIT_ARGUMENT_2 and (b) each bit\par
within BIT_ARGUMENT_1 compares as equal to the corresponding bit in\par
BIT_ARGUMENT_2. For example, the result of a comparison of these two bit strings:\par
\par
   B'101'\par
\par
   B'1010'\par
\par
is that the first (shorter) bit string is less than the second (longer) bit string.\par
\par
Other Operations:\par
With SQL, you have several other operations that you can perform on bit\par
strings, or on other values to get a bit string result.\par
\par
## Concatenation\par
The required syntax for a bit string concatenation is:\par
\par
bit concatenation ::=\par
bit_string_operand_1 || bit_string_operand_2\par
\par
The concatenation operator operates on two operands, both of which must\par
evaluate to a bit string. It joins the strings together in the order given and\par
returns a bit string with a length equal to the sum of the lengths of its\par
operands. If either of the operands is NULL, the result of the operation is\par
also NULL. Here are two examples of bit string concatenations:\par
\par
   B'0000' || B'0011'    -- returns 00000011\par
\par
   bit_column || B'0011' -- returns bit_column's value followed by 0011\par
\par
[Obscure Rule] If both operands are fixed length bit strings, the\par
concatenation result is a fixed length bit string with a length equal to the\par
sum of the lengths of the operands -- this length may not exceed the maximum\par
allowed for a fixed length bit string. If either operand is a variable length\par
bit string and the sum of their lengths is not greater than the maximum\par
allowed length for a variable length bit string, the concatenation result is a\par
variable length bit string with a length equal to the sum of the lengths of\par
the operands. If the sum of the operands' lengths is greater than the maximum\par
allowed, but the extra bits are all 0- bits, the concatenation result is a\par
variable length bit string with a length equal to the maximum allowed length.\par
If the sum of the operands' lengths is greater than the maximum allowed, and\par
the extra bits are not all 0-bits, the concatenation will fail: your DBMS will\par
return the SQLSTATE error 22001 "data exception-string data, right truncation".\par
\par
If you want to restrict your code to Core SQL, don't use the concatenation\par
operator with bit strings.\par
\par
## Scalar functions\par
SQL provides three scalar functions that return a bit string: the <case\par
expression>, the <cast specification> and the <bit substring function>. It\par
also provides four scalar functions that operate on bit strings, returning a\par
number: the <bit position expression>, the <bit length expression>, the <char\par
length expression> and the <octet length expression>. All but the first two\par
are described below. We'll discuss the rest in other chapters; for now, just\par
remember that they evaluate to a bit string and can therefore be used anywhere\par
in an SQL statement that a bit string could be used.\par
\par
<bit substring function> --\par
The required syntax for a <bit substring function> is:\par
\par
<bit substring function> ::=\par
SUBSTRING (\par
      bit_argument\par
      FROM start_argument\par
      [ FOR length_argument ])\par
\par
SUBSTRING operates on three arguments: the first must evaluate to a bit\par
string, the other two must evaluate to exact numeric integers. It extracts a\par
substring from "bit_argument" and returns a variable length bit string with a\par
maximum length that equals the fixed length, or maximum variable length, of\par
the bit argument (as applicable). If any of the arguments are NULL, SUBSTRING\par
returns NULL.\par
\par
The "start_argument" is a number that marks the first bit you want to extract\par
from "bit_argument". If SUBSTRING includes the (optional) FOR clause,\par
"length_argument" is the total number of bits you want to extract. If you omit\par
the FOR clause, SUBSTRING will begin at "start_argument" and extract all the\par
rest of the bits in "bit_argument". Here are some examples of SUBSTRING:\par
\par
   SUBSTRING(B'10001100' FROM 5)        -- returns 1100\par
\par
   SUBSTRING(B'10001100' FROM 5 FOR 3)  -- returns 110\par
\par
   SUBSTRING(bit_column FROM 1 FOR 4)   -- returns the first four bits of the value in BIT_COLUMN\par
\par
If "start_argument" is larger than the length of "bit_argument", or if the\par
length of the required substring is less than one, SUBSTRING returns a zero-\par
length bit string. If the length of the required substring is less than\par
"start_argument", SUBSTRING will fail: your DBMS will return the SQLSTATE\par
error 22011 "data exception-substring error".\par
\par
[Obscure Rule] SUBSTRING can also operate on a character string and a BLOB.\par
We've ignored these options for now -- look for them in our chapters on\par
character strings and BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use SUBSTRING with bit strings.\par
\par
<bit position expression> --\par
The required syntax for a <bit position expression> is:\par
\par
<bit position expression> ::=\par
POSITION (\par
      bit_argument_1\par
      IN bit_argument_2)\par
\par
POSITION operates on two arguments, both of which must evaluate to a bit\par
string. It determines the first bit position (if any) at which\par
"bit_argument_1" is found in "bit_argument_2" and returns this as an exact\par
numeric integer. If either of the arguments are NULL, POSITION returns NULL.\par
If "bit_argument_1" is a zero-length bit string, POSITION returns one. If\par
"bit_argument_1" is not found in "bit_argument_2", POSITION returns zero. Here\par
is an example:\par
\par
   POSITION(B'1011' IN B'001101011011')\par
   -- returns 9\par
\par
[NON-PORTABLE] The precision of POSITION's result is non-standard because the\par
SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of POSITION an INTEGER <data type>.\par
\par
[Obscure Rule] POSITION can also operate on a character string and a BLOB.\par
We've ignored these options for now -- look for them in our chapters on\par
character strings and BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use POSITION with bit strings.\par
\par
<bit length expression> --\par
The required syntax for a <bit length expression> is:\par
\par
<bit length expression> ::=\par
BIT_LENGTH (bit_argument)\par
\par
BIT_LENGTH operates on an argument that evaluates to a bit string. It\par
determines the length of the argument, in bits, and returns this as an exact\par
numeric integer, e.g.: BIT_LENGTH(B'10110011') returns 8 and\par
BIT_LENGTH(X'4AD9') returns 16. If the argument is NULL, BIT_LENGTH returns NULL.\par
\par
[NON-PORTABLE] The precision of BIT_LENGTH's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of BIT_LENGTH an INTEGER <data type>.\par
\par
[Obscure Rule] BIT_LENGTH can also operate on a character string and a BLOB.\par
We've ignored these options for now -- look for them in our chapters on\par
character strings and BLOBs.\par
\par
<char length expression> --\par
The required syntax for a <char length expression> is:\par
\par
<char length expression> ::=\par
\{CHAR_LENGTH | CHARACTER_LENGTH\} (bit_argument)\par
\par
CHAR_LENGTH (or CHARACTER_LENGTH) operates on an argument that evaluates to a\par
bit string. It determines the length of the argument, in octets, and returns\par
this as an exact numeric integer, e.g.: CHAR_LENGTH(B'10110011') returns 1 and\par
CHAR_LENGTH(X'4AD9') returns 2. (The octet length of a string is the bit\par
length divided by 8, ignoring any remainder.) If the argument is NULL,\par
CHAR_LENGTH returns NULL.\par
\par
[NON-PORTABLE] The precision of CHAR_LENGTH's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of CHAR_LENGTH an INTEGER <data type>.\par
\par
[Obscure Rule] CHAR_LENGTH can also operate on a character string and a BLOB.\par
We've ignored these options for now -- look for them in our chapters on\par
character strings and BLOBs.\par
\par
<octet length expression> --\par
The required syntax for a <octet length expression> is:\par
\par
<octet length expression> ::=\par
OCTET_LENGTH (bit_argument)\par
\par
OCTET_LENGTH operates on an argument that evaluates to a bit string. It\par
determines the length of the argument, in octets, and returns this as an exact\par
numeric integer, e.g.: OCTET_LENGTH(B'10110011') returns 1 and\par
OCTET_LENGTH(X'4AD9') returns 2. (The octet length of a string is the bit\par
length divided by 8, ignoring any remainder.) If the argument is NULL,\par
OCTET_LENGTH returns NULL.\par
\par
[NON-PORTABLE] The precision of OCTET_LENGTH's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of OCTET_LENGTH an INTEGER <data type>.\par
\par
[Obscure Rule] OCTET_LENGTH can also operate on a character string and a BLOB.\par
We've ignored these options for now -- look for them in our chapters on\par
character strings and BLOBs.\par
\par
## Set functions\par
SQL provides five set functions that operate on bit strings: COUNT(*), COUNT,\par
MAX, MIN and GROUPING. Since none of these operate exclusively with bit string\par
arguments, we won't discuss them here; look for them in our chapter on set functions.\par
\par
## Predicates\par
In addition to the comparison operators, SQL provides eight other predicates\par
that operate on bit strings: the <between predicate>, the <in predicate>, the\par
<null predicate>, the <exists predicate>, the <unique predicate>, the <match\par
predicate>, the <quantified predicate> and the <distinct predicate>. Each will\par
return a boolean value: either TRUE, FALSE or UNKNOWN. None of these operate\par
strictly on bit strings, so we won't discuss them here. Look for them in our\par
chapter on search conditions.\par
\page\par
Chapter 5 -- Binary strings\par
\par
In SQL, a binary string, or BLOB, is any arbitrary sequence of zero or more\par
octets that isn't associated with either a Character set or a Collation. A\par
BLOB value may be a <literal>, the value of a parameter or a host language\par
variable or the result of any expression or argument (including a possibly\par
qualified <Column name>) that evaluates to a binary string. BLOBS represent an\par
unknown lump of binary data: the typical use of a BLOB <data type> is to store\par
an image.\par
\par
Octets in a BLOB are numbered (from left to right) beginning with 1 (the most\par
significant octet). BLOBs are stored in the binary string <data type>: BLOB.\par
\par
<BLOB literal>s\par
\par
A <BLOB literal> is the letter "X" (upper case mandatory) followed by a string\par
of zero or more hexits inside a pair of single quote marks. (A hexit is either\par
(a) any of the digits 0 through 9 or (b) any of the letters A through F (upper\par
case or lower case allowed) and is four bits long -- 0, 1, 2, 3, 4, 5, 6, 7,\par
8, 9, A, B, C, D, E and F are interpreted as 0000, 0001, 0010, 0011, 0100,\par
0101, 0110, 0111, 1000, 1001, 1010, 1011, 1100, 1101, 1110 and 1111,\par
respectively.) Its <data type> is variable length BLOB. The <literal>'s length\par
is four times the number of hexits inside the quote marks; the delimiting\par
single quotes are not part of the <literal>, therefore they are not included\par
in the calculation of the <BLOB literal>'s size. Here are some examples of <BLOB literal>s:\par
\par
   X'49FE'\par
\par
   X'a31d'\par
\par
[Obscure Rule] A long <BLOB literal> may be broken up into two or more smaller\par
<BLOB literal>s, split by a <separator> that must include a newline character.\par
When such a <literal> is encountered, your DBMS will ignore the <separator>\par
and treat the multiple strings as a single <literal>. For example, these two\par
<BLOB literal>s are equivalent:\par
\par
   X'49FE'\par
'A31D'\par
\par
   X'49FEA31D'\par
\par
(In the first example, there is a carriage return newline <separator> between "FE'" and "'A3".)\par
\par
BLOB <data type>s\par
\par
A BLOB <data type> is defined by a descriptor that contains two pieces of information:\par
      ## The <data type>'s name: BINARY LARGE OBJECT.\par
      ## The <data type>'s maximum length in octets.\par
\par
BLOB:\par
The required syntax for a BINARY LARGE OBJECT <data type> specification is:\par
\par
BINARY LARGE OBJECT <data type> ::=\par
\{ BINARY LARGE OBJECT | BLOB \} [ (length) ]\par
\par
BINARY LARGE OBJECT may be abbreviated as BLOB and is a variable length binary\par
string, up to "length" octets long; it defines a set of binary string values\par
that are any correctly sized string of octets that are not associated with a\par
Character set or a Collation. For example, these <BLOB literal>s:\par
\par
   X'49FE'\par
\par
   X'178FA3A8'\par
\par
are both valid values for this <data type> specification:\par
\par
   BLOB(8)\par
\par
The optional length, if specified, is an unsigned positive integer, possibly\par
followed by a letter code (either K, M or G), that defines the maximum octet\par
length of acceptable values. The minimum length allowed is 1.\par
      ## If the length is defined as "integer K", the BLOB may hold up to\par
"integer*1024" octets; if the length is defined as "integer M", the BLOB may\par
hold up to "integer*1,048,576" octets and if the length is defined as "integer\par
G", the BLOB may hold up to "integer*1,073,741,824" octets. For example, this\par
<data type> specification defines a set of binary string values that may range\par
from zero to 20 octets:\par
\par
   BLOB(20)\par
\par
(Zero length binary strings can be stored in a BLOB field.)\par
\par
This <data type> specification defines a set of binary string values that may\par
range from zero to 2048 octets:\par
\par
   BLOB(2K)\par
\par
This <data type> specification defines a set of binary string values that may\par
range from zero to 2,097,152 octets:\par
\par
   BLOB(2M)\par
\par
And this <data type> specification defines a set of binary string values that\par
may range from zero to 2,147,483,648 octets:\par
\par
   BLOB(2G)\par
\par
[NON-PORTABLE] The default length and the maximum length for BLOB are non-\par
standard because the SQL Standard requires implementors to define BLOB's\par
default and maximum lengths.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the length of BLOB to range from 1 to 32 and sets the default length of a BLOB\par
<data type> to 1K. For example, these two <data type> specifications are\par
equivalent: both define a set of binary string values that may range from zero to 1024 octets:\par
\par
   BLOB\par
\par
   BLOB(1K)\par
\par
Now that we've described SQL's BLOB <data type>, let's look at some example\par
SQL statements that put it to use.\par
\par
These SQL statements make a Table with one binary string Column, insert a row,\par
then search for any binary string equal to the bit string 01000100.\par
\par
CREATE TABLE Binary_Examples (\par
      occurrence_binary BLOB(2K));\par
\par
INSERT INTO Binary_Examples (\par
      occurrence_binary)\par
      VALUES (X'4D');\par
\par
SELECT occurrence_binary,\par
FROM   Binary_Examples\par
WHERE  occurrence_binary = X'44';\par
\par
BLOB Operations\par
\par
A BLOB is compatible with, and comparable to, all other BLOBs -- that is, all\par
BLOBs are mutually assignable and mutually comparable. BLOBs may not be\par
directly compared with, or directly assigned to, any other <data type> class,\par
though implicit type conversions can sometimes occur in expressions, SELECTs,\par
INSERTs, DELETEs and UPDATEs. Explicit BLOB conversions can be forced with the CAST operator.\par
\par
CAST:\par
In SQL, CAST is a scalar operator that converts a given scalar value to a\par
given scalar <data type>. The required syntax for the CAST operator is:\par
\par
CAST (<cast operand> AS <cast target>)\par
\par
   <cast operand> ::= scalar_expression\par
\par
   <cast target> ::= <Domain name> | <data type>\par
\par
The CAST operator converts values of a source <data type> into values of a\par
target <data type>, where each <data type> is an SQL pre-defined <data type>\par
(data conversions between UDTs are done with a user-defined cast). The source\par
<data type>, or <cast operand>, can be any expression that evaluates to a\par
single value. The target <data type>, or <cast target>, is either an SQL\par
predefined <data type> specification or the name of a Domain whose defined\par
<data type> is the SQL predefined <data type> that you want to convert the\par
value of "scalar_expression" into. (If you use CAST ... AS <Domain name>, your\par
current <AuthorizationID> must have the USAGE Privilege on that Domain.)\par
\par
It isn't, of course, possible to convert the values of every <data type> into\par
the values of every other <data type>. For BLOBs, the rules are:\par
      ## CAST (NULL AS <data type>) and CAST (blob_source_is_a_null_value AS <data type>)\par
both result in a CAST of NULL.\par
      ## You can CAST a BLOB source to a BLOB target. You can also CAST a BLOB\par
source to a UDT target or a <reference type> target if a user-defined cast\par
exists for this purpose and your current <AuthorizationID> has the EXECUTE\par
Privilege on that user-defined cast.\par
\par
When you CAST a BLOB to a BLOB target, if the octet length of the source value\par
is less than or equals the maximum octet length of the target, the result of\par
the CAST is the source BLOB value. If the octet length of the source value is\par
greater than the maximum octet length of the target, the result of the CAST is\par
as much of the source BLOB value as will fit into the target -- in this case,\par
and your DBMS will return the SQLSTATE warning 01004 "warning-string data, right truncation".\par
\par
When you CAST a BLOB to a UDT or a <reference type> target, your DBMS invokes\par
the user defined cast routine, with the source value as the routine's\par
argument. The CAST result is the value returned by the user defined cast.\par
\par
If you want to restrict your code to Core SQL, don't use <Domain name> as a\par
CAST target: CAST only to a <data type> and don't use CAST to convert any BLOB\par
value to another <data type>.\par
\par
Assignment:\par
In SQL, when a BLOB is assigned to a BLOB target, the assignment is done one\par
octet at a time, from left to right -- that is, the source value's most\par
significant octet is assigned to the target's most significant octet, then the\par
source's next octet is assigned to the target's next octet, and so on.\par
\par
When a BLOB is taken from SQL-data to be assigned to a BLOB target, the size\par
of the target is first set either to the size of the source or to its own\par
maximum length, whichever is less. If the source is longer than the target,\par
the source is truncated to fit the target. In this case, your DBMS will return\par
the SQLSTATE warning 01004 "warning-string data, right truncation".\par
\par
[Obscure Rule] Since only SQL accepts null values, if your source is NULL,\par
then your target's value is not changed. Instead, your DBMS will set its\par
indicator parameter to -1, to indicate that an assignment of the null value\par
was attempted. If your target doesn't have an indicator parameter, the\par
assignment will fail: your DBMS will return the SQLSTATE error 22002 "data\par
exception-null value, no indicator parameter". If your source is a non-null\par
value that fits into your target, your DBMS will set the target's indicator\par
parameter (if any) to zero. If your source is longer than your target, your\par
DBMS will set your target's indicator parameter to the length of the source;\par
that is, if your source is 12 octets long and your target can accept only 10\par
octets, your DBMS will set the target's indicator parameter to 12, to indicate\par
that 2 octets were lost on assignment. If the source's length is too big to be\par
assigned to the indicator, the assignment will fail: your DBMS will return the\par
SQLSTATE error 22022 "data exception-indicator overflow". We'll talk more\par
about indicator parameters in our chapters on SQL binding styles.\par
\par
When a BLOB is assigned to a SQL-data BLOB target, the size of the target is\par
first set either to the size of the source or to its own maximum length,\par
whichever is less. If the source is larger than the target, but the extra\par
octets are all 0-octets, the source's significant octet value is assigned to\par
the target. If the source is larger than the target and the extra octets are\par
not all 0-octets, the assignment will fail: your DBMS will return the SQLSTATE\par
error 22001 "data exception-string data, right truncation".\par
\par
[Obscure Rule] There are two ways to assign a null value to an SQL-data\par
target. Within SQL, you can use the <keyword> NULL in an INSERT or an UPDATE\par
statement to indicate that the target should be set to NULL; that is, if your\par
source is NULL, your DBMS will set your target to NULL. Outside of SQL, if\par
your source has an indicator parameter that is set to -1, your DBMS will set\par
your target to NULL (regardless of the value of the source). (An indicator\par
parameter with a value less than -1 will cause an error: your DBMS will return\par
the SQLSTATE error 22010 "data exception-invalid indicator parameter value".)\par
\par
Comparison:\par
SQL provides only two scalar comparison operators -- = and <> -- to perform\par
operations on BLOBs. These will be familiar; there are equivalent operators in\par
other computer languages. If any of the comparands are NULL, the result of the\par
operation is UNKNOWN. For example:\par
\par
   X'A3D0' = X'A3D0'\par
\par
returns TRUE.\par
\par
   X'A3D0' <> \{result is NULL\}\par
\par
returns UNKNOWN.\par
\par
When a BLOB is compared to another BLOB, the comparison is done one octet at a\par
time, from left to right -- that is, the first comparand's most significant\par
octet is compared to the second comparand's most significant octet, then the\par
next two octets are compared, and so on. Two BLOBs, blob_argument_1 and\par
blob_argument_2, are equal if (a) they have the same length and (b) each octet\par
within blob_argument_1 compares as equal to the corresponding octet in blob_argument_2.\par
\par
If you want to restrict your code to Core SQL, don't use BLOBs in comparisons.\par
\par
Other Operations:\par
With SQL, you have several other operations that you can perform on BLOBs.\par
\par
## Concatenation\par
The required syntax for a BLOB concatenation is:\par
\par
BLOB concatenation ::=\par
BLOB operand_1 || BLOB operand_2\par
\par
The concatenation operator operates on two operands, both of which must\par
evaluate to a BLOB. It joins the binary strings together in the order given\par
and returns a BLOB with a length equal to the sum of the lengths of its\par
operands. If either of the operands is NULL, the result of the operation is\par
also NULL. Here are two examples of BLOB concatenations:\par
\par
   X'0000' || X'0011'     -- returns 00000011\par
\par
   blob_column || X'0011' -- returns blob_column's value followed by 0011\par
\par
[Obscure Rule] If the sum of the lengths of a BLOB concatenation's operands is\par
not greater than the maximum allowed length for a BLOB, the concatenation\par
result is a BLOB with a length equal to the sum of the lengths of the\par
operands. If the sum of the operands' lengths is greater than the maximum\par
allowed, but the extra octets are all 0-octets, the concatenation result is a\par
BLOB with a length equal to the maximum allowed length. If the sum of the\par
operands' lengths is greater than the maximum allowed and the extra octets are\par
not all 0-octets, the concatenation will fail: your DBMS will return the\par
SQLSTATE error 22001 "data exception-string data, right truncation".\par
\par
If you want to restrict your code to Core SQL, don't use the concatenation operator with BLOBs.\par
\par
## Scalar functions\par
SQL provides five scalar functions that return a BLOB: the <case expression>,\par
the <cast specification>, the <BLOB substring function>, the <BLOB overlay\par
function> and the <BLOB trim function>. It also provides four scalar functions\par
that operate on BLOBs, returning a number: the <BLOB position expression>, the\par
<bit length expression>, the <char length expression> and the <octet length\par
expression>. All but the first two are described below. We'll discuss the rest\par
in other chapters; for now, just remember that they evaluate to a binary\par
string and can therefore be used anywhere in an SQL statement that a binary string could be used.\par
\par
<BLOB substring function> --\par
The required syntax for a <BLOB substring function> is:\par
\par
<BLOB substring function> ::=\par
SUBSTRING (blob_argument\par
   FROM start_argument [ FOR length_argument ])\par
\par
SUBSTRING operates on three arguments: the first must evaluate to a BLOB, the\par
other two must evaluate to exact numeric integers. It extracts a substring\par
from "blob_argument" and returns a BLOB with a maximum length that equals the\par
maximum length of the BLOB argument. If any of the arguments are NULL,\par
SUBSTRING returns NULL.\par
\par
The "start_argument" is a number that marks the first octet you want to\par
extract from "blob_argument". If SUBSTRING includes the (optional) FOR clause,\par
"length_argument" is the total number of octets you want to extract. If you\par
omit the FOR clause, SUBSTRING will begin at "start_argument" and extract all\par
the rest of the octets from "blob_argument". Here are some examples of\par
SUBSTRING:\par
\par
   SUBSTRING(X'1049FE2996D54AB7' FROM 5)        -- returns 96D54AB7\par
\par
   SUBSTRING(X'1049FE2996D54AB7' FROM 5 FOR 3)  -- returns 96D54A\par
\par
   SUBSTRING(blob_column FROM 1 FOR 4)          -- returns the first four octets of the value in BLOB_COLUMN\par
\par
If "start_argument" is larger than the length of "blob_argument", or if the\par
length of the required substring is less than one, SUBSTRING returns a zero-\par
length binary string. If the length of the required substring is less than\par
"start_argument", SUBSTRING will fail: your DBMS will return the SQLSTATE\par
error 22011 "data exception-substring error".\par
\par
[Obscure Rule] SUBSTRING can also operate on a bit string and a character\par
string. We've ignored these options for now -- look for them in our chapters\par
on bit strings and character strings.\par
\par
If you want to restrict your code to Core SQL, don't use SUBSTRING with BLOBs.\par
\par
<BLOB overlay function> --\par
The required syntax for a <BLOB overlay function> is:\par
\par
<BLOB overlay function> ::=\par
OVERLAY (blob_argument_1 PLACING blob_argument_2\par
   FROM start_argument [ FOR length_argument ])\par
\par
OVERLAY operates on four arguments: the first two must evaluate to BLOBs, the\par
other two must evaluate to exact numeric integers. It extracts a substring\par
from "blob_argument_1", replacing it with "blob_argument_2", and returns the\par
resulting BLOB. If any of the arguments are NULL, OVERLAY returns NULL.\par
\par
The "start_argument" is a number that marks the first octet you want to\par
replace in "blob_argument_1". If OVERLAY includes the (optional) FOR clause,\par
"length_argument" is the total number of octets you want to extract from\par
"blob_argument_1". If you omit the FOR clause, OVERLAY will begin at\par
"start_argument" and extract the number of octets in "blob_argument_2". Here\par
are some examples of OVERLAY:\par
\par
   OVERLAY(X'1049FE2996D54AB7' PLACING X'1010' FROM 5)\par
    -- returns 1049FE2910104AB7\par
\par
   OVERLAY(X'1049FE2996D54AB7' PLACING X'1010' FROM 5 FOR 1)\par
    -- returns 1049FE291010D54AB7\par
\par
[Obscure Rule] OVERLAY can also operate on a character string. We've ignored\par
this option for now -- look for it in our chapter on character strings.\par
\par
<BLOB trim function> --\par
The required syntax for a <BLOB trim function> is:\par
\par
<BLOB trim function> ::=\par
TRIM ( [ [ \{ LEADING | TRAILING | BOTH \} ]\par
      [ blob_argument_1 ] FROM ]\par
      blob_argument_2)\par
\par
TRIM operates on two arguments, both of which must evaluate to BLOBs. It\par
strips all leading, all trailing or all leading and all trailing trim octets\par
from "blob_argument_2" and returns the resulting BLOB. If any of the arguments\par
are NULL, TRIM returns NULL.\par
\par
The trim specification is either LEADING (i.e.: trim all leading trim octets),\par
TRAILING (i.e.: trim all trailing trim octets) or BOTH (i.e.: trim all leading\par
and all trailing trim octets). If this clause is omitted, TRIM defaults to\par
BOTH. For example, these two TRIM functions are equivalent: they both strip\par
away all leading and all trailing zero-octets:\par
\par
   TRIM(X'00' FROM blob_column)\par
\par
   TRIM(BOTH X'00' FROM blob_column)\par
\par
"blob_argument_1" defines the trim octet: the octet that should be stripped\par
away by the TRIM function. If "blob_argument_1" is omitted, TRIM strips zero-\par
octets away. For example, these two TRIM functions are equivalent: they both\par
strip away all trailing zero-octets:\par
\par
   TRIM(TRAILING FROM blob_column)\par
\par
   TRIM(TRAILING X'00' FROM blob_column)\par
\par
These two TRIM functions are equivalent: they both strip away all leading zero-octets:\par
\par
  TRIM(LEADING FROM blob_column)\par
\par
  TRIM(LEADING X'00' FROM blob_column)\par
\par
These two TRIM functions are equivalent: they both strip away all leading and all trailing zero-octets:\par
\par
   TRIM(blob_column)\par
\par
   TRIM(BOTH X'00' FROM blob_column)\par
\par
If the length of "blob_argument_1" is not one octet, TRIM will fail: your DBMS\par
will return the SQLSTATE error 22027 "data exception-trim error".\par
\par
[Obscure Rule] TRIM can also operate on a character string. We've ignored this\par
option for now -- look for it in our chapter on character strings.\par
\par
<BLOB position expression> --\par
The required syntax for a <BLOB position expression> is:\par
\par
<BLOB position expression> ::=\par
POSITION (blob_argument_1 IN blob_argument_2)\par
\par
POSITION operates on two arguments, both of which must evaluate to a BLOB. It\par
determines the first octet position (if any) at which "blob_argument_1" is\par
found in "blob_argument_2" and returns this as an exact numeric integer. If\par
either of the arguments are NULL, POSITION returns NULL. If "blob_argument_1"\par
is a zero-length binary string, POSITION returns one. If "blob_argument_1" is\par
not found in "blob_argument_2", POSITION returns zero.  Here is an example:\par
\par
   POSITION(X'3D' IN X'AF923DA7')\par
   -- returns 5\par
\par
[NON-PORTABLE] The precision of POSITION's result is non-standard because the\par
SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of POSITION an INTEGER <data type>.\par
\par
[Obscure Rule] POSITION can also operate on a bit string and a character\par
string. We've ignored these options for now -- look for them in our chapters\par
on bit strings and character strings.\par
\par
<bit length expression> --\par
The required syntax for a <bit length expression> is:\par
\par
<bit length expression> ::=\par
BIT_LENGTH (blob_argument)\par
\par
BIT_LENGTH operates on an argument that evaluates to a BLOB. It determines the\par
length of the argument, in bits, and returns this as an exact numeric integer,\par
e.g.: BIT_LENGTH(X'4AD9') returns 16. If the argument is NULL, BIT_LENGTH returns NULL.\par
\par
[NON-PORTABLE] The precision of BIT_LENGTH's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of BIT_LENGTH an INTEGER <data type>.\par
\par
[Obscure Rule] BIT_LENGTH can also operate on a bit string and a character\par
string. We've ignored these options for now -- look for them in our chapters\par
on bit strings and character strings.\par
\par
<char length expression> --\par
The required syntax for a <char length expression> is:\par
\par
<char length expression> ::=\par
\{CHAR_LENGTH | CHARACTER_LENGTH\} (blob_argument)\par
\par
CHAR_LENGTH (or CHARACTER_LENGTH) operates on an argument that evaluates to a\par
BLOB. It determines the length of the argument, in octets, and returns this as\par
an exact numeric integer, e.g.: CHAR_LENGTH(X'4AD9') returns 2. (The octet\par
length of a string is the bit length divided by 8, ignoring any remainder.) If\par
the argument is NULL, CHAR_LENGTH returns NULL.\par
\par
[NON-PORTABLE] The precision of CHAR_LENGTH's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of CHAR_LENGTH an INTEGER <data type>.\par
\par
[Obscure Rule] CHAR_LENGTH can also operate on a bit string and a character\par
string. We've ignored these options for now -- look for them in our chapters\par
on bit strings and character strings.\par
\par
<octet length expression> --\par
The required syntax for a <octet length expression> is:\par
\par
<octet length expression> ::=\par
OCTET_LENGTH (blob_argument)\par
\par
OCTET_LENGTH operates on an argument that evaluates to a BLOB. It determines\par
the length of the argument, in octets, and returns this as an exact numeric\par
integer, e.g.: OCTET_LENGTH(X'4AD9') returns 2. (The octet length of a string\par
is the bit length divided by 8, ignoring any remainder.) If the argument is\par
NULL, OCTET_LENGTH returns NULL.\par
\par
[NON-PORTABLE] The precision of OCTET_LENGTH's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of OCTET_LENGTH an INTEGER <data type>.\par
\par
[Obscure Rule] OCTET_LENGTH can also operate on a bit string and a character\par
string. We've ignored these options for now -- look for them in our chapters\par
on bit strings and character strings.\par
\par
## Set functions\par
SQL provides three set functions that operate on binary strings: COUNT(*),\par
COUNT, and GROUPING. Since none of these operate exclusively with binary\par
string arguments, we won't discuss them here; look for them in our chapter on set functions.\par
\par
## Predicates\par
In addition to the comparison operators, SQL provides four other predicates\par
that operate on BLOBs: the <like predicate>, the <null predicate>, the <exists\par
predicate> and the <quantified predicate>. Each will return a boolean value:\par
either TRUE, FALSE or UNKNOWN. Only the first predicate operates strictly on\par
string values; we'll discuss it here. Look for the rest in our chapter on search conditions.\par
\par
<like predicate> --\par
The required syntax for a <like predicate> is:\par
\par
<like predicate> ::=\par
blob_argument [ NOT ] LIKE pattern [ ESCAPE escape_octet ]\par
\par
LIKE is a predicate that operates on three operands that evaluate to BLOBs: it\par
searches for values that contain a given pattern. NOT LIKE is the converse and\par
lets you search for values that don't contain a given pattern. The\par
"blob_argument" is the binary string you're searching within, the "pattern" is\par
the pattern you're searching for and the optional "escape_octet" is an octet\par
that tells your DBMS to treat a metacharacter in the pattern as itself (rather\par
than as a metacharacter). If "blob_argument" contains the pattern, LIKE\par
returns TRUE and NOT LIKE returns FALSE. If "blob_argument" does not contain\par
the pattern, LIKE returns FALSE and NOT LIKE returns TRUE. If any of the\par
operands are NULL, LIKE and NOT LIKE return UNKNOWN.\par
\par
The pattern you specify in "pattern" may contain any combination of regular\par
octets and metaoctets. Any single octet in "pattern" that is not a metaoctet\par
or the "escape_octet" represents itself in the pattern. For example, this predicate:\par
\par
   blob_column LIKE X'A3'\par
\par
is TRUE for the octet represented by 'A3'.\par
\par
Special significance is attached to metaoctets in a pattern. The metaoctets\par
are: _ and %. (That is, an underline octet has the same bit pattern as an\par
underline character in the SQL_TEXT Character set and a percent octet has the\par
same bit pattern as a percent sign in the SQL_TEXT Character set.) If the\par
predicate doesn't include an ESCAPE clause, they are interpreted as follows:\par
      ## _ An underline octet means "any single octet". For example, this predicate:\par
\par
   blob_column LIKE X'A_C'\par
\par
is TRUE for X'A C', X'AAC', X'ABC', X'A6C' and so on.\par
      ## %  A percent sign means "any string of zero or more octets". For example, this predicate:\par
\par
   blob_column LIKE X'A%C'\par
\par
is TRUE for X'AC', X'A C', X'ABC', X'A6C', X'A66666C' and so on.\par
\par
If you want to search for an octet that would normally be interpreted as a\par
metaoctet, you must use the optional ESCAPE clause. To do so:\par
      ## Pick an octet that you won't need in the pattern and designate it as your escape octet.\par
      ## In the pattern, use your escape octet followed immediately by the\par
metaoctet, to designate the metaoctet as an octet you want to search for. For example:\par
\par
   ... LIKE X'B%'\par
\par
(without an ESCAPE clause) means "like the hexit B followed by anything at\par
all", while:\par
\par
   ... LIKE X'B?%' ESCAPE X'?'\par
\par
means "like the hexit B followed by a percent octet" (since % is preceded by\par
the escape character it has no special significance in this pattern). Your\par
escape character can also be followed by itself in the pattern, if you want to\par
search for the escape character. For example:\par
\par
   ... LIKE X'B??' ESCAPE X'?'\par
\par
means "like the hexit B followed by a question mark octet" (since ? is\par
preceded by the escape character it has no special significance in this\par
pattern). Your best choice for an escape character is an SQL special character\par
which isn't a [NOT] LIKE metacharacter. We suggest the question mark.\par
\par
The "escape_octet" must be exactly one octet long. If it isn't, [NOT] LIKE\par
will fail: your DBMS will return the SQLSTATE error 2200D "data\par
exception-invalid escape octet". If "escape_octet" is _ or % and that\par
metaoctet is used once only in your pattern, or if "escape_octet" is used\par
without being followed by a metaoctet (or by itself) in your pattern, [NOT]\par
LIKE will fail: your DBMS will return the SQLSTATE error 22025 "data\par
exception-invalid escape sequence". For example, these two predicates will\par
both result in SQLSTATE 22025:\par
\par
   LIKE X'B%B' ESCAPE X'%'\par
\par
   LIKE X'B?B' ESCAPE X'?'\par
\par
For the purposes of [NOT] LIKE, a substring of "blob_argument" is a sequence\par
of zero or more contiguous octets, where each octet belongs to exactly one\par
such substring. A substring specifier of "pattern" is either (a) _: an\par
arbitrary octet specifier, (b) %: an arbitrary string specifier, (c)\par
"escape_octet" followed by _ or % or "escape_octet" or (d) any other single\par
octet. If "blob_argument" and "pattern" both have a length of zero, LIKE\par
returns TRUE. LIKE also returns TRUE if "pattern" is found in "blob_argument".\par
That is, LIKE returns TRUE only if the number of substrings in "blob_argument"\par
equals the number of substring specifiers in "pattern" and all of these\par
conditions are also met:\par
      ## If the pattern's n-th substring specifier is _, then the argument's n-th substring must be any single octet.\par
      ## If the pattern's n-th substring specifier is %, then the argument's n-th substring must be any sequence of zero or more octets.\par
      ## If the pattern's n-th substring specifier is any other octet, then\par
the argument's n-th substring must have the same length and bit pattern as that substring specifier.\par
\par
[Obscure Rule] [NOT] LIKE can also operate on character strings. We've ignored\par
this option for now -- look for it in our chapter on character strings.\par
\par
If you want to restrict your code to Core SQL, don't use the [NOT] LIKE\par
predicate with BLOBs.\par
\page\par
Chapter 6 -- Characters\par
\par
      "Now we know our Alphabet all the way from A to Z[ed]"\par
(Grade 1 Tune)\par
      "Now we know our ABC all the way from A to Z[ee]"\par
(same, USA variant)\par
\par
If you remember one of the above jingles, you've probably got a few things to\par
unlearn before you can use SQL character strings properly. Many people think\par
that the alphabet is something from grade 1: that they know it already. If you\par
fall into this category, be patient with us. By the end of this chapter,\par
you'll understand why we feel it's necessary to devote so much space to what\par
appears to be a fairly simple topic.\par
\par
Before we can begin to address the question "what does SQL do with\par
characters?", we have first have to ask: "what should it do?". That's why this\par
book has two chapters on characters and character strings. The first one, the\par
one you're reading, explains what characters are, what the important character\par
sets are and how to relate or switch ... the universal things. The next\par
chapter gets into what the database solutions are. After you've read this\par
chapter, you'll see why the "solutions" are varied, random and wrong.\par
\par
What is a Character?\par
\par
Consider two vertical bars with a horizontal bar between them: H. This H is a\par
glyph. To us, this glyph is a symbol -- it's the letter "Aitch" and it appears\par
in English words. Thus, a "letter" is a combination of a glyph and a meaning.\par
(The importance of this will become apparent as you go through this chapter.)\par
We know that H is the eighth letter of an alphabet. Or -- in SQL terms -- H is\par
the eighth symbol in a character repertoire. While an alphabet is a familiar\par
example of a character repertoire, any computer will also support a repertoire\par
containing digits, punctuators and special characters as well as glyphless\par
(non-printing) characters such as the '\\0' which terminates strings in C.\par
\par
However, no computer can handle the letter H by itself. It can only handle\par
numbers, so we have a convention that the letter H will be represented by some\par
number, such as 72. If we all agree that "72 is the code for H ... 74 is the\par
code for J ..." and so on for every character in the repertoire, we can make a\par
computer character set. Every character set has two parts: a character\par
repertoire and an agreement on how the repertoire's characters will be encoded\par
as numbers. (The SQL Standard calls the encoding scheme itself a Form-of-use.)\par
\par
Internationally, there are many character sets, and many names for them. When\par
using SQL, you'll be concerned mainly with the ones that the International\par
Standards Organization (ISO) has published standards for:\par
     ## ISO 646 (1965), also known as US-ASCII, DIN 66003, etc.\par
     ## ISO 8859-1 (1985), also known as LATIN 1 and Windows Code Page 1252.\par
     ## ISO 8859-2 (1987), also known as LATIN 2 and Windows Code Page 1250.\par
... and several others which we'll describe as we go along. The numeric codes\par
between 0 and 127 have the same meaning in every ISO standard; differences\par
exist only for codes greater than 127. In each standard, the codes between 0\par
and 127 include punctuation, digits, special characters and (what's most\par
important for this discussion) the upper case letters A to Z (for example, the\par
code for H is indeed 72) and the lower case letters a to z. Thus, all\par
character sets start with Latin.\par
\par
Latin:\par
Cicero never saw a W or a lower-case j, but medieval and modern Latin have 26\par
letters, each of which has two forms ("Upper Case" and "Lower Case"). These\par
are the simple Latin letters:\par
ABCDEFGHIJKLMNOPQRSTUVWXYZ     -- simple upper-case Latin letters\par
abcdefghijklmnopqrstuvwxyz     -- simple lower-case Latin letters\par
\par
These letters appear in all standard computer character sets including 7-bit\par
ASCII and EBCDIC. They even appear in character sets for languages which don't\par
use Latin. For instance, character sets used in Russia (such as KOI8R or ISO\par
8859-5) contain all the Latin letters with the same codes as 7-bit ASCII has;\par
the Russian Cyrillic letters follow the Latin letters.\par
\par
Because they are universal, the Latin letters are vital for computer\par
languages. In SQL, all <keyword>s and <regular identifier>s (or names) are\par
made with Latin letters (though they may also contain digits and the underline\par
character).\par
\par
The letters of the Latin alphabet are in alphabetic order. That might sound\par
... well, "Duh" ... but it helps to point out the most fundamental point about\par
a collation, or collating sequence -- namely, that a collation represents a\par
fixed order, and that order is known to most members of the general public.\par
They expect to see words and names sorted that way (though they don't expect A\par
to sort before a -- that's a computer thing).\par
\par
English:\par
English uses the Latin alphabet but adds rules when sorting. To set the scene\par
for the complexities that follow, here are the rules for English sorting.\par
(We'll na\'8dvely pretend that when we write \'85 l'anglaise we don't need even a\par
soup\'87on of those pesky "accented letters" for names like El Ni\'a4o -- we'll look\par
at English only. All examples come from The Concise Oxford Dictionary Of\par
Current English.)\par
\par
PREPROCESS (Map to Simple Latin Upper Case Letters)\par
     ## Preprocessing involves stripping accents off all accented characters\par
(e.g.:   becomes O), eliminating all special characters such as hyphen or\par
space or apostrophe or dot, and changing ligatures such as AE to\par
double-characters such as \rquote .\par
\par
SORT\par
     ## Use the alphabetical order: ABCDEFGHIJKLMNOPQRSTUVWXYZ\par
\par
TIE BREAKERS\par
     ## Tie breakers apply only if two words are otherwise equal.\par
     ## If a special character (such as a hyphen or apostrophe) was stripped\par
in the preprocess stage, the word containing it FOLLOWS. For example: "cant"\par
before "can't" before "Cant", "recollect" before "re-collect", "nones" before\par
"non est", "francophone" before "franc tireur".\par
     ## If a word contained an accented character, it FOLLOWS. For example:\par
"lame" before "lam\'8a".\par
     ## If a word contains a capital letter, it DOESN'T MATTER. For example:\par
"Negus" before "negus", "AR" before "Ar" -- but: "dan" before "Dan", "ma"\par
before "MA". (We acknowledge that some people believe it does matter: we\par
report only what actually happens.)\par
\par
About 50% of English-world phone books have additional rules:\par
     ## Mc and Mac appear before M (sometimes M' does too, but only in\par
Ireland). For example: "McDonald" before "Macdonald" before "Maastricht".\par
     ## Ste and St appear as if they were spelled "Saint". For example: "St\par
John" before "Saan Stores Limited".\par
     ## In these cases, we effectively combine a group of letters into one,\par
and place the result in the hidden interstices between O and M, or between R\par
and S. It looks odd, but many languages have two-letter combinations (called\par
"digraphs") which fit between primary letters of the alphabet.\par
\par
From all this, we see that English sorting involves, in addition to the basic\par
A-to-Z stuff, several special collation rules, including mapping, ligatures\par
("one character maps to two"), tie breaking and digraphs ("two characters map\par
to one"). Nobody makes a fuss about English because the special cases are\par
rare. But special cases in non-English languages are not rare at all -- they\par
are the norm, so it's the non-English collation rules that get the attention.\par
\par
French:\par
French words have:\par
a or e with Grave accent     \'8as \'85\par
a or e with Acute accent     Chr\'82tien r\'82sum\'82\par
a or i or o with Circumflex  h\ldblquote te c\ldblquote te\par
c with Cedilla               soup\'87on \'87a\par
i or e or o with Diaeresis   na\'8bf co\rdblquote p\'89rant\par
\par
In simple cases, the French sorting rules are like the English rules.\par
      ## Accented characters map to their Latin upper case equivalents\par
("r\'82sum\'82" comes after "rester" but before "retard").\par
      ## Words with accented characters come after words with none -- "\'85"\par
comes after "a" -- but that's only a tie-breaker, "\'85" comes before "abbe`".\par
Then things get complicated.\par
      ## For words with multiple accented characters, the word with the last\par
accented character FOLLOWS. For example: "p\'8ache" before "p\'8ach\'8a".\par
      ## France and French Canada don't capitalize accented letters the same\par
way. In France the upper case of the word r\'8asum\'8a is RESUME -- there are no\par
capital letters with accents, which is why the old PC-DOS Character set (IBM\par
extended ASCII) could dispense with the letters  ,   etc. But French Canadians\par
capitalize the word r\'8asum\'8a and keep the accents: R SUM .\par
\par
This shows us that we have more characters, another collation rule and\par
conflicting ideas for changing lower case to upper case.\par
\par
German:\par
German words have:\par
a or o or u with umlaut   M\'84dchen \rdblquote stlich F\'81hrer\par
sharp S or Eszet          bi\'e1chen\par
\par
Sharp S's similarity to a Greek Beta is just coincidence: it is really a\par
ligature which maps to "ss". This is the only character in any Latin alphabet\par
which is always lower case.\par
\par
There are three ways to sort characters with umlauts, depending on the\par
German-speaking country and the application.\par
      ## In the German DIN-1 official standard, \'8e = A and \'99 = O and \'9a = U.\par
That is, accented characters map to unaccented equivalents. This is the\par
standard used for dictionaries, book indexes or any lists of words. Thus,\par
F\'81hrer = Fuhrer.\par
      ## In German DIN-2 official standard, \'8e = AE and \'99 = OE and \'9a = UE. That\par
is, accented characters map to unaccented character plus E. This is the\par
standard used for phone books, voter lists, or any lists of names in Germany.\par
Thus, G\rdblquote bbels = Goebbels and D\'81sseldorf = Duesseldorf.\par
      ## In the Austrian unofficial standard, \'8e > AZ and \'99 > OZ and \'9a > UZ.\par
That is, accented character are treated as a separate letter between A and B\par
or O and P or U and V. This is the standard used for lists of names in\par
Austria. Thus, M\'81ller > Mzilikaze.\par
      ## The Swiss use DIN 1 for all sorting.\par
\par
The German tie-breaker rules are: unaccented before accented (this rule is\par
universal), Eszet before umlaut, umlaut before any other accent. Here are\par
three lists sorted according to DIN 1 (Z\'81rich phone book), DIN 2 (Berlin phone\par
book) and Austrian collation (Vienna phone book):\par
\par
DIN-1     DIN-2     Austrian\par
Moeller   Moeller   Moeller\par
Moffat    M\rdblquote ller    Moffat\par
M\rdblquote ller    Moffat    Morse\par
Morse     Morse     M\rdblquote ller\par
M\rdblquote se      M\rdblquote se      M\rdblquote se\par
Motler    Motler    Motler\par
\par
At this point, you may be wondering what happens if you click "use German\par
collating sequence" on some Windows dialog box. Well, Microsoft seems to\par
prefer DIN 1, but the point is: if you just click, you'll get a Microsoft\par
choice which is wrong at least half the time. As we said at the beginning of\par
this chapter: you have to know what the problem is before you know what the\par
solutions are worth.\par
\par
Spanish:\par
Spanish words have:\par
tilde over n               ca\'a4on\par
acute accent over a u o i  coraz\bullet n\par
\par
Some circles (such as the Spanish-speaking community in the United States) use\par
the English style rules to sort Spanish words: all accented characters map to\par
their simple Latin equivalents, period. However, the following discussion on\par
Spanish collation refers to the traditional rules which apply in most situations.\par
      ## CH comes between C and D\par
      ## LL comes between L and M\par
      ## N comes before \'a5\par
(From now on, we'll use the formula "<x> follows <y>" to mean "<x> is treated\par
as a separate letter which follows <y> in the alphabet", as in: CH follows C.\par
\par
The Spanish CH and LL digraphs are truly separate letters. They get separate\par
headings in the dictionaries and the Spanish alphabet really has 28 letters:\par
"a b c ch d e f g h i j k l ll m n \'a4 o p q r s t u v x y z".\par
\par
Here is an example of a sorted Spanish list:\par
calza\par
calle\par
cantor\par
canon\par
culto\par
che\par
\par
Dutch, Italian, Portuguese, Basque, Catalan:\par
These languages present no special problems. Dutch does have one digraph, IJ,\par
which is sometimes used for Y, but it is acceptable to use the letters IJ and\par
sort with the digraph IJ. Acute accents are common in Portuguese, grave\par
accents in Italian; however, they all map to simple Latin letters and there\par
are no special collation rules.\par
\par
Welsh:\par
CH follows C. FF follows F. LL follows L. PH follows P. RH follows R. TH follows T.\par
\par
Nordic:\par
The Scandinavian alphabets have a common history and a few similar features,\par
the most notable of which is their tendency to add letters at the end of the\par
alphabet (after Z).\par
\par
Central Europe:\par
So far, we've discussed eleven alphabets and collations without having to\par
change the standard computer character set. Every one of the symbols in the\par
alphabets we've discussed appears in ISO 8859-1, usually called the LATIN I\par
character set. They also appear in ISO 8859-1's most famous derivative,\par
Windows code page 1252, which is the default code page on computers in North\par
America and in all European countries west of a line drawn through Finland,\par
Germany, Austria and Italy. We are now going to cross that line, and briefly\par
discuss ISO 8859-2, usually called the LATIN 2 character set (or, in Windows,\par
code page 1250).\par
\par
The Central European character set supports languages that use Latin-based\par
characters with macrons, slashes, haceks, ogoneks, breves, bars and carons.\par
Many of these do not map to a simple Latin letter when sorting.\par
\par
The many extra letters created by adding these marks to the simple Latin\par
letters made it impossible to fit them all into the 8-bit LATIN 1 character\par
set, since there can only be a maximum of 256 different symbols in an 8-bit\par
set. (In fact, LATIN 1 actually provides fewer than 256 characters because\par
0x00 to 0x1f and 0x7f to 0x9f are reserved for control "characters".)\par
Therefore, the most convenient thing to do was group the Latin-based East\par
European character sets together into LATIN 2.\par
\par
There has been lots of confusion in the past and several national character\par
set encodings are still in common use, so it's a bit idealist to write as if\par
the ISO standards were already universal; however, there's no other useful\par
assumption that a small shop can make.\par
\par
Baltic:\par
The Baltic countries have alphabets containing yet more characters,\par
culminating in the world's longest Latin-based alphabet -- Latvian. Again, the\par
addition of the extra letters made it necessary to set up another 8-bit\par
character set. This one is ISO 8859-4, usually called the BALTIC character set\par
(or, in Windows, code page 1257). The Baltic collations are the only ones in\par
which the simple Latin letters do not follow what we usually think of as\par
alphabetic order.\par
\par
Turkish:\par
The Turkish character set is defined by ISO 8859-9, usually called the LATIN 5\par
character set (or, in Windows, code page 1254). There is an irritating\par
capitalization problem in Turkish (irritating to us that is, we assume it\par
doesn't bother the Turks much): the capital of \'a1 is I, and the capital of \'8d is\par
 . Because of this single character, it is impossible to capitalize\par
simple-Latin-letter strings without being sure that the strings are not written\par
in Turkish.\par
\par
Cyrillic:\par
The main Cyrillic character sets can be represented by a single Windows code\par
page: 1251, a derivative of ISO 8859-5. In Ukrainian, the soft sign appears at\par
the end of the alphabet, instead of the position (between YERU and E) used by\par
other Cyrillic languages. This affects the order of a few words, so two\par
collations are necessary for completeness: a Ukrainian collation and a\par
generalized-Cyrillic (Bulgarian Russian Serbian) collation, which differs only\par
with respect to the position of this one letter.\par
\par
** TRAP: The Cyrillic letters A B E I J K M H O P C S T Y X are only similar\par
to Latin letters in one respect: their appearance. Remember that we defined a\par
character as "a combination of a glyph and a meaning" -- this is why.\par
Similarity don't mean equivalence. These Cyrillic letters have codes of their\par
own, they never map to Latin letters.\par
\par
Greek:\par
Greek is the oldest European character set and contains a few archaic features\par
(for example, breath marks) which don't really indicate anything nowadays. On\par
the other hand, we'd just as often want to use the Greek letters for classical\par
texts as for modern Greek. So it's good that they're all found in ISO 8859-7,\par
usually called the GREEK character set (or, in Windows, code page 1253).\par
\par
The Rest of the World:\par
We have now described all the alphabets of Europe and given you some idea of\par
their collation quirks. We think that's the minimum requirement for a book\par
that mentions character sets. We also think that it's the maximum! With some\par
relief, we note that other alphabets and other writing systems (syllabaries,\par
hieroglyphs etc.) are unavailable on a typically-configured computer in "the\par
western world", so we won't talk about them in any detail. Three other systems\par
deserve a mention, though.\par
\par
In Arabic, a character is displayable in several different forms, depending on\par
whether it is alone, or is the first, middle or last character in a word.\par
Thus, search and sort features are needed that can recognize multiple\par
encodings of the same symbol.\par
\par
In Chinese, there are at least 13000 different signs, which are implemented\par
with double byte character sets (usually "BIG5" in Taiwan, or "GB" in Red\par
China); ideally the arrangement is that characters are sorted phonetically\par
(Level 1) or according to radical and number of strokes (Level 2).\par
\par
In Japanese, several systems are in simultaneous use. For example, the word\par
for "water" can be a single character (Kanji), two characters (Hiragana), two\par
characters (Katakana) or four Latin letters (Romaji). The double character\par
sets are usually encoded using escape characters. That saves space, but makes\par
it impossible to determine a text's length or find its nth letter without\par
starting at the front and working through the text.\par
\par
What's in it for Me?\par
\par
Now that you've read this far, you know everything you'll need to write your\par
own Serbian Sort or make party chat about the relative utility of 8-bit-code\par
subsets. Of course, you're a high-level programmer -- you haven't got any\par
intention of doing either. Instead, you're going to want to ask:\par
      ## 1. Is it safe to regard character sets and collations as black boxes,\par
for which you only need to know what the inputs are without worrying about the\par
process or the outputs?\par
      ## 2. Are my OS and DBMS vendors aware of the problems and do they\par
handle all cases correctly?\par
\par
Answers (we hope you got this, if not read the chapter again):\par
      ## 1. No.\par
      ## 2. No.\par
\par
If you got both answers right, congratulations -- you've understood the\par
problem. In the next chapter, we'll look at how an SQL implementation solves\par
it, but first we'll look at the Character sets that you can expect your DBMS\par
to provide.\par
\par
Predefined Character sets\par
\par
In SQL, a Character set may be a Character set defined by a national or\par
international standard, by your DBMS or by a user of SQL-data.\par
\par
Standard-defined Character sets consist of a set of characters predefined by\par
some standards body and have a default Collation that is the order of the\par
characters in the relevant standard. The default Collation has the PAD SPACE\par
characteristic. The SQL Standard requires a DBMS to support, at a minimum,\par
these standard-defined Character sets: SQL_CHARACTER, GRAPHIC_IRV (also called\par
ASCII_GRAPHIC), LATIN1, ISO8BIT (also called ASCII_FULL) and UNICODE (also\par
called ISO10646).\par
\par
Implementation-defined Character sets consist of a set of characters\par
predefined by your DBMS and have a default Collation that is also defined by\par
your DBMS. The default Collation may have either the PAD SPACE characteristic\par
or the NO PAD characteristic. The SQL Standard requires a DBMS to support, at\par
a minimum, this implementation-defined Character set: SQL_TEXT.\par
\par
SQL_CHARACTER:\par
The SQL_CHARACTER Character set is an 8-bit Character set that consists of the\par
83 <SQL language character>s. These are found in codepage 1252; the\par
characters, and their codepage 1252 Form-of-use codes, are:\par
decimal code 032 =   <space>\par
decimal code 034 = " <double quote>\par
decimal code 037 = % <percent>\par
decimal code 038 = & <ampersand>\par
decimal code 039 = ' <single quote>\par
decimal code 040 = ( <left parenthesis>\par
decimal code 041 = ) <right parenthesis>\par
decimal code 042 = * <asterisk>\par
decimal code 043 = + <plus sign>\par
decimal code 044 = , <comma>\par
decimal code 045 = - <minus sign>\par
decimal code 046 = . <period>\par
decimal code 047 = / <solidus>\par
decimal code 048 = 0\par
decimal code 049 = 1\par
decimal code 050 = 2\par
decimal code 051 = 3\par
decimal code 052 = 4\par
decimal code 053 = 5\par
decimal code 054 = 6\par
decimal code 055 = 7\par
decimal code 056 = 8\par
decimal code 057 = 9\par
decimal code 058 = : <colon>\par
decimal code 059 = ; <semicolon>\par
decimal code 060 = < <less than operator>\par
decimal code 061 = = <equals operator>\par
decimal code 062 = > <greater than operator>\par
decimal code 063 = ? <question mark>\par
decimal code 065 = A\par
decimal code 066 = B\par
decimal code 067 = C\par
decimal code 068 = D\par
decimal code 069 = E\par
decimal code 070 = F\par
decimal code 071 = G\par
decimal code 072 = H\par
decimal code 073 = I\par
decimal code 074 = J\par
decimal code 075 = K\par
decimal code 076 = L\par
decimal code 077 = M\par
decimal code 078 = N\par
decimal code 079 = O\par
decimal code 080 = P\par
decimal code 081 = Q\par
decimal code 082 = R\par
decimal code 083 = S\par
decimal code 084 = T\par
decimal code 085 = U\par
decimal code 086 = V\par
decimal code 087 = W\par
decimal code 088 = X\par
decimal code 089 = Y\par
decimal code 090 = Z\par
decimal code 095 = _ <underscore>\par
decimal code 097 = a\par
decimal code 098 = b\par
decimal code 099 = c\par
decimal code 100 = d\par
decimal code 101 = e\par
decimal code 102 = f\par
decimal code 103 = g\par
decimal code 104 = h\par
decimal code 105 = i\par
decimal code 106 = j\par
decimal code 107 = k\par
decimal code 108 = l\par
decimal code 109 = m\par
decimal code 110 = n\par
decimal code 111 = o\par
decimal code 112 = p\par
decimal code 113 = q\par
decimal code 114 = r\par
decimal code 115 = s\par
decimal code 116 = t\par
decimal code 117 = u\par
decimal code 118 = v\par
decimal code 119 = w\par
decimal code 120 = x\par
decimal code 121 = y\par
decimal code 122 = z\par
decimal code 124 = | <vertical bar>\par
\par
[NON-PORTABLE] The default Collation for the SQL_CHARACTER Character set is\par
non-standard because the SQL Standard requires implementors to define\par
SQL_CHARACTER's default Collation. Most DBMSs will sort the characters of\par
SQL_CHARACTER in the decimal order shown above.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book has a\par
default Collation (called SQL_CHARACTER) for the SQL_CHARACTER Character set\par
that sorts the characters in their codepage 1252 decimal order.\par
\par
GRAPHIC_IRV and ASCII_GRAPHIC:\par
The GRAPHIC_IRV Character set (ASCII_GRAPHIC is a synonym) is an 8-bit\par
Character set that consists of 95 characters: all of the SQL_CHARACTER\par
characters, plus an additional 12 characters from codepage 1252. The default\par
Collation for the GRAPHIC_IRV Character set sorts the characters in their\par
codepage 1252 decimal order. The GRAPHIC_IRV characters, and their codepage\par
1252 Form-of-use codes, are (in default Collation order):\par
decimal code 032 =   <space>\par
decimal code 033 = ! <exclamation mark>\par
decimal code 034 = " <double quote>\par
decimal code 035 = # <number sign>\par
decimal code 036 = $ <dollar sign>\par
decimal code 037 = % <percent>\par
decimal code 038 = & <ampersand>\par
decimal code 039 = ' <single quote>\par
decimal code 040 = ( <left parenthesis>\par
decimal code 041 = ) <right parenthesis>\par
decimal code 042 = * <asterisk>\par
decimal code 043 = + <plus sign>\par
decimal code 044 = , <comma>\par
decimal code 045 = - <minus sign>\par
decimal code 046 = . <period>\par
decimal code 047 = / <solidus>\par
decimal code 048 = 0\par
decimal code 049 = 1\par
decimal code 050 = 2\par
decimal code 051 = 3\par
decimal code 052 = 4\par
decimal code 053 = 5\par
decimal code 054 = 6\par
decimal code 055 = 7\par
decimal code 056 = 8\par
decimal code 057 = 9\par
decimal code 058 = : <colon>\par
decimal code 059 = ; <semicolon>\par
decimal code 060 = < <less than operator>\par
decimal code 061 = = <equals operator>\par
decimal code 062 = > <greater than operator>\par
decimal code 063 = ? <question mark>\par
decimal code 064 = @ <commercial at sign>\par
decimal code 065 = A\par
decimal code 066 = B\par
decimal code 067 = C\par
decimal code 068 = D\par
decimal code 069 = E\par
decimal code 070 = F\par
decimal code 071 = G\par
decimal code 072 = H\par
decimal code 073 = I\par
decimal code 074 = J\par
decimal code 075 = K\par
decimal code 076 = L\par
decimal code 077 = M\par
decimal code 078 = N\par
decimal code 079 = O\par
decimal code 080 = P\par
decimal code 081 = Q\par
decimal code 082 = R\par
decimal code 083 = S\par
decimal code 084 = T\par
decimal code 085 = U\par
decimal code 086 = V\par
decimal code 087 = W\par
decimal code 088 = X\par
decimal code 089 = Y\par
decimal code 090 = Z\par
decimal code 091 = [ <left square bracket>\par
decimal code 092 = \\ <backslash>\par
decimal code 093 = ] <right square bracket>\par
decimal code 094 = ^ <circumflex accent mark>\par
decimal code 095 = _ <underline character>\par
decimal code 096 = ` <grave accent mark>\par
decimal code 097 = a\par
decimal code 098 = b\par
decimal code 099 = c\par
decimal code 100 = d\par
decimal code 101 = e\par
decimal code 102 = f\par
decimal code 103 = g\par
decimal code 104 = h\par
decimal code 105 = i\par
decimal code 106 = j\par
decimal code 107 = k\par
decimal code 108 = l\par
decimal code 109 = m\par
decimal code 110 = n\par
decimal code 111 = o\par
decimal code 112 = p\par
decimal code 113 = q\par
decimal code 114 = r\par
decimal code 115 = s\par
decimal code 116 = t\par
decimal code 117 = u\par
decimal code 118 = v\par
decimal code 119 = w\par
decimal code 120 = x\par
decimal code 121 = y\par
decimal code 122 = z\par
decimal code 123 = \{ <left brace>\par
decimal code 124 = | <vertical bar>\par
decimal code 125 = \} <right brace>\par
decimal code 126 = ~ <tilde>\par
\par
[NON-PORTABLE] The default Collation for the GRAPHIC_IRV Character set has a\par
non-standard name because the SQL Standard requires implementors to define\par
what a legal <Collation name> is.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book has a\par
default Collation called ASCII_GRAPHIC for the GRAPHIC_IRV Character set.\par
\par
LATIN1:\par
The LATINI Character set is an 8-bit Character set that consists of all the\par
characters commonly used in Danish, Dutch, English, Faeroese, Finnish, French,\par
German, Icelandic, Irish, Italian, Norwegian, Portuguese, Spanish and Swedish\par
-- a total of 191 characters: all of the GRAPHIC_IRV characters, plus an\par
additional 96 characters from codepage 1252. The default Collation for the\par
LATIN1 Character set sorts the characters in their codepage 1252 decimal\par
order. The additional LATIN1 characters, and their codepage 1252 Form-of-use\par
codes, are (in default Collation order):\par
decimal code 160 =   <no-break space>\par
decimal code 161 = \- <inverted exclamation mark>\par
decimal code 162 = \'9b <cent sign>\par
decimal code 163 = \'9c <pound sign>\par
decimal code 164 =   <currency sign>\par
decimal code 165 = \'9d <yen sign>\par
decimal code 166 =   <broken bar>\par
decimal code 167 = \'b6 <paragraph sign>\par
decimal code 168 = \'a8 <diaeresis>\par
decimal code 169 = (c) <copyright sign>\par
decimal code 170 = \'a6 <feminine ordinal indicator>\par
decimal code 171 = \'ae <left angle quotation mark>\par
decimal code 172 = \'aa <not sign>\par
decimal code 173 =   <soft hyphen>\par
decimal code 174 = (r) <registered trade mark sign>\par
decimal code 175 = \'af <macron>\par
decimal code 176 =   <degree sign>\par
decimal code 177 = \'f1 <plus-minus sign>\par
decimal code 178 =   <superscript two>\par
decimal code 179 =   <superscript three>\par
decimal code 180 =   <acute accent>\par
decimal code 181 = \'e6 <micro sign>\par
decimal code 182 =   <pilcrow sign>\par
decimal code 183 =   <middle dot>\par
decimal code 184 =   <cedilla>\par
decimal code 185 =   <superscript one>\par
decimal code 186 = \'a7 <masculine ordinal indicator>\par
decimal code 187 = \'af <right angle quotation mark>\par
decimal code 188 = \'ac <fraction one quarter>\par
decimal code 189 = \'ab <fraction one half>\par
decimal code 190 = 3/4 <fraction three quarters>\par
decimal code 191 = \'a8 <inverted question mark>\par
decimal code 192 =   <A accent grave>\par
decimal code 193 =   <A acute accent>\par
decimal code 194 =   <A circumflex>\par
decimal code 195 =   <A tilde>\par
decimal code 196 = \'8e <A umlaut>\par
decimal code 197 = \'8f <A circle>\par
decimal code 198 = \rquote  <AE>\par
decimal code 199 = \'80 <C cedilla>\par
decimal code 200 =   <E accent grave>\par
decimal code 201 = \'90 <E acute accent>\par
decimal code 202 =   <E carat>\par
decimal code 203 =   <E umlaut>\par
decimal code 204 =   <I accent grave>\par
decimal code 205 =   <I acute accent>\par
decimal code 206 =   <I circumflex>\par
decimal code 207 =   <I umlaut>\par
decimal code 208 =   <D thorn>\par
decimal code 209 = \'a5 <N tilde>\par
decimal code 210 =   <O accent grave>\par
decimal code 211 =   <O acute accent>\par
decimal code 212 =   <O circumflex>\par
decimal code 213 =   <O tilde>\par
decimal code 214 = \'99 <O umlaut>\par
decimal code 215 = x <multiplication sign>\par
decimal code 216 =   <O slash>\par
decimal code 217 =   <U accent grave>\par
decimal code 218 =   <U acute accent>\par
decimal code 219 =   <U circumflex>\par
decimal code 220 = \'9a <U umlaut>\par
decimal code 221 =   <Y acute accent>\par
decimal code 222 =   <nordic P>\par
decimal code 223 = \'e1 <Eszet>\par
decimal code 224 = \'85 <a accent grave>\par
decimal code 225 = \~ <a acute accent>\par
decimal code 226 = \'83 <a circumflex>\par
decimal code 227 =   <a tilde>\par
decimal code 228 = \'84 <a umlaut>\par
decimal code 229 = \'86 <a circle>\par
decimal code 230 = \lquote  <ae>\par
decimal code 231 = \'87 <c cedilla>\par
decimal code 232 = \'8a <e accent grave>\par
decimal code 233 = \'82 <e acute accent>\par
decimal code 234 = \'88 <e circumflex>\par
decimal code 235 = \'89 <e umlaut>\par
decimal code 236 = \'8d <i accent grave>\par
decimal code 237 = \'a1 <i acute accent>\par
decimal code 238 = \'8c <i circumflex>\par
decimal code 239 = \'8b <i umlaut>\par
decimal code 240 =   <d thorn>\par
decimal code 241 =   <n tilde>\par
decimal code 242 = \bullet  <o accent grave>\par
decimal code 243 = \'a2 <o acute accent>\par
decimal code 244 = \ldblquote  <o circumflex>\par
decimal code 245 =   <o tilde>\par
decimal code 246 = \rdblquote  <o umlaut>\par
decimal code 247 = \'f6 <division sign>\par
decimal code 248 =   <o slash>\par
decimal code 249 = \emdash  <u accent grave>\par
decimal code 250 = \'a3 <u acute accent>\par
decimal code 251 = \endash  <u circumflex>\par
decimal code 252 = \'81 <u umlaut>\par
decimal code 253 =   <y acute accent>\par
decimal code 254 =   <nordic p>\par
decimal code 255 = \'98 <y umlaut>\par
\par
[NON-PORTABLE] The default Collation for the LATIN1 Character set has a non-\par
standard name because the SQL Standard requires implementors to define what a\par
legal <Collation name> is.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book has a\par
default Collation called LATIN1 for the LATIN1 Character set.\par
\par
ISO8BIT and ASCII_FULL:\par
The ISO8BIT Character set (ASCII_FULL is a synonym) is an 8-bit Character set\par
that consists of 256 characters: all of the LATIN1 characters, plus the rest\par
of the characters (including control characters and graphic characters) from\par
codepage 1252. The default Collation for the ISO8BIT Character set sorts the\par
characters in their codepage 1252 decimal order. The ISO8BIT characters, and\par
their codepage 1252 Form-of-use codes, are (in default Collation order):\par
decimal code 000 =      control character; not displayed\par
decimal code 001 =      control character; not displayed\par
decimal code 002 =      control character; not displayed\par
decimal code 003 =      control character; not displayed\par
decimal code 004 =      control character; not displayed\par
decimal code 005 =      control character; not displayed\par
decimal code 006 =      control character; not displayed\par
decimal code 007 =      control character; not displayed\par
decimal code 008 =      control character; not displayed\par
decimal code 009 =      control character; not displayed\par
decimal code 010 =      control character; not displayed\par
decimal code 011 =      control character; not displayed\par
decimal code 012 =      control character; not displayed\par
decimal code 013 =      control character; not displayed\par
decimal code 014 =      control character; not displayed\par
decimal code 015 =      control character; not displayed\par
decimal code 016 =      control character; not displayed\par
decimal code 017 =      control character; not displayed\par
decimal code 018 =      control character; not displayed\par
decimal code 019 =      control character; not displayed\par
decimal code 020 =      control character; not displayed\par
decimal code 021 =      control character; not displayed\par
decimal code 022 =      control character; not displayed\par
decimal code 023 =      control character; not displayed\par
decimal code 024 =      control character; not displayed\par
decimal code 025 =      control character; not displayed\par
decimal code 026 =      control character; not displayed\par
decimal code 027 =      control character; not displayed\par
decimal code 028 =      control character; not displayed\par
decimal code 029 =      control character; not displayed\par
decimal code 030 =      control character; not displayed\par
decimal code 031 =      control character; not displayed\par
decimal codes 032 through 126, from LATIN1\par
decimal code 127 =      control character; not displayed\par
decimal code 128 =      control character; not displayed\par
decimal code 129 =      control character; not displayed\par
decimal code 130 = ,   <comma>\par
decimal code 131 =     <f italics>\par
decimal code 132 =     <close curly double quote subscript>\par
decimal code 133 = ... <ellipsis>\par
decimal code 134 =     <cross>\par
decimal code 135 =     <double cross>\par
decimal code 136 =     <carat>\par
decimal code 137 =     <modified percent sign>\par
decimal code 138 =     <S hacek>\par
decimal code 139 =     <modified less than>\par
decimal code 140 =     <OE>\par
decimal code 141 =     control character; not displayed\par
decimal code 142 =     control character; not displayed\par
decimal code 143 =     control character; not displayed\par
decimal code 144 =     control character; not displayed\par
decimal code 145 =     <open quote sign>\par
decimal code 146 =     <close quote sign>\par
decimal code 147 =     <open curly double quote>\par
decimal code 148 =     <close curly double quote>\par
decimal code 149 =     <dark circle>\par
decimal code 150 =     <long hyphen>\par
decimal code 151 =     <hyphen>\par
decimal code 152 =     control character; not displayed\par
decimal code 153 =     <TM sign>\par
decimal code 154 =     <s hacek>\par
decimal code 155 =     <modified greater than>\par
decimal code 156 =     <oe>\par
decimal code 157 =     control character; not displayed\par
decimal code 158 =     control character; not displayed\par
decimal code 159 =     <Y umlaut>\par
decimal codes 160 through 256, from LATIN1\par
\par
[NON-PORTABLE] The default Collation for the ISO8BIT Character set has a non-\par
standard name because the SQL Standard requires implementors to define what a\par
legal <Collation name> is.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book has a\par
default Collation called ASCII_FULL for the ISO8BIT Character set.\par
\par
UNICODE and ISO10646:\par
The UNICODE Character set (ISO10646 is a synonym) is a 16-bit Character set\par
that consists of every character represented by the Unicode specification\par
(specifically, by The Unicode Standard Version 2.1). Since there are 38,887\par
characters in this set, we won't include a list in this book. It suffices to\par
say that the UNICODE Character set includes all of the ISO8BIT characters,\par
plus many others. The default Collation for the UNICODE Character set sorts\par
the characters in their Unicode Form-of-use code order.\par
[NON-PORTABLE] The default Collation for the UNICODE Character set has a non-\par
standard name because the SQL Standard requires implementors to define what a\par
legal <Collation name> is.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book has a\par
default Collation called SQL_TEXT for the UNICODE Character set.\par
\par
SQL_TEXT:\par
The SQL Standard requires every DBMS to provide an Ur-Character set named\par
SQL_TEXT. The complete set of SQL_TEXT characters is implementation defined,\par
but SQL_TEXT must contain every <SQL language character> plus every other\par
character that the DBMS supports -- that is, SQL_TEXT (at a minimum) includes\par
all of the UNICODE characters and is therefore at least a 16-bit Character\par
set.\par
\par
[NON-PORTABLE] The default Collation for the SQL_TEXT Character set must be\par
called SQL_TEXT too, but is otherwise non-standard because the SQL Standard\par
requires implementors to define the default Collation and Form-of-use of\par
SQL_TEXT.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book sorts\par
the characters of SQL_TEXT in their Unicode Form-of-use code order.\par
\par
There are some curious consequences to making SQL_TEXT (and UNICODE) a 16-bit,\par
rather than an 8-bit Character set.\par
\par
The consequences are the result of the fact that all <identifier>s and other\par
character strings in INFORMATION_SCHEMA, all <SQL-server name>s, all\par
<Connection name>s, all <AuthorizationID>s, and the results of many functions\par
(e.g.: USER, CURRENT_USER, SESSION_USER, SYSTEM_USER) are SQL_TEXT character strings.\par
\par
SQL_TEXT, however, is normally not the default Character set (the default\par
Character set is almost always an 8-bit Character set) -- and SQL specifically\par
prohibits comparisons between strings that belong to different Character sets.\par
(The rules require that, for such comparisons, one string be translated to the\par
other string's Character set first -- see "TRANSLATE function" in our chapter\par
on character strings.)\par
\par
So, will you have special trouble when you want to display INFORMATION_SCHEMA\par
strings, <AuthorizationID>s, <SQL-server name>s, <Connection name>s or the\par
like? There are two possibilities, and the answer is usually "NO" to both.\par
\par
Possibility 1:\par
Consider the following SQL statements:\par
\par
   SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES;\par
\par
   SELECT SESSION_USER FROM INFORMATION_SCHEMA.TABLES;\par
\par
The SQL Standard allows a DBMS to decide whether there should be an automatic\par
translation from SQL_TEXT to the default Character set when an SQL statement\par
assigns an SQL_TEXT string to a host language variable or parameter. In such\par
cases, most DBMSs do the automatic translation for you (as, for example, the\par
OCELOT DBMS that comes with this book does) -- so, to display the result of a\par
SELECT from INFORMATION_SCHEMA or the result from a function that returns an\par
SQL_TEXT string, you won't need to do anything special. It won't normally be\par
necessary to use the TRANSLATE function to translate the retrieved values from\par
16-bit SQL_TEXT characters into 8-bit, readable format (or vice versa) -- just\par
write your SQL statement as if the Character set difference doesn't exist. (In\par
the example above, by the way, the ASCII <identifier> TABLE_NAME would also be\par
automatically converted to a SQL_TEXT string by your DBMS before the search was done.)\par
\par
Possibility 2:\par
Consider this SQL statement:\par
\par
   SELECT TABLE_NAME\par
   FROM   INFORMATION_SCHEMA.TABLES\par
   WHERE  TABLE_NAME = 'ocelot';\par
\par
The SQL Standard does not allow a DBMS to decide whether there should be an\par
automatic translation from SQL_TEXT to the default Character set when an SQL\par
statement involves a comparison between a SQL_TEXT string and a default\par
Character set string -- but the rules do allow a DBMS to provide a predefined\par
Translation for this purpose. In such cases, most DBMSs will use this option\par
to do an automatic translation for you (as, for example, the OCELOT DBMS that\par
comes with this book does) -- so, to compare SQL_TEXT strings with default\par
Character set strings, you won't need to do anything special. It won't\par
normally be necessary to use the TRANSLATE function to translate the retrieved\par
values from 16-bit SQL_TEXT characters into 8-bit, readable format (or vice\par
versa) -- just write your SQL statement as if the Character set difference doesn't exist.\par
\par
A second consequence of the fact that SQL_TEXT is 16-bit and the default\par
Character set is usually 8-bit involves the use of <AuthorizationID>s,\par
<SQL-server name>s and <Connection name>s. Although <AuthorizationID>s,\par
<SQL-server name>s and <Connection name>s are stored as 16-bit SQL_TEXT\par
strings, the SQL-Connection arguments in CONNECT TO are inevitably in 8-bit\par
sets, since ASCII is used to type them. If, however, these same arguments are\par
assigned to host language variable parameters, you will see them as 16-bit\par
strings. Therefore, when you have an expression like this:\par
\par
   ... WHERE <AuthorizationID> = 'x' ...\par
\par
you know that the <character string literal> 'x' is a 16-bit string because\par
<Authorization ID>s are SQL_TEXT strings. But the same <literal> in a CONNECT\par
statement, e.g.:\par
\par
   CONNECT TO 'x';\par
\par
has to be an 8-bit string because it is typed in ASCII.\par
\par
One last comment, about parsing SQL_TEXT strings. Consider the following\par
expression, which concatenates a character string with a value from a Column:\par
\par
   ... _INFORMATION_SCHEMA.SQL_TEXT 'A ' || column_1\par
\par
The default Character set for an SQL statement is usually an 8-bit Character\par
set, but the string 'A ' in this example is explicitly introduced as 16-bit\par
SQL_TEXT. Thus, what appears to be two 8-bit characters -- A and <space> --\par
is, in fact, one 16-bit character, the Unicode value 4120h.\par
\par
Parsing of SQL statements is always based on 8-bit values regardless of the\par
Character set of a string, so your DBMS will consider the SQL_TEXT string 'A '\par
to begin after the first single quote mark and end before the second single\par
quote mark; i.e.: although the characters inside the single quotes are 16-bit,\par
the delimiting single quote marks themselves are 8-bit. Thus, when the parser\par
reaches the second single quote mark it knows that the string is over --\par
despite the fact that in 16-bit, a single quote mark character has not yet\par
been found.\par
\page\par
Chapter 7 -- Character strings\par
\par
In SQL, a character string is any sequence of zero or more alphanumeric\par
characters that belong to a given Character set. (A Character set is a named\par
character repertoire that includes a Form-of-use encoding scheme which defines\par
how the repertoire's characters are encoded as numbers. The SQL Standard\par
defines several standard Character sets that your DBMS must support.) A\par
character string value may be a <literal>, an <identifier>, the value of a\par
parameter or a host language variable or the result of any expression or\par
argument that evaluates to a character string. All character strings belong to\par
some Character set and are governed by the rules of some Collation during\par
comparisons. (A Collation is a named collating sequence.) Character strings\par
that belong to the same Character set are compatible.\par
\par
A character string has a length: a non-negative integer equal to the number of\par
characters in the string. Characters in a character string are numbered (from\par
left to right), beginning with 1. A Character string also has a coercibility\par
attribute; this helps your DBMS determine which Collation to use for a\par
comparison that doesn't provide an explicit COLLATE clause. The coercibility\par
attribute can be either COERCIBLE, EXPLICIT, IMPLICIT or NO COLLATION. (A\par
coercibility attribute of COERCIBLE, EXPLICIT or IMPLICIT means the string has\par
a current default Collation. A coercibility attribute of NO COLLATION means\par
the string does not have a current default Collation.) Character strings are\par
stored in either of the six character string <data type>s: CHARACTER,\par
CHARACTER VARYING, CHARACTER LARGE OBJECT, NATIONAL CHARACTER, NATIONAL\par
CHARACTER VARYING or NATIONAL CHARACTER LARGE OBJECT.\par
\par
Character string <literal>s\par
\par
An SQL <character string literal> has five parts:\par
      ## Its value: the sequence of characters that make up the <literal>.\par
      ## Its length: the number of characters that make up the <literal>.\par
      ## The name of the Character set that the <literal> belongs to.\par
      ## The name of the <literal>'s default Collation. (This is\par
the Collation that may be used to compare the <literal> with another character\par
string in the absence of an explicit COLLATE clause.)\par
      ## The <literal>'s coercibility attribute: normally COERCIBLE, but can\par
be EXPLICIT. (The coercibility attribute helps your DBMS determine which\par
Collation to use for a comparison that doesn't provide an explicit COLLATE clause.)\par
\par
A <character string literal> is either a <character string literal> or a\par
national <character string literal>.\par
\par
<character string literal>:\par
The required syntax for a <character string literal> is:\par
\par
<character string literal> ::=\par
[ _<Character set name> ]'string' [ COLLATE <Collation name> ]\par
\par
A <character string literal> is a string of zero or more alphanumeric\par
characters inside a pair of single quote marks. The string's characters must\par
all belong to the same Character set. Its <data type> is fixed length\par
CHARACTER, though it is compatible with the CHARACTER, CHARACTER VARYING,\par
CHARACTER LARGE OBJECT, NATIONAL CHARACTER, NATIONAL CHARACTER VARYING and\par
NATIONAL CHARACTER LARGE OBJECT <data type>s. The <literal>'s length is the\par
number of characters inside the quote marks; the delimiting single quotes\par
aren't part of the <literal>, so they're not included in the calculation of\par
the <character string literal>'s size. Two consecutive single quotes within a\par
character string (i.e.: '') represent one single quote mark; together, they\par
count as one character when calculating the size of the <literal>. Here is an\par
example of a <character string literal>:\par
\par
   'This is a <character string literal>'\par
\par
[Obscure Rule] The optional Character set specification -- an underline\par
character immediately preceding a <Character set name> (no space is allowed\par
between them) -- names the Character set that the <literal> belongs to. Your\par
current <AuthorizationID> must have the USAGE Privilege for that Character\par
set. For example, this <character string literal>:\par
\par
   _LATIN1'Hello'\par
\par
belongs to the LATIN1 Character set. (Note: For qualified names, the underline\par
character always precedes the highest level of explicit qualification in the\par
<Character set name>.) If you omit the Character set specification, the\par
characters in the <literal> must belong to the Character set of the SQL-client\par
Module that contains the <literal>. Here are two examples of a <character\par
string literal>:\par
\par
   'This is a string in the default Character set'\par
\par
   _LATIN1'This is a string in the LATIN1 Character set'\par
\par
[Obscure Rule] A <character string literal> normally has a coercibility\par
attribute of COERCIBLE and a default Collation that is the Collation defined\par
for its Character set -- see "Character Strings and Collations". The optional\par
COLLATE clause names the <literal>'s EXPLICIT Collation for an operation. The\par
Collation named must be a Collation defined for the relevant Character set,\par
but you may specify a default Collation for a <literal> that is different from\par
the default Collation of its Character set. If you're using COLLATE in an SQL-\par
Schema statement, then the <AuthorizationID> that owns the containing Schema\par
must have the USAGE Privilege on "<Collation name>". If you're using COLLATE\par
in any other SQL statement, then your current <AuthorizationID> must have the\par
USAGE Privilege on "<Collation name>". Here are four more examples of a\par
<character string literal>:\par
\par
   'This string in the default Character set will use the default Character set''s Collation'\par
\par
   _LATIN1'This in the LATIN1 Character set will use LATIN1''s Collation'\par
\par
   'This string in the default Character set will use a Collation named MY.COLLATION_1' COLLATE my.collation_1\par
\par
   _LATIN1'This string in the LATIN1 Character set will use a Collation named MY.COLLATION_1' COLLATE my.collation_1\par
\par
[Obscure Rule] SQL allows you to break a long <character string literal> up\par
into two or more smaller <character string literal>s, split by a <separator>\par
that includes a newline character. When it sees such a <literal>, your DBMS\par
will ignore the <separator> and treat the multiple strings as a single\par
<literal>. For example, here are two equivalent <character string literal>s:\par
\par
   'This is part of a string'\par
' and this is the other part'\par
\par
   'This is part of a string and this is the other part'\par
\par
(In the first example, there is a carriage return newline <separator> between\par
"string'" and "' and".)\par
\par
If you want to restrict your code to Core SQL, don't add a Character set\par
specification to <character string literal>s, don't add a COLLATE clause to\par
<character string literal>s and don't split long <character string literal>s\par
into smaller strings.\par
\par
<national character string literal>:\par
The required syntax for a <national character string literal> is:\par
\par
<national character string literal> ::=\par
N'string' [ COLLATE <Collation name> ]\par
\par
A <national character string literal> is a <character\par
string literal> preceded by the letter N; it is a synonym for a\par
<character string literal> that belongs to a predefined "national" Character\par
set. Its <data type> is fixed length NATIONAL CHARACTER, though it is\par
compatible with the CHARACTER, CHARACTER VARYING, CHARACTER LARGE OBJECT,\par
NATIONAL CHARACTER, NATIONAL CHARACTER VARYING and NATIONAL CHARACTER LARGE\par
OBJECT <data type>s.\par
\par
Other than the fact that you may not add a Character set specification to a\par
<national character string literal> because N'string' implies the same\par
national Character set used for NCHAR, NCHAR VARYING and NCLOB <data type>s,\par
the specifications for the two types of <character string literal>s are the\par
same. Here are two examples of a <national character string literal>:\par
\par
   N'This string in the national Character set will use the national Character set''s Collation'\par
\par
   N'This string in the national Character set will use a Collation named MY.COLLATION_1' COLLATE my.collation_1\par
\par
[NON-PORTABLE] The national Character set used by <national character string\par
literal>s and the NCHAR, NCHAR VARYING and NCLOB <data type>s is non-standard\par
because the SQL Standard requires implementors to define a national Character set.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
defines the national Character set to be ASCII_FULL. For example, here are two\par
equivalent <character string literal>s:\par
\par
   N'Hello there'\par
\par
   _ASCII_FULL'Hello there'\par
\par
If you want to restrict your code to Core SQL, don't use <national character\par
string literal>s.\par
\par
Character string <data type>s\par
\par
A character string <data type> is defined by a descriptor that contains five\par
pieces of information:\par
      ## The <data type>'s name: either CHARACTER, CHARACTER VARYING,\par
CHARACTER LARGE OBJECT, NATIONAL CHARACTER, NATIONAL CHARACTER VARYING or\par
NATIONAL CHARACTER LARGE OBJECT.\par
      ## The <data type>'s fixed length or maximum length (as applicable).\par
      ## The name of the Character set that the <data type>'s set of valid\par
values belong to. (An operation that attempts to make a character string <data\par
type> contain a character that does not belong to its Character set will fail:\par
your DBMS will return the SQLSTATE error 22021 "data exception-character not\par
in repertoire".)\par
      ## The name of the <data type>'s default Collation. (This is the\par
Collation that may be used to compare the <data type>'s values in the absence\par
of an explicit COLLATE clause.)\par
      ## The <data type>'s coercibility attribute: normally IMPLICIT, but can\par
be EXPLICIT. (The coercibility attribute helps your DBMS determine which\par
Collation to use for a comparison that doesn't provide an explicit COLLATE clause.)\par
\par
CHARACTER:\par
The required syntax for a CHARACTER <data type> specification is:\par
\par
CHARACTER <data type> ::=\par
CHARACTER [ (length) ] \par
[ CHARACTER SET <Character set name> ] \par
[ COLLATE <Collation name> ]\par
\par
CHARACTER may be abbreviated as CHAR and is a fixed length alphanumeric\par
string, exactly "length" characters long. It defines a set of character string\par
values that belong to a given Character set. For example, this <character\par
string literal>:\par
\par
   'BOB'\par
\par
is a valid value for this <data type> specification:\par
\par
   CHAR(3)\par
\par
The optional length, if specified, is an unsigned, positive integer that\par
defines the exact length, in characters, of acceptable values. The minimum\par
length and the default length are both 1. For example, these two <data type>\par
specifications:\par
\par
   CHAR\par
\par
  CHAR(1)\par
\par
both define a set of character string values that are exactly one character long.\par
\par
[NON-PORTABLE] The maximum length for CHAR is non-standard because the SQL\par
Standard requires implementors to define CHAR's maximum length. FIPS says that\par
CHAR should have a maximum length of at least 1000 characters.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
you to define a length ranging from 1 to 4096 for CHAR.\par
\par
[Obscure Rule] The optional CHARACTER SET clause names the Character set that\par
the <data type>'s values belong to. Your current <AuthorizationID> must have\par
the USAGE Privilege for that Character set. For example, this <data type>\par
specification:\par
\par
   CHAR(15) CHARACTER SET LATIN1\par
\par
defines a set of character string values, exactly 15 characters long, that\par
belong to the LATIN1 Character set. If you omit the CHARACTER SET clause when\par
specifying a character string <data type> in a <Column definition or a CREATE\par
DOMAIN statement, the <data type>'s Character set is the Character set named\par
in the DEFAULT CHARACTER SET clause of the CREATE SCHEMA statement that\par
defines the Schema that the <data type> belongs to. For example, consider this\par
SQL statement, which creates a Schema that has a default Character set of LATIN1:\par
\par
   CREATE SCHEMA schema_example \par
      DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN;\par
\par
Based on this definition, the <data type> specification in this SQL statement\par
defines a set of character string values, exactly 15 characters long, that\par
belong to the LATIN1 Character set:\par
\par
   CREATE TABLE schema_example.Table_1 ( \par
      column_1 CHAR(15));\par
\par
[NON-PORTABLE] If you omit the CHARACTER SET clause when specifying a\par
character string <data type> anywhere other than in a <Column definition> or a\par
CREATE DOMAIN statement, the <data type>'s Character set is non-standard\par
because the SQL Standard requires implementors to define a default Character\par
set for such situations.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
defines INFORMATION_SCHEMA.ASCII_FULL as the default Character set for such\par
situations.\par
\par
[Obscure Rule] A CHAR <data type> has a coercibility attribute of IMPLICIT.\par
The optional COLLATE clause defines the <data type>'s default Collation. The\par
Collation named must be a Collation defined for the relevant Character set,\par
but you may define a Column, Field or Domain with a default Collation that is\par
different from the default Collation of its Character set. If you're using\par
COLLATE in a SQL-Schema statement, then the <AuthorizationID> that owns the\par
containing Schema must have the USAGE Privilege on "<Collation name>". If\par
you're using COLLATE in any other SQL statement, then your current\par
<AuthorizationID> must have the USAGE Privilege on "<Collation name>". For\par
example, these two <data type> specifications:\par
\par
   CHAR(15) COLLATE my.collation_1\par
\par
   CHAR(15) CHARACTER SET my.charset_1 COLLATE my.collation_1\par
\par
both define a set of character string values exactly 15 characters long. The\par
first example defines the <data type>'s Character set to be the default\par
Character set. The second example defines the <data type>'s Character set to\par
be a Character set named MY.CHARSET_1. Both examples define the <data type>'s\par
default Collation to be a Collation named MY.COLLATION_1. If you omit the\par
COLLATE clause, the <data type> is defined as if its Character set's default\par
Collation was explicitly specified -- see "Character Strings and Collations".\par
\par
If you want to restrict your code to Core SQL, don't use the CHARACTER SET\par
clause or the COLLATE clause for CHAR <data type> specifications.\par
\par
NATIONAL CHARACTER:\par
The required syntax for a NATIONAL CHARACTER <data type> specification is:\par
\par
NATIONAL CHARACTER <data type> ::=\par
NATIONAL CHARACTER [ (length) ] [ COLLATE <Collation name> ]\par
\par
NATIONAL CHARACTER may be abbreviated as NATIONAL CHAR and as NCHAR. NCHAR is\par
a synonym for a CHAR <data type> that belongs to a predefined "national"\par
Character set.\par
\par
Other than the fact that you may not add a CHARACTER SET clause to an NCHAR\par
<data type> specification because NCHAR implies the same national Character\par
set used for <national character string literal>s and NCHAR VARYING and NCLOB\par
<data type>s, the specifications for the NCHAR and CHAR <data type>s are the\par
same. Here are two examples of an NCHAR <data type> specification:\par
\par
   NCHAR(10) \par
    -- uses the national Character set's Collation\par
\par
   NCHAR(10) COLLATE my.collation_1 \par
    -- uses a Collation named MY.COLLATION_1\par
\par
[NON-PORTABLE] The national Character set used by <national character string\par
literal>s and the NCHAR, NCHAR VARYING and NCLOB <data type>s is non-standard\par
because the SQL Standard requires implementors to define a national Character set.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
defines the national Character set to be ASCII_FULL. For example, these two\par
<data type> specifications both define the same set of valid values:\par
\par
   NCHAR(10)\par
\par
   CHAR(10) CHARACTER SET ASCII_FULL\par
\par
If you want to restrict your code to Core SQL, don't use the NCHAR <data type>.\par
\par
CHARACTER VARYING:\par
The required syntax for a CHARACTER VARYING <data type> specification is:\par
\par
CHARACTER VARYING <data type> ::=\par
CHARACTER VARYING (length) \par
[ CHARACTER SET <Character set name> ] \par
[ COLLATE <Collation name> ]\par
\par
CHARACTER VARYING may be abbreviated as CHAR VARYING and as VARCHAR and is a\par
variable length alphanumeric string, from zero to "length" characters long. It\par
defines a set of character string values that belong to a given Character set.\par
For example, these three <character string literal>s:\par
\par
   'BOB'\par
\par
   'BOBBY'\par
\par
   'ROBERT'\par
\par
are all valid values for this <data type> specification:\par
\par
   VARCHAR(6)\par
\par
The mandatory length specification is an unsigned, positive integer that\par
defines the maximum length, in characters, of acceptable values. The minimum\par
length is 1.\par
\par
[NON-PORTABLE] The maximum length for VARCHAR is non-standard because the SQL\par
Standard requires implementors to define VARCHAR's maximum length. FIPS says\par
that VARCHAR should have a maximum length of at least 1000 characters.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
you to define a length ranging from 1 to 4096 for VARCHAR.\par
\par
[Obscure Rule] The optional CHARACTER SET clause names the Character set that\par
the <data type>'s values belong to; see the remarks under "CHARACTER". For\par
example, this <data type> specification:\par
\par
   VARCHAR(15) CHARACTER SET LATIN1\par
\par
defines a set of character string values, 0 to 15 characters long, that belong\par
to the LATIN1 Character set. (Zero length strings may be stored in a VARCHAR field.)\par
\par
[Obscure Rule] A VARCHAR <data type> has a coercibility attribute of IMPLICIT.\par
The optional COLLATE clause defines the <data type>'s default Collation; see\par
the remarks under "CHARACTER". For example, these two <data type> specifications:\par
\par
   VARCHAR(15) COLLATE my.collation_1\par
\par
   VARCHAR(15) CHARACTER SET my.charset_1 COLLATE my.collation_1\par
\par
both define a set of character string values, 0 to 15 characters long, that\par
have a default Collation called MY.COLLATION_1.\par
\par
If you want to restrict your code to Core SQL, don't use the CHARACTER SET\par
clause or the COLLATE clause for VARCHAR <data type> specifications.\par
\par
NATIONAL CHARACTER VARYING:\par
The required syntax for a NATIONAL CHARACTER VARYING <data type> specification is:\par
\par
NATIONAL CHARACTER VARYING <data type> ::=\par
NATIONAL CHARACTER VARYING (length) [ COLLATE <Collation name> ]\par
\par
NATIONAL CHARACTER VARYING may be abbreviated as NATIONAL CHAR VARYING and as\par
NCHAR VARYING. NCHAR VARYING is a synonym for a VARCHAR <data type> that\par
belongs to a predefined "national" Character set.\par
\par
Other than the fact that you may not add a CHARACTER SET clause to an NCHAR\par
VARYING <data type> specification because NCHAR VARYING implies the same\par
national Character set used for <national character string literal>s and NCHAR\par
and NCLOB <data type>s, the specifications for the NCHAR VARYING and VARCHAR\par
<data type>s are the same. Here are two examples of an NCHAR VARYING <data\par
type> specification:\par
\par
   NCHAR VARYING(10) \par
    -- uses the national Character set's Collation\par
\par
   NCHAR VARYING(10) COLLATE my.collation_1 \par
    -- uses a Collation named MY.COLLATION_1\par
\par
[NON-PORTABLE] The national Character set used by <national character string\par
literal>s and the NCHAR, NCHAR VARYING and NCLOB <data type>s is non-standard\par
because the SQL Standard requires implementors to define a national Character set.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
defines the national Character set to be ASCII_FULL.For example, these two\par
<data type> specifications both define the same set of valid values:\par
\par
   NCHAR VARYING(10)\par
\par
   VARCHAR(10) CHARACTER SET ASCII_FULL\par
\par
If you want to restrict your code to Core SQL, don't use the NCHAR VARYING <data type>.\par
\par
CHARACTER LARGE OBJECT:\par
The required syntax for a CHARACTER LARGE OBJECT <data type> specification is:\par
\par
CHARACTER LARGE OBJECT <data type> ::=\par
\{CHARACTER LARGE OBJECT | CLOB\} [ (length) ] \par
[ CHARACTER SET <Character set name> ] \par
[ COLLATE <Collation name> ]\par
\par
CHARACTER LARGE OBJECT may be abbreviated as CHAR LARGE OBJECT and as CLOB and\par
is a variable length alphanumeric string, from zero to "length" characters\par
long. It defines a set of large object character string values that belong to\par
a given Character set. For example, these three <character string literal>s:\par
\par
   'BOB'\par
\par
   'BOBBY'\par
\par
   'ROBERT'\par
\par
are all valid values for this <data type> specification:\par
\par
   CLOB(6)\par
\par
The optional length, if specified, is an unsigned positive integer, possibly\par
followed by a letter code (either K, M or G), that defines the maximum length,\par
in characters, of acceptable values. The minimum length is 1. If the length is\par
defined as "integer K", the CLOB may hold up to "integer*1024" characters; if\par
the length is defined as "integer M", the CLOB may hold up to\par
"integer*1,048,576" characters and if the length is defined as "integer G",\par
the CLOB may hold up to "integer*1,073,741,824" characters. For example, this\par
<data type> specification defines a set of large object character string\par
values that may range from zero to 20 characters:\par
\par
   CLOB(20)\par
\par
(Zero length large object character strings can be stored in a CLOB field.)\par
\par
This <data type> specification defines a set of large object character string\par
values that may range from zero to 2048 characters:\par
\par
   CLOB(2K)\par
\par
This <data type> specification defines a set of large object character string\par
values that may range from zero to 2,097,152 characters:\par
\par
   CLOB(2M)\par
\par
And this <data type> specification defines a set of large object character\par
string values that may range from zero to 2,147,483,648 characters:\par
\par
   CLOB(2G)\par
\par
[NON-PORTABLE] The default length and the maximum length for CLOB are non-\par
standard because the SQL Standard requires implementors to define CLOB's\par
default and maximum lengths.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the length of CLOB to range from 1 to 32 and sets the default length of a CLOB\par
<data type> to 1K. For example, these two <data type> specifications are\par
equivalent: both define a set of large object character string values that may\par
range from zero to 1024 characters:\par
\par
   CLOB\par
\par
   CLOB(1K)\par
\par
[Obscure Rule] The optional CHARACTER SET clause names the Character set that\par
the <data type>'s values belong to; see the remarks under "CHARACTER". For\par
example, this <data type> specification:\par
\par
   CLOB(5M) CHARACTER SET LATIN1\par
\par
defines a set of large object character string values, 0 to 5,242,880\par
characters long, that belong to the LATIN1 Character set.\par
\par
[Obscure Rule] A CLOB <data type> has a coercibility attribute of IMPLICIT.\par
The optional COLLATE clause defines the <data type>'s default Collation; see\par
the remarks under "CHARACTER". For example, these two <data type> specifications:\par
\par
   CLOB(3G) COLLATE my.collation_1\par
\par
   CLOB(3G) CHARACTER SET my.charset_1 COLLATE my.collation_1\par
\par
both define a set of large object character string values, 0 to 3,221,225,472\par
characters long, that have a default Collation called MY.COLLATION_1.\par
\par
If you want to restrict your code to Core SQL, don't use the CHARACTER SET\par
clause or the COLLATE clause for CLOB <data type> specifications.\par
\par
NATIONAL CHARACTER LARGE OBJECT:\par
The required syntax for a NATIONAL CHARACTER LARGE OBJECT <data type> specification is:\par
\par
NATIONAL CHARACTER LARGE OBJECT <data type> ::=\par
NATIONAL CHARACTER LARGE OBJECT [ (length) ][ COLLATE <Collation name> ]\par
\par
NATIONAL CHARACTER LARGE OBJECT may be abbreviated as NCHAR LARGE OBJECT and\par
as NCLOB. NCLOB is a synonym for a CLOB <data type> that belongs to a\par
predefined "national" Character set.\par
\par
Other than the fact that you may not add a CHARACTER SET clause to an NCLOB\par
<data type> specification because NCLOB implies the same national Character\par
set used for <national character string literal>s and NCHAR and NCHAR VARYING\par
<data type>s, the specifications for the NCLOB and CLOB <data type>s are the\par
same. Here are two examples of an NCLOB <data type> specification:\par
\par
   NCLOB(2K) \par
    -- uses the national Character set's Collation\par
\par
   NCLOB(2K) COLLATE my.collation_1 \par
    -- uses a Collation named MY.COLLATION_1\par
\par
[NON-PORTABLE] The national Character set used by <national character string\par
literal>s and the NCHAR, NCHAR VARYING and NCLOB <data type>s is non-standard\par
because the SQL Standard requires implementors to define a national Character set.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
defines the national Character set to be ASCII_FULL. For example, these two\par
<data type> specifications both define the same set of valid values:\par
\par
   NCLOB(1G)\par
\par
   CLOB(1G) CHARACTER SET ASCII_FULL\par
\par
If you want to restrict your code to Core SQL, don't use the NCLOB <data type>.\par
\par
Now that we've described SQL's character string <data type>s, let's look at\par
some example SQL statements that put them to use.\par
\par
These SQL statements make a Table with six fixed length character string\par
Columns, insert a row, then search for any string greater than 'hi'.\par
\par
   CREATE TABLE Fixed_Char_Examples (\par
      occurrence_char_1 CHAR(2),\par
      occurrence_char_2 CHAR(2) CHARACTER SET LATIN1,\par
      occurrence_char_3 CHAR(2) COLLATE my.collation_1,\par
      occurrence_char_4 CHAR(2) CHARACTER SET LATIN1 COLLATE my.collation_1,\par
      occurrence_nchar_1 NCHAR(2),\par
      occurrence_nchar_2 NCHAR(2) COLLATE my.collation_1);\par
\par
INSERT INTO Fixed_Char_Examples (\par
      occurrence_char_1,\par
      occurrence_char_2,\par
      occurrence_char_3,\par
      occurrence_char_4,\par
      occurrence_nchar_1,\par
      occurrence_nchar_2)\par
      VALUES ('mm','mm','mm','mm','mm','mm');\par
\par
SELECT occurrence_char_1,\par
       occurrence_char_2,\par
       occurrence_char_3,\par
       occurrence_char_4,\par
       occurrence_nchar_1,\par
       occurrence_nchar_2\par
FROM   Fixed_Char_Examples\par
WHERE  occurrence_char_4 > 'hi';\par
\par
SELECT occurrence_char_1,\par
       occurrence_char_2,\par
       occurrence_char_3,\par
       occurrence_char_4,\par
       occurrence_nchar_1,\par
       occurrence_nchar_2\par
FROM   Fixed_Char_Examples\par
WHERE  occurrence_nchar_2 > N'hi';\par
\par
These SQL statements make a Table with six variable length character string\par
Columns, insert a row, then search for any string not equal to 'hi'.\par
\par
   CREATE TABLE Varying_Char_Examples (\par
      occurrence_varchar_1 VARCHAR(5),\par
      occurrence_varchar_2 VARCHAR(5) CHARACTER SET LATIN1,\par
      occurrence_varchar_3 VARCHAR(5) COLLATE my.collation_1,\par
      occurrence_varchar_4 VARCHAR(5) CHARACTER SET LATIN1 COLLATE my.collation_1,\par
      occurrence_nvchar_1 NCHAR VARYING(5),\par
      occurrence_nvchar_2 NCHAR VARYING(5) COLLATE my.collation_1);\par
\par
INSERT INTO Varying_Char_Examples (\par
      occurrence_varchar_1,\par
      occurrence_varchar_2,\par
      occurrence_varchar_3,\par
      occurrence_varchar_4,\par
      occurrence_nvchar_1,\par
      occurrence_nvchar_2)\par
      VALUES ('mm','mm','mm','mm','mm','mm');\par
\par
SELECT occurrence_varchar_1,\par
       occurrence_varchar_2,\par
       occurrence_varchar_3,\par
       occurrence_varchar_4,\par
       occurrence_nvchar_1,\par
       occurrence_nvchar_2\par
FROM   Varying_Char_Examples\par
WHERE  occurrence_varchar_4 <> 'hi';\par
\par
SELECT occurrence_varchar_1,\par
       occurrence_varchar_2,\par
       occurrence_varchar_3,\par
       occurrence_varchar_4,\par
       occurrence_nvchar_1,\par
       occurrence_nvchar_2\par
FROM   Varying_Char_Examples\par
WHERE  occurrence_nvchar_2 <> N'hi';\par
\par
These SQL statements make a Table with six large object character string\par
Columns, insert a row, then search for any string equal to 'hi'.\par
\par
   CREATE TABLE Large_Char_Examples (\par
      occurrence_clob_1 CLOB(10),\par
      occurrence_clob_2 CLOB(10K) CHARACTER SET LATIN1,\par
      occurrence_clob_3 CLOB(10M) COLLATE my.collation_1,\par
      occurrence_clob_4 CLOB(10G) CHARACTER SET LATIN1 COLLATE my.collation_1,\par
      occurrence_nclob_1 NCLOB(2K),\par
      occurrence_nclob_2 NCLOB COLLATE my.collation_1);\par
\par
INSERT INTO Large_Char_Examples (\par
      occurrence_clob_1,\par
      occurrence_clob_2,\par
      occurrence_clob_3,\par
      occurrence_clob_4,\par
      occurrence_nclob_1,\par
      occurrence_nclob_2)\par
      VALUES ('mm','mm','mm','mm','mm','mm');\par
\par
SELECT occurrence_clob_1,\par
       occurrence_clob_2,\par
       occurrence_clob_3,\par
       occurrence_clob_4,\par
       occurrence_nclob_1,\par
       occurrence_nclob_2\par
FROM   Large_Char_Examples\par
WHERE  occurrence_clob_4 = 'hi';\par
\par
SELECT occurrence_clob_1,\par
       occurrence_clob_2,\par
       occurrence_clob_3,\par
       occurrence_clob_4,\par
       occurrence_nclob_1,\par
       occurrence_nclob_2\par
FROM   Large_Char_Examples\par
WHERE  occurrence_nclob_2 = N'hi';\par
\par
Character string Operations\par
\par
A character string is compatible with, and comparable to, all other character\par
strings from the same Character set -- that is, character strings are mutually\par
comparable and mutually assignable as long as they belong to the same\par
Character set. Character strings may not be directly compared with, or\par
directly assigned to, any other <data type> class, though implicit type\par
conversions can occur in expressions, SELECTs, INSERTs, DELETEs and UPDATEs.\par
Explicit character string type conversions can be forced with the CAST operator.\par
\par
CAST:\par
In SQL, CAST is a scalar operator that converts a given scalar value to a\par
given scalar <data type>. The required syntax for the CAST operator is:\par
\par
CAST (<cast operand> AS <cast target>)\par
\par
   <cast operand> ::= scalar_expression\par
\par
   <cast target> ::= <Domain name> | <data type>\par
\par
The CAST operator converts values of a source <data type> into values of a\par
target <data type>, where each <data type> is an SQL pre-defined <data type>\par
(data conversions between UDTs are done with a user-defined cast). The source\par
<data type>, or <cast operand>, can be any expression that evaluates to a\par
single value. The target <data type>, or <cast target>, is either an SQL\par
predefined <data type> specification or the name of a Domain whose defined\par
<data type> is the SQL predefined <data type> that you want to convert the\par
value of "scalar_expression" into. (If you use CAST ... AS <Domain name>, your\par
current <AuthorizationID> must have the USAGE Privilege on that Domain.)\par
\par
It isn't, of course, possible to convert the values of every <data type> into\par
the values of every other <data type>. For character strings, the rules are:\par
      ## CAST (NULL AS <data type>) and CAST (character_string_source_is_a_null_value AS <data type>) both result in a CAST result of NULL.\par
      ## You can CAST a fixed length or variable length character string or a\par
CLOB or NCLOB source to these targets: exact numeric, approximate numeric,\par
fixed length character string (if source and target belong to the same\par
Character set), variable length character string (if source and target belong\par
to the same Character set), CLOB (if source and target belong to the same\par
Character set), NCLOB (if source and target belong to the same Character set),\par
fixed length bit string, variable length bit string, date, time, timestamp,\par
year-month interval, day-time interval and boolean. You can also CAST a fixed\par
length or variable length character string or a CLOB or NCLOB source to a UDT\par
target or a <reference type> target if a user-defined cast exists for this\par
purpose and your current <AuthorizationID> has the EXECUTE Privilege on that\par
user-defined cast.\par
\par
When you CAST a character string to an exact numeric target or an approximate\par
numeric target, your DBMS strips any leading or trailing spaces from the\par
source and converts the remaining string -- which must be the character\par
representation of a number -- to that number. For example, "CAST '-25' AS\par
SMALLINT" results in a SMALLINT value of -25. If your source string doesn't\par
represent a number, the CAST will fail: your DBMS will return the SQLSTATE\par
error 22018 "data exception-invalid character value for cast".\par
\par
When you CAST a character string to a fixed length character string target, a\par
variable length character string target or a CLOB or NCLOB target, both source\par
and target must belong to the same Character set, the result has the COERCIBLE\par
coercibility attribute and the Collation of the result is the default\par
Collation of the target's Character set.\par
      ## For fixed length character string targets, if the length of the\par
source equals the fixed length of the target, the result of the CAST is the\par
source string. If the length of the source is shorter than the fixed length of\par
the target, the result of the CAST is the source string padded on the right\par
with however many spaces are required to make the lengths match. If the length\par
of the source is longer than the fixed length of the target, the result of the\par
CAST is a character string that contains as much of the source string as\par
possible -- in this case, if the truncated characters are not all spaces, your\par
DBMS will return the SQLSTATE warning 01004 "warning-string data, right truncation".\par
      ## For variable length character string or CLOB or NCLOB targets, if the\par
length of the source is less than or equals the maximum length of the target,\par
the result of the CAST is the source string. If the length of the source is\par
longer than the maximum length of the target, the result of the CAST is a\par
character string that contains as much of the source string as possible -- in\par
this case, if the truncated characters are not all spaces, your DBMS will\par
return the SQLSTATE warning 01004 "warning-string data, right truncation".\par
\par
When you CAST a character string to a fixed length bit string or a variable\par
length bit string target, the result is the character string converted to a\par
string of bits. That is, when you CAST a character string (which has a "form-\par
of-use encoding") to a bit string (which has no encoding), you get the bits\par
that make up the characters in the source string. For example, assume the\par
source character string for a CAST belongs to the ASCII_FULL Character set. In\par
this Character set, the code for the letter 'A' is 41 hexadecimal (the binary\par
number 01000001) and the code for the letter 'B' is 42 hexadecimal (the binary\par
number 01000010) -- so "CAST ('AB' TO BIT(16))" will result in B'0100000101000010'.\par
      ## For fixed length bit string targets, if the bit length of the\par
converted source string equals the fixed bit length of the target, the result\par
of the CAST is the converted source string. If the converted source value's \par
bit length is larger than the fixed bit length of the target, the result of \par
the CAST is a bit string that contains as much of the converted source string \par
as possible -- in this case, if the truncated bits are not all zero-bits, \par
your DBMS will return the SQLSTATE warning 01004 "warning-string data, right \par
truncation". If the converted source value's bit length is less than the \par
fixed bit length of the target, the result of the CAST is the converted bit \par
string, padded on the least significant end with as many zero-bits as \par
required to make the lengths match -- in this case, your DBMS will return the \par
SQLSTATE warning 01008 "warning-implicit zero-bit padding".\par
      ## For variable length bit string targets, if the bit length of the\par
converted source string is less than or equals the maximum bit length of the\par
target, the result of the CAST is the converted source string. If the\par
converted source value's bit length is larger than the maximum bit length of\par
the target, the result of the CAST is a bit string that contains as much of\par
the converted source string as possible -- in this case, if the truncated bits\par
are not all zero-bits, your DBMS will return the SQLSTATE warning 01004\par
"warning-string data, right truncation".\par
\par
When you CAST a character string to a date target, your DBMS strips any\par
leading or trailing spaces from the source and converts the remaining string -\par
- which must be the character representation of a valid date -- to that date.\par
If your source string doesn't represent a valid date, the CAST will fail: your\par
DBMS will return the SQLSTATE error 22007 "data exception-invalid datetime format".\par
\par
When you CAST a character string to a time target, your DBMS strips any\par
leading or trailing spaces from the source and converts the remaining string -\par
- which must be the character representation of a valid time -- to that time.\par
If your source string doesn't represent a valid time, the CAST will fail: your\par
DBMS will return the SQLSTATE error 22007 "data exception-invalid datetime\par
format". If your source string isn't a string that could represent any time\par
(even an invalid one), the CAST will also fail: your DBMS will return the\par
SQLSTATE error 22018 "data exception-invalid character value for cast".\par
\par
When you CAST a character string to a timestamp target, your DBMS strips any\par
leading or trailing spaces from the source and converts the remaining string -\par
- which must be the character representation of a valid timestamp -- to that\par
timestamp. If your source string doesn't represent a valid timestamp, the CAST\par
will fail: your DBMS will return the SQLSTATE error 22007 "data\par
exception-invalid datetime format". If your source string isn't a string that\par
could represent any timestamp (even an invalid one), the CAST will also fail:\par
your DBMS will return the SQLSTATE error 22018 "data exception-invalid\par
character value for cast".\par
\par
When you CAST a character string to an interval target, your DBMS strips any\par
leading or trailing spaces from the source and converts the remaining string -\par
- which must be the character representation of a valid interval for the\par
target -- to that interval. If your source string doesn't represent a valid\par
interval for the target, the CAST will fail: your DBMS will return the\par
SQLSTATE error 22XXX "data exception-invalid interval format". If your source\par
string isn't a string that could represent any interval (even an invalid one\par
for the target), the CAST will also fail: your DBMS will return the SQLSTATE\par
error 22007 "data exception-invalid datetime format".\par
\par
When you CAST a character string to a boolean target, your DBMS strips any\par
leading or trailing spaces from the source and converts the remaining string -\par
- which must be the character representation of one of the truth values TRUE,\par
FALSE or UNKNOWN -- to that truth value. If your source string doesn't\par
represent a truth value, the CAST will fail: your DBMS will return the\par
SQLSTATE error 22018 "data exception-invalid character value for cast".\par
\par
When you CAST a character string to a UDT or a <reference type> target, your\par
DBMS invokes the user defined cast routine, with the source value as the\par
routine's argument. The CAST result is the value returned by the user defined cast.\par
\par
If you want to restrict your code to Core SQL, don't use <Domain name> as a\par
CAST target: CAST only to a <data type> and don't use CAST to convert any CLOB\par
or NCLOB values to another <data type>.\par
\par
Assignment:\par
SQL allows you to assign only compatible character strings -- that is,\par
character strings are mutually assignable only if the source string and the\par
target string belong to the same Character set. If you need to assign a\par
character string to a target that belongs to a different Character set, use\par
the TRANSLATE function to translate the source into an equivalent string that\par
belongs to the target's Character set.\par
\par
In SQL, when a character string is assigned to a character string target, the\par
assignment is done one character at a time, from left to right.\par
\par
When a character string is taken from SQL-data to be assigned to a fixed\par
length character string target and the source is shorter than the target, the\par
source is padded (on the right) with spaces until it matches the target's\par
size. If the source is longer than the target, the source is truncated to fit\par
the target. In this case, your DBMS will return the SQLSTATE warning 01004\par
"warning-string data, right truncation". When a character string is taken from\par
SQL-data to be assigned to a variable length character string or CLOB target,\par
the size of the target is first set either to the size of the source or to its\par
own maximum length, whichever is less. The source may then be truncated, if\par
necessary, to match the size of the target. In this case, your DBMS will\par
return the SQLSTATE warning 01004 "warning-string data, right truncation".\par
\par
[Obscure Rule] Since only SQL accepts null values, if your source is NULL,\par
then your target's value is not changed. Instead, your DBMS will set its\par
indicator parameter to -1, to indicate that an assignment of the null value\par
was attempted. If your target doesn't have an indicator parameter, the\par
assignment will fail: your DBMS will return the SQLSTATE error 22002 "data\par
exception-null value, no indicator parameter". If your source is a non-null\par
value that fits into your target, your DBMS will set the target's indicator\par
parameter (if any) to zero. If your source is longer than your target, your\par
DBMS will set your target's indicator parameter to the length of the source;\par
that is, if your source is 12 characters long and your target can accept only\par
10 characters, your DBMS will set the target's indicator parameter to 12, to\par
indicate that 2 characters were lost on assignment. If the source's length is\par
too big to be assigned to the indicator, the assignment will fail: your DBMS\par
will return the SQLSTATE error 22022 "data exception-indicator overflow".\par
We'll talk more about indicator parameters in our chapters on SQL binding styles.\par
\par
When a character string is assigned to a fixed length SQL-data character\par
string target and the source is shorter than the target, the source is padded\par
(on the right) with spaces until it matches the target's size. If the source\par
is larger than the target, but the extra characters are all spaces, the\par
source's significant character string value is assigned to the target. If the\par
source is larger than the target and the extra characters are not all spaces,\par
the assignment will fail: your DBMS will return the SQLSTATE error 22001 "data\par
exception-string data, right truncation". When a character string is assigned\par
to a variable length SQL-data character string or CLOB target, the size of the\par
target is first set either to the size of the source or to its own maximum\par
length, whichever is less. If the source is larger than the target, but the\par
extra characters are all spaces, the source's significant character string\par
value is assigned to the target. If the source is larger than the target and\par
the extra characters are not all spaces, the assignment will fail: your DBMS\par
will return the SQLSTATE error 22001 "data exception-string data, right truncation".\par
\par
[Obscure Rule] There are two ways to assign a null value to an SQL-data\par
target. Within SQL, you can use the <keyword> NULL in an INSERT or an UPDATE\par
statement to indicate that the target should be set to NULL; that is, if your\par
source is NULL, your DBMS will set your target to NULL. Outside of SQL, if\par
your source has an indicator parameter that is set to -1, your DBMS will set\par
your target to NULL (regardless of the value of the source). (An indicator\par
parameter with a value less than -1 will cause an error: your DBMS will return\par
the SQLSTATE error 22010 "data exception-invalid indicator parameter value".)\par
\par
Comparison:\par
SQL provides the usual scalar comparison operators -- = and <> and < and <=\par
and > and >= -- to perform operations on CHAR, VARCHAR, NCHAR and NCHAR\par
VARYING character strings but provides only the = and <> operators to perform\par
operations on CLOB and NCLOB character strings. All of them will be familiar;\par
there are equivalent operators in other computer languages. If any of the\par
comparands are NULL, the result of the operation is UNKNOWN. For example:     \par
\par
   'hello' < 'zebra'\par
\par
returns TRUE.\par
\par
   'hello' > \{result is NULL\}\par
\par
returns UNKNOWN.\par
\par
SQL also provides three quantifiers -- ALL, SOME, ANY -- which you can use\par
along with a comparison operator to compare a CHAR, VARCHAR, NCHAR or NCHAR\par
VARYING value with the collection of values returned by a <table subquery>.\par
(You can't use quantifiers in CLOB or NCLOB comparisons.) Place the quantifier\par
after the comparison operator, immediately before the <table subquery>. For\par
example:\par
\par
   SELECT char_column \par
   FROM   Table_1 \par
   WHERE  char_column = ALL ( \par
      SELECT char_column \par
      FROM   Table_2);\par
\par
ALL returns TRUE either (a) if the collection is an empty set (i.e.: if it\par
contains zero rows) or (b) if the comparison operator returns TRUE for every\par
value in the collection. ALL returns FALSE if the comparison operator returns\par
FALSE for at least one value in the collection.\par
\par
SOME and ANY are synonyms. They return TRUE if the comparison operator returns\par
TRUE for at least one value in the collection. They return FALSE either (a) if\par
the collection is an empty set or (b) if the comparison operator returns FALSE\par
for every value in the collection. (The search condition "= ANY (collection)"\par
is equivalent to "IN (collection)".)\par
\par
SQL allows you to compare character strings only if (a) they belong to the\par
same Character set and (b) have, or can be coerced into having, the same\par
Collation for the comparison -- that is, character strings are mutually\par
comparable only if both their Character sets and their Collations are the\par
same. When a character string is compared to another character string, the\par
comparison is done one character at a time, from left to right. The result of\par
the comparison is determined by the rules of the relevant Collation. Because\par
of this, two strings with different lengths may, or may not, compare as equal.\par
\par
Although a comparison involves two character strings, both of which have a\par
default Collation, only one of the Collations can be used to govern the result\par
of the comparison. So, when you (a) compare character strings that have\par
different current default Collations and (b) don't explicitly specify a\par
Collation for the comparison, your DBMS will use the coercibility attribute of\par
each string to choose the relevant Collation. \par
\par
A <Column name>, <Column reference> or other character string value that\par
includes a COLLATE clause has a coercibility attribute of EXPLICIT: its\par
Collation is the Collation named. If a <Column name> or <Column reference>\par
doesn't include a COLLATE clause, it has a coercibility attribute of IMPLICIT:\par
its Collation is the Collation specified when the Column was created (see the\par
<data type> definitions). If any other character string value (e.g.: a host\par
variable or a <literal>) doesn't include a COLLATE clause, it normally has a\par
coercibility attribute of COERCIBLE: its Collation is the default Collation\par
for its Character set. Sometimes a character string value is the result of an\par
expression that joins strings with different Collations (e.g.: a concatenation\par
operation that doesn't include a COLLATE clause). These character strings have\par
a coercibility attribute of NO COLLATION.\par
\par
After determining the coercibility attribute of each character string in a\par
comparison, your DBMS will choose the relevant Collation using these rules:\par
      ## Strings with COERCIBLE coercibility may be compared to strings with\par
any coercibility attribute except NO COLLATION. If both comparands have\par
COERCIBLE coercibility, the relevant Collation is the default Collation of\par
their mutual Character set. If one comparand has COERCIBLE coercibility and\par
the other has EXPLICIT coercibility, the relevant Collation is the EXPLICIT\par
Collation. If one comparand has COERCIBLE coercibility and the other has\par
IMPLICIT coercibility, the relevant Collation is the IMPLICIT Collation.\par
      ## Strings with EXPLICIT coercibility may be compared to strings with\par
any coercibility attribute. If one comparand has EXPLICIT coercibility and the\par
other has COERCIBLE, IMPLICIT or NO COLLATION coercibility, the relevant\par
Collation is the EXPLICIT Collation. If both comparands have EXPLICIT\par
coercibility, they must also have the same Collation. The relevant Collation\par
is their mutual EXPLICIT Collation.\par
      ## Strings with IMPLICIT coercibility may be compared to strings with\par
any coercibility attribute except NO COLLATION.If one comparand has IMPLICIT\par
coercibility and the other has COERCIBLE coercibility, the relevant Collation\par
is the IMPLICIT Collation. If one comparand has IMPLICIT coercibility and the\par
other has EXPLICIT coercibility, the relevant Collation is the EXPLICIT\par
Collation. If both comparands have IMPLICIT coercibility, they must also have\par
the same Collation. The relevant Collation is their mutual IMPLICIT Collation.\par
      ## Strings with NO COLLATION coercibility may only be compared to\par
strings with a coercibility attribute of EXPLICIT. The relevant Collation is\par
the EXPLICIT Collation.\par
\par
When you compare character strings that have different lengths, the result\par
also depends on whether the relevant Collation has the PAD SPACE attribute or\par
the NO PAD attribute. If the relevant Collation has the PAD SPACE attribute,\par
your DBMS will extend the shorter character string to the length of the larger\par
string (by padding it on the right with spaces) before comparing the strings.\par
If the relevant Collation has the NO PAD attribute, your DBMS will extend the\par
shorter character string to the length of the larger string (by padding it on\par
the right with some other character) before comparing the strings. The NO PAD\par
character may be any character that (a) collates less than any string under\par
the relevant Collation and (b) is different from every character that belongs\par
to the comparands' Character sets. The result of these rules is that a shorter\par
comparand which is equal to the same-length substring of a larger comparand\par
will evaluate as less than the larger comparand -- even if the remainder of\par
the larger string consists only of spaces. For example, a comparison of\par
these two <literal>s:\par
\par
   'BOB'\par
\par
   'BOB    '\par
\par
would result in the first <literal> being evaluated as less than the second.\par
(Note: This last requirement by the SQL Standard is, by definition, impossible\par
to fulfill, since the SQL_TEXT Character set must contain every possible\par
character supported by the DBMS. If, then, a comparand's Character set is\par
SQL_TEXT, the DBMS's NO PAD character must belong to the comparand's Character\par
set.)\par
\par
[NON-PORTABLE] The NO PAD character is non-standard because the SQL Standard\par
requires implementors to choose the NO PAD character. This decision is\par
implementation-dependent; vendors are not required to document the NO PAD\par
character they choose.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book uses\par
ASCII 0 as the NO PAD character for Collations with the NO PAD attribute. To\par
fulfill the SQL Standard's requirement that a string that is equal to a\par
same-length substring of a larger comparand must be evaluated as less than the\par
larger string, the OCELOT library follows an evaluation rule that determines\par
the required result in cases where a string ending in one or more ASCII 0\par
characters would otherwise compare equal to a string which has been padded\par
with ASCII 0 characters before comparison.\par
\par
Here's another example of the difference between the PAD SPACE and the NO PAD\par
attributes for Collations.\par
\par
   CREATE TABLE Table_1 ( \par
      char_column CHAR(5));\par
\par
   INSERT INTO Table_1 (char_column) \par
   VALUES ('A');\par
\par
In this example, the string actually inserted is five characters long, i.e.:\par
\par
   'A    '\par
\par
Thus, with a PAD SPACE Collation, this predicate is TRUE:\par
\par
   ... WHERE char_column = 'A'\par
\par
and with a NO PAD Collation, the same predicate is FALSE.\par
\par
To summarize, SQL doesn't allow character strings to be compared unless they\par
belong to the same Character set and have the same Collation for the\par
comparison. You may explicitly specify the relevant Character set or allow it\par
to default to an implicit Character set chosen by your DBMS. You may also\par
explicitly specify the relevant Collation by adding a COLLATE clause to your\par
expression; this will override the expression's default collating sequence. If\par
you omit the COLLATE clause, your DBMS will choose the relevant Collation for\par
you -- see "Character Strings and Collations", later in this chapter.\par
\par
If you want to restrict your code to Core SQL, don't use CLOBs or NCLOBs in\par
comparisons.\par
\par
Other Operations:\par
With SQL, you have a wide range of operations that you can perform on\par
character strings, or on other values to get a character string result.\par
\par
## Concatenation\par
The required syntax for a character string concatenation is:\par
\par
character concatenation ::=\par
character_string_operand_1 || character_string_operand_2 \par
[ COLLATE <Collation name> ]\par
\par
The concatenation operator operates on two operands, both of which must\par
evaluate to character strings belonging to the same Character set. It joins\par
the strings together in the order given and returns a character string with a\par
length equal to the sum of the lengths of its operands. If either of the\par
operands is NULL, the result of the operation is also NULL. Here are two\par
examples of character string concatenations:\par
\par
   'hello' || ' bob' \par
    -- returns hello bob\par
\par
   char_column || 'hello' \par
    -- returns CHAR_COLUMN's value followed by hello\par
\par
[Obscure Rule] If both operands are fixed length character strings, the\par
concatenation result is a fixed length character string with a length equal to\par
the sum of the lengths of the operands -- this length may not exceed the\par
maximum allowed for a fixed length character string. If either operand is a\par
variable length character string and the sum of their lengths is not greater\par
than the maximum allowed length for a variable length character string, the\par
concatenation result is a variable length character string with a length equal\par
to the sum of the lengths of the operands. If the sum of the operands' lengths\par
is greater than the maximum allowed, but the extra characters are all spaces,\par
the concatenation result is a variable length character string with a length\par
equal to the maximum allowed length. If the sum of the operands' lengths is\par
greater than the maximum allowed, and the extra characters are not all spaces,\par
the concatenation will fail: your DBMS will return the SQLSTATE error 22001\par
"data exception-string data, right truncation".\par
\par
[Obscure Rule] The result of a character string concatenation normally has a\par
coercibility attribute and Collation determined by Table 7-2 "Collating\par
Sequences and Coercibility Rules for Dyadic Operations", but you can use the\par
optional COLLATE clause to force EXPLICIT coercibility with a specific\par
Collation. The Collation named must be a Collation defined for the relevant\par
Character set. If you're using COLLATE in an SQL-Schema statement, then the\par
<AuthorizationID> that owns the containing Schema must have the USAGE\par
Privilege on "<Collation name>". If you're using COLLATE in any other SQL\par
statement, then your current <AuthorizationID> must have the USAGE Privilege\par
on "<Collation name>". For example:\par
\par
   'hello' || 'bob' COLLATE my.collation_1\par
\par
specifies that the result of the concatenation should use a Collation named MY.COLLATION_1.\par
\par
If you want to restrict your code to Core SQL, don't use the concatenation\par
operator with CLOBs or NCLOBs and don't use the COLLATE clause to force an\par
EXPLICIT Collation for any character string concatenation.\par
\par
## Scalar functions\par
SQL provides eleven scalar functions that return a character string: the <case\par
expression>, the <cast specification>, the <char substring function>, the\par
<char overlay function>, the <char trim function>, the <fold function>, the\par
<character translation function>, the <form-of-use conversion function>, the\par
<regular expression substring function>, the <specific type function> and the\par
<niladic user function>. It also provides four scalar functions that operate\par
on character strings, returning a number: the <char position expression>, the\par
<bit length expression>, the <char length expression> and the <octet length\par
expression>. We'll discuss all but the <specific type function>, the <niladic\par
user function>, the <case expression> and the <cast specification> here. Look\par
for the rest in other chapters; for now, just remember that they all evaluate\par
to a character string and can therefore be used anywhere in SQL that a\par
character string could be used.\par
\par
<char substring function> --\par
The required syntax for a <char substring function> is:\par
\par
<char substring function> ::=\par
SUBSTRING (character_string_argument \par
   FROM start_argument [ FOR length_argument ] \par
   [ COLLATE <Collation name> ])\par
\par
SUBSTRING operates on three arguments: the first must evaluate to a character\par
string, the other two must evaluate to exact numeric integers. It extracts a\par
substring from "character_string_argument" and returns a variable length\par
character string with a maximum length that equals the fixed length or maximum\par
variable length (as applicable) of the character string argument. If any of\par
the arguments are NULL, SUBSTRING returns NULL.\par
\par
The "start_argument" is a number that marks the first character you want to\par
extract from "character_string_argument". If SUBSTRING includes the (optional)\par
FOR clause, "length_argument" is the total number of characters you want to\par
extract. If you omit the FOR clause, SUBSTRING will begin at "start_argument"\par
and extract all the rest of the characters in "character_string_argument".\par
Here are some examples of SUBSTRING:\par
\par
   SUBSTRING('epiphany' FROM 5)\par
    -- returns hany\par
\par
   SUBSTRING('epiphany' FROM 5 FOR 3)\par
    -- returns han\par
\par
   SUBSTRING(char_column FROM 1 FOR 4)\par
    -- returns the first four characters of the value in CHAR_COLUMN\par
\par
   ... WHERE SUBSTRING (char_column FROM 3 FOR 1) = 'A'\par
    -- returns "true" if the third character of the value in CHAR_COLUMN is the letter A\par
\par
If "start_argument" is larger than the length of "character_string_argument",\par
or if the length of the required substring is less than one, SUBSTRING returns\par
a zero-length character string. If the length of the required substring is\par
less than "start_argument", SUBSTRING will fail: your DBMS will return the\par
SQLSTATE error 22011 "data exception-substring error". Note that:\par
\par
   SUBSTRING('abc' FROM -2 FOR 4)\par
\par
is legal SQL syntax, but pointless. SUBSTRING will return a zero-length string\par
for this operation.\par
\par
[Obscure Rule] The result of SUBSTRING belongs to the same Character set that\par
its string argument does. It normally has a coercibility attribute and\par
Collation determined by Table 7-1 "Collating Sequences and Coercibility Rules\par
for Monadic Operations", where "character_string_argument" is the monadic\par
operator, but you can use the optional COLLATE clause to force EXPLICIT\par
coercibility with a specific Collation. The Collation named must be a\par
Collation defined for the relevant Character set. If you're using COLLATE in\par
an SQL-Schema statement, then the <AuthorizationID> that owns the containing\par
Schema must have the USAGE Privilege on "<Collation name>". If you're using\par
COLLATE in any other SQL statement, then your current <AuthorizationID> must\par
have the USAGE Privilege on "<Collation name>". For example:\par
\par
   SUBSTRING(char_column FROM 1 FOR 4) COLLATE my.collation_1\par
\par
specifies that the result of SUBSTRING should use a Collation named MY.COLLATION_1.\par
\par
[Obscure Rule] SUBSTRING can also operate on a bit string and a BLOB. We've\par
ignored these options for now -- look for them in our chapters on bit strings\par
and BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use SUBSTRING with NCLOBs\par
and don't use the COLLATE clause to force an EXPLICIT Collation for any\par
SUBSTRING operation.\par
\par
<char overlay function> --\par
The required syntax for a <char overlay function> is:\par
\par
<character overlay function> ::=\par
OVERLAY (character_string_argument_1 \par
   PLACING character_string_argument_2 \par
   FROM start_argument [ FOR length_argument ] \par
   [ COLLATE <Collation name> ])\par
\par
OVERLAY operates on four arguments: the first two must evaluate to character\par
strings belonging to the same Character set, the other two must evaluate to\par
exact numeric integers. It extracts a substring from "character_argument_1",\par
replacing it with "character_argument_2", and returns the resulting character\par
string. If any of the arguments are NULL, OVERLAY returns NULL.\par
\par
The "start_argument" is a number that marks the first character you want to\par
replace in "character_string_argument_1". If OVERLAY includes the (optional)\par
FOR clause, "length_argument" is the total number of characters you want to\par
extract from "character_string_argument_1". If you omit the FOR clause,\par
OVERLAY will begin at "start_argument" and extract the number of characters in\par
"character_string_argument_2". Here are some examples of OVERLAY:\par
\par
   OVERLAY('epiphany' PLACING 'no' FROM 5)\par
    -- returns epipnony\par
\par
   OVERLAY('epiphany' PLACING 'no' FROM 5 FOR 3)\par
    -- returns epipnoy\par
\par
[Obscure Rule] The result of OVERLAY belongs to the same Character set that\par
its arguments do. It normally has a coercibility attribute and Collation\par
determined by Table 7-2 "Collating Sequences and Coercibility Rules for Dyadic\par
Operations", but you can use the optional COLLATE clause to force EXPLICIT\par
coercibility with a specific Collation. The Collation named must be a\par
Collation defined for the relevant Character set. If you're using COLLATE in\par
an SQL-Schema statement, then the <AuthorizationID> that owns the containing\par
Schema must have the USAGE Privilege on "<Collation name>". If you're using\par
COLLATE in any other SQL statement, then your current <AuthorizationID> must\par
have the USAGE Privilege on "<Collation name>". For example:\par
\par
   OVERLAY('epiphany' PLACING 'no' FROM 5) COLLATE my.collation_1\par
\par
specifies that the result of OVERLAY should use a Collation named MY.COLLATION_1.\par
\par
[Obscure Rule] OVERLAY can also operate on a BLOB. We've ignored this option\par
for now -- look for it in our chapter on BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use OVERLAY with\par
character strings.\par
\par
<char trim function> --\par
The required syntax for a <char trim function> is:\par
\par
<char trim function> ::=\par
TRIM ([ [ \{LEADING | TRAILING | BOTH\} ] [ character_string_argument_1 ] \par
   FROM ] character_string_argument_2 \par
   [ COLLATE <Collation name> ])\par
\par
TRIM operates on two arguments, both of which must evaluate to character\par
strings that belong to the same Character set and have the same Collation for\par
the operation. It strips all leading, all trailing or all leading and all\par
trailing trim characters from "character_string_argument_2" and returns the\par
resulting variable length character string. The result has a maximum length\par
that equals the fixed length or maximum variable length (as applicable) of\par
"character_string_argument_2". If any of the arguments are NULL, TRIM returns NULL.\par
\par
The trim specification is either LEADING (i.e.: trim all leading trim\par
characters), TRAILING (i.e.: trim all trailing trim characters) or BOTH (i.e.:\par
trim all leading and all trailing trim characters). If this clause is omitted,\par
TRIM defaults to BOTH. For example, these two TRIM functions are equivalent:\par
they both strip away all leading and all trailing letters A:\par
\par
   TRIM('A' FROM char_column)\par
\par
   TRIM(BOTH 'A' FROM char_column)\par
\par
The "character_string_argument_1" defines the trim character: the character\par
that should be stripped away by the TRIM function. If\par
"character_string_argument_1" is omitted, TRIM strips spaces away. For\par
example, these two TRIM functions are equivalent: they both strip away all\par
trailing spaces:\par
\par
   TRIM(TRAILING FROM char_column)\par
\par
   TRIM(TRAILING ' ' FROM char_column)\par
\par
These two TRIM functions are equivalent: they both strip away all leading spaces:\par
\par
   TRIM(LEADING FROM char_column)\par
\par
   TRIM(LEADING ' ' FROM char_column)\par
\par
These two TRIM functions are equivalent: they both strip away all leading and all trailing spaces:\par
\par
   TRIM(char_column)\par
\par
   TRIM(BOTH ' ' FROM char_column)\par
\par
If the length of "character_string_argument_1" is not one character, TRIM will\par
fail: your DBMS will return the SQLSTATE error 22027 "data exception-trim error".\par
\par
[Obscure Rule] The result of TRIM belongs to the same Character set that its\par
arguments do. It normally has a coercibility attribute and Collation\par
determined by Table 7-1 "Collating Sequences and Coercibility Rules for\par
Monadic Operations" (where "character_string_argument_2" is the monadic\par
operand), but you can use the optional COLLATE clause to force EXPLICIT\par
coercibility with a specific Collation. The Collation named must be a\par
Collation defined for the relevant Character set. If you're using COLLATE in\par
an SQL-Schema statement, then the <AuthorizationID> that owns the containing\par
Schema must have the USAGE Privilege on "<Collation name>". If you're using\par
COLLATE in any other SQL statement, then your current <AuthorizationID> must\par
have the USAGE Privilege on "<Collation name>". For example:\par
\par
   TRIM(BOTH ' ' FROM char_column) COLLATE my.collation_1\par
\par
specifies that the result of TRIM should use a Collation named MY.COLLATION_1.\par
\par
[Obscure Rule] TRIM can also operate on a BLOB. We've ignored this option for\par
now -- look for it in our chapter on BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use TRIM with NCLOBs and\par
don't use the COLLATE clause to force an EXPLICIT Collation for any TRIM operation.\par
\par
<fold function> --\par
The required syntax for a <fold function> is:\par
\par
<fold function> ::=\par
\{ UPPER | LOWER \} (character_string_argument [ COLLATE <Collation name> ])\par
\par
UPPER and LOWER operate on an argument that evaluates to a character string.\par
UPPER converts every lower case letter in "character_string_argument" to its\par
corresponding upper case equivalent, while LOWER converts every upper case\par
letter in "character_string_argument" to its corresponding lower case\par
equivalent. Any character that has no upper or lower case equivalent (as\par
applicable) remains unchanged. The conversion reflects the normal rules for\par
letters of the simple Latin 26-letter alphabet -- that is\par
"abcdefghijklmnopqrstuvwxyz" converts to and from "ABCDEFGHIJKLMNOPQRSTUVWXYZ"\par
-- but it also reflects the normal rules for the accented letters in\par
"character_string_argument"'s Character set, e.g.: "\rdblquote " converts to and from\par
"\'99".\par
\par
Both UPPER and LOWER return a character string with a length that equals the\par
fixed length or maximum variable length (as applicable) of\par
"character_string_argument". If the character string argument is NULL, UPPER\par
and LOWER return NULL. Here are some examples:\par
\par
   UPPER('E. E. Cummings') \par
    -- returns E. E. CUMMINGS\par
\par
   LOWER('E. E. Cummings') \par
    -- returns e. e. cummings\par
\par
   UPPER(LOWER('E. E. Cummings')) \par
    -- returns E. E. CUMMINGS\par
\par
In the last example, UPPER and LOWER do not cancel each other out; the output\par
string is not the same as the input string. Such information loss occurs\par
because fold functions don't affect characters which are already in the right case.\par
\par
** TIP: A string which contains no letters will be the same after UPPER and\par
LOWER, so if you need to test whether a character string contains letters do this:\par
\par
   SELECT character_column\par
   FROM   Table_Of_Character_Strings\par
   WHERE  UPPER(character_column) <> LOWER(character_column);\par
\par
Such a query will find '1a 2' but will not find '1$ 2'; thus you can use fold\par
functions to filter out strings which contain letters.\par
\par
[Obscure Rule] The result of UPPER and LOWER is a fixed length string if\par
"character_string_argument" is a fixed length string and a variable length\par
string if "character_string_argument" is a variable length string. In either\par
case, the result belongs to the same Character set that the argument does. It\par
normally has a coercibility attribute and Collation determined by Table 7-1\par
"Collating Sequences and Coercibility Rules for Monadic Operations", but you\par
can use the optional COLLATE clause to force EXPLICIT coercibility with a\par
specific Collation. The Collation named must be a Collation defined for the\par
relevant Character set. If you're using COLLATE in an SQL-Schema statement,\par
then the <AuthorizationID> that owns the containing Schema must have the USAGE\par
Privilege on "<Collation name>". If you're using COLLATE in any other SQL\par
statement, then your current <AuthorizationID> must have the USAGE Privilege\par
on "<Collation name>". For example:\par
\par
   UPPER('hello') COLLATE my.collation_1\par
\par
specifies that the result of UPPER should use a Collation named MY.COLLATION_1 and\par
\par
   LOWER('HELLO') COLLATE my.collation_1\par
\par
specifies that the result of LOWER should use a Collation named MY.COLLATION_1.\par
\par
If you want to restrict your code to Core SQL, don't use the COLLATE clause to\par
force an EXPLICIT Collation for any UPPER or LOWER operation.\par
\par
<character translation function> --\par
The required syntax for a <character translation function> is:\par
\par
<character translation function> ::=\par
TRANSLATE (character_string_argument USING <Translation name> \par
   [ COLLATE <Collation name> ])\par
\par
TRANSLATE operates on an argument that evaluates to a character string. It\par
converts every character in "character_string_argument" to its corresponding\par
equivalent in another Character set (by changing each character according to\par
some many-to-one or one-to-one mapping) and returns a variable length\par
character string that belongs to the target Character set defined for\par
"<Translation name>". If the character string argument is NULL, TRANSLATE\par
returns NULL. Here is an example of TRANSLATE:\par
\par
   TRANSLATE('hello' USING my.translation_1)\par
    -- returns a string, equivalent to hello, that belongs to the target Character set defined for a Translation called MY.TRANSLATION_1\par
\par
(Translations are defined using the CREATE TRANSLATION statement.)\par
\par
If you're using TRANSLATE in an SQL-Schema statement, then the\par
<AuthorizationID> that owns the containing Schema must have the USAGE\par
Privilege on "<Translation name>". If you're using TRANSLATE in any other SQL\par
statement, then your current <AuthorizationID> must have the USAGE Privilege\par
on "<Translation name>".\par
\par
[Obscure Rule] The result of TRANSLATE normally has a coercibility attribute\par
of IMPLICIT and uses the default Collation of the Translation's target\par
Character set, but you can use the optional COLLATE clause to force EXPLICIT\par
coercibility with a specific Collation. The Collation named must be a\par
Collation defined for the target Character set. If you're using COLLATE in an\par
SQL-Schema statement, then the <AuthorizationID> that owns the containing\par
Schema must have the USAGE Privilege on "<Collation name>". If you're using\par
COLLATE in any other SQL statement, then your current <AuthorizationID> must\par
have the USAGE Privilege on "<Collation name>". For example:\par
\par
   TRANSLATE('hello' USING my.translation_1) COLLATE my.collation_1\par
\par
specifies that the result of TRANSLATE should use a Collation named MY.COLLATION_1.\par
\par
If you want to restrict your code to Core SQL, don't use TRANSLATE.\par
\par
<form-of-use conversion function> --\par
The required syntax for a <form-of-use conversion function> is:\par
\par
<form-of-use conversion function> ::=\par
CONVERT (character_string_argument USING <Form-of-use conversion name> \par
   [ COLLATE <Collation name> ])\par
\par
CONVERT operates on an argument that evaluates to a character string. It\par
converts every character in "character_string_argument" to its corresponding\par
equivalent using another Form-of-use and returns the resulting variable length\par
character string. If the character string argument is NULL, CONVERT returns\par
NULL. Here is an example of CONVERT:\par
\par
   CONVERT('hello' USING INFORMATION_SCHEMA.new_form)\par
    -- returns a string, equivalent to hello, whose characters are encoded using a Form-of-use called NEW_FORM\par
\par
A Form-of-use is a character repertoire's encoding scheme -- the one-to-one\par
mapping scheme between each character in the repertoire and a set of internal\par
codes (usually 8-bit values) that define how the repertoire's characters are\par
encoded as numbers. (These codes are also used to specify the order of the\par
characters within the repertoire.) Supported Forms-of-use are all predefined\par
by your DBMS and thus belong to INFORMATION_SCHEMA. SQL provides no ability to\par
define your own Forms-of-use.\par
\par
CONVERT's purpose is to allow you to transfer character strings between SQL-\par
data and your host application, therefore you may only use the function in\par
certain places. When transferring SQL-data to the host, CONVERT is legal only\par
as part of a <select sublist>. For example:\par
\par
   SELECT CONVERT(char_column USING INFORMATION_SCHEMA.new_form) \par
   FROM   Table_1\par
   WHERE  char_column = 'hello';\par
\par
When transferring host values into SQL-data, use CONVERT to change any host\par
parameter. For example:\par
\par
   INSERT INTO Table_1 (char_column)\par
   VALUES (CONVERT(:char_parameter USING INFORMATION_SCHEMA.new_form));\par
\par
** TIP: You might want to use CONVERT to change a character string's encoding\par
scheme from 8-bit to 16-bit.\par
\par
[NON-PORTABLE] Whether you can use CONVERT or not is non-standard because the\par
SQL Standard requires implementors to define all Forms-of-use supported -- but\par
has no requirement that a DBMS must support any Form-of-use at all. However,\par
you can use TRANSLATE to provide an equivalent operation.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book does\par
not provide support for any Form-of-use.\par
\par
[Obscure Rule] The result of CONVERT belongs to a Character set that consists\par
of the same character repertoire that its argument's Character set has -- but\par
with a different Form-of-use encoding. It normally has a coercibility\par
attribute of IMPLICIT and uses the default Collation of its Character set, but\par
you can use the optional COLLATE clause to force EXPLICIT coercibility with a\par
specific Collation. The Collation named must be a Collation defined for the\par
target Character set. If you're using COLLATE in an SQL-Schema statement, then\par
the <AuthorizationID> that owns the containing Schema must have the USAGE\par
Privilege on "<Collation name>". If you're using COLLATE in any other SQL\par
statement, then your current <AuthorizationID> must have the USAGE Privilege\par
on "<Collation name>". For example:\par
\par
   CONVERT('hello' USING INFORMATION_SCHEMA.new_form) COLLATE my.collation_1\par
\par
specifies that the result of CONVERT should use a Collation named MY.COLLATION_1.\par
\par
If you want to restrict your code to Core SQL, don't use CONVERT.\par
\par
<regular expression substring function> --\par
The required syntax for a <regular expression substring function> is:\par
\par
<regular expression substring function> ::=\par
SUBSTRING (character_string_argument FROM pattern FOR escape_character \par
   [ COLLATE <Collation name> ]) \par
\par
SUBSTRING operates on three arguments, all of which evaluate to character\par
strings that belong to the same Character set. It extracts a substring based\par
on "pattern" from "character_string_argument" and returns a variable length\par
character string with a maximum length that equals the fixed length or maximum\par
variable length (as applicable) of "character_string_argument". Both "pattern"\par
and "escape_character" must be regular expressions (see our discussion of the\par
SIMILAR predicate) and "escape_character" must be exactly one character long.\par
If any of the arguments are NULL, SUBSTRING returns NULL.\par
\par
The "pattern" shows the substring you want to extract from\par
"character_string_argument". It's actually a triple pattern: it must consist\par
of three regular expressions, the middle of which is a tagged regular\par
expression (a regular expression that is delimited by "escape_character"\par
immediately followed by a double quote sign). For example, if your escape\par
character is ?, then "pattern" must contain ?" exactly two times, as in:\par
\par
   'The rain?"%?"Spain'\par
\par
The three parts of "pattern" -- start pattern ?" middle pattern ?" end pattern\par
-- must match "character_string_argument"'s start, middle and end; that is,\par
the expression:\par
\par
   'character_string_argument' SIMILAR TO 'pattern'\par
\par
must be TRUE if the "escape <double quote>" markers are stripped from the\par
pattern. If that's not the case -- that is, if the start or end patterns\par
aren't in the string -- SUBSTRING returns NULL. Otherwise the result of\par
SUBSTRING is "character_string_argument"'s middle string which corresponds to\par
the middle pattern. Thus, for this SUBSTRING function:\par
\par
   SUBSTRING('The rain in Spain' FROM 'The rain?"%?"Spain' FOR '?')\par
\par
the result is ' in ' -- that is, the return from SUBSTRING is the string of\par
characters which appears between the start pattern ('The rain') and the end\par
pattern ('Spain').\par
\par
[Obscure Rule] The result of SUBSTRING belongs to the same Character set that\par
its string arguments do. It normally has a coercibility attribute and\par
Collation determined by Table 7-1 "Collating Sequences and Coercibility Rules\par
for Monadic Operations", where "character_string_argument_1" is the monadic\par
operator, but you can use the optional COLLATE clause to force EXPLICIT\par
coercibility with a specific Collation. The Collation named must be a\par
Collation defined for the relevant Character set. If you're using COLLATE in\par
an SQL-Schema statement, then the <AuthorizationID> that owns the containing\par
Schema must have the USAGE Privilege on "<Collation name>". If you're using\par
COLLATE in any other SQL statement, then your current <AuthorizationID> must\par
have the USAGE Privilege on "<Collation name>". For example:\par
\par
   SUBSTRING(char_column FROM 'hi/"[b-o]/"by' FOR '/') COLLATE my.collation_1\par
\par
specifies that the result of SUBSTRING should use a Collation named MY.COLLATION_1.\par
\par
If you want to restrict your code to Core SQL, don't use the <regular\par
expression substring function> form of SUBSTRING.\par
\par
<char position expression> --\par
The required syntax for a <char position expression> is:\par
\par
<char position expression> ::=\par
POSITION (character_string_argument_1 IN character_string_argument_2)\par
\par
POSITION operates on two arguments, both of which must evaluate to character\par
strings that belong to the same Character set. It determines the first\par
character position (if any) at which "character_string_argument_1" is found in\par
"character_string_argument_2" and returns this as an exact numeric integer. If\par
either of the arguments are NULL, POSITION returns NULL. If\par
"character_string_argument_1" is a zero-length character string, POSITION\par
returns one. If "character_string_argument_1" is not found in\par
"character_string_argument_2", POSITION returns zero. Here are some examples\par
of POSITION:\par
\par
   POSITION('is' IN 'mistake') \par
    -- returns 2\par
\par
   POSITION('yy' IN 'mistake') \par
    -- returns 0\par
\par
   POSITION('' IN 'mistake') \par
    -- returns 1\par
\par
[NON-PORTABLE] The precision of POSITION's result is non-standard because the\par
SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of POSITION an INTEGER <data type>.\par
\par
[Obscure Rule] POSITION can also operate on a bit string and a BLOB. We've\par
ignored these options for now -- look for them in our chapters on bit strings\par
and BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use POSITION with\par
character strings.\par
\par
<bit length expression> --\par
The required syntax for a <bit length expression> is:\par
\par
<bit length expression> ::=\par
BIT_LENGTH (character_string_argument)\par
\par
BIT_LENGTH operates on an argument that evaluates to a character string. It\par
determines the length of the argument, in bits, and returns this as an exact\par
numeric integer, e.g.: BIT_LENGTH('hello') returns 40 (assuming that an 8-bit\par
Character set is in use). If the argument is NULL, BIT_LENGTH returns NULL.\par
** TIP: The length of a character string argument depends on the Character set\par
it belongs to. Most Character sets are 8-bit sets, so BIT_LENGTH would return\par
8 for each character in your argument. But if you're using a DBCS, remember\par
that BIT_LENGTH will allot 16 bits for each character.\par
\par
** TIP: BIT_LENGTH will return the total length of your character string\par
argument -- including any trailing (or leading) spaces. If you're looking for\par
the length of the significant value only, use TRIM with BIT_LENGTH. For example:\par
\par
   BIT_LENGTH('hello   ')\par
    -- returns 64; the length of hello followed by 3 spaces\par
\par
   BIT_LENGTH(TRIM('hello   '))\par
    -- returns 40; the length of hello\par
\par
** TIP: BIT_LENGTH returns the number of bits taken up by each Latin letter in\par
your character string argument. For example, if your argument is 'Chorizo' and\par
you're using a Spanish Collation, the second character is 'h' -- it is not 'o'\par
despite the digraph, because BIT_LENGTH doesn't care about the Collation. Thus:\par
\par
   BIT_LENGTH('Chorizo') COLLATE my.spanish_collation\par
\par
returns 56, not 48.\par
\par
[NON-PORTABLE] The precision of BIT_LENGTH's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of BIT_LENGTH an INTEGER <data type>.\par
\par
[Obscure Rule] BIT_LENGTH can also operate on a bit string and a BLOB. We've\par
ignored these options for now -- look for them in our chapters on bit strings\par
and BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use BIT_LENGTH with NCLOBs.\par
\par
<char length expression> --\par
The required syntax for a <char length expression> is:\par
\par
<char length expression> ::=\par
\{CHAR_LENGTH | CHARACTER_LENGTH\} (character_string_argument)\par
\par
CHAR_LENGTH (or CHARACTER_LENGTH) operates on an argument that evaluates to a\par
character string. It determines the length of the argument, in characters, and\par
returns this as an exact numeric integer, e.g.: CHAR_LENGTH('hello') returns\par
5. If the argument is NULL, CHAR_LENGTH returns NULL.\par
\par
** TIP: CHAR_LENGTH will return the total length of your character string\par
argument -- including any trailing (or leading) spaces. If you're looking for\par
the length of the significant value only, use TRIM with CHAR_LENGTH. For example:\par
\par
   CHAR_LENGTH('hello   ')\par
    -- returns 8; the length of hello followed by 3 spaces\par
\par
   CHAR_LENGTH(TRIM('hello   '))\par
    -- returns 5; the length of hello\par
\par
** TIP: CHAR_LENGTH returns the number of Latin letters in your character\par
string argument. For example, if your argument is 'Chorizo' and you're using a\par
Spanish Collation, the second character is 'h' -- it is not 'o' despite the\par
digraph, because CHAR_LENGTH doesn't care about the Collation. Thus:\par
\par
   CHAR_LENGTH('Chorizo') COLLATE my.spanish_collation\par
\par
returns 7, not 6.\par
\par
[NON-PORTABLE] The precision of CHAR_LENGTH's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of CHAR_LENGTH an INTEGER <data type>.\par
\par
[Obscure Rule] CHAR_LENGTH can also operate on a bit string and a BLOB. We've\par
ignored these options for now -- look for them in our chapters on bit strings\par
and BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use CHAR_LENGTH with NCLOBs.\par
\par
<octet length expression> --\par
The required syntax for a <octet length expression> is:\par
\par
<octet length expression> ::=\par
OCTET_LENGTH (character_string_argument)\par
\par
OCTET_LENGTH operates on an argument that evaluates to a character string. It\par
determines the length of the argument, in octets, and returns this as an exact\par
numeric integer, e.g.: OCTET_LENGTH('hello') returns 5 (assuming that an 8-bit\par
Character set is in use; the octet length of a string is the bit length\par
divided by 8, ignoring any remainder.) If the argument is NULL, OCTET_LENGTH\par
returns NULL.\par
\par
** TIP: The length of a character string argument depends on the Character set\par
it belongs to. Most Character sets are 8-bit sets, so OCTET_LENGTH would\par
return 1 for each character in your argument. But if you're using a DBCS,\par
remember that OCTET_LENGTH will allot 2 octets for each character.\par
\par
** TIP: OCTET_LENGTH will return the total length of your character string\par
argument -- including any trailing (or leading) spaces. If you're looking for\par
the length of the significant value only, use TRIM with OCTET_LENGTH. For example:\par
\par
   OCTET_LENGTH('hello   ')\par
    -- returns 8; the length of hello followed by 3 spaces\par
\par
   OCTET_LENGTH(TRIM('hello   '))\par
    -- returns 5; the length of hello\par
\par
** TIP: OCTET_LENGTH returns the number of octets taken up by each Latin\par
letter in your character string argument. For example, if your argument is\par
'Chorizo' and you're using a Spanish Collation, the second character is 'h' --\par
it is not 'o' despite the digraph, because OCTET_LENGTH doesn't care about the\par
Collation. Thus:\par
\par
   OCTET_LENGTH('Chorizo') COLLATE my.spanish_collation\par
\par
returns 7, not 6.\par
\par
[NON-PORTABLE] The precision of OCTET_LENGTH's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of OCTET_LENGTH an INTEGER <data type>.\par
\par
[Obscure Rule] OCTET_LENGTH can also operate on a bit string and a BLOB. We've\par
ignored these options for now -- look for them in our chapters on bit strings\par
and BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use OCTET_LENGTH with NCLOBs.\par
\par
## Set functions\par
SQL provides five set functions that operate on CHAR, VARCHAR, NCHAR and NCHAR\par
VARYING character strings: COUNT(*), COUNT, MAX, MIN and GROUPING. SQL also\par
provides three set functions that operate on CLOB and NCLOB character strings:\par
COUNT(*), COUNT and GROUPING. Since none of these operate exclusively with\par
character string arguments, we won't discuss them here; look for them in our\par
chapter on set functions.\par
\par
## Predicates\par
In addition to the comparison operators, SQL provides ten other predicates\par
that operate on CHAR, VARCHAR, NCHAR and NCHAR VARYING character strings: the\par
<like predicate>, the <similar predicate>, the <between predicate>, the <in\par
predicate>, the <null predicate>, the <exists predicate>, the <unique\par
predicate>, the <match predicate>, the <quantified predicate> and the\par
<distinct predicate>. SQL also provides five predicates that operate on CLOB\par
and NCLOB character strings: the <like predicate>, the <similar predicate>,\par
the <null predicate>, the <exists predicate> and the <quantified predicate>.\par
Each will return a boolean value: either TRUE, FALSE or UNKNOWN. Only the\par
<like predicate> and the <similar predicate> operate strictly on strings;\par
we'll discuss them here. Look for the rest in our chapter on search conditions.\par
\par
<like predicate> --\par
The required syntax for a <like predicate> is:\par
\par
<like predicate> ::=\par
character_string_argument [ NOT ] LIKE pattern [ ESCAPE escape_character ]\par
\par
LIKE is a predicate that operates on three operands that evaluate to character\par
strings belonging to the same Character set: it searches for values that\par
contain a given pattern. NOT LIKE is the converse and lets you search for\par
values that don't contain a given pattern. The "character_string_argument" is\par
the character string you're searching within, the "pattern" is the pattern\par
you're searching for and the optional "escape_character" is a character that\par
tells your DBMS to treat a metacharacter in the pattern as itself (rather than\par
as a metacharacter). If "character_string_argument" contains the pattern, LIKE\par
returns TRUE and NOT LIKE returns FALSE. If "character_string_argument" does\par
not contain the pattern, LIKE returns FALSE and NOT LIKE returns TRUE. If any\par
of the operands are NULL, LIKE and NOT LIKE return UNKNOWN.\par
\par
The pattern you specify in "pattern" may contain any combination of regular\par
characters and metacharacters. Any single character in "pattern" that is not a\par
metacharacter or the "escape_character" represents itself in the pattern. For\par
example, this predicate:\par
\par
   char_column LIKE 'A'\par
\par
is TRUE for 'A'.\par
\par
Special significance is attached to metacharacters in a pattern. The\par
metacharacters are: _ and %. If the predicate doesn't include an ESCAPE\par
clause, they are interpreted as follows:\par
      ## _ An underline character means "any single character". For example,\par
this predicate:\par
\par
   char_column LIKE 'A_C'\par
\par
is TRUE for 'A C', 'AAC', 'ABC', 'A#C' and so on.\par
      ## %  A percent sign means "any string of zero or more characters". For\par
example, this predicate:\par
\par
   char_column LIKE 'A%C'\par
\par
is TRUE for 'AC', 'A C', 'AxC', 'AxxxxxxxxC' and so on.\par
\par
If you want to search for a character that would normally be interpreted as a\par
metacharacter, you must use the optional ESCAPE clause. To do so:\par
      ## Pick a character that you won't need in the pattern and designate it\par
as your escape character.\par
      ## In the pattern, use your escape character followed immediately by the\par
metacharacter, to designate the metacharacter as a character you want to\par
search for. For example:\par
\par
   ... LIKE 'B$%'\par
\par
(without an ESCAPE clause) means "like the letter B followed by a dollar sign\par
followed by anything at all", while:\par
\par
   ... LIKE 'B$?%' ESCAPE '?'\par
\par
means "like the letter B followed by a dollar sign followed by a percent sign"\par
(since % is preceded by the escape character it has no special significance in\par
this pattern). Your escape character can also be followed by itself in the\par
pattern, if you want to search for the escape character. For example:\par
\par
   ... LIKE 'B$??' ESCAPE '?'\par
\par
means "like the letter B followed by a dollar sign followed by a question\par
mark" (since ? is preceded by the escape character it has no special\par
significance in this pattern). Your best choice for an escape character is an\par
SQL special character which isn't a [NOT] LIKE metacharacter. We suggest the\par
question mark.\par
\par
The "escape_character" must be exactly one character long. If it isn't, [NOT]\par
LIKE will fail: your DBMS will return the SQLSTATE error 22019 "data\par
exception-invalid escape character". If "escape_character" is _ or % and that\par
metacharacter is used once only in your pattern, or if "escape_character" is\par
used without being followed by a metacharacter (or by itself) in your pattern,\par
[NOT] LIKE will fail: your DBMS will return the SQLSTATE error 22025 "data\par
exception-invalid escape sequence". For example, this predicate will result in\par
SQLSTATE 22025:\par
\par
   LIKE 'B%B' ESCAPE '%'\par
\par
For the purposes of [NOT] LIKE, a substring of "character_string_argument" is\par
a sequence of zero or more contiguous characters, where each character belongs\par
to exactly one such substring (this includes any trailing spaces in the\par
argument). A substring specifier of "pattern" is either (a) _: an arbitrary\par
character specifier, (b) %: an arbitrary string specifier, (c)\par
"escape_character" followed by _ or % or "escape_character" or (d) any other\par
single character. If "character_string_argument" and "pattern" are both\par
variable length character strings with a length of zero, LIKE returns TRUE.\par
LIKE also returns TRUE if "pattern" is found in "character_string_argument".\par
That is, LIKE returns TRUE only if the number of substrings in\par
"character_string_argument" equals the number of substring specifiers in\par
"pattern" and all of these conditions are also met:\par
      ## If the pattern's n-th substring specifier is _, then the argument's\par
n-th substring must be any single character.\par
      ## If the pattern's n-th substring specifier is %, then the argument's\par
n-th substring must be any sequence of zero or more characters.\par
      ## If the pattern's n-th substring specifier is any other character,\par
then the argument's n-th substring must be equal, in length and character\par
representation, to that substring specifier -- without trailing spaces being\par
added to the argument. Note that this means if the pattern is found in the\par
argument, but the lengths don't match, LIKE returns FALSE. For example, these\par
four predicates all return TRUE:\par
\par
   'bob' LIKE 'b_b'\par
\par
   'bob' LIKE 'b%b'\par
\par
   'bob   ' LIKE 'b_b   '\par
\par
   'bob   ' LIKE 'b%b   '\par
\par
But these two predicates return FALSE because of the trailing spaces in\par
"character_string_argument" that aren't found in pattern:\par
\par
   'bob   ' LIKE 'b_b'\par
\par
   'bob   ' LIKE 'b%b'\par
\par
And these two predicates return FALSE because of the trailing spaces in\par
"pattern" that aren't found in "character_string_argument":\par
\par
   'bob' LIKE 'b_b   '\par
\par
   'bob' LIKE 'b%b   '\par
\par
Note that this is only a problem with fixed length character string arguments.\par
Here's a more complete example:\par
\par
   CREATE TABLE Test_Stuffs ( \par
      column_1 CHAR(4));\par
\par
   INSERT INTO Test_Stuffs (column_1) \par
   VALUES ('ABC');\par
   -- actually inserts 'ABC ' (four characters)\par
\par
   SELECT * \par
   FROM   Test_Stuffs \par
   WHERE  column_1 = 'ABC';\par
   -- works because comparisons will pad the shorter argument (assuming the relevant Collation has the PAD SPACE attribute) so the test is WHERE 'ABC ' = 'ABC '\par
\par
   SELECT * \par
   FROM   Test_Stuffs \par
   WHERE  column_1 LIKE '%C';\par
   -- fails because LIKE never pads the shorter argument, no matter what Collation is used, so the test is "find a value of any length that ends in C" -- and 'ABC ' ends in a space, not in C\par
\par
To get around this, use TRIM to get rid of trailing spaces in your\par
"character_string_argument", like this:\par
\par
   SELECT * \par
   FROM   Test_Stuffs \par
   WHERE  TRIM (TRAILING FROM column_1) LIKE '%C';\par
\par
[Obscure Rule] The result of [NOT] LIKE belongs to the same Character set that\par
its operands do. If you omit the ESCAPE clause, then it has a Collation\par
determined by Table 7-3 "Collating Sequences used for Comparisons", where\par
"character_string_argument" is comparand 1 and "pattern" is comparand 2. If\par
you include the ESCAPE clause, then it also has a Collation determined by\par
Table 7-3 "Collating Sequences used for Comparisons", where:\par
      ## comparand 1 is determined by Table 7-2 "Collating Sequences and\par
Coercibility Rules for Dyadic Operations", where "character_string_argument"\par
is operand 1 and "pattern" is operand 2.\par
      ## comparand 2 is "escape_character".\par
\par
[Obscure Rule] [NOT] LIKE can also operate on BLOBs. We've ignored this option\par
for now -- look for it in our chapter on BLOBs.\par
\par
If you want to restrict your code to Core SQL, don't use the [NOT] LIKE\par
predicate with CLOBs or NCLOBs and, when you do use [NOT LIKE], make sure your\par
"character_string_argument" is a <Column reference> and that your "pattern"\par
and your "escape_character" are both <value specification>s.\par
\par
<similar predicate> --\par
The required syntax for a <similar predicate> is:\par
\par
<similar predicate> ::= \par
character_string_argument [ NOT ] SIMILAR TO pattern \par
   [ ESCAPE escape_character ]\par
\par
SIMILAR is a predicate that operates on three operands that evaluate to\par
character strings belonging to the same Character set. It works much like\par
Unix's grep: it searches for values that contain a given pattern. NOT SIMILAR\par
is the converse and lets you search for values that don't contain a given\par
pattern. The "character_string_argument" is the character string you're\par
searching within, the "pattern" is the pattern you're searching for and the\par
optional "escape_character" is a character that tells your DBMS to treat a\par
metacharacter in the pattern as itself (rather than as a metacharacter). If\par
"character_string_argument" contains the pattern, SIMILAR returns TRUE and NOT\par
SIMILAR returns FALSE. If "character_string_argument" does not contain the\par
pattern, SIMILAR returns FALSE and NOT SIMILAR returns TRUE. If any of the\par
operands are NULL, SIMILAR and NOT SIMILAR return UNKNOWN.\par
\par
The pattern you specify in "pattern" must be a regular expression: a sequence\par
of ordinary characters combined with some special characters (or\par
metacharacters). It may contain character ranges, repetitions and\par
combinations. Any single character in "pattern" that is not a metacharacter or\par
the "escape_character" represents itself in the pattern. For example, this\par
predicate:\par
\par
   char_column SIMILAR TO 'A'\par
\par
is TRUE for 'A'.\par
\par
Special significance is attached to metacharacters in a pattern. The\par
metacharacters are: _ and % and * and + and | and ( and ) and [ and ] and ^\par
and - and :. If the predicate doesn't include an ESCAPE clause, they are\par
interpreted as follows:\par
      ## _ An underline character means "any single character". For example, this predicate:\par
\par
   char_column SIMILAR TO 'A_C'\par
\par
is TRUE for 'A C', 'AAC', 'ABC', 'A#C' and so on.\par
      ## %  A percent sign means "any string of zero or more characters". For example, this predicate:\par
\par
   char_column SIMILAR TO 'A%C'\par
\par
is TRUE for 'AC', 'A C', 'AxC', 'AxxxxxxxxC' and so on.\par
      ## * An asterisk means "preceding repeats indefinitely" (from zero to\par
infinity times). For example, this predicate:\par
\par
   char_column SIMILAR TO 'A*'\par
\par
is TRUE for '', 'A', 'AA', 'AAA', 'AAAA' and so on.\par
      ## + A plus sign means "preceding repeats indefinitely" (from one to\par
infinity times). For example, this predicate:\par
\par
   char_column SIMILAR TO 'A+'\par
\par
is TRUE for 'A', 'AA', 'AAA', 'AAAA' and so on.\par
      ## [ ] Brackets are used for character enumeration in the pattern. There\par
are two ways to enumerate: as a simple list or with a minus sign, with the\par
result that a match is made with any one of the characters inside the\par
brackets. For example, this predicate:\par
\par
   char_column SIMILAR TO '[A]'\par
\par
is TRUE for 'A'. This predicate:\par
\par
   char_column SIMILAR TO '[AQZ]'\par
\par
is TRUE for 'A' or 'Q' or 'Z'. This predicate:\par
\par
   char_column SIMILAR TO '[A-E]'\par
\par
is TRUE for 'A' or 'B' or 'C' or 'D' or 'E'. And this predicate:\par
\par
   char_column SIMILAR TO '[A-EQ-S]'\par
\par
is TRUE for 'A' or 'B' or 'C' or 'D' or 'E' or 'Q' or 'R' or 'S'.\par
      ## [^ ] A circumflex inside enumerating brackets means negative\par
enumeration. The options are the same as for ordinary enumeration, with a\par
negated meaning. For example, this predicate:\par
\par
   char_column SIMILAR TO '[^A-C]'\par
\par
is TRUE for anything not equal to 'A' or to 'B' or to 'C'. This predicate:\par
\par
   char_column SIMILAR TO '[^AQZ]'\par
\par
is TRUE for anything not equal to 'A' or 'Q' or 'Z'. And this predicate:\par
\par
   'ABCDE' SIMILAR TO '[^C-F]'\par
\par
is FALSE, since the last character in the character string argument must not\par
be 'C' or 'D' or 'E' or 'F'.\par
      ## [: :] Brackets containing colons surrounding one of: ALPHA, UPPER,\par
LOWER, DIGIT or ALNUM are used for set enumeration in the pattern. For example, this predicate:\par
\par
   char_column SIMILAR TO '[:ALPHA:]'\par
\par
is TRUE for values of CHAR_COLUMN that are equal to any simple Latin letter,\par
i.e.: to any of "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz". This predicate:\par
\par
   char_column SIMILAR TO '[:UPPER:']\par
\par
is TRUE for values of CHAR_COLUMN that are equal to any simple Latin upper\par
case letter, i.e.: to any of "ABCDEFGHIJKLMNOPQRSTUVWXYZ". This predicate:\par
\par
   char_column SIMILAR TO '[:LOWER:]'\par
\par
is TRUE for values of CHAR_COLUMN that are equal to any simple Latin lower\par
case letter, i.e.: to any of "abcdefghijklmnopqrstuvwxyz". This predicate:\par
\par
   char_column SIMILAR TO '[:DIGIT:]'\par
\par
is TRUE for values of CHAR_COLUMN that are equal to any digit, i.e.: to any of\par
"0123456789". And this predicate:\par
\par
   char_column SIMILAR TO '[:ALNUM:]'\par
\par
is TRUE for values of CHAR_COLUMN that are equal to any simple Latin letter or\par
to any digit, i.e.: to any of "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789".\par
      ## | The vertical bar means "the logical OR of the first and second\par
expressions". For example, this predicate:\par
\par
   char_column SIMILAR TO '[A-C']|[:DIGIT:]'\par
\par
is TRUE for any of "ABC0123456789". The | operator has a lower priority than * and + have.\par
      ## || The concatenation operator means "concatenate one element from\par
first expression with one element from second expression". For example, this predicate:\par
\par
   char_column SIMILAR TO '[A-C]||[:DIGIT:]'\par
\par
is TRUE for: 'A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'B0',\par
'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8' 'B9', 'C0', 'C1', 'C2', 'C3',\par
'C4', 'C5', 'C6', 'C7', 'C8' and 'C9'.\par
      ## ( ) Parentheses in a pattern force the order of evaluation, in the\par
usual way. For example, this predicate:\par
\par
   char_column SIMILAR TO '[:UPPER:]|([:DIGIT:][:DIGIT:])'\par
\par
is TRUE for any single upper case letter, or for any two digits.\par
      ## If "pattern" is not a valid pattern, [NOT] SIMILAR will fail: your\par
DBMS will return the SQLSTATE error 2201B "data exception-invalid regular\par
expression". Here are two examples of invalid patterns:\par
\par
   '^[:UPER:]' \par
\par
   '[:abc:]'\par
\par
If you want to search for a character that would normally be interpreted as a\par
metacharacter, you must use the optional ESCAPE clause. To do so:\par
      ## Pick a character that you won't need in the pattern and designate it\par
as your escape character.\par
      ## In the pattern, use your escape character followed immediately by the\par
metacharacter, to designate it as a character you want to search for. For example:\par
\par
   ... SIMILAR TO 'B$%'\par
\par
(without an ESCAPE clause) means "similar to the letter B followed by a dollar\par
sign followed by anything at all", while:\par
\par
   ... SIMILAR TO 'B$?%' ESCAPE '?'\par
\par
means "similar to the letter B followed by a dollar sign followed by a percent\par
sign" (since % is preceded by the escape character it has no special\par
significance in this pattern). Your escape character can also be followed by\par
itself in the pattern, if you want to search for the escape character. For example:\par
\par
   ... SIMILAR TO 'B$??' ESCAPE '?'\par
\par
means "similar to the letter B followed by a dollar sign followed by a\par
question mark" (since ? is preceded by the escape character it has no special\par
significance in this pattern). Your best choice for an escape character is an\par
SQL special character which isn't a [NOT] SIMILAR metacharacter. We suggest\par
the question mark.\par
\par
The "escape_character" must be exactly one character long. If it isn't, [NOT]\par
SIMILAR will fail: your DBMS will return the SQLSTATE error 22019 "data\par
exception-invalid escape character". If "escape_character" is [ or ] or ( or )\par
or | or ^ or - or + or * or _ or % and that metacharacter is used once only in\par
your pattern, or if "escape_character" is used without being followed by a\par
metacharacter (or itself) in your pattern, [NOT] SIMILAR will fail: your DBMS\par
will return the SQLSTATE error 2200C "data exception-invalid use of escape\par
character". For example, this predicate will result in SQLSTATE 2200C:\par
\par
   SIMILAR TO 'B?B' ESCAPE '?'\par
\par
If "escape_character" is a colon and your pattern contains that metacharacter\par
surrounding one of: ALPHA, UPPER, LOWER, DIGIT or ALNUM, [NOT] SIMILAR will\par
fail: your DBMS will return the SQLSTATE error 2200B "data exception-escape\par
character conflict".\par
\par
[Obscure Rule] The result of [NOT] SIMILAR belongs to the same Character set\par
that its operands do. If you omit the ESCAPE clause, then it has a Collation\par
determined by Table 7-3 "Collating Sequences used for Comparisons", where\par
"character_string_argument" is comparand 1 and "pattern" is comparand 2. If\par
you include the ESCAPE clause, then it also has a Collation determined by\par
Table 7-3 "Collating Sequences used for Comparisons", where:\par
      ## comparand 1 is determined by Table 7-2 "Collating Sequences and\par
Coercibility Rules for Dyadic Operations", where "character_string_argument"\par
is operand 1 and "pattern" is operand 2.\par
      ## comparand 2 is "escape_character".\par
\par
If you want to restrict your code to Core SQL, don't use the [NOT] SIMILAR predicate.\par
\par
Common checks --\par
Although [NOT] SIMILAR is not terribly useful in WHERE clauses (it's too\par
inefficient) it is great for CHECK clauses. Here are some real-world examples\par
of strings which have rigid format specifications. [NOT] SIMILAR is\par
appropriate for making sure the strings meet the specifications.\par
      ## POSTAL CODES. These strings must be "letter digit letter space digit\par
letter digit" -- and the letters must be upper case simple Latin letters,\par
e.g.: 'T5E 1G7', 'V1K 4K0'. To make sure your data fits these requirements,\par
use a simple Domain Constraint:\par
\par
   ALTER DOMAIN postal_code \par
   ADD CONSTRAINT postal_code_specs \par
   CHECK (VALUE SIMILAR TO \par
     '[:UPPER:][DIGIT:][:UPPER] [:DIGIT]:[UPPER:][:DIGIT:]');\par
\par
      ## PERIODIC-TABLE SYMBOLS. These strings are either a single upper case\par
simple Latin letter capital letter (e.g.: 'H', 'O') or one upper case and one\par
lower case letter (E.G.: 'Al', 'Fe'). To make sure your data fits these\par
requirements, use another simple Domain Constraint:\par
\par
   CREATE DOMAIN periodic_table_element CHAR(2) \par
   CHECK (VALUE SIMILAR TO '[A-Z]|([A-Z][a-z])');\par
\par
      ## NORTH AMERICAN TELEPHONE NUMBERS. These strings must be "digit digit\par
digit minus-sign digit digit digit digit"; optionally preceded by\par
"left-parenthesis digit digit digit right-parenthesis" (e.g.: '498-1234' or\par
'(604)498-1234'). This is a hard one: the string includes both an optional\par
format and a special character that needs "escaping". To make sure your data\par
fits these requirements, use a Table Constraint:\par
\par
   CREATE TABLE Table_1 ( \par
   phone_number CHAR(13), \par
   CHECK (phone_number SIMILAR TO\par
      '([:DIGIT:][:DIGIT:][:DIGIT:]?-[:DIGIT:][:DIGIT:][:DIGIT:][:DIGIT:])\par
       | \par
       (?([:DIGIT:][:DIGIT:][:DIGIT:]?)[:DIGIT:][:DIGIT:][:DIGIT:]?-[:DIGIT:][:DIGIT:][:DIGIT:][:DIGIT:])'\par
       ESCAPE '?');\par
\par
This example is shown on multiple lines for clarity; in reality the string may\par
not contain carriage returns, nor would the "pattern".\par
\par
[NOT] LIKE or [NOT] SIMILAR? --\par
[NOT] LIKE and [NOT] SIMILAR are both pattern-matching predicates. You should\par
continue to use [NOT] LIKE if the pattern contains only _ and % wildcards --\par
although [NOT] SIMILAR can use these wildcards too, there is no advantage in\par
using an SQL3 expression when an SQL-92 expression will do. For more complex\par
patterns, your choice is between [NOT] SIMILAR and nothing. When you make the\par
switchover, remember that there are subtle differences between [NOT] SIMILAR\par
and [NOT] LIKE, in the way that collating sequences are handled (which affects\par
which characters are regarded as "equal" and whether there are pad spaces at\par
the end of a string).\par
\par
Character strings and Character Sets\par
\par
[Obscure Rule] applies for this entire section.\par
\par
In the last chapter, we made the observation that a computer character set has\par
two parts: a character repertoire and an agreement on how the repertoire's\par
characters will be encoded as numbers. SQL has a similar rule: An SQL\par
Character set is a combination of two things:\par
      ## A character repertoire: the set of characters that belong to the\par
Character set.\par
      ## A Form-of-use: the repertoire's encoding scheme -- the one-to-one\par
mapping scheme between each character in the repertoire and a set of internal\par
codes (usually 8-bit values) that define how the repertoire's characters are\par
encoded as numbers. (These codes are also used to specify the order of the\par
characters within the repertoire.)\par
\par
All SQL character strings belong to some Character set. Whenever you're\par
working with an SQL character string, you may either specify the Character set\par
it belongs to, or allow it to belong to a default Character set chosen by your\par
DBMS. (To simplify matters, we recommend that you always follow the latter\par
course. This will ensure that you get standard results across SQL-sessions.)\par
\par
To explicitly specify a Character set for a character string, add a CHARACTER\par
SET clause to a <data type> specification and/or "_<Character set name>" to a\par
<literal>, as shown in the appropriate syntax diagrams in this chapter. Your\par
current <AuthorizationID> must have the USAGE Privilege for the Character set named.\par
\par
If you choose not to specify a Character set for a character string, the\par
current default Character set is implicit. Your DBMS will choose the current\par
default Character set using these rules:\par
      ## A character string <data type> specification (in CREATE SCHEMA,\par
CREATE TABLE, CREATE DOMAIN, ALTER TABLE and ALTER DOMAIN) that doesn't\par
include an explicit CHARACTER SET clause is treated as if the default\par
Character set of the Schema it's defined in was explicitly named.\par
            [NON-PORTABLE] In any operation other than defining a Domain,\par
defining a Column or defining a Field (e.g.: in a CAST operation), a character\par
string <data type> specification that doesn't include a CHARACTER SET clause\par
will be treated as if it belongs to a Character set that is non-standard\par
because the SQL Standard requires implementors to define what the operation's\par
default Character set is.\par
                  [OCELOT Implementation] The OCELOT DBMS that comes with this\par
book uses ASCII_FULL -- the DBMS's initial default Character set -- as the\par
default Character set for such operations.\par
      ## Any other character string value that doesn't include an explicit\par
Character set specification must either consist only of <SQL language\par
character>s or the value's Character set defaults to (a) the default Character\par
set of the Schema, if it's found in a CREATE SCHEMA statement, (b) the default\par
Character set of the SQL-session, if it's found in a dynamic SQL statement or\par
(c) the default Character set of the Module you're running, if it's found in\par
any other SQL statement in a Module.\par
\par
Every Character set has at least one Collation: its default Collation. You may\par
define additional Collations for any Character set.\par
\par
If you want to restrict your code to Core SQL, don't explicitly define the\par
Character set that any character string belongs to -- always allow it to\par
belong to the default Character set.\par
\par
Character strings and Collations\par
\par
[Obscure Rule] applies for this entire section.\par
\par
A Collation, or collating sequence, is a set of rules that determines the\par
result when character strings are compared. The result of any character string\par
comparison thus depends on the Collation used -- we'll call this the "relevant\par
Collation". Different Collations might result in different comparison results\par
for the same two strings, e.g.: a case-sensitive Collation will determine that\par
the letter "A" and the letter "a" are not equal, but a case-insensitive\par
Collation will determine that "A" and "a" are equal.\par
\par
Whenever you're comparing an SQL character string, you may either specify the\par
relevant Collation, or allow the comparison to be governed by a default\par
Collation chosen by your DBMS. (To simplify matters, we recommend that you\par
always follow the latter course. This will ensure that you get standard\par
results across SQL-sessions.)\par
\par
To explicitly specify a Collation for a comparison, add a COLLATE clause to\par
your character string, as shown in the appropriate syntax diagrams in chapter.\par
The Collation you name must either (a) be the default Collation for the\par
relevant Character set or (b) be defined as a Collation for the relevant\par
Character set by some CREATE COLLATION statement. If you're using COLLATE in\par
an SQL-Schema statement, then the <AuthorizationID> that owns the containing\par
Schema must have the USAGE Privilege on "<Collation name>". If you're using\par
COLLATE in any other SQL statement, then your current <AuthorizationID> must\par
have the USAGE Privilege on "<Collation name>".\par
\par
If you choose not to specify a Collation for a comparison, the current default\par
Collation is implicit. Your DBMS will choose the current default Collation for\par
a character string using these rules:\par
\par
First, to choose a character string's default Collation:\par
      ## If a character string <data type> specification doesn't include a\par
COLLATE clause but does include a CHARACTER SET clause, the default Collation\par
for that <data type>'s values is the default Collation of the Character set named.\par
      ## If any other character string value doesn't include a COLLATE clause,\par
the default Collation for that value is the default Collation of the value's\par
Character set.\par
\par
Second, to choose one of the comparand's default Collations for the\par
comparison:\par
      ## Expressions that involve only non-Columns (i.e.: a <literal>, host\par
language variable, parameter or expression result) are compared using the\par
default Collation for the character string values' mutual Character set.\par
      ## Expressions that involve both Columns (i.e.: <Column name>s or\par
<Column reference>s) and non-Columns are compared using the Column(s)' mutual\par
default Collation. If you want to compare values from multiple Columns with\par
different default Collations, you must include a COLLATE clause in your\par
expression.\par
\par
Table 7-1 shows how the collating sequence and coercibility attribute are\par
determined for the result of a monadic operation.\par
\par
<<<INSERT CHAP7_T1.DOC HERE>>>\par
\par
Table 7-2 shows how the collating sequence and coercibility attribute are\par
determined for the result of a dyadic operation.\par
\par
<<<INSERT CHAP7_T2.DOC HERE>>>\par
\par
Table 7-3 shows how the collating sequence is determined for a particular\par
comparison.\par
\par
<<<INSERT CHAP7_T3.DOC HERE>>>\par
\par
Dialects\par
\par
The "typical" SQL DBMS supports most of the standard character data types, but\par
often uses preferred local names. For example, Oracle has a 2000-byte maximum\par
(2048 for Oracle Lite) for the CHAR <data type> and offers a (non-standard)\par
LONG VARCHAR type to define larger character string fields.\par
\par
Sybase allows for a large variety of Character sets, with only one "group"\par
(Character set) allowed at a time. Baltic languages are in the East European\par
group (8859-2), though it doesn't seem possible to get a correct result in\par
this case. Collations supported are: English+French+German (all together!),\par
Spanish, Hungarian, Russian; then everything else is binary. Sybase does not\par
support SQL CHARACTER SETs, COLLATIONs or TRANSLATIONs, nor does it support\par
CONVERT -- to convert you need an offline utility. It does provide some\par
Unicode support.\par
\par
\par
Table 7-1:\par
Collating Sequences and Coercibility Rules for Monadic Operations\par
\par
OPERAND'S      OPERAND'S   RESULT'S       RESULT'S\par
COERCIBILITY   COLLATION   COERCIBILITY   COLLATION\par
ATTRIBUTE                  ATTRIBUTE\par
Coercible      Default     Coercible      Default\par
Implicit       X           Implicit       X\par
No Collation   None        No Collation   None\par
Explicit       X           Explicit       X\par
\par
\par
Table 7-2:\par
Collating Sequences and Coercibility Rules for Dyadic Operations\par
\par
OPERAND_1'S  OPERAND_1'S OPERAND_2'S  OPERAND_2'S RESULT'S     RESULT'S\par
COERCIBILITY COLLATION   COERCIBILITY COLLATION   COERCIBILITY COLLATION\par
ATTRIBUTE                ATTRIBUTE                ATTRIBUTE\par
Coercible    Default     Coercible    Default     Coercible    Default\par
Coercible    Default     Implicit     X           Implicit     X\par
Coercible    Default     No Collation None        No Collation None\par
Coercible    Default     Explicit     X           Explicit     X\par
Implicit     X           Coercible    Default     Implicit     X\par
Implicit     X           Implicit     X           Implicit     X\par
Implicit     X           Implicit     Y<>X        No Collation None\par
Implicit     X           No Collation None        No Collation None\par
Implicit     X           Explicit     Y           Explicit     Y\par
No Collation None        Coercible    Default     No Collation None\par
No Collation None        Implicit     X           No Collation None\par
No Collation None        No Collation None        No Collation None\par
No Collation None        Explicit     X           Explicit     X\par
Explicit     X           Coercible    Default     Explicit     X\par
Explicit     X           Implicit     Y           Explicit     X\par
Explicit     X           No Collation None        Explicit     X\par
Explicit     X           Explicit     X           Explicit     X\par
Explicit     X           Explicit     Y<>X        invalid syntax\par
\par
\par
Table 7-3:\par
Collating Sequences used for Comparisons\par
\par
COMPARAND_1'S COMPARAND_1'S COMPARAND_2'S COMPARAND_2'S COLLATION\par
COERCIBILITY  COLLATION     COERCIBILITY  COLLATION     USED FOR\par
ATTRIBUTE                   ATTRIBUTE                   COMPARISON\par
Coercible     Default       Coercible     Default       Default\par
Coercible     Default       Implicit      X             X\par
Coercible     Default       No Collation  None          invalid syntax\par
Coercible     Default       Explicit      X             X\par
Implicit      X             Coercible     Default       X\par
Implicit      X             Implicit      X             X\par
Implicit      X             Implicit      Y<>X          invalid syntax\par
Implicit      X             No Collation  None          invalid syntax\par
Implicit      X             Explicit      Y             Y\par
No Collation  None          Coercible     Default       invalid syntax\par
No Collation  None          Implicit      X             invalid syntax\par
No Collation  None          No Collation  None          invalid syntax\par
No Collation  None          Explicit      X             X\par
Explicit      X             Coercible     Default       X\par
Explicit      X             Implicit      Y             X\par
Explicit      X             No Collation  None          X\par
Explicit      X             Explicit      X             X\par
Explicit      X             Explicit      Y<>X          invalid syntax\par
(Note: For expressions involving more than two comparands, the collating\par
sequence is effectively determined on a cumulative basis: the result for the\par
first two comparands becomes "comparand_1" for the next comparison, the result\par
for this becomes "comparand_1" for the comparison after that, and so on.)\par
\page\par
Chapter 8 -- Temporal values\par
\par
In SQL, a temporal value is either a datetime (i.e.: a date, a clock time or a\par
timestamp) or an interval (i.e.: a span of time). They consist of a contiguous\par
subset of one or more of the datetime fields (in their order of significance):\par
YEAR, MONTH, DAY, HOUR, MINUTE, SECOND, TIMEZONE_HOUR and TIMEZONE_MINUTE. A\par
temporal value may be a <literal>, the value of a parameter or a host language\par
variable or the result of any expression or argument (including a possibly\par
qualified <Column name>) that evaluates to a date, a time, a timestamp or an\par
interval. Temporal values are constrained by their datetime fields and must\par
obey the natural rules for dates and times according to the Gregorian calendar.\par
\par
Datetimes are either dates, times or timestamps. Dates are stored in the DATE\par
<data type>, times are stored in either the TIME or the TIME WITH TIME ZONE\par
<data type>s and timestamps are stored in either the TIMESTAMP or the\par
TIMESTAMP WITH TIME ZONE <data type>s. \par
\par
Intervals are either year-month intervals (spans of time involving years\par
and/or months) or day-time intervals (spans of time involving days and/or\par
hours and/or minutes and/or seconds and/or fractions of a second); they\par
include a qualifier which specifies which of the datetime fields are\par
represented in the interval. All interval values are signed. Intervals are\par
stored in the INTERVAL <data type>.\par
\par
Some Preliminaries\par
\par
Before we talk about datetimes and intervals, there is some necessary\par
background to go through. We provide most of this information mainly for\par
reference purposes, though. If you decide not to read it thoroughly right now,\par
you'll still understand most of what follows. However, we will be referring to\par
these concepts throughout this chapter.\par
\par
[Obscure Rule] applies for the rest of this section.\par
\par
The Gregorian Calendar:\par
The SQL Standard says that all dates must be valid "according to the Gregorian\par
calendar". Most people know the main rules:\par
   ## Thirty days hath September, April, June and November, all the rest have\par
thirty-one, except (the rhyme scheme starts to fail here) February which has\par
28 days, or 29 in a leap year.\par
   ## A leap year occurs every four years.\par
\par
These first two rules are the rules of the Julian Calendar. Pope Gregory XIII\par
added this exception in 1582:\par
   ## A leap year does not occur at the end of a century, except every 400\par
years. (That is: 1700, 1800, 1900, 2100, 2200 and 2300 are not leap years.)\par
\par
In a majority of practical situations it's only necessary to know what the \par
Gregorian calendar is and that SQL enforces it. A minority of practical cases,\par
however, involve historians or astronomers. For these cases, let's clear out\par
the wrong ideas about the calendar rules and about the Julian-to-Gregorian transition.\par
\par
The Julian calendar took effect starting January 1, 45 BC. (It is a nice\par
coincidence that January 1 was the year-start in 45 BC and in our time; we\par
ignore the variations that happened between then and now.) There was some\par
confusion and fiddling until 4 AD (which was not a leap year) but after that,\par
the first two rules held firmly: a leap year every 4 years, with the average\par
"Julian year" being 365.25000 days long. (We now consider that the correct\par
period for a year is 365.24220 days, decreasing by about 0.5 seconds per\par
century. The difference, 000.00780 days, is statable as 3 days every 400 years.)\par
\par
The result of this, though, meant that by the 1500s, the spring equinox was on\par
March 11th. This violated Church teaching, particularly the finding of the\par
4th-century Council of Nicaea, which made clear that the spring equinox is\par
March 21st. To solve the problem, Pope Gregory XIII had to do two things:\par
shift the calendar forward 10 days and change the rules, so that there would\par
no longer be an overestimate of 3 days every 400 years. He therefore decreed\par
that the day after Thursday, October 4th, 1582 should be Friday, October 15th,\par
1582. The decree took effect immediately in the Papal States and Iberia, after\par
a short delay in France, by 1700 in most German Protestant states and\par
Scandinavia (though Sweden went back and forth). England held out until 1752\par
(by which time the discrepancy was 11 days, from September 3rd to September\par
14th). Japan went Gregorian in 1873, with the proviso that Year #1 is based on\par
the Emperor's reign rather than Christ's birth. China changed in 1911, Russia\par
in 1918 and Greece in 1923. Even among Moslem countries, the only\par
non-fully-gregorianized significant holdout, there has been a breakaway: Turkey, in 1927.\par
\par
As we said earlier, the switch to the Gregorian calendar doesn't affect most\par
of us -- but it has caused some problems for groups like historians and\par
astronomers who use SQL.\par
\par
The first problem is that SQL allows dates like DATE '1582-10-14' -- even\par
though, according to Pope Gregory, there was no such date. Also, any Gregorian\par
date before October 3rd, 1582 is what the Oxford Concise Dictionary calls\par
"Prolepsis: ... representation of thing as existing before it actually does or\par
did so". (When Americans observed Washington's birthday on February 22nd, they\par
were proleptic: he was born on February 11 OS, where the initials "OS" stand\par
for "Old Style" i.e. Julian.) Going the other way, into the future, there will\par
certainly have to be more tweaking, since the Pope's rules do not remove all drift.\par
\par
The second problem is that, although it serves many purposes well, the\par
Gregorian calendar is inevitably non-decimal. It would be simpler to begin\par
with a fixed moment far in the past -- noon on January 1st, 4713 BC for\par
example -- and count how many million days have elapsed since then, with no\par
regard for higher units or any calendar rules. This is the system of "Julian\par
days". Since a Julian day is expressible as a DECIMAL, there is no need for a\par
separate data type for such values. Some ephemerides tables use Julian days,\par
so if your project involves astronomy look for a DBMS that can convert a\par
Julian day to a (proleptic Gregorian) DATE. Standard SQL DBMSs can't because\par
they may only allow for dates starting with 0001 AD.\par
\par
Leap Seconds:\par
The earth's revolutions are getting shorter: it goes round the sun about 0.5\par
seconds faster than it did in 1900. We point this out for the sake of people\par
who define "1 year" as "1 earth revolution period" -- that kind of year is\par
getting shorter, but the other kind, the "civil year", isn't. Here's why.\par
\par
The earth's rotations are getting longer: it turns on its axis about 0.04\par
seconds slower than it did in 1900. A bit of the slowdown is due to tidal\par
friction but mostly we're looking at an irregular and unpredictable\par
fluctuation -- indeed, for all we know, the rotation may get faster in future.\par
We point this out for the sake of people who define "1 day" as "the average\par
period between two sunrises" which is closely linked to the earth's rotation\par
period. You can keep that definition, but you should see that such a shifty\par
period cannot be the standard in a precise measurement system.\par
\par
The resonance of a cesium-133 atom is getting neither shorter nor longer. Its\par
electrons change spin (relative to the nucleus) at a constant frequency. So\par
the International System of Units bases its definition of a "second" on a\par
cesium clock, thus: "the duration of 9,192,631,770 periods of the radiation\par
corresponding to [the shift between parallel and anti-parallel electron spin]\par
of the caesium-133 atom". The official second is this atomic second, and since\par
1972 we have defined a day as 60*60*24 atomic seconds.\par
\par
At one instant, the standard day was the same as the\par
day-derived-from-rotation. But since the latter fluctuates, the two figures\par
won't stay in synch. Yet we must synch them, else the number of days in a year\par
would change fractionally with each revolution. The solution is: when the\par
atomic-second time gains/loses relative to the from-rotation time, add/drop 1\par
or 2 seconds in the last second of the last day of a month. In practice it has\par
always been necessary to add, and the change has always been on June 30th or\par
December 31st. Since we are adding to the year, the term "leap second" is good\par
by analogy.\par
\par
The day-derived-from-rotation time is known as "Universal Time 1" (UT1);\par
corrected for polar wobble, it is used for celestial navigation. The\par
day-based-purely-on-atomic-clock time is known as "International Atomic Time"\par
(TAI); it represents the consensus of several cesium clocks as monitored by a\par
standards bureau in France. The atomic-but-synched-with-UT1-by-leap-seconds\par
time is "Co-ordinated Universal Time" (UTC). It is this last time -- UTC --\par
which matters for time signals, for SQL and for us. Do not confuse UTC with\par
the old standard "Greenwich Mean Time" (GMT); GMT was a variant of UT1 that\par
used a different method to correct for fluctuations. Beware of two prevalent\par
but false opinions: that years are not getting longer (they are), or that UTC\par
is a renaming of GMT (it is not). The distinctions are tiny, but any program\par
which uses leap seconds or fractional seconds is getting into magnitudes which\par
are smaller than those tiny distinctions.\par
\par
Knowing what leap seconds are, we can move at last to their use in SQL:\par
   ## First, the Standard requires a DBMS to extend the range of \par
seconds-field values to "less than 62" (rather than "less than 60") and thus\par
account for up to 2 positive leap seconds. (There is a GOTCHA here: leap\par
seconds should always be for the last minute of a day, as in TIME '23:59:60',\par
but the Standard allows erroneous values like TIME '12:34:60'.)\par
   ## Second, because of leap seconds, it isn't possible to tell whether TIME\par
'23:59:58' is two seconds before midnight, one second before midnight (leap\par
seconds can be negative, though it has never happened) or as much as four\par
seconds before midnight -- the information is simply not present in the syntax\par
of a TIME expression, nor derivable from any Table. Thus, arithmetic with\par
carrying has uncertainty. Not surprisingly, the SQL Standard states that any\par
expressions which involve leap-seconded TIMEs will show implementation-defined results.\par
\par
Time Zones:\par
In 330 BC, a lunar eclipse was seen at Arbela around 3 AM and in Carthage\par
around midnight. The ancient Greeks knew how eclipses worked so this was one\par
proof that the earth is round (their other proofs were that the sun gets\par
higher in the sky as we travel south and that we can still see ships' masts\par
after their hulls disappear below the horizon). In our terms, Aristotle and\par
Company were seeing that our anchor point of midnight -- the halfway point\par
between dusk and dawn -- must change with longitude.\par
\par
Nowadays, we mark the world off into time zones, with one time zone equal to\par
about 15 degrees of longitude. Time zones are political divisions that allow\par
us to use the convention that all locations in a time zone have the same time,\par
known as local time. Thus, although times and timestamps are supposed to\par
represent an absolute time of day (times) and an absolute time of a specific\par
day (timestamps), they can have ambiguous meanings when an SQL-environment\par
spans multiple time zones. The SQL Standard tries to cater both to users who\par
have only local dealings and thus care only about local time, and to users who\par
operate across time zones. It does this by providing a <time zone interval>\par
option for time and timestamp values: a value without a <time zone interval>\par
(e.g.: a TIME or TIMESTAMP <data type>) may represent local time or UTC time,\par
while a value with a <time zone interval> (e.g.: a TIME WITH TIME ZONE or\par
TIMESTAMP WITH TIME ZONE <data type>) always represents the UTC time. Unless\par
your SQL-environment spans multiple time zones and you have a need for "real\par
time" database operations, the entire matter of time zones probably won't\par
concern you. In that case, be sure to define your time and timestamp fields\par
with the TIME and TIMESTAMP <data type>s; don't use the TIME WITH TIME ZONE or\par
the TIMESTAMP WITH TIME ZONE <data type>s at all. If, however, "real time"\par
operations are vital, you may want to define time and timestamp fields with\par
the TIME WITH TIME ZONE and TIMESTAMP WITH TIME ZONE <data type>s.\par
\par
## <time zone interval>\par
The required syntax for a <time zone interval> is:\par
\par
<time zone interval> ::=\par
\{+ | -\} HH:MM\par
\par
A <time zone interval> specifies a time or timestamp value's time zone offset\par
from UTC. It has a <data type> of INTERVAL HOUR TO MINUTE.\par
      ## "HH" is 2 digits (ranging from 0 to 13) representing the number of\par
hours (called TIMEZONE_HOURs) in the time zone offset and "MM" is 2 digits\par
(ranging from 0 to 59) representing the number of additional minutes (called\par
TIMEZONE_MINUTEs) in the time zone offset. For example, this represents a\par
<time zone interval> of 3 hours:\par
\par
   +3:00\par
\par
A <time zone interval>'s mandatory sign -- either "+" (plus) or "-" (minus) --\par
indicates whether the time zone offset is added to, or subtracted from, the\par
UTC time to obtain the local time. The valid range of <time zone interval>s is\par
from -12:59 to +13:00. Any operation that attempts to specify a <time zone\par
interval> that is not within this range will fail: your DBMS will return the\par
SQLSTATE error 22009 "data exception-invalid time zone displacement value".\par
\par
A time or timestamp value that doesn't include a <time zone interval>\par
represents a time in the SQL-session's current default time zone, that is, it\par
represents a local time. A time or timestamp value that does include a <time\par
zone interval> represents a time in the specified time zone.\par
\par
If you want to restrict your code to Core SQL, don't use <time zone interval>s.\par
\par
## Time Zone Example\par
Time zones start at zero longitude (the Prime Meridian), which goes through\par
Greenwich, Britain. The time zones West Of Greenwich ("Wogs") are behind UTC\par
because the earth rotates from west to east. Therefore, when it's 12:00 UTC\par
it's only 8:30 AM in Newfoundland, and even earlier as we go west from there.\par
The time zones East Of Greenwich ("Eogs") are ahead of UTC, so when it's 12:00\par
UTC it's already 5:30 PM in Dehli, India, and even later as we go east from\par
there. Consider this timeline:\par
\par
+8:00       +5:00     +0:00       -2:00    -5:30\par
Vancouver   Detroit   Greenwich   Moscow   Dehli\par
\par
The numbers on the timeline indicate the time zones' offsets from UTC, in\par
hours and minutes. (The math is somewhat counterintuitive, since the SQL\par
Standard requires you to subtract the offset from the local time to calculate\par
UTC.) A time zone's offset from UTC is its <time zone interval>.\par
\par
As an example, consider an SQL-environment with three installations: one in\par
Vancouver, Canada (with a default time zone offset of +8:00), one in London,\par
England (with a default time zone offset of +0:00) and one in Delhi, India\par
(with a default time zone offset of -5:30). All three installations have\par
access to this Table:\par
\par
   CREATE TABLE Time_Examples (\par
      Time_Local TIMESTAMP,\par
      Time_With_Time_Zone TIMESTAMP WITH TIME ZONE);\par
\par
A user at the London installation adds this row to the Table:\par
\par
   INSERT INTO Time_Examples (Time_Local, Time_With_Time_Zone)\par
   VALUES (TIMESTAMP '1995-07-15 07:30', TIMESTAMP '1995-07-15 07:30');\par
\par
Now, to a user at the Vancouver installation, this moment in time is\par
equivalent to a local timestamp of '1995-07-14 23:30' (Vancouver time is 8\par
hours earlier than London time) and to a user at the Delhi installation, the\par
same moment in time is equivalent to a local timestamp of '1995-07-15 13:00'\par
(Delhi time is 5.5 hours after London time). So, despite the fact that\par
"1995-07-15 07:30", "1995-07-14 23:30" and "1995-07-15 13:00" look like three\par
different values, in this case they all, in fact, represent the same absolute\par
moment in time. If each user now does a SELECT on the Table, this is the\par
result they'll see:\par
\par
TIME_LOCAL           TIME_WITH_TIME_ZONE\par
1995-07-15 07:30:00  1995-07-14 23:30:30-8:00  -- in Vancouver\par
1995-07-15 07:30:00  1995-07-15 07:30:00+0:00  -- in London\par
1995-07-15 07:30:00  1995-07-15 13:00:00+5:30  -- in Dehli\par
\par
Note that the value in the TIME_LOCAL Column stays the same regardless of the\par
installation: a time or timestamp without a <time zone interval> always means\par
"local time" unless the application requires it to take on a time zone offset.\par
The value in the TIME_WITH_TIME_ZONE Column, however, changes with the\par
installation -- this is because the <timestamp literal> was forced to take on\par
the default time zone offset at each installation. In this example, the UTC\par
time is equal to the London local time of '1995-07-15 07:30' -- i.e.: when the\par
London user selects from the Table, the display shows:\par
\par
   '1995-07-15 07:30+00:00' \par
\par
to show that the local time is the same as the UTC time; that is, it must be\par
offset by 0 hours and 0 minutes to a UTC time of:\par
\par
   '1995-07-15 07:30' \par
\par
When the Vancouver user does the same SELECT, however, the display shows:\par
\par
   '1995-07-14 23:30-08:00' \par
\par
to show that the local time is 8 hours less than the UTC time; that is, it\par
must be offset by 8 hours and 0 minutes to a UTC time of:\par
\par
   '1995-07-15 07:30' \par
\par
And when the Delhi user does the same SELECT, the display shows:\par
\par
   '1995-07-15 13:00+05:30' \par
\par
to show that the local time is 5.5 hours greater than the UTC time; that is,\par
it must be offset -5 hours and 30 minutes to a UTC time of:\par
\par
   '1995-07-15 07:30' \par
\par
## Time Zone Offset Arithmetic\par
Earlier we said that time zone offset arithmetic is somewhat counterintuitive\par
-- here's a more detailed explanation. Recall that a time zone offset is the\par
difference between local time and UTC time -- say, for example, 4 hours. Then:\par
   ## In the case of a time zone that is 4 hours earlier than UTC (e.g.: 12:00\par
local is 16:00 UTC), the time zone offset is -04:00 (i.e.: local time is 4\par
hours less than UTC time).\par
   ## In the case of a time zone that is 4 hours later than UTC (e.g.: 16:00\par
UTC is 20:00 local), the time zone offset is +04:00 (i.e.: local time is 4\par
hours plus UTC time).\par
\par
The rule is: to get the UTC value, subtract the time zone offset from the time\par
or timestamp. Thus, a local time of '12:00-04:00' evaluates to UTC 16:00 (add\par
the 4 hours, you're subtracting a negative) and a local time of '20:00+04:00'\par
evaluates to UTC 16:00 (subtract the 4 hours). \par
\par
Temporal <literal>s\par
\par
A temporal <literal> is any temporal value in one of two categories: datetimes\par
and intervals.\par
\par
Datetime <literal>s:\par
A datetime <literal> is either a <date literal>, a <time literal> or a\par
<timestamp literal>. Datetime <literal>s are constrained by the natural rules\par
for dates and times according to the Gregorian calendar.\par
\par
## <date literal>\par
A <date literal> represents a date in the Gregorian calendar. The required syntax for a <date literal> is: \par
\par
<date literal> ::= \par
DATE 'yyyy-mm-dd'\par
\par
"yyyy" is 4 digits (ranging from 1 to 9999) representing a YEAR, "mm" is 2\par
digits (ranging from 1 to 12) representing a MONTH in the specified year and\par
"dd" is 2 digits (ranging from 1 to 31, depending on the month) representing a\par
DAY of the specified month. For example, this <date literal> represents "July\par
15, 1997":\par
\par
   DATE '1997-07-15'\par
\par
The valid range of dates is from DATE '0001-01-01' (January 1, 1 AD) to DATE\par
'9999-12-31' (December 31, 9999 AD).\par
\par
A <date literal>'s <data type> is DATE.\par
\par
## <time literal>\par
A <time literal> represents a time of day. The required syntax for a <time literal> is: \par
\par
<time literal> ::= \par
TIME 'hh:mm:ss[.[nnnnnn]][ <time zone interval> ]'\par
\par
"hh" is 2 digits (ranging from 0 to 23) representing an HOUR on a 24 hour\par
clock, "mm" is 2 digits (ranging from 0 to 59) representing a MINUTE within\par
the specified hour and "ss" is 2 digits (ranging from 0 to 61) representing a\par
SECOND within the specified minute (SQL allows for the addition of up to 2\par
"leap" seconds in a valid time). For example, this <time literal> represents\par
"1:35:16 PM":\par
\par
   TIME '13:35:16'\par
\par
The optional ".nnnnnn", if specified, is a period followed by an unsigned\par
integer and represents a fraction of a second within the specified second:\par
this is the time value's fractional seconds precision. The minimum fractional\par
seconds precision and the default fractional seconds precision are both zero.\par
For example, these three <time literal>s all represent "1:35:16 PM":\par
\par
   TIME '13:35:16'\par
\par
   TIME '13:35:16.'\par
\par
   TIME '13:35:16.00'\par
\par
This <time literal> represents "1:35:16 and one-hundredth of a second PM":\par
\par
   TIME '13:35:16.01'\par
\par
[NON-PORTABLE] The valid range of times must include, at a minimum, all times\par
from TIME '00:00:00' to TIME '23:59:61.999999' but is non-standard because the\par
SQL Standard requires implementors to define the maximum fractional seconds\par
precision for time values.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
<time literal>s to have a fractional seconds precision up to 6 digits long.\par
This allows you to deal with times ranging from whole seconds to millionths of\par
a second.\par
\par
[Obscure Rule] A <time literal> may include a <time zone interval> to specify\par
the value's time zone offset. A <time literal> without a <time zone interval>\par
represents a time in the SQL-session's current default time zone, that is, it\par
represents a local time. A <time literal> that includes a <time zone interval>\par
represents a time in the specified time zone. For example, this <time literal>\par
represents "12:35 and 16.5 seconds AM" with a time zone offset of 3 hours and\par
15 minutes (UTC '09:20:16.5):\par
\par
   TIME '12:35:16.5+03:15'\par
\par
This <time literal> represents the local time "12:35 and 16.5 seconds AM":\par
    \par
   TIME '12:35:16.5'\par
\par
A <time literal> without a <time zone interval> has a <data type> of\par
TIME(fractional seconds precision), though it is compatible with the TIME and\par
TIME WITH TIME ZONE <data type>s. For example, this <literal>:\par
\par
   TIME '13:35:16'\par
\par
has a <data type> of TIME and this <literal>:\par
\par
   TIME '13:35:16.01'\par
\par
has a <data type> of TIME(2).\par
\par
[Obscure Rule] A <time literal> with a <time zone interval> has a <data type>\par
of TIME(fractional seconds precision) WITH TIME ZONE, though it is compatible\par
with the TIME and TIME WITH TIME ZONE <data type>s. For example, this <literal>:\par
\par
   TIME '13:35:16.5+10:30'\par
\par
has a <data type> of TIME(1) WITH TIME ZONE.\par
\par
If you want to restrict your code to Core SQL, don't add a fractional seconds\par
precision or a <time zone interval> to your time values.\par
\par
## <timestamp literal>\par
A <timestamp literal> represents a time of a given day. The required syntax for a <timestamp literal> is:\par
\par
<timestamp literal> ::=\par
TIMESTAMP 'date value <space> time value'\par
\par
that is:\par
\par
TIMESTAMP 'yyyy-mm-dd hh:mm:ss[.[nnnnnn]][ <time zone interval> ]'\par
\par
As with dates, "yyyy" is 4 digits representing a YEAR, "mm" is 2 digits\par
representing a MONTH in the specified year, "dd" is 2 digits representing a\par
DAY of the specified month and, as with times, "hh" is 2 digits representing\par
an HOUR on within the specified day, "mm" is 2 digits representing a MINUTE\par
within the specified hour, "ss" is 2 digits representing a SECOND within the\par
specified minute and the optional ".nnnnnn" represents a fraction of a second\par
within the specified second. For example, this <timestamp literal> represents\par
"1:35:16 PM on July 15, 1997":\par
\par
   TIMESTAMP '1997-07-15 13:35:16'\par
\par
This <timestamp literal> represents "1:35:16 and one-hundredth of a second PM\par
on July 15, 1997":\par
\par
   TIMESTAMP      '1997-07-15 13:35:16.01'\par
\par
[NON-PORTABLE] The valid range of timestamps must include, at a minimum, all\par
timestamps from TIMESTAMP '0001-01-01 00:00:00' to TIMESTAMP '9999-12-31\par
23:59:61.999999' but is non-standard because the SQL Standard requires\par
implementors to define the maximum fractional seconds precision for timestamp values.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
<timestamp literal>s to have a fractional seconds precision up to 6 digits\par
long. This allows you to deal with timestamps whose time values range from\par
whole seconds to millionths of a second.\par
\par
[Obscure Rule] A <timestamp literal> may include a <time zone interval>. As\par
with times, a <timestamp literal> without a <time zone interval> represents a\par
local timestamp, while a <timestamp literal> that includes a <time zone\par
interval> represents a timestamp in the specified time zone. A <timestamp\par
literal> without a <time zone interval> has a <data type> of\par
TIMESTAMP(fractional seconds precision), though it is compatible with the\par
TIMESTAMP and TIMESTAMP WITH TIME ZONE <data type>s. For example, this <literal>:\par
\par
   TIMESTAMP '1997-07-15 13:35:16'\par
\par
has a <data type> of TIMESTAMP and this <literal>:\par
\par
   TIMESTAMP '1997-07-15 13:35:16.01'\par
\par
has a <data type> of TIMESTAMP(2).\par
\par
[Obscure Rule] A <timestamp literal> with a <time zone interval> has a <data\par
type> of TIMESTAMP(fractional seconds precision) WITH TIME ZONE, though it is\par
compatible with the TIMESTAMP and TIMESTAMP WITH TIME ZONE <data type>s. For example, this <literal>:\par
\par
   TIMESTAMP '1997-07-15 13:35:16.5+10:30'\par
\par
has a <data type> of TIMESTAMP(1) WITH TIME ZONE.\par
\par
If you want to restrict your code to Core SQL, don't add a fractional seconds\par
precision greater than 6 digits or a <time zone interval> to your timestamp values.\par
\par
Interval <literal>s:\par
An <interval literal> is either a <year-month interval literal> or a <day-time\par
interval literal>. The type of interval is determined by the <interval\par
qualifier> that is part of the <interval literal>.\par
\par
## <interval qualifier>:\par
An <interval qualifier> defines the type (or precision) of an interval. The\par
required syntax for an <interval qualifier> is: \par
\par
<interval qualifier> ::= \par
start_datetime [ TO end_datetime ]\par
\par
   start_datetime ::= \par
   YEAR [ (leading precision) ] | \par
   MONTH [ (leading precision) ] | \par
   DAY [ (leading precision) ] | \par
   HOUR [ (leading precision) ] | \par
   MINUTE [ (leading precision) ] | \par
   SECOND [ (leading precision [ ,fractional seconds precision ]) ]\par
\par
end_datetime ::=\par
   YEAR | \par
   MONTH | \par
   DAY | \par
   HOUR | \par
   MINUTE | \par
   SECOND [ (fractional seconds precision) ])\par
\par
Both "start_datetime" and "end_datetime" may be either: YEAR, MONTH, DAY,\par
HOUR, MINUTE or SECOND, providing that "start_datetime" is not less\par
significant than "end_datetime". If "start_datetime" is YEAR, then\par
"end_datetime" must either be YEAR, MONTH or it must be omitted. If\par
"start_datetime" is MONTH, then "end_datetime" must be omitted. If\par
"start_datetime" is SECOND, then "end_datetime must either be SECOND with a\par
fractional seconds precision less than "start_datetime"'s fractional seconds\par
precision or it must be omitted.\par
\par
The optional "start_datetime" leading precision, if specified, is an unsigned\par
integer that defines the maximum number of digits allowed in the\par
"start_datetime" value. For example, this "start_datetime":\par
\par
   MONTH(1)\par
\par
means that the month value may range from 0 to 9 months (up to 1 digit). The\par
minimum "start_datetime" precision is 1. The default "start_datetime"\par
precision is 2. For example, these two <interval qualifier>s both describe an\par
interval that may contain from 0 to 99 seconds:\par
\par
   SECOND\par
\par
   SECOND(2) \par
\par
[NON-PORTABLE] The maximum "start_datetime" leading precision may not be less\par
than 2 digits but is non-standard because the SQL Standard requires\par
implementors to define an <interval qualifier>'s maximum leading precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the leading precision of YEAR to range from 1 to 4 digits and allows the\par
leading precision of MONTH, DAY, HOUR, MINUTE and SECOND to range from 0 to 2 digits.\par
\par
An <interval qualifier>'s "start_datetime" has a precision as specified. All\par
other datetime fields in the interval, except for SECOND, have an implied\par
precision of 2 digits. The implied precision for SECOND is 2 digits before the\par
decimal point and a number of digits equal to the fractional seconds precision\par
after the decimal point. The optional fractional seconds precision for a\par
"start_datetime" or an "end_datetime" of SECOND, if specified, is an unsigned\par
integer that defines the number of digits in the SECOND value's fractional\par
seconds portion. For example, this "start_datetime":\par
\par
   SECOND(2,3)\par
\par
means that the seconds value may range from 0 to 99.999 seconds (up to 2\par
digits for the seconds value, followed by up to 3 digits for the fractional\par
seconds value). This "end_datetime":\par
\par
   TO SECOND(3)\par
\par
also means that the seconds value may range from 0 to 99.999 seconds. (Note\par
that "end_datetime" may never have an explicit leading precision, even for\par
SECOND.) The minimum fractional seconds precision is 0. The default fractional\par
seconds precision is 6. For example, these two "start_datetime"s both describe\par
an interval that may contain from 0 to 99 seconds:\par
\par
   SECOND(2)\par
\par
   SECOND(2,0)\par
\par
These two "start_datetime"s both describe an interval that may contain from 0\par
to 99.999999 seconds:\par
\par
   SECOND\par
\par
   SECOND(2,6)\par
\par
This "end_datetime" describes an interval that may contain from 0 to 99 seconds:\par
\par
   TO SECOND(0)\par
\par
And these two "end_datetime"s both describe an interval that may contain from 0 to 99.999999 seconds:\par
\par
   TO SECOND\par
\par
   TO SECOND(6)\par
\par
[NON-PORTABLE] The maximum fractional seconds precision for an <interval\par
qualifier>'s "start_datetime" or "end_datetime" of SECOND may not be less than\par
6 digits but is non-standard because the SQL Standard requires implementors to\par
define an <interval qualifier>'s maximum fractional seconds precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the fractional seconds precision of SECOND to range from 0 to 6 digits.\par
\par
[Obscure Rule] Of two "start_datetime"s that are the same except for their\par
leading precision, the one with the higher precision is treated as more\par
significant. Of two "end_datetime" values with a <data type> of SECOND that\par
are the same except for their fractional seconds precision, the one with the\par
larger fractional seconds precision is treated as more significant. This may\par
become relevant during assignments, comparisons and type conversions.\par
\par
This <interval qualifier> means that the YEAR value for the interval may be\par
any 3 digit number, i.e.: the YEAR value may range from 0 to 999 years:\par
\par
   YEAR(3)\par
\par
Other examples of <interval qualifier>s include:\par
\par
YEAR               -- YEAR may range from 0 to 99 \par
YEAR(4) TO MONTH   -- YEAR may range from 0 to 9999, \par
                      MONTH may range from 0 to 99 \par
SECOND             -- SECOND may range from 0 to 99 \par
SECOND(1)          -- SECOND may range from 0 to 9 \par
SECOND(1,3)        -- SECOND may range from 0.000 to 9.999 \par
HOUR TO SECOND     -- HOUR may range from 0 to 99, \par
                      SECOND may range from 0.000000 to 99.999999\par
HOUR TO SECOND(3)  -- HOUR may range from 0 to 99, \par
                      SECOND may range from 0.000 to 99.999\par
\par
If you want to restrict your code to Core SQL, don't use <interval qualifier>s.\par
\par
## <interval literal>\par
An <interval literal> represents a span of time and is either a <year-month\par
literal> or a <day-time literal>.\par
\par
<year-month literal> --\par
The required syntax for a <year-month literal> is: \par
\par
<year-month literal> ::= \par
INTERVAL [ \{+ | -\} ]'yy' <interval qualifier> | \par
INTERVAL [ \{+ | -\} ]'[ yy- ] mm' <interval qualifier>\par
\par
A <year-month literal> includes either YEAR, MONTH or both. It may not include\par
the datetime fields DAY, HOUR, MINUTE or SECOND. Its <data type> is INTERVAL\par
with a matching <interval qualifier>.\par
\par
The optional sign specifies whether this is a positive interval or a negative\par
interval. If you omit the sign, it defaults to + -- a positive interval. A\par
negative <interval literal> can be written in one of two ways. For example,\par
for the interval "minus (5 years 5 months)", you could write either:\par
\par
   INTERVAL -'05-05' YEAR TO MONTH\par
\par
or \par
\par
   INTERVAL '-05-05' YEAR TO MONTH\par
\par
that is, the minus sign can be either outside or inside the interval string.\par
(In fact it can even be both, e.g.:\par
\par
   -'-05-05' YEAR TO MONTH\par
\par
which is a double negative and therefore a positive interval: "plus (5 years 5\par
months)".)\par
\par
** TIP: Use the second form. If you're going to be passing intervals as\par
parameters, get used to the idea that the sign can be part of the string.\par
\par
"yy" is 1 or more digits representing a number of YEARs and "mm" is 1 or more\par
digits representing a number of MONTHs. There are three types of <year-month\par
literal>s. For ease of reading, the following examples mostly exclude the use\par
of explicit leading precisions.\par
\par
This <year-month literal> has a <data type> of INTERVAL YEAR and represents a\par
time span of four years:\par
\par
   INTERVAL '4' YEAR\par
\par
These two <year-month literal>s have a <data type> of INTERVAL MONTH and both\par
represent a negative time span of fifty months:\par
\par
   INTERVAL -'50' MONTH\par
\par
   INTERVAL '-50' MONTH\par
\par
(Note the sign, which may be written outside the single quotes delimiting the\par
month value or within the quotes.)\par
\par
This <year-month literal> has a <data type> of INTERVAL YEAR TO MONTH and\par
represents a time span of four hundred years and 6 months:\par
\par
   INTERVAL '400-03' YEAR(3) TO MONTH\par
\par
(Note the minus sign between the year value and the month value.)\par
\par
<day-time literal> --\par
The required syntax for a <day-time literal> is: \par
\par
<day-time literal> ::= \par
INTERVAL [ \{+ | -\} ]'dd [ <space>hh [ :mm [ :ss ]]]' <interval qualifier>\par
INTERVAL [ \{+ | -\} ]'hh [ :mm [ :ss [ .nn ]]]' <interval qualifier>\par
INTERVAL [ \{+ | -\} ]'mm [ :ss [ .nn ]]' <interval qualifier>\par
INTERVAL [ \{+ | -\} ]'ss [ .nn ]' <interval qualifier>\par
\par
A <day-time literal> includes either DAY, HOUR, MINUTE, SECOND or some\par
contiguous subset of these fields. It may not include the datetime fields YEAR\par
or MONTH. Its <data type> is INTERVAL with a matching <interval qualifier>.\par
\par
The optional sign specifies whether this is a positive interval or a negative\par
interval. If you omit the sign, it defaults to + -- a positive interval.  If\par
you omit the sign, it defaults to + -- a positive interval. A negative\par
<interval literal> can be written with the sign inside or outside the string;\par
see "<year-month literal>".\par
\par
"dd" is 1 or more digits representing a number of DAYs, "hh" is 1 or more\par
digits representing a number of HOURs, "mm" is 1 or more digits representing a\par
number of MINUTEs, "ss" is 1 or more digits representing a number of SECONDs\par
and ".nn" is 1 or more digits representing a number of fractions of a SECOND.\par
There are ten types of <day-time literal>s. For ease of reading, the following\par
examples mostly exclude the use of explicit leading precisions and fractional\par
seconds precisions.\par
\par
This <day-time literal> has a <data type> of INTERVAL DAY and represents a\par
time span of 94 days:\par
\par
   INTERVAL '94' DAY\par
\par
This <day-time literal> has a <data type> of INTERVAL HOUR and represents a\par
time span of 35 hours:\par
\par
   INTERVAL '35' HOUR(2)\par
\par
This <day-time literal> has a <data type> of INTERVAL MINUTE and represents a\par
time span of 20 minutes:\par
\par
   INTERVAL '20' MINUTE\par
\par
This <day-time literal> has a <data type> of INTERVAL SECOND and represents a\par
time span of 77 seconds (or 77.000000 seconds):\par
\par
   INTERVAL '77' SECOND(0)\par
\par
This <day-time literal> has a <data type> of INTERVAL SECOND and represents a\par
time span of 142.999 seconds:\par
\par
   INTERVAL '142.999' SECOND(3,3)\par
\par
This <day-time literal> has a <data type> of INTERVAL DAY TO HOUR and\par
represents a time span of forty days and 23 hours:\par
\par
   INTERVAL '40 23' DAY(2) TO HOUR\par
\par
(Note the space between the day value and the hour value.)\par
\par
This <day-time literal> has a <data type> of INTERVAL DAY TO MINUTE and\par
represents a time span of 45 days, 23 hours and 16 minutes:\par
\par
   INTERVAL '45 23:16' DAY TO MINUTE\par
\par
(Note the colon between the hour value and the minute value.)\par
\par
This <day-time literal> has a <data type> of INTERVAL DAY TO SECOND and\par
represents a time span of 45 days, 23 hours, 16 minutes and 15 seconds:\par
\par
   INTERVAL '45 23:16:15' DAY TO SECOND(0)\par
\par
(Note the colon between the minute value and the second value.)\par
\par
This <day-time literal> has a <data type> of INTERVAL DAY TO SECOND and\par
represents a time span of 45 days, 23 hours, 16 minutes and 15.25 seconds:\par
\par
   INTERVAL '45 23:16:15.25' DAY TO SECOND(2)\par
\par
(Note the decimal point between the second value and the fractional second value.)\par
\par
This <day-time literal> has a <data type> of INTERVAL HOUR TO MINUTE and\par
represents a time span of 23 hours and 16 minutes:\par
\par
   INTERVAL '23:16' HOUR TO MINUTE\par
\par
This <day-time literal> has a <data type> of INTERVAL HOUR TO SECOND and\par
represents a time span of 23 hours, 16 minutes and 15.25 seconds:\par
\par
   INTERVAL '23:16:15.25' HOUR TO SECOND(2)\par
\par
This <day-time literal> has a <data type> of INTERVAL MINUTE TO SECOND and\par
represents a time span of 16 minutes and 15.25 seconds:\par
\par
   INTERVAL '16:15.25' MINUTE TO SECOND(2)\par
\par
If you want to restrict your code to Core SQL, don't use <interval literal>s.\par
\par
Temporal <data type>s\par
\par
A temporal <data type> is either a datetime <data type> or an interval <data type>.\par
\par
Datetime <data type>s:\par
A datetime <data type> is defined by a descriptor that contains two pieces of information:\par
      ## The <data type>'s name: either DATE, TIME, TIME WITH TIME ZONE,\par
TIMESTAMP or TIMESTAMP WITH TIME ZONE.\par
      ## The <data type>s fractional seconds precision (for TIME, TIME WITH\par
TIME ZONE, TIMESTAMP and TIMESTAMP WITH TIME ZONE types).\par
\par
## DATE\par
The required syntax for a DATE <data type> specification is:\par
\par
DATE <data type> ::=\par
DATE\par
\par
DATE combines the datetime fields YEAR, MONTH and DAY; it defines a set of\par
correctly formed values that represent any valid Gregorian calendar date\par
between '0001-01-01' and '9999-12-31' (i.e.: between January 1, 1 AD and\par
December 31, 9999 AD). It has a length of 10 SQL_TEXT characters.\par
\par
DATE expects dates to have the following form:\par
   \par
   yyyy-mm-dd \par
\par
e.g.: this date represents "July 15, 1994":\par
\par
   1994-07-15 \par
\par
Any operation that attempts to make a DATE <data type> contain a YEAR value\par
that is either less than 1 or greater than 9999 will fail: the DBMS will\par
return the SQLSTATE error 22007 "data exception-invalid datetime format".\par
\par
Here is an example of DATE:\par
\par
   CREATE TABLE date_table_1 ( \par
      start_date DATE); \par
\par
   INSERT INTO date_table_1 (start_date) \par
   VALUES (DATE '1996-01-01');\par
\par
## TIME\par
The required syntax for a TIME <data type> specification is:\par
\par
TIME <data type> ::=\par
TIME [ (fractional seconds precision) ] [ WITHOUT TIME ZONE ]\par
\par
TIME (or TIME WITHOUT TIME ZONE) combines the datetime fields HOUR, MINUTE and\par
SECOND; it defines a set of correctly formed values that represent any valid\par
time of day (based on a 24 hour clock) between '00:00:00' and (at a minimum)\par
'23:59:61.999999'. (The SQL Standard requires DBMSs to allow for the addition\par
of up to 2 "leap" seconds in a valid time.) It has a length of at least 8\par
SQL_TEXT characters.\par
\par
The optional fractional seconds precision, if specified, is an unsigned\par
integer that specifies the number of digits following the decimal point in the\par
SECOND datetime field. The minimum fractional seconds precision and the\par
default fractional seconds precision are both zero. For example, these two\par
<data type> specifications both define a set of times with a fractional\par
seconds precision of zero digits:\par
\par
   TIME \par
   -- would contain values like 13:30:22\par
\par
   TIME(0) \par
   -- would also contain values like 13:30:22\par
\par
This <data type> specification defines a set of times with a fractional\par
seconds precision of two digits, i.e.: of one-hundredth of a second:\par
\par
   TIME(2) \par
   -- would contain values like 13:30:22.05 \par
\par
NON-PORTABLE] The maximum fractional seconds precision for TIME (a) may not be\par
less than 6 digits and (b) must be equal to the maximum allowed for the TIME\par
WITH TIME ZONE, TIMESTAMP and TIMESTAMP WITH TIME ZONE <data type>s but is\par
non-standard because the SQL Standard requires implementors to define TIME's\par
maximum fractional seconds precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the fractional seconds precision of TIME to range from 0 to 6 digits. \par
\par
TIME expects times to have the following form:\par
\par
   hh:mm:ss[.nnnnnn] \par
\par
e.g.: these two times both represent "half past one, plus 22 seconds, PM": \par
\par
   13:30:22\par
\par
   13:30:22.00\par
\par
and this time represents "half past one, plus 22 and one-tenth seconds, PM":\par
\par
   13:30:22.10\par
\par
The actual length of a TIME depends on the fractional seconds precision. These\par
two <data type> specifications have a length of 8 SQL_TEXT characters:\par
\par
   TIME\par
\par
   TIME(0)\par
\par
This <data type> specification has a length of 10 SQL_TEXT characters:\par
\par
   TIME(1)\par
   -- 8 plus decimal point plus 1 digit in fractional seconds precision \par
\par
This <data type> specification has a length of 15 SQL_TEXT characters:\par
\par
   TIME(6)\par
\par
[Obscure Rule] TIME has a time zone offset equal to the current default time\par
zone offset of the SQL-session: it represents a local time.\par
\par
Here is an example of TIME:\par
\par
   CREATE TABLE time_table_1 ( \par
      start_time_1 TIME,\par
      start_time_2 TIME(2)); \par
\par
   INSERT INTO time_table_1 (start_time_1, start_time_2) \par
   VALUES (TIME '14:14:14', TIME '14:14:14.00'); \par
\par
   INSERT INTO time_table_1 (start_time_1, start_time_2) \par
   VALUES (TIME '15:15:15.', TIME '15:15:15.10'); \par
\par
   INSERT INTO time_table_1 (start_time_1, start_time_2) \par
   VALUES (TIME '16:16:16.00', TIME '16:16:16.05');\par
\par
If you want to restrict your code to Core SQL, don't define your TIME <data\par
type>s with a fractional seconds precision and don't add the optional noise\par
words WITHOUT TIME ZONE: use only TIME, never TIME(x) WITHOUT TIME ZONE.\par
\par
## TIME WITH TIME ZONE\par
[Obscure Rule] applies for this entire section. \par
\par
The required syntax for a TIME WITH TIME ZONE <data type> specification is: \par
\par
TIME WITH TIME ZONE <data type> ::= \par
TIME [ (fractional seconds precision) ] WITH TIME ZONE \par
\par
TIME WITH TIME ZONE combines the datetime fields HOUR, MINUTE, SECOND,\par
TIMEZONE_HOUR and TIMEZONE_MINUTE; it defines a set of correctly formed values\par
that represent any valid time of day (based on a 24 hour clock) between\par
'00:00:00' and (at a minimum) '23:59:61.999999' with a time zone offset that\par
must be between '-12:59' and '+13:00'. (The SQL Standard requires DBMSs to\par
allow for the addition of up to 2 "leap" seconds in a valid time.) It has a\par
length of at least 14 SQL_TEXT characters.\par
\par
As with TIME, the optional fractional seconds precision for TIME WITH TIME\par
ZONE specifies the number of digits following the decimal point in the SECOND\par
datetime field. The minimum fractional seconds precision and the default\par
fractional seconds precision are both zero.\par
\par
[NON-PORTABLE] The maximum fractional seconds precision for TIME WITH TIME\par
ZONE (a) may not be less than 6 digits and (b) must be equal to the maximum\par
allowed for the TIME, TIMESTAMP and TIMESTAMP WITH TIME ZONE <data type>s but\par
is non-standard because the SQL Standard requires implementors to define TIME\par
WITH TIME ZONE's maximum fractional seconds precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the fractional seconds precision of TIME WITH TIME ZONE to range from 0 to 6 digits.\par
\par
TIME WITH TIME ZONE expects times to have the following form:\par
\par
   hh:mm:ss[.nnnnnn ][\{+|-\}HH:MM ] \par
\par
e.g.: the following time represents "half past one, plus 22 seconds, PM" with a time zone offset of 2 and a half hours:\par
\par
   13:30:22+02:30 \par
\par
The actual length of a TIME WITH TIME ZONE depends on the fractional seconds\par
precision. These two <data type> specifications have a length of 14 SQL_TEXT characters:\par
\par
   TIME WITH TIME ZONE\par
\par
   TIME(0) WITH TIME ZONE\par
\par
This <data type> specification has a length of 16 SQL_TEXT characters:\par
\par
   TIME(1) WITH TIME ZONE\par
   -- 14 plus decimal point plus 1 digit in fractional seconds precision \par
\par
This <data type> specification has a length of 21 SQL_TEXT characters:\par
\par
   TIME(6) WITH TIME ZONE\par
\par
[Obscure Rule] TIME WITH TIME ZONE has a time zone offset equal to the <time\par
zone interval> specified for a given time value: it represents a time in the\par
given time zone. If the <time zone interval> is omitted from a given time\par
value, TIME WITH TIME ZONE has a time zone offset equal to the default time\par
zone offset of the SQL-session: it represents a local time. The default time\par
zone offset is the <time zone interval> specified in the most recent SET TIME\par
ZONE statement issued during the SQL-session. If you haven't issued a SET TIME\par
ZONE statement, the default time zone offset is your DBMS's initial default time zone offset.\par
      ## [NON-PORTABLE] The default time zone offset is non-standard because\par
the SQL Standard requires implementors to define the initial default time zone\par
offset for an SQL-session.\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
sets the SQL-session's initial default time zone offset to INTERVAL +'00:00'\par
HOUR TO MINUTE -- this represents UTC.\par
\par
Here is an example of TIME WITH TIME ZONE:\par
\par
   CREATE TABLE time_table_2 ( \par
      start_time_1 TIME WITH TIME ZONE, \par
      start_time_2 TIME(2) WITH TIME ZONE); \par
\par
   INSERT INTO time_table_2 (start_time_1, start_time_2) \par
   VALUES (TIME '14:14:14+03:00', TIME '14:14:14.00+03:00'); \par
\par
   INSERT INTO time_table_2 (start_time_1, start_time_2) \par
   VALUES (TIME '15:15:15.-03:00', TIME '15:15:15.10-03:00'); \par
\par
   INSERT INTO time_table_2 (start_time_1, start_time_2) \par
   VALUES (TIME '16:16:16.00+03:30', TIME '16:16:16.05+03:30');\par
\par
If you want to restrict your code to Core SQL, don't use TIME WITH TIME ZONE <data type>s.\par
\par
## TIMESTAMP\par
The required syntax for a TIMESTAMP <data type> specification is: \par
\par
TIMESTAMP <data type> ::= \par
TIMESTAMP [ (fractional seconds precision) ][ WITHOUT TIME ZONE ]\par
\par
TIMESTAMP (or TIMESTAMP WITHOUT TIME ZONE) combines the datetime fields YEAR,\par
MONTH, DAY, HOUR, MINUTE and SECOND; it defines a set of correctly formed\par
values that represent any valid Gregorian calendar date between '0001-01-01'\par
and '9999-12-31' (i.e.: between January 1, 1 AD and December 31, 9999 AD)\par
combined with any valid time of day (based on a 24 hour clock) between\par
'00:00:00' and (at a minimum) '23:59:61.999999'. (The SQL Standard requires\par
DBMSs to allow for the addition of up to 2 "leap" seconds in a valid time.) It\par
has a length of at least 19 SQL_TEXT characters.\par
\par
The optional fractional seconds precision, if specified, is an unsigned\par
integer that specifies the number of digits following the decimal point in the\par
SECOND datetime field. The minimum fractional seconds precision is zero. The\par
default fractional seconds precision is 6. For example, this <data type>\par
specification defines a set of timestamps with a fractional seconds precision of zero digits:\par
\par
   TIMESTAMP(0)\par
   -- would contain values like '1994-07-15 13:30:22'\par
\par
These two <data type> specifications both define a set of timestamps with a\par
fractional seconds precision of 6 digits, i.e.: of one-millionth of a second:\par
\par
   TIMESTAMP\par
   -- would contain values like '1994-07-15 13:30:22.999999'\par
\par
   TIMESTAMP(6)\par
   -- would also contain values like '1994-07-15 13:30:22.999999'\par
\par
[NON-PORTABLE] The maximum fractional seconds precision for TIMESTAMP (a) may\par
not be less than 6 digits and (b) must be equal to the maximum allowed for the\par
TIME, TIME WITH TIME ZONE and TIMESTAMP WITH TIME ZONE <data type>s but is\par
non-standard because the SQL Standard requires implementors to define\par
TIMESTAMP's maximum fractional seconds precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the fractional seconds precision of TIMESTAMP to range from 0 to 6 digits.\par
\par
Any operation that attempts to make a TIMESTAMP <data type> contain a YEAR\par
value that is either less than 1 or greater than 9999 will fail: the DBMS will\par
return the SQLSTATE error 22007 "data exception-invalid datetime format".\par
\par
TIMESTAMP expects timestamps to have the following form:\par
\par
   yyyy-mm-dd hh:mm:ss[.nnnnnn] \par
\par
e.g.: these two timestamps both represent "half past one, plus 22 seconds, PM on July 15, 1994":\par
\par
   1994-07-15 13:30:22\par
\par
   1994-07-15 13:30:22.00\par
\par
and this timestamp represents "half past one, plus 22 and one-tenth seconds, PM on July 15, 1994":\par
\par
   1994-07-15 13:30:22.10\par
\par
Note the mandatory space between the date portion and the time portion of the timestamps.\par
\par
The actual length of a TIMESTAMP depends on the fractional seconds precision.\par
This <data type> specification has a length of 19 SQL_TEXT characters:\par
\par
   TIMESTAMP(0)\par
\par
This <data type> specification has a length of 21 SQL_TEXT characters:\par
\par
   TIMESTAMP(1)\par
   -- 19 plus decimal point plus 1 digit in fractional seconds precision\par
\par
These two <data type> specifications both have a length of 26 SQL_TEXT characters:\par
\par
   TIMESTAMP\par
\par
   TIMESTAMP(6)\par
\par
[Obscure Rule] TIMESTAMP has a time zone offset equal to the current default\par
time zone offset of the SQL-session: it represents a local timestamp.\par
\par
Here is an example of TIMESTAMP:\par
\par
   CREATE TABLE timestamp_table_1 ( \par
      start_timestamp_1 TIMESTAMP,\par
      start_timestamp_2 TIMESTAMP(2));\par
\par
   INSERT INTO timestamp_table_1 (start_timestamp_1, start_timestamp_2) \par
   VALUES ( \par
      TIMESTAMP '1997-04-01 14:14:14.999999', \par
      TIMESTAMP '1994-07-15 15:15:15.15');\par
\par
If you want to restrict your code to Core SQL, don't define your TIMESTAMP\par
<data type>s with a fractional seconds precision other than 0 or 6 and don't\par
add the optional noise words WITHOUT TIME ZONE: use only TIMESTAMP,\par
TIMESTAMP(0) or TIMESTAMP(6), never TIMESTAMP(x) WITHOUT TIME ZONE.\par
\par
TIP: Consider using a TIMESTAMP to store time-of-day values if you plan on\par
doing time arithmetic: TIMESTAMP '1000-01-01 13:45:00' instead of TIME\par
'13:45:00'. Although this wastes space on a meaningless date value, your time\par
arithmetic will be more meaningful, since any "carries" or "borrows" will show\par
up in the results.\par
\par
## TIMESTAMP WITH TIME ZONE\par
[Obscure Rule] applies for this entire section. \par
\par
The required syntax for a TIMESTAMP WITH TIME ZONE <data type> specification is: \par
\par
TIMESTAMP WITH TIME ZONE <data type> ::= \par
TIMESTAMP [ (fractional seconds precision) ] WITH TIME ZONE \par
\par
TIMESTAMP WITH TIME ZONE combines the datetime fields YEAR, MONTH, DAY, HOUR,\par
MINUTE, SECOND, TIMEZONE_HOUR and TIMEZONE_MINUTE; it defines a set of\par
correctly formed values that represent any valid Gregorian calendar date\par
between '0001-01-01' and '9999-12-31' (i.e.: between January 1, 1 AD and\par
December 31, 9999 AD) combined with any valid time of day (based on a 24 hour\par
clock) between '00:00:00' and (at a minimum) '23:59:61.999999' with a time\par
zone offset that must be between '-12:59' and '+13:00'. (The SQL Standard\par
requires DBMSs to allow for the addition of up to 2 "leap" seconds in a valid\par
time.) It has a length of at least 25 SQL_TEXT characters.\par
\par
As with TIMESTAMP, the optional fractional seconds precision for TIMESTAMP\par
WITH TIME ZONE specifies the number of digits following the decimal point in\par
the SECOND datetime field. The minimum fractional seconds precision is zero.\par
The default fractional seconds precision is 6.\par
\par
[NON-PORTABLE] The maximum fractional seconds precision for TIMESTAMP WITH\par
TIME ZONE (a) may not be less than 6 digits and (b) must be equal to the\par
maximum allowed for the TIME, TIME WITH TIME ZONE and TIMESTAMP <data type>s\par
but is non-standard because the SQL Standard requires implementors to define\par
TIMESTAMP WITH TIME ZONE's maximum fractional seconds precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the fractional seconds precision of TIMESTAMP WITH TIME ZONE to range from 0 to 6 digits.\par
\par
Any operation that attempts to make a TIMESTAMP WITH TIME ZONE <data type>\par
contain a YEAR value that is either less than 1 or greater than 9999 will\par
fail: the DBMS will return the SQLSTATE error 22007 "data exception-invalid\par
datetime format".\par
\par
TIMESTAMP WITH TIME ZONE expects timestamps to have the following form:\par
\par
   yyyy-mm-dd hh:mm:ss[.nnnnnn ][\{+|-\}HH:MM ] \par
\par
e.g.: the following timestamps all represent "half past one, plus 22 seconds, PM on July 15, 1994" with a time zone offset of 2 and a half hours:\par
\par
   1994-07-15 13:30:22+02:30\par
\par
   1994-07-15 13:30:22.+02:30\par
\par
   1994-07-15 13:30:22.00+02:30\par
\par
The actual length of a TIMESTAMP WITH TIME ZONE depends on the fractional\par
seconds precision. This <data type> specification has a length of 25 SQL_TEXT characters:\par
\par
   TIMESTAMP(0) WITH TIME ZONE\par
\par
This <data type> specification has a length of 27 SQL_TEXT characters:\par
\par
   TIMESTAMP(1) WITH TIME ZONE\par
   -- 25 plus decimal point plus 1 digit in fractional seconds precision\par
\par
These two <data type> specifications both have a length of 32 SQL_TEXT characters:\par
\par
   TIMESTAMP WITH TIME ZONE\par
\par
   TIMESTAMP(6) WITH TIME ZONE\par
\par
[Obscure Rule] TIMESTAMP WITH TIME ZONE has a time zone offset equal to the\par
<time zone interval> specified for a given timestamp value: it represents a\par
timestamp in the given time zone. If the <time zone interval> is omitted from\par
a given timestamp value, TIMESTAMP WITH TIME ZONE has a time zone offset equal\par
to the default time zone offset of the SQL-session: it represents a local\par
timestamp. The default time zone offset is the <time zone interval> specified\par
in the most recent SET TIME ZONE statement issued during the SQL-session. If\par
you haven't issued a SET TIME ZONE statement, the default time zone offset is\par
your DBMS's initial default time zone offset.\par
      ## [NON-PORTABLE] The default time zone offset is non-standard because\par
the SQL Standard requires implementors to define the initial default time zone\par
offset for an SQL-session.\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
sets the SQL-session's initial default time zone offset to INTERVAL +'00:00'\par
HOUR TO MINUTE -- this represents UTC.\par
\par
Here is an example of TIMESTAMP WITH TIME ZONE:\par
\par
   CREATE TABLE timestamp_table_2 ( \par
      start_timestamp_1 TIMESTAMP WITH TIME ZONE,\par
      start_timestamp_2 TIMESTAMP(2) WITH TIME ZONE); \par
\par
   INSERT INTO timestamp_table_2 (start_timestamp_1, start_timestamp_2) \par
   VALUES ( \par
      TIMESTAMP '1997-04-01 14:14:14.999999-03:00',\par
      TIMESTAMP '1994-07-15 14:14:14.35+02:15');\par
\par
If you want to restrict your code to Core SQL, don't use TIMESTAMP WITH TIME\par
ZONE <data type>s.\par
\par
Interval <data type>s:\par
An interval <data type> is defined by a descriptor that contains two pieces of information:\par
      ## The <data type>'s name: INTERVAL.\par
      ## The <data type>s <interval qualifier>, which specifies the type of interval and the precision of the interval's set of valid values.\par
\par
## INTERVAL\par
The required syntax for an INTERVAL <data type> specification is:\par
\par
INTERVAL <data type> ::=\par
INTERVAL <interval qualifier>\par
\par
INTERVAL is a span of time; it defines a set of correctly formed values that\par
represent any span of time compatible with the <interval qualifier>. It\par
combines the datetime fields YEAR and/or MONTH if it is a year-month interval.\par
It combines the datetime fields DAY and/or HOUR and/or MINUTE and/or SECOND if\par
it is a day-time interval. It has a length of at least 1 SQL_TEXT character.\par
\par
A year-month INTERVAL combines one or more of the datetime fields YEAR and\par
MONTH in the <interval qualifier>. The possible definitions are thus:\par
\par
   INTERVAL YEAR [ (leading precision) ] \par
\par
   INTERVAL MONTH [ (leading precision) ] \par
\par
   INTERVAL YEAR [ (leading precision) ] TO MONTH\par
\par
The leading precision, if specified, is as described in "<interval\par
qualifier>". The values of the "start_datetime" field are constrained only by\par
the leading precision of that field. The month value in INTERVAL YEAR TO MONTH\par
represents an additional number of months (within years) and can thus range\par
only from 0 to 11.\par
\par
INTERVAL YEAR expects intervals to have the following form:\par
\par
   'y[...]'\par
\par
e.g.: '20' represents a span of 20 years. INTERVAL YEAR has a length of\par
"leading precision" SQL_TEXT characters. For example, this <data type>\par
specification has a length of 4 SQL_TEXT characters:\par
\par
   INTERVAL YEAR(4)\par
\par
INTERVAL MONTH expects intervals to have the following form:\par
\par
   'm[...]'\par
\par
e.g.: '15' represents a span of 15 months. INTERVAL MONTH has a length of\par
"leading precision" SQL_TEXT characters. For example, this <data type>\par
specification has a length of 2 SQL_TEXT characters:\par
\par
   INTERVAL MONTH\par
\par
(The default precision is 2 digits.)\par
\par
INTERVAL YEAR TO MONTH expects intervals to have the following form: \par
\par
   'y[...]-mm' \par
\par
e.g.: '20-03' represents a span of 20 years plus 3 months. INTERVAL YEAR TO\par
MONTH has a length of "leading precision" plus 3 SQL_TEXT characters. For\par
example, this <data type> specification has a length of 5 SQL_TEXT characters:\par
\par
   INTERVAL YEAR TO MONTH\par
\par
A day-time INTERVAL combines one or more of the datetime fields DAY, HOUR,\par
MINUTE and SECOND in the <interval qualifier>. The possible definitions are thus:\par
\par
   INTERVAL DAY [ (leading precision) ] \par
\par
   INTERVAL HOUR [ (leading precision) ] \par
\par
   INTERVAL MINUTE [ (leading precision) ] \par
\par
   INTERVAL SECOND [ (leading precision [ ,fractional seconds precision ]) ] \par
\par
   INTERVAL DAY [ (leading precision) ] TO HOUR \par
\par
   INTERVAL DAY [ (leading precision) ] TO MINUTE \par
\par
   INTERVAL DAY [ (leading precision) ] TO SECOND [ (fractional seconds precision) ] \par
\par
   INTERVAL HOUR [ (leading precision) ] TO MINUTE \par
\par
   INTERVAL HOUR [ (leading precision) ] TO SECOND [ (fractional seconds precision) ] \par
\par
   INTERVAL MINUTE [ (leading precision) ] TO SECOND [ (fractional seconds precision) ]\par
\par
The leading precision, if specified, is as described in "<interval\par
qualifier>". The values of the "start_datetime" field are constrained only by\par
the leading precision of that field. The hour value in INTERVAL DAY TO HOUR,\par
INTERVAL DAY TO MINUTE and INTERVAL DAY TO SECOND represents an additional\par
number of hours (within days) and can thus range only from 0 to 23. The minute\par
value in INTERVAL DAY TO MINUTE, INTERVAL DAY TO SECOND, INTERVAL HOUR TO\par
MINUTE and INTERVAL HOUR TO SECOND represents an additional number of minutes\par
(within hours) and can thus range only from 0 to 59. The seconds value in\par
INTERVAL DAY TO SECOND, INTERVAL HOUR TO SECOND and INTERVAL MINUTE TO SECOND\par
represents an additional number of seconds and fractions of a second (within\par
minutes) and can thus range only from 0 to 59.9n (where ".9n" represents the\par
number of digits defined for the fractional seconds precision). The fractional\par
seconds precision, if specified, is as described in "<interval qualifier>".\par
\par
INTERVAL DAY expects intervals to have the following form: \par
\par
   'd[...]' \par
\par
e.g.: '1' represents a span of 1 day. INTERVAL DAY has a length of "leading\par
precision" SQL_TEXT characters. For example, this <data type> specification\par
has a length of 2 SQL_TEXT characters:\par
\par
   INTERVAL DAY\par
\par
(The default precision is 2 digits.)\par
\par
INTERVAL HOUR expects intervals to have the following form: \par
\par
   'h[...]' \par
\par
e.g.: '15' represents a span of 15 hours. INTERVAL HOUR has a length of\par
"leading precision" SQL_TEXT characters. For example, this <data type>\par
specification has a length of 2 SQL_TEXT characters:\par
\par
   INTERVAL HOUR\par
\par
INTERVAL MINUTE expects intervals to have the following form: \par
\par
   'm[...]' \par
\par
e.g.: '75' represents a span of 75 minutes. INTERVAL MINUTE has a length of\par
"leading precision" SQL_TEXT characters. For example, this <data type>\par
specification has a length of 2 SQL_TEXT characters:\par
\par
   INTERVAL MINUTE\par
\par
INTERVAL SECOND expects intervals to have the following form:\par
\par
   's[...[.n...]]' \par
\par
e.g.: '1' represents a span of 1 second, '20' and '20.0' both represent a span\par
of 20 seconds and '20.5' represents a span of 20.5 seconds. INTERVAL SECOND\par
has a length of "leading precision" plus "fractional seconds precision"\par
SQL_TEXT characters. For example, this <data type> specification has a length\par
of 2 SQL_TEXT characters:\par
\par
   INTERVAL SECOND(0)\par
\par
These two <data type> specifications both have a length of 9 SQL_TEXT\par
characters:\par
\par
   INTERVAL SECOND\par
\par
   INTERVAL SECOND(6)\par
\par
(The default fractional seconds precision is 6 digits. A fractional seconds\par
precision greater than zero includes one position for the decimal point.)\par
\par
INTERVAL DAY TO HOUR expects intervals to have the following form:\par
\par
   'd[...] h[...]' \par
\par
e.g.: '1 1' represents a span of 1 day plus 1 hour and '20 10' represents a\par
span of 20 days plus 10 hours. (Note the mandatory space between the days\par
portion and the hours portion of the interval.) INTERVAL DAY TO HOUR has a\par
length of "leading precision" plus 3 SQL_TEXT characters. For example, this\par
<data type> specification has a length of 5 SQL_TEXT characters:\par
\par
   INTERVAL DAY TO HOUR\par
\par
INTERVAL DAY TO MINUTE expects intervals to have the following form: \par
\par
   'd[...] h[...]:m[...]' \par
\par
e.g.: '1 1:1' represents a span of 1 day, 1 hour plus 1 minute and '20 10:15'\par
represents a span of 20 days, 10 hours plus 15 minutes. (Note the mandatory\par
colon between the hours portion and the minutes portion of the interval.)\par
INTERVAL DAY TO MINUTE has a length of "leading precision" plus 6 SQL_TEXT\par
characters. For example, this <data type> specification has a length of 8\par
SQL_TEXT characters:\par
\par
   INTERVAL DAY TO MINUTE\par
\par
INTERVAL DAY TO SECOND expects intervals to have the following form: \par
\par
   'd[...] h[...]:m[...]:s[...[.n...]]' \par
\par
e.g.: '1 1:1:1' and '01 01:01:01.00' both represent a span of 1 day, 1 hour, 1\par
minute plus 1 second and '20 10:15:20.5' represents a span of 20 days, 10\par
hours, 15 minutes plus 20.5 seconds. (Note the mandatory colon between the\par
minutes portion and the seconds portion of the interval.) INTERVAL DAY TO\par
SECOND has a length of "leading precision" plus "fractional seconds precision"\par
plus 9 SQL_TEXT characters. For example, this <data type> specification has a\par
length of 11 SQL_TEXT characters:\par
\par
   INTERVAL DAY TO SECOND(0)\par
\par
These two <data type> specifications both have a length of 18 SQL_TEXT characters:\par
\par
   INTERVAL DAY TO SECOND\par
\par
   INTERVAL DAY TO SECOND(6)\par
\par
INTERVAL HOUR TO MINUTE expects intervals to have the following form:\par
\par
   'h[...]:m[...]' \par
\par
e.g.: '10:15' represents a span of 10 hours plus 15 minutes. INTERVAL HOUR TO\par
MINUTE has a length of "leading precision" plus 3 SQL_TEXT characters. For\par
example, this <data type> specification has a length of 5 SQL_TEXT characters:\par
\par
   INTERVAL HOUR TO MINUTE\par
\par
INTERVAL HOUR TO SECOND expects intervals to have the following form: \par
\par
   'h[...]:m[...]:s[...[.n...]]' \par
\par
e.g.: '10:15:20.5' represents a span of 10 hours, 15 minutes plus 20.5\par
seconds. INTERVAL HOUR TO SECOND has a length of "leading precision" plus\par
"fractional seconds precision" plus 6 SQL_TEXT characters. For example, this\par
<data type> specification has a length of 8 SQL_TEXT characters:\par
\par
   INTERVAL HOUR TO SECOND(0)\par
\par
These two <data type> specifications both have a length of 15 SQL_TEXT characters:\par
\par
   INTERVAL HOUR TO SECOND\par
\par
   INTERVAL HOUR TO SECOND(6)\par
\par
INTERVAL MINUTE TO SECOND expects intervals to have the following form: \par
\par
   'm[...]:s[...[.n...]]' \par
\par
e.g.: '15:20.5' represents a span of 15 minutes plus 20.5 seconds and '14:15'\par
represents a span of 14 minutes plus 15 seconds. INTERVAL MINUTE TO SECOND has\par
a length of "leading precision" plus "fractional seconds precision" plus 3\par
SQL_TEXT characters. For example, this <data type> specification has a length\par
of 5 SQL_TEXT characters:\par
\par
   INTERVAL MINUTE TO SECOND(0)\par
\par
These two <data type> specifications both have a length of 12 SQL_TEXT characters:\par
\par
   INTERVAL MINUTE TO SECOND\par
\par
   INTERVAL MINUTE TO SECOND(6)\par
\par
Here is an example of INTERVAL:\par
\par
   CREATE interval_table ( \par
      interval_column_1 INTERVAL YEAR(3) TO MONTH,\par
      interval_column_2 INTERVAL DAY TO MINUTE, \par
      interval_column_3 INTERVAL MINUTE TO SECOND(4));\par
\par
   INSERT INTO interval_table ( \par
      interval_column_1, \par
      interval_column_2,\par
      interval_column_3) \par
   VALUES ( \par
      INTERVAL '150-01' YEAR TO MONTH,\par
      INTERVAL '-36 22:30' DAY TO MINUTE,\par
      INTERVAL -'15:22.0001' MINUTE TO SECOND(4));\par
\par
If you want to restrict your code to Core SQL, don't use the INTERVAL <data type>.\par
\par
Now that we've described SQL's datetime <data type>s, let's look at some\par
example SQL statements that put them to use.\par
\par
These SQL statements make a Table with a date Column, insert a row, then search for any date after January 2nd, 2000.\par
\par
   CREATE TABLE Date_Examples ( \par
      occurrence_date DATE);\par
\par
   INSERT INTO Date_Examples (occurrence_date)\par
   VALUES (DATE '2001-02-29');\par
\par
   SELECT occurrence_date \par
   FROM   Date_Examples \par
   WHERE  occurrence_date > DATE '2000-01-02';\par
\par
These SQL statements make a Table with two time-of-day Columns, insert a row, then search for any time before 8:30 PM.\par
\par
   CREATE TABLE Time_Examples ( \par
      occurrence_time TIME,\par
      occurrence_time_zone TIME WITH TIME ZONE);\par
\par
   INSERT INTO Time_Examples (occurrence_time, occurrence_time_zone)\par
   VALUES (TIME '12:00:00', TIME '12:00:00+3:00');\par
\par
   SELECT occurrence_time, occurrence_time_zone \par
   FROM   Time_Examples \par
   WHERE  occurrence_time < TIME '20:30:00';\par
\par
These SQL statements make a Table with two timestamp Columns,\par
insert a row, then search for any timestamp equal to January 2nd, 2000 at 1\par
second past midnight.\par
\par
   CREATE TABLE Timestamp_Examples ( \par
      occurrence_timestamp TIMESTAMP, \par
      occurrence_timestamp_zone TIMESTAMP WITH TIME ZONE);\par
\par
   INSERT INTO Timestamp_Examples ( \par
      occurrence_timestamp, \par
      occurrence_timestamp_zone) \par
   VALUES ( \par
      TIMESTAMP '2001-02-29 16:00:00', \par
      TIMESTAMP '2001-02-29 16:00:00+0:00'); \par
\par
SELECT occurrence_timestamp, occurrence_timestamp_zone \par
FROM   Timestamp_Examples \par
WHERE  occurrence_timestamp_zone = TIMESTAMP '2000-01-02 00:00:01';\par
\par
These SQL statements make a Table with two year-month interval Columns, insert\par
a row, then search for any interval that is less than or equal to 37 months.\par
\par
   CREATE TABLE YInterval_Examples ( \par
      occurrence_interval_1 INTERVAL YEAR, \par
      occurrence_interval_2 INTERVAL YEAR TO MONTH);\par
\par
   INSERT INTO YInterval_Examples ( \par
      occurrence_interval_1, \par
      occurrence_interval_2) \par
   VALUES ( \par
      INTERVAL '3' YEAR,\par
      INTERVAL '02-10' YEAR TO MONTH');\par
\par
   SELECT occurrence_interval_1, occurrence_interval_2 \par
   FROM   YInterval_Examples \par
   WHERE  occurrence_interval_1 <= INTERVAL '37' MONTH;\par
\par
These SQL statements make a Table with two day-time interval Columns, insert\par
two rows, then search for any interval that doesn't equal 30 seconds.\par
\par
   CREATE TABLE DInterval_Examples ( \par
      occurrence_interval_1 INTERVAL SECOND, \par
      occurrence_interval_2 INTERVAL SECOND(2,4));\par
\par
   INSERT INTO DInterval_Examples ( \par
      occurrence_interval_1, \par
      occurrence_interval_2) \par
   VALUES ( \par
      INTERVAL '25.000005' SECOND,\par
      INTERVAL '25.0001' SECOND');\par
\par
   INSERT INTO DInterval_Examples ( \par
      occurrence_interval_1, \par
      occurrence_interval_2) \par
   VALUES ( \par
      INTERVAL '22' SECOND,\par
      INTERVAL '22' SECOND');\par
\par
   SELECT occurrence_interval_1, occurrence_interval_2 \par
   FROM   DInterval_Examples \par
   WHERE  occurrence_interval_1 <> INTERVAL '30' SECOND;\par
\par
Temporal Operations\par
\par
A temporal value is only compatible with, and comparable to, a matching\par
temporal value; that is, only temporal values of the same type, that also\par
consist of matching datetime fields, are mutually comparable and mutually\par
assignable. Thus, all dates are mutually comparable and mutually assignable,\par
all times are mutually comparable and mutually assignable, all timestamps are\par
mutually comparable and mutually assignable, all year-month intervals are\par
mutually comparable and mutually assignable and all day-time intervals are\par
mutually comparable and mutually assignable. Temporal values may not be\par
directly compared with, or directly assigned to, non-compatible datetimes or\par
intervals or to any other <data type> class, though implicit type conversions\par
can occur in expressions, SELECTs, INSERTs, DELETEs and UPDATEs. Explicit\par
temporal type conversions can be forced with the CAST operator.\par
\par
CAST:\par
In SQL, CAST is a scalar operator that converts a given scalar value to a\par
given scalar <data type>. The required syntax for the CAST operator is:\par
\par
CAST (<cast operand> AS <cast target>)\par
\par
   <cast operand> ::= scalar_expression\par
\par
   <cast target> ::= <Domain name> | <data type>\par
\par
The CAST operator converts values of a source <data type> into values of a\par
target <data type>, where each <data type> is an SQL pre-defined <data type>\par
(data conversions between UDTs are done with a user-defined cast). The source\par
<data type>, or <cast operand>, can be any expression that evaluates to a\par
single value. The target <data type>, or <cast target>, is either an SQL\par
predefined <data type> specification or the name of a Domain whose defined\par
<data type> is the SQL predefined <data type> that you want to convert the\par
value of "scalar_expression" into. (If you use CAST (... AS <Domain name>),\par
your current <AuthorizationID> must have the USAGE Privilege on that Domain.)\par
\par
It isn't, of course, possible to convert the values of every <data type> into\par
the values of every other <data type>. For temporal values, the rules are:\par
      ## CAST (NULL AS <data type>) and CAST (temporal_source_is_a_null_value\par
AS <data type>) both result in a CAST result of NULL.\par
      ## You can CAST a date source to these targets: fixed length character\par
string, variable length character string, CLOB, NCLOB, date and timestamp. You\par
can also CAST a date source to a UDT target or a <reference type> target if a\par
user-defined cast exists for this purpose and your current <AuthorizationID>\par
has the EXECUTE Privilege on that user-defined cast.\par
      ## You can CAST a time source to these targets: fixed length character\par
string, variable length character string, CLOB, NCLOB, time and timestamp. You\par
can also CAST a time source to a UDT target or a <reference type> target if a\par
user-defined cast exists for this purpose and your current <AuthorizationID>\par
has the EXECUTE Privilege on that user-defined cast.\par
      ## You can CAST a timestamp source to these targets: fixed length\par
character string, variable length character string, CLOB, NCLOB, date, time\par
and timestamp. You can also CAST a timestamp source to a UDT target or a\par
<reference type> target if a user-defined cast exists for this purpose and\par
your current <AuthorizationID> has the EXECUTE Privilege on that user-defined\par
cast.\par
      ## You can CAST a year-month interval source to these targets: fixed\par
length character string, variable length character string, CLOB, NCLOB and\par
year-month interval. You can CAST a day-time interval source to these targets:\par
fixed length character string, variable length character string, CLOB, NCLOB\par
and day-time interval. You can also CAST an interval source to an exact\par
numeric target, provided the source contains only one datetime field -- that\par
is, you can CAST an INTERVAL YEAR to an integer or an INTERVAL MONTH to an\par
integer, but you can't CAST an INTERVAL YEAR TO MONTH to an integer. You can\par
CAST an interval source to a UDT target or a <reference type> target if a\par
user-defined cast exists for this purpose and your current <AuthorizationID>\par
has the EXECUTE Privilege on that user-defined cast.\par
\par
When you CAST any temporal value to a fixed length character string, variable\par
length character string, CLOB or NCLOB target, your DBMS converts the source\par
value to the shortest possible character string that can express the source\par
value (for example, "CAST (DATE '1994-07-15' AS CHAR(10))" results in the\par
character string '1994-07-15').\par
      ## For fixed length character string targets, if the length of the\par
result equals the fixed length of the target, then the source is CAST to that\par
result. If the length of the result is shorter than the fixed length of the\par
target, then the source is CAST to that result, padded on the right with\par
however many spaces is required to make the lengths the same. If the length of\par
the result is longer than the fixed length of the target, the CAST will fail:\par
your DBMS will return the SQLSTATE error 22001 "data exception-string data,\par
right truncation". And if the result contains any characters that don't belong\par
to the target's Character set, the CAST will also fail: your DBMS will return\par
the SQLSTATE error 22018 "data  exception-invalid character value for cast".\par
      ## For variable length character string, CLOB or NCLOB targets, if the\par
length of the result is less than or equals the maximum length of the target,\par
then the source is CAST to that result. If the length of the result is longer\par
than the maximum length of the target, the CAST will fail: your DBMS will\par
return the SQLSTATE error 22001 "data exception-string data, right\par
truncation". And if the result contains any characters that don't belong to\par
the target's Character set, the CAST will also fail: your DBMS will return the\par
SQLSTATE error 22018 "data  exception-invalid character value for cast".\par
      ## [Obscure Rule] The result of a CAST to a character string target has\par
the COERCIBLE coercibility attribute; its Collation is the default Collation\par
for the target's Character set.\par
\par
When you CAST any temporal value to a UDT or a <reference type> target, your\par
DBMS invokes the user defined cast routine, with the source value as the\par
routine's argument. The CAST result is the value returned by the user defined cast.\par
\par
CAST DATE\par
      ## When you CAST a date to a date target, the result is the source date.\par
      ## When you CAST a date to a timestamp target, the result is a timestamp\par
whose date portion is the same as the source date and whose time portion is\par
zero (that is, "CAST (DATE '1994-07-15' AS TIMESTAMP)" results in TIMESTAMP\par
'1994-07-15 00:00:00.000000').\par
\par
CAST TIME\par
      ## When you CAST a time to a time target or a time with time zone to a\par
time with time zone target, the result is the source time.\par
      ## When you CAST a time to a time with time zone target, the result is\par
the source time converted to UTC.\par
      ## When you CAST a time with time zone to a time target, the result is\par
the source time converted to the local time.\par
      ## When you CAST a time to a timestamp target or a time with time zone\par
to a timestamp with time zone target, the result is a timestamp whose date\par
portion is the value of CURRENT_DATE and whose time portion is the same as the\par
source time (that is, "CAST (TIME '10:10:10.01' AS TIMESTAMP)" results in\par
TIMESTAMP '1994-07-15 10:10:10.010000' if today's date is July 15, 1994).\par
      ## When you CAST a time to a timestamp with time zone target, the result\par
is a timestamp whose date portion is the value of CURRENT_DATE and whose time\par
portion is the same as the source time converted to UTC.\par
      ## When you CAST a time with time zone to a timestamp target, the result\par
is a timestamp whose date portion is the value of CURRENT_DATE and whose time\par
portion is the same as the source time converted to the local time.\par
\par
CAST TIMESTAMP\par
      ## When you CAST a timestamp to a date target, the result is the date\par
portion of the timestamp. For example, "CAST (TIMESTAMP '1994-07-15\par
10:10:10:010000' AS DATE)" results in DATE '1994-07-15'. When you CAST a\par
timestamp with time zone to a date target, the result is the date portion of\par
the timestamp, adjusted by the time zone offset if required.\par
      ## When you CAST a timestamp to a time target or a timestamp with time\par
zone to a time with time zone target, the result is the time portion of the\par
timestamp. For example, "CAST (TIMESTAMP '1994-07-15 10:10:10:010000+02:30')" \par
results in TIME '10:10:10:010000+02:30'.\par
      ## When you CAST a timestamp to a time with time zone target, the result\par
is the time portion of the timestamp converted to UTC.\par
      ## When you CAST a timestamp with time zone to a time target, the result\par
is the time portion of the timestamp converted to the local time.\par
      ## When you CAST a timestamp to a timestamp target or a timestamp with\par
time zone to a timestamp with time zone target, the result is the source timestamp.\par
      ## When you CAST a timestamp to a timestamp with time zone target, the\par
result is the source timestamp, with its time portion converted to UTC.\par
      ## When you CAST a timestamp with time zone to a timestamp target, the\par
result is the source timestamp, with its time portion converted to the local time.\par
\par
CAST INTERVAL\par
      ## When you CAST an interval to an exact numeric target, your interval\par
has to be for one datetime field only. The result of the CAST is the numeric\par
value of that datetime field. For example, "CAST ('100' INTERVAL YEAR(3) AS\par
SMALLINT)" results in a SMALLINT value of 100. (Note: if the numeric value of\par
your interval can't be represented as a target value without losing any\par
leading significant digits, the CAST will fail: your DBMS will return the\par
SQLSTATE error 22003 "data exception-numeric value out of range".\par
      ## When you CAST a year-month interval to a year-month interval target\par
or a day-time interval to a day-time interval target, if both source and\par
target have the same <interval qualifier> then the result of the CAST is the\par
source interval.\par
      ## When you CAST a year-month interval to a year-month interval target\par
or a day-time interval to a day-time interval target, if the source and target\par
have different <interval qualifier>s, then the result of the CAST is the\par
source interval converted to its equivalent in units of the target interval.\par
For example, "CAST ('3' INTERVAL YEAR TO INTERVAL MONTH)" results in INTERVAL\par
'36' MONTH" and "CAST ('62' INTERVAL MINUTE AS INTERVAL HOUR TO MINUTE)" \par
results in INTERVAL '01:02' HOUR TO MINUTE. (Note: if the CAST would result \par
in the loss of precision of the most significant datetime field of the \par
converted source value, the CAST will fail: your DBMS will return the \par
SQLSTATE error 22015 "data exception-interval field overflow".\par
\par
If you want to restrict your code to Core SQL, don't use <Domain name> as a\par
CAST target: CAST only to a <data type>.\par
\par
Assignment:\par
In SQL, temporal values must be compatible to be assigned to one another --\par
that is, the source and the target must either (a) both be dates, (b) both be\par
times (with or without time zone), (c) both be timestamps (with or without\par
time zone), (d) both be year-month intervals or (e) both be day-time intervals.\par
\par
[Obscure Rule] Since only SQL accepts null values, if your source is NULL and\par
your target is not an SQL-data target, then your target's value is not\par
changed. Instead, your DBMS will set the target's indicator parameter to -1,\par
to indicate that an assignment of the null value was attempted. If your target\par
doesn't have an indicator parameter, the assignment will fail: your DBMS will\par
return the SQLSTATE error 22002 "data exception-null value, no indicator\par
parameter". Going the other way, there are two ways to assign a null value to\par
an SQL-data target. Within SQL, you can use the <keyword> NULL in an INSERT or\par
an UPDATE statement to indicate that the target should be set to NULL; that\par
is, if your source is NULL, your DBMS will set your target to NULL. Outside of\par
SQL, if your source has an indicator parameter that is set to -1, your DBMS\par
will set your target to NULL (regardless of the value of the source). (An\par
indicator parameter with a value less than -1 will cause an error: your DBMS\par
will return the SQLSTATE error 22010 "data exception-invalid indicator\par
parameter value".) We'll talk more about indicator parameters in our chapters\par
on SQL binding styles.\par
\par
## Datetime Assignment\par
When you assign a datetime to a datetime target, your DBMS checks whether the\par
source is a valid value for the target's <data type> (or if a valid value can\par
be obtained from the source by rounding). If so, then the target is set to\par
that value. If neither of these are true, the assignment will fail: your DBMS\par
will return the SQLSTATE error 22008 "data exception-datetime field overflow".\par
\par
DATE assignment is straightforward, since all dates have the same form.\par
\par
[Obscure Rule] TIME, TIME WITH TIME ZONE, TIMESTAMP and TIMESTAMP WITH TIME\par
ZONE assignment is somewhat more complicated, due to the possibility that only\par
one of the source and target may include a <time zone interval>. If this is\par
the case, your DBMS will effectively replace the source value with the result\par
obtained by:\par
\par
   CAST (source TO target)\par
\par
This means that if you're assigning a datetime without time zone source value\par
to a datetime WITH TIME ZONE target, your DBMS will (a) assume the source is a\par
local time value, (b) subtract the default SQL-session time zone offset from\par
the source to convert to the source's UTC equivalent and then (c) assign the\par
UTC result, with resulting time zone offset, to the target. If you're\par
assigning a datetime WITH TIME ZONE source value to a datetime without time\par
zone target, your DBMS will (a) assume the source is a UTC time value, (b) add\par
the source's time zone offset to the source to convert to the source's local\par
time equivalent and then (c) assign the local time result, without a time zone\par
offset, to the target.\par
\par
## Interval Assignment\par
When you assign an interval to an interval target, your DBMS checks whether\par
the source is a valid value for the target's <data type> (or if a valid value\par
can be obtained from the source by rounding or truncation). If so, then the\par
target is set to that value. If neither of these are true, the assignment will\par
fail: your DBMS will return the SQLSTATE error 22015 "data exception-interval\par
field overflow".\par
\par
[NON-PORTABLE] If your source value is not a valid value for your interval\par
target's <data type>, then the value assigned to the target is non-standard\par
because the SQL Standard requires implementors to define whether the DBMS will\par
round or will truncate the source to obtain a valid value.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
truncates the interval source to obtain a valid value for the target.\par
\par
Assignment of year-month intervals with other year-month intervals, or of\par
day-time intervals with other day-time intervals, is straightforward,\par
providing both target and source have the same <interval qualifier>. That is,\par
for example, if both year-month intervals are INTERVAL YEAR, or both are\par
INTERVAL MONTH, or both are INTERVAL YEAR TO MONTH, assignment is\par
straightforward, since all intervals with the same <interval qualifier> have\par
the same form.\par
\par
If, however, the <interval qualifier>s of the source and target do not match\par
exactly, then your DBMS will effectively convert both to the same precision\par
before the operation is carried out. The conversion is done either by a simple\par
mathematical process or by extending one of the intervals at its most\par
significant and/or at its least significant end, with an appropriate datetime\par
field set (initially) to zero. Thus, for example:\par
      ## If you assign INTERVAL '3' YEAR to an INTERVAL YEAR TO MONTH target,\par
your DBMS will extend the source at its least significant end by attaching a\par
zero MONTH field. The source effectively becomes INTERVAL '3-00' YEAR TO\par
MONTH, and assignment becomes straightforward.\par
      ## If you assign INTERVAL '13' MONTH to an INTERVAL YEAR TO MONTH\par
target, your DBMS will extend the source at its most significant end by\par
attaching a zero YEAR field. The source effectively becomes INTERVAL '0-13'\par
YEAR TO MONTH. Since a MONTH field may not be more than 11 months in a\par
year-month interval, the source is further adjusted to INTERVAL '1-01' YEAR TO\par
MONTH (1 year and 1 month equals 13 months), and assignment becomes\par
straightforward.\par
      ## If you assign INTERVAL '3' YEAR to an INTERVAL MONTH target, your\par
DBMS converts the source to an INTERVAL MONTH value by multiplying the year\par
value by 12. The source effectively becomes INTERVAL '36' MONTH, and\par
assignment becomes straightforward.\par
      ## If you assign INTERVAL '3-01' YEAR TO MONTH to an INTERVAL MONTH\par
target, your DBMS converts the source to an INTERVAL MONTH value by\par
multiplying the year value by 12, and adding the number of months to the\par
result. The source effectively becomes INTERVAL '37' MONTH, and assignment\par
becomes straightforward.\par
      ## If you assign INTERVAL '24' MONTH to an INTERVAL YEAR target, your\par
DBMS converts the source to an INTERVAL YEAR value by dividing the month value\par
by 12. The source effectively becomes INTERVAL '2' YEAR, and assignment\par
becomes straightforward. If, however, the source's month value is not evenly\par
divisible by 12 (e.g.: a source of INTERVAL '37' MONTH being assigned to an\par
INTERVAL YEAR target), the assignment will fail so that no information is\par
lost: your DBMS will return the SQLSTATE error 22015 "data exception-interval\par
field overflow".\par
      ## If you assign INTERVAL '2-00' YEAR TO MONTH to an INTERVAL YEAR\par
target, your DBMS converts the source to an INTERVAL YEAR value by assigning\par
the source's year value to the target, that is, the source effectively becomes\par
INTERVAL '2' YEAR, and assignment becomes straightforward. If, however, the\par
source's month value is not equal to zero (e.g.: a source of INTERVAL '2-05'\par
YEAR TO MONTH being assigned to an INTERVAL YEAR target), the assignment will\par
fail so that no information is lost: your DBMS will return the SQLSTATE error\par
22015 "data exception-interval field overflow".\par
      ## The same considerations apply for assignments of day-time intervals\par
that don't have the same <interval qualifier>.\par
\par
Comparison:\par
SQL provides the usual scalar comparison operators -- = and <> and < and <=\par
and > and >= -- to perform operations on temporal values. All of them will be\par
familiar; there are equivalent operators in other computer languages. If any\par
of the comparands are NULL, the result of the operation is UNKNOWN. For example:    \par
\par
   DATE '1997-07-15' = DATE '1997-08-01'\par
\par
returns FALSE.\par
\par
   'DATE '1997-07-15' = (result is NULL\}\par
\par
returns UNKNOWN.\par
\par
SQL also provides three quantifiers -- ALL, SOME, ANY -- which you can use\par
along with a comparison operator to compare a value with the collection of\par
values returned by a <table subquery>. Place the quantifier after the\par
comparison operator, immediately before the <table subquery>. For example:\par
\par
   SELECT date_column \par
   FROM   Table_1 \par
   WHERE  date_column < ALL ( \par
      SELECT date_column \par
      FROM   Table_2);\par
\par
ALL returns TRUE either (a) if the collection is an empty set (i.e.: if it\par
contains zero rows) or (b) if the comparison operator returns TRUE for every\par
value in the collection. ALL returns FALSE if the comparison operator returns\par
FALSE for at least one value in the collection.\par
\par
SOME and ANY are synonyms. They return TRUE if the comparison operator returns\par
TRUE for at least one value in the collection. They return FALSE either (a) if\par
the collection is an empty set or (b) if the comparison operator returns FALSE\par
for every value in the collection. (The search condition "= ANY (collection)"\par
is equivalent to "IN (collection)".)\par
\par
Temporal values must be compatible to be compared with one another -- that is,\par
the source and the target must either (a) both be dates, (b) both be times\par
(with or without time zone), (c) both be timestamps (with or without time\par
zone), (d) both be year-month intervals or (e) both be day-time intervals. The\par
results of temporal comparisons are governed by the natural rules for dates\par
and times according to the Gregorian calendar.\par
\par
## Datetime Comparison\par
[Obscure Rule] When you compare two datetime values, the result is determined\par
according to the interval obtained when your comparands are subtracted from\par
one another. If you're comparing times or timestamps with different <time zone\par
interval>s, your DBMS will ignore the value of the time zone offset for the comparison.\par
\par
## Interval Comparison\par
[Obscure Rule] When you compare two interval values, your DBMS will\par
effectively convert both comparands to the same precision before the operation\par
is carried out. The conversion is done either by a simple mathematical process\par
or by extending one (or both) of the comparands at the most significant and/or\par
at the least significant end, with an appropriate datetime field set\par
(initially) to zero, just as is done with interval assignments. For example,\par
for this comparison:\par
\par
   INTERVAL '2-05' YEAR TO MONTH = INTERVAL '3' YEAR\par
\par
both comparands are first converted to INTERVAL MONTH, making the actual comparison:\par
\par
   INTERVAL '29' MONTH = INTERVAL '36' MONTH\par
\par
The result, of course, is FALSE.\par
\par
Other Operations:\par
With SQL, you have several other operations that you can perform on temporal\par
values to get a temporal result.\par
\par
## Arithmetic\par
SQL provides the usual scalar arithmetic operators -- + and - and * and / --\par
to perform operations on temporal values. All of them will be familiar; there\par
are equivalent operators in other computer languages. Arithmetic operations on\par
temporal values are governed by the natural rules for dates and times and\par
yield valid datetimes or intervals according to the Gregorian calendar. If any\par
of the operands are NULL, the result of the operation is also NULL.\par
\par
SQL doesn't allow you to do arithmetic on every possible combination of\par
datetime and interval operands. Here are the valid possibilities, and the\par
<data type> of the result:\par
      ## Date + Interval and Interval + Date both yield Date\par
      ## Date - Interval yields Date\par
      ## Date - Date yields Interval\par
      ## Time + Interval and Interval + Time both yield Time\par
      ## Time - Interval yields Time\par
      ## Timestamp + Interval and Interval + Timestamp both yield Timestamp\par
      ## Timestamp - Interval yields Timestamp\par
      ## year-month Interval + year-month Interval yields year-month Interval\par
      ## day-time Interval + day-time Interval yields day-time Interval\par
      ## year-month Interval - year-month Interval yields year-month Interval\par
      ## day-time Interval - day-time Interval yields day-time Interval\par
      ## Time - Time yields Interval\par
      ## Timestamp - Timestamp yields Interval\par
      ## Interval * Number and Number * Interval both yield Interval\par
      ## Interval / Number yields Interval\par
In each of these cases, the operands can be any argument that evaluates to the specified <data type>.\par
\par
The rules for temporal arithmetic can be explained with this analogy. When you\par
subtract the INTEGER value 123456 from 123557, you get another INTEGER value:\par
-101. So, when you subtract TIME '12:34:56' from TIME '12:35:57', should you\par
get the TIME value: -'00:01:01'? Well, no -- there's no such thing as a\par
negative time-of-day so SQL's TIME <data type> can't hold this value.\par
\par
Regardless, some people are of the opinion that it looks right to represent\par
the result as <negative> zero hours : zero minutes : 1 second. After all, the \par
result is still a time, although it is reasonable to distinguish "time as an \par
elapsed duration" from "time as a moment in the time scale".\par
\par
Other people don't believe that the "negative time value" looks correct. They\par
feel that (time minus time) should result in an INTEGER -- the number of\par
elapsed seconds, 61. While there are still several DBMSs which follow this\par
line, they aren't SQL DBMSs -- the SQL Standard states that operations like\par
(datetime minus datetime) results in an INTERVAL, which can be signed.\par
\par
Our analogy would make us expect "date intervals" along these lines:\par
\par
 1994-03-02            1994-01-31\par
-1994-01-31           +0000-01-02\par
 ----------            ----------\par
 0000-01-02            1994-03-02\par
\par
but SQL considers these calculations to be illegal because year-month\par
intervals are not compatible with day-time intervals. That is, in SQL temporal\par
arithmetic, you cannot carry from the days field to the months field, nor\par
borrow from the months field to the days field. There is a way to get around\par
what we call "The Day-Month Arithmetic Barrier" -- but first we'll look at the\par
interval combinations that are encouraged by the Standard.\par
      ## As stated earlier, the year-month intervals are compatible with each other, so this is legal:\par
\par
   INTERVAL '0000' YEAR + INTERVAL '00' MONTH\par
\par
The result is INTERVAL '0000-00' YEAR TO MONTH.\par
      ## The day-time intervals are also compatible with each other, so this is legal:\par
\par
   INTERVAL '00:00' HOUR TO MINUTE + INTERVAL '00:00' MINUTE TO SECOND\par
\par
The result is INTERVAL '00:00:00' HOUR TO SECOND.\par
      ## Since year-month intervals and day-time intervals are no compatible, this is illegal:\par
\par
   INTERVAL '00' MONTH + INTERVAL '01' DAY\par
\par
(From this it is apparent that the Standard's words "INTERVAL <data type>" are\par
misleading. For all practical purposes we really have two <data types> that\par
are not compatible with one other.)\par
\par
The 1998 movie TITANIC was billed as a "2 hour 74 minute" movie. This is\par
legitimate if there is no law that says "when number of minutes is greater\par
than or equal to 60, carry into the hours column". Similarly, SQL allows\par
<interval literal>s like:\par
\par
   INTERVAL '02:74' HOUR TO MINUTE\par
\par
In fact, the amount in the secondary datetime fields may be any 2 digit\par
integer ranging from 0 to 99 (assuming you're using SQL's defaults). This is\par
not to say, though, that the result of temporal arithmetic operations should\par
look odd -- as with assignment and comparison, your DBMS will normalize the\par
result  to maintain the integrity of its datetime <data type>. For year-month\par
intervals, it carries: (if month>=12 carry to year). For the day-time\par
intervals, it also carries: (if second>=60 carry to minute), (if minute>=60\par
carry to hour), (if hour>=24 carry to day). Because the result is normalized,\par
this expression:\par
\par
   INTERVAL '02:74' HOUR TO MINUTE + INTERVAL '00:00' HOUR TO MINUTE\par
\par
yields:\par
\par
   INTERVAL '03:14' HOUR TO MINUTE\par
\par
Here, then, is the syntax allowed for temporal expressions:\par
\par
datetime expression ::=\par
datetime value [ AT \{LOCAL | TIME ZONE <time zone interval\} ] | \par
interval expression + datetime value [ AT \{LOCAL | TIME ZONE <time zone interval\} ] | \par
datetime value [ AT \{LOCAL | TIME ZONE <time zone interval\} ] + interval term | \par
datetime value [ AT \{LOCAL | TIME ZONE <time zone interval\} ] - interval term\par
\par
interval expression ::=\par
interval term | \par
interval expression + interval term | \par
interval expression - interval term | \par
(datetime expression - datetime value [ AT \{LOCAL | TIME ZONE <time zone interval\} ]) <interval qualifier>\par
\par
   interval term ::=\par
   [ + | - ] interval value | \par
   [ + | - ] interval value * number | \par
   [ + | - ] interval value / number | \par
   number * [ + | - ] interval value\par
\par
Datetime expressions may only contain values of the same type. A datetime\par
expression involving dates evaluates to a date. A datetime expression\par
involving times evaluates to a time. A datetime expression involving\par
timestamps evaluates to a timestamp. The optional AT LOCAL or AT TIME ZONE\par
clause is valid only for datetime values that evaluate to times or to\par
timestamps. The first case -- e.g.: TIME '10:15:00' AT LOCAL -- means you want\par
the time value to be adjusted to the current default time zone offset for the\par
SQL-session; this is the default situation. The second case, -- e.g.:\par
TIMESTAMP '1994-07-15 14:00:00' AT TIME ZONE INTERVAL '-04:00' HOUR TO MINUTE\par
-- means you want the timestamp value to be adjusted to the time zone offset\par
you've specified. The result <data type> is TIME WITH TIME ZONE or TIMESTAMP\par
WITH TIME ZONE, as applicable. If <time zone interval> is NULL, the result of\par
the operation is also NULL.\par
\par
Interval expressions may only contain values of the same type. An interval\par
expression involving year-month intervals evaluates to a year-month interval.\par
An interval expression involving day-time intervals evaluates to a day-time interval.\par
\par
All temporal arithmetic depends on the concept of the interval: a span of time\par
expressed in calendar or clock units (as appropriate). Intervals may only be\par
used with datetime and/or interval expressions that involve at least one\par
compatible datetime field. For example, this is a legal expression:\par
\par
   start_date + INTERVAL '2' MONTH\par
\par
because a date and the specified interval have the MONTH field in common. This\par
is not a legal expression:\par
\par
   start_date + (INTERVAL '2' MONTH + INTERVAL '1' DAY)\par
\par
because the interval expression inside the parentheses would have to be\par
evaluated first, and the two intervals have no datetime fields in common.\par
\par
These rules apply for date arithmetic:\par
      ## If one operand evaluates to a date, the other operand must evaluate\par
to a date, an INTERVAL YEAR, an INTERVAL MONTH, an INTERVAL YEAR TO MONTH or\par
an INTERVAL DAY.\par
      ## You can't add two dates. You can only add a date and an interval.\par
      ## You can subtract a date from a date and you can subtract an interval\par
from a date. You can't subtract a date from an interval.\par
      ## Date expressions are evaluated according to the rules for valid\par
Gregorian calendar dates. If the result is an invalid date, the expression\par
will fail: your DBMS will return the SQLSTATE error 22008 "data\par
exception-datetime field overflow".\par
      ## Remember that if your interval operand is a year-month interval,\par
there is no carry from the date operand's DAY field. Thus while this expression:\par
\par
   DATE '1997-07-31' + INTERVAL '1' MONTH\par
\par
returns DATE '1997-08-31' as expected, the result of this expression:\par
\par
   DATE '1997-10-31' + INTERVAL '1' MONTH\par
\par
is an error. There is no DAY field carry, so the result evaluates to DATE '1997-11-31' -- an invalid date.\par
\par
These rules apply for time arithmetic:\par
      ## If one operand evaluates to a time, the other operand must evaluate\par
to a time, an INTERVAL DAY, an INTERVAL HOUR, an INTERVAL MINUTE, an INTERVAL\par
SECOND, an INTERVAL DAY TO HOUR, an INTERVAL DAY TO MINUTE, an INTERVAL DAY TO\par
SECOND, an INTERVAL HOUR TO MINUTE, an INTERVAL HOUR TO SECOND or an INTERVAL\par
MINUTE TO SECOND.\par
      ## You can't add two times. You can only add a time and an interval.\par
      ## You can subtract a time from a time and you can subtract an interval\par
from a time. You can't subtract a time from an interval.\par
      ## Time expressions are evaluated modulo 24 -- that is:\par
\par
   TIME '19:00:00' + INTERVAL '9' HOUR\par
\par
returns TIME '04:00:00'. If the result is an invalid time, the expression will\par
fail: your DBMS will return the SQLSTATE error 22008 "data exception-datetime\par
field overflow".\par
      ## The result of an operation between operands containing a SECONDs\par
value has a fractional seconds precision that is the greater of the operands'\par
fractional seconds precisions.\par
      ## [Obscure Rule] Arithmetic operations involving a time and an interval\par
preserve the time operand's <time zone interval>. If your operand is a time\par
without time zone, then the current default time zone offset is assumed.\par
\par
These rules apply for timestamp arithmetic:\par
      ## If one operand evaluates to a timestamp, the other operand must\par
evaluate to a timestamp, an INTERVAL YEAR, an INTERVAL MONTH, an INTERVAL YEAR\par
TO MONTH, an INTERVAL DAY, an INTERVAL HOUR, an INTERVAL MINUTE, an INTERVAL\par
SECOND, an INTERVAL DAY TO HOUR, an INTERVAL DAY TO MINUTE, an INTERVAL DAY TO\par
SECOND, an INTERVAL HOUR TO MINUTE, an INTERVAL HOUR TO SECOND or an INTERVAL\par
MINUTE TO SECOND.\par
      ## You can't add two timestamps. You can only add a timestamp and an interval.\par
      ## You can subtract a timestamp from a timestamp and you can subtract an\par
interval from a timestamp. You can't subtract a timestamp from an interval.\par
      ## Timestamp expressions are evaluated according to the rules for valid\par
Gregorian calendar dates. This means that, unlike time expressions, timestamp\par
expressions are not evaluated modulo 24 because HOURs will carry to/from DAYs.\par
Thus, the result of this expression:\par
\par
   TIMESTAMP '1997-07-15 19:00:00' + INTERVAL '9' HOUR\par
\par
is TIMESTAMP '1997-07-16 04:00:00'. If the result of a timestamp expression is\par
an invalid timestamp, the expression will fail: your DBMS will return the\par
SQLSTATE error 22008 "data exception-datetime field overflow".\par
      ## The result of an operation between operands containing a SECONDs\par
value has a fractional seconds precision that is the greater of the operands'\par
fractional seconds precisions.\par
      ## [Obscure Rule] Arithmetic operations involving a timestamp and an\par
interval preserve the timestamp operand's <time zone interval>. If your\par
operand is a timestamp without time zone, then the current default time zone\par
offset is assumed.\par
\par
These additional rules apply for INTERVAL arithmetic:\par
      ## If one operand evaluates to a year-month interval, the other operand\par
must evaluate to a year-month interval, a date or a timestamp. If one operand\par
evaluates to a day-time interval, the other operand must evaluate to a day-\par
time interval, a date, a time or a timestamp.\par
      ## You can add two intervals of the same type.\par
      ## You can subtract two intervals of the same type.\par
      ## You can multiply an interval with a number, or a number with an interval.\par
      ## You can divide an interval by a number. You can't divide a number by an interval.\par
      ## The result of an operation between interval operands containing a\par
SECONDs value has a fractional seconds precision that is the greater of the\par
operands' fractional seconds precisions.\par
      ## Interval expressions that result in invalid intervals will fail: your\par
DBMS will return the SQLSTATE error 22015 "data exception-interval field overflow".\par
\par
If you want to restrict your code to Core SQL, don't add or subtract datetime\par
expressions, don't add the optional AT LOCAL/AT TIME ZONE clause to any time\par
or timestamp value and don't use interval expressions at all.\par
\par
Coming back to the problem of subtracting two dates, we can see that the expression:\par
\par
   DATE '1994-03-02' - DATE '1994-01-31'\par
\par
is impossible on the face of it, because it would yield a nonexistent\par
year-month-day interval. The converse is also true -- the expression:\par
\par
   DATE '1994-01-31' + INTERVAL '0000-01-02' YEAR TO DAY\par
\par
will return a syntax error. All, however, is not lost. When subtracting these\par
dates, you can force the result with the syntax (datetime expression -\par
datetime value) <interval qualifier>, where the result is determined by the\par
least significant datetime field in <interval qualifier>. For example, if you\par
want to know the difference between the two dates in years, use:\par
\par
   (DATE '1994-03-02' - DATE '1994-01-31') YEAR\par
\par
which results in INTERVAL '00' YEAR. (The least significant datetime field in\par
the interval is YEAR, and 1994-1994 is zero.) If you want to know the\par
difference between the two dates in months, use:\par
\par
   (DATE '1994-03-02' - DATE '1994-01-31') MONTH\par
\par
which results in INTERVAL '02' MONTH. (Note that this is not the "intuitive"\par
answer one might expect! The least significant field in the interval is MONTH,\par
and ((1994*12 months)+ 3 months)-((1994*12 months)+ 1 month) is two, so even\par
though we can see that the difference between the dates is not a full two\par
months, the correct SQL result is two.) If you want to know the difference\par
between the two dates in years and months, use:\par
\par
   (DATE '1994-03-02' - DATE '1994-01-31') YEAR TO MONTH\par
\par
which results in INTERVAL '00-01' YEAR TO MONTH. If you want to know the\par
difference between the two dates in days, use:\par
\par
   (DATE '1994-03-02' - DATE '1994-01-31') DAY\par
\par
which results in INTERVAL '30' DAY. (The least significant field in the\par
interval is DAY, and (61 days - 31 days) is 30.) \par
\par
A runaway serf must hide in a town for a year and a day to gain freedom. If he\par
runs away on March 12 1346, when can he party? SQL doesn't allow this\par
expression:\par
\par
   DATE '1346-03-12' + (INTERVAL '1' YEAR + INTERVAL '1' DAY)\par
\par
since the two interval types can't combine. But they each go well with a date, so:\par
\par
   (DATE '1346-03-12' + INTERVAL '1' YEAR) + INTERVAL '1' DAY\par
\par
yields DATE '1347-03-13'. (The parentheses here are optional, because calculation is left-to-right.)\par
\par
errors\par
The three common arithmetic exception conditions are:\par
SQLSTATE 22007 -- data exception - invalid datetime format\par
      ## e.g.: returned for this result: DATE '1994-02-30'\par
SQLSTATE 22008 -- data exception - datetime field overflow\par
      ## e.g.: returned for this expression: DATE '9999-01-01' + INTERVAL '1-00' YEAR TO MONTH\par
SQLSTATE 22015 -- data exception - interval field overflow\par
      ## e.g.: returned for this result: INTERVAL '999-11' YEAR TO MONTH (too many digits in leading field)\par
SQLSTATE 22009 -- data exception - invalid time zone displacement value\par
      ## e.g.: returned for this result: TIME '02:00:00+14:00'\par
\par
## Scalar functions\par
SQL provides nine scalar functions that return a temporal value: the <case\par
expression>, the <cast specification>, the current date value function, the\par
current time value function, the current timestamp value function, the current\par
local time value function and the current local timestamp value function\par
(we'll call these five the niladic datetime functions), the <extract\par
expression> and the <interval absolute value function>. We'll discuss all but\par
the first two here. Look for the rest in other chapters; for now, just\par
remember that they evaluate to a temporal value and can therefore be used\par
anywhere in SQL that a temporal value could be used.\par
\par
niladic datetime functions --\par
The required syntax for a niladic datetime function is:\par
\par
niladic datetime function ::=\par
CURRENT_DATE | \par
CURRENT_TIME [ (fractional seconds precision) ] | \par
CURRENT_TIMESTAMP [ (fractional seconds precision) ] | \par
LOCALTIME [ (fractional seconds precision) | \par
LOCALTIMESTAMP [ (fractional seconds precision) ] \par
\par
CURRENT_DATE is a niladic datetime function with a result <data type> of DATE.\par
It returns "today": that is, the current date. Here is an example of CURRENT_DATE:\par
\par
   ...WHERE date_column = CURRENT_DATE\par
\par
CURRENT_TIME is a niladic datetime function with a result <data type> of TIME\par
WITH TIME ZONE. It returns "now": that is, the current time, with a time zone\par
offset equal to the SQL-session default time zone offset. The default time\par
zone offset is the <time zone interval> specified in the most recent SET TIME\par
ZONE statement issued during the SQL-session. If you haven't issued a SET TIME\par
ZONE statement, the default time zone offset is your DBMS's initial default\par
time zone offset.\par
      ## [NON-PORTABLE] The default time zone offset is non-standard because\par
the SQL Standard requires implementors to define the initial default time zone\par
offset for an SQL-session.\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
sets the SQL-session's initial default time zone offset to INTERVAL +'00:00'\par
HOUR TO MINUTE -- this represents UTC.\par
\par
Here is an example of CURRENT_TIME:\par
\par
   ...WHERE time_column <> CURRENT_TIME\par
\par
As with the TIME WITH TIME ZONE <data type>, the optional fractional seconds\par
precision, if specified, is an unsigned integer that specifies the number of\par
digits following the decimal point in the SECONDs field of CURRENT_TIME's\par
result.\par
\par
CURRENT_TIMESTAMP is a niladic datetime function with a result <data type> of\par
TIMESTAMP WITH TIME ZONE. It returns "now": that is, the current time "today",\par
with a time zone offset equal to the SQL-session default time zone offset. As\par
with the TIMESTAMP WITH TIME ZONE <data type>, the optional fractional seconds\par
precision, if specified, is an unsigned integer that specifies the number of\par
digits following the decimal point in the SECONDs field of CURRENT_TIMESTAMP's\par
result. Here is an example of CURRENT_TIMESTAMP:\par
\par
   ...WHERE timestamp_column > CURRENT_TIMESTAMP\par
\par
LOCALTIME is a niladic datetime function with a result <data type> of TIME. It\par
returns "now-here": that is, the current local time, with no time zone offset.\par
As with the TIME <data type>, the optional fractional seconds precision, if\par
specified, is an unsigned integer that specifies the number of digits\par
following the decimal point in the SECONDs field of LOCALTIME's result. The\par
result of LOCALTIME is obtained by casting CURRENT_TIME's result -- that is:\par
\par
   LOCALTIME = CAST (CURRENT_TIME AS TIME)\par
\par
or, if fractional seconds precision is specified:\par
\par
   LOCALTIME(precision) = CAST (CURRENT_TIME(precision) AS TIME(precision))\par
\par
Here is an example of LOCALTIME:\par
\par
   ...WHERE time_column < LOCALTIME\par
\par
LOCALTIMESTAMP is a niladic datetime function with a result <data type> of\par
TIMESTAMP. It returns "now-here": that is, the current local time "today",\par
with no time zone offset. As with the TIMESTAMP <data type>, the optional\par
fractional seconds precision, if specified, is an unsigned integer that\par
specifies the number of digits following the decimal point in the SECONDs\par
field of LOCALTIMESTAMP's result. The result of LOCALTIMESTAMP is obtained by\par
casting CURRENT_TIMESTAMP's result -- that is:\par
\par
   LOCALTIMESTAMP = CAST (CURRENT_TIMESTAMP AS TIMESTAMP)\par
\par
or, if fractional seconds precision is specified:\par
\par
   LOCALTIMESTAMP(precision) = CAST (CURRENT_TIMESTAMP(precision) AS TIMESTAMP(precision))\par
\par
Here is an example of LOCALTIMESTAMP:\par
\par
   ...WHERE timestamp_column >= LOCALTIMESTAMP\par
\par
All niladic datetime functions in a SQL statement are effectively evaluated at\par
the same time; that is, all references to CURRENT_DATE, CURRENT_TIME,\par
CURRENT_TIMESTAMP, LOCALTIME or LOCALTIMESTAMP in a single SQL statement will\par
return their respective values based on a single clock reading. CURRENT_DATE,\par
CURRENT_TIMESTAMP and LOCALTIMESTAMP will therefore always return the same\par
date, and CURRENT_TIME, CURRENT_TIMESTAMP, LOCALTIME and LOCALTIMESTAMP will\par
always return the same effective time, when used within the same SQL\par
statement. \par
      ## [NON-PORTABLE] The timing of the clock reading for the evaluation of\par
these functions is non-standard because the SQL Standard requires implementors\par
to define when the clock is read. The choices are to read the clock at the\par
beginning of a transaction, at the end of a transaction or somewhere in-\par
between.\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
reads the clock immediately prior to performing any operations based on a\par
niladic datetime function. \par
\par
If you want to restrict your code to Core SQL, don't use CURRENT_TIME or\par
CURRENT_TIMESTAMP, don't specify a fractional seconds precision for LOCALTIME\par
and don't specify a fractional seconds precision for LOCALTIMESTAMP other than\par
zero or 6.\par
\par
<extract expression> --\par
The required syntax for an <extract expression> is:\par
\par
<extract expression> ::=\par
EXTRACT(datetime_field FROM temporal_argument)\par
\par
EXTRACT operates on an argument that evaluates to a date, a time, a timestamp\par
or an interval. It extracts the numeric value of "datetime_field" from\par
"temporal_argument" and returns it as a exact numeric value. If the argument\par
is NULL, EXTRACT returns NULL.\par
\par
The "datetime_field" may be any one of: YEAR, MONTH, DAY, HOUR, MINUTE,\par
SECOND, TIMEZONE_HOUR or TIMEZONE_MINUTE. If "datetime_field" is TIMEZONE_HOUR\par
or TIMEZONE_MINUTE, "temporal_argument" must evaluate to a TIME WITH TIME ZONE\par
value or a TIMESTAMP WITH TIME ZONE value.\par
\par
For any "datetime_field" other than SECOND, EXTRACT returns an integer. For a\par
"datetime_field" of SECOND, EXTRACT returns a decimal number. For example:\par
\par
   EXTRACT (MINUTE FROM INTERVAL '-05:01:22.01' HOUR TO SECOND)\par
\par
returns the integer -1 (when "temporal_argument" is a negative interval, the\par
result will be a negative number).\par
\par
   EXTRACT (SECOND FROM INTERVAL '-05:01:22.01' HOUR TO SECOND)\par
\par
returns the decimal number -22.01.\par
\par
[NON-PORTABLE] The precision of EXTRACT's result is non-standard because the\par
SQL Standard requires implementors to define the result's precision and (if\par
applicable) the result's scale. (The scale defined must be at least large\par
enough to accept the full size of the argument's fractional seconds precision.)\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
gives the result of EXTRACT an INTEGER <data type> for all "datetime_field"s\par
other than SECOND. It gives the result of EXTRACT a DECIMAL(8,2) <data type>\par
for a "datetime_field" of SECOND.\par
\par
Here is a SQL statement which extracts the YEAR field from a timestamp:\par
\par
   SELECT EXTRACT(YEAR FROM occurrence_timestamp) \par
   FROM   Timestamp_Examples;\par
\par
The result is the integer 2001.\par
\par
If you want to restrict your code to Core SQL, don't use EXTRACT.\par
\par
<interval absolute value function> --\par
The required syntax for an <interval absolute value function> is:\par
\par
<interval absolute value function> ::=\par
ABS (interval_argument)\par
\par
ABS operates on an argument that evaluates to an interval. It strips a\par
negative sign (if it's present) from the argument and returns a non-negative\par
interval whose <data type> is the same as the argument's <data type>, e.g.:\par
ABS('-05' YEAR) returns '5' YEAR, ABS('05' YEAR) returns '05' YEAR and\par
ABS('00' YEAR) returns '00' YEAR. If the argument is NULL, ABS returns NULL.\par
\par
[Obscure Rule] ABS can also operate on a number. We've ignored this option for\par
now -- look for it in our chapter on numbers.\par
\par
If you want to restrict your code to Core SQL, don't use ABS with an interval argument.\par
\par
## Set functions\par
SQL provides five set functions that operate on datetime values: COUNT(*),\par
COUNT, MAX, MIN and GROUPING. SQL also provides seven set functions that\par
operate on intervals: COUNT(*), COUNT, MAX, MIN, SUM, AVG and GROUPING. Since\par
none of these operate exclusively with temporal argument, we won't discuss\par
them here; look for them in our chapter on set functions.\par
\par
## Predicates\par
In addition to the comparison operators, SQL provides nine other predicates\par
that operate on temporal values: the <overlaps predicate>, the <between\par
predicate>, the <in predicate>, the <null predicate>, the <exists predicate>,\par
the <unique predicate>, the <match predicate>, the <quantified predicate> and\par
the <distinct predicate>. Each will return a boolean value: either TRUE, FALSE\par
or UNKNOWN. Only the first predicate operates strictly on temporal values;\par
we'll discuss it here. Look for the rest in our chapter on search conditions.\par
\par
<overlaps predicate> --\par
The required syntax for an <overlaps predicate> is:\par
\par
<overlaps predicate> ::=\par
(datetime_argument_1, temporal_argument_1) \par
OVERLAPS \par
(datetime_argument_2, temporal_argument_2) \par
\par
OVERLAPS is a predicate that operates on two operands that evaluate to a\par
period of time. It compares either a pair of datetimes, or a datetime and an\par
interval, to test whether the two periods overlap in time. It returns TRUE if\par
they do, FALSE if they don't and UNKNOWN if the result can't be determined\par
because of NULL arguments.\par
\par
Each OVERLAPS operand is a parenthesized pair of temporal arguments separated\par
by a comma. (This is a special case of a <row value expression>). The first\par
argument in each operand must evaluate either to a date, a time or a\par
timestamp. The second argument in each operand must either (a) evaluate to the\par
same datetime <data type> as the first argument or (b) evaluate to an interval\par
that contains only the same datetime fields as the first argument. Each pair\par
of arguments represents a period, as either "start to end" or "start and\par
interval". The possible argument combinations are thus:\par
   ## (date,date) OVERLAPS (date,date)\par
   ## (date,date) OVERLAPS (date,interval of years or months or days)\par
   ## (date,interval of years or months or days) OVERLAPS (date,date)\par
   ## (date,interval of years or months or days) OVERLAPS (date,interval of years or months or days)\par
   ## (time,time) OVERLAPS (time,time)\par
   ## (time,time) OVERLAPS (time,interval of hours or minutes or seconds)\par
   ## (time,interval of hours or minutes or seconds) OVERLAPS (time,time)\par
   ## (time,interval of hours or minutes or seconds) OVERLAPS (time,interval of hours or minutes or seconds)\par
   ## (timestamp,timestamp) OVERLAPS (timestamp,timestamp)\par
   ## (timestamp,timestamp) OVERLAPS (timestamp,interval of years or months or days or hours or minutes or seconds)\par
   ## (timestamp,interval of years or months or days or hours or minutes or seconds) OVERLAPS (timestamp,timestamp)\par
   ## (timestamp,interval of years or months or days or hours or minutes or seconds) OVERLAPS (timestamp,interval of years or months or days or hours or minutes or seconds)\par
\par
Here is an example of a search condition using OVERLAPS:\par
\par
   (DATE '1994-01-01',DATE '1994-05-01') OVERLAPS \par
   (DATE '1993-07-01',DATE '1994-03-01')\par
\par
The example is asking whether the two temporal periods overlap as in this diagram:\par
\par
                   January 1 1994                      May 1 1994\par
                   **********************************************\par
                   ^               ^\par
July 1 1993                        March 1 1994\par
***********************************************\par
\par
The diagram shows us that there is an overlap: the search condition result is\par
TRUE. In this example, both OVERLAPS operands are "start to end" argument\par
pairs: they're both of the same <data type>. Here is an equivalent example,\par
using "start and interval" argument pairs instead:\par
\par
   (DATE '1994-01-01',INTERVAL '05' MONTH) OVERLAPS \par
   (DATE '1993-07-01',INTERVAL '08' MONTH)\par
\par
(The INTERVAL argument must be compatible with the datetime <data type>, so\par
that the operation "datetime + interval" will be possible. This is how\par
OVERLAPS determines the "end" argument.)\par
\par
OVERLAPS is really a comparison operation, whose result is determined by this\par
equivalent search condition (the OVERLAPS "datetime_argument_1" is\par
"first_start", "temporal_argument_1" is "first_end", "datetime_argument_2" is\par
"second_start" and "temporal_argument_2" is "second_end"):\par
\par
   (first_start>second_start AND \par
      (first_start<second_end OR first_end<second_end)) \par
   OR \par
   (second_start>first_start AND \par
      (second_start<first_end OR second_end<first_end)) \par
   OR \par
   (first_start=second_start AND \par
      (first_end<>second_end OR first_end=second_end)) \par
\par
If the second argument of a pair is smaller than the first (i.e.: if the end\par
point is earlier in time than the start point) or if the first argument of a\par
pair is NULL, OVERLAPS switches them around. For example, if the search\par
condition contains:\par
\par
   (DATE '1994-01-01',DATE '1993-05-01') OVERLAPS \par
   (DATE '1993-07-01',DATE '1994-03-01')\par
\par
the expression your DBMS will actually evaluate is:\par
\par
   (DATE '1993-05-01',DATE '1994-01-01') OVERLAPS \par
   (DATE '1993-07-01',DATE '1994-03-01')\par
\par
which evaluates to TRUE: the periods overlap. If the search condition contains:\par
\par
   (NULL,DATE '1994-05-01') OVERLAPS \par
   (DATE '1993-07-01',DATE '1994-03-01')\par
\par
the expression your DBMS will actually evaluate is:\par
\par
   (DATE '1994-05-01',NULL) OVERLAPS \par
   (DATE '1993-07-01',DATE '1994-03-01')\par
\par
which evaluates to UNKNOWN. However, this search condition evaluates to TRUE, despite the NULL argument:\par
\par
   (DATE '1994-07-01',INTERVAL '06' MONTH') OVERLAPS \par
   (DATE '1994-08-01',NULL)\par
\par
If you want to restrict your code to Core SQL, don't use the OVERLAPS predicate.\par
\par
Dialects\par
\par
The "typical" SQL DBMS supports date, time and timestamp data types but\par
interval (as a separate data type) is not common yet. The majority of SQL\par
DBMSs can't handle time zones, can't handle fractional seconds and can't\par
handle leap seconds. For example, the Oracle DATE data type is typically a\par
timestamp (i.e.: it includes both a date portion and a time portion, despite\par
the name) with no fractional seconds, formatted as DD-MON-YY (e.g.:\par
06-JAN-97). Valid dates fall into the range January 1 4712 B.C. to December 31\par
4712 A.D. Intervals are expressed only as integers, representing number of\par
days. The Oracle SYSDATE function returns the current date and the current time.\par
\par
ODBC has several datetime functions; most are replaceable with standard SQL.\par
Here are the different names to expect.\par
\par
Standard                      ODBC        \par
CURRENT_DATE                  CURDATE\par
CURRENT_TIME                  CURTIME\par
CURRENT_TIMESTAMP             NOW\par
EXTRACT(MONTH ...             MONTH\par
(EXTRACT(MONTH...)/4          QUARTER\par
EXTRACT(DAY ...               DAYOFMONTH\par
not supported                 DAYOFWEEK\par
not supported                 DAYOFYEAR\par
EXTRACT(HOUR ...              HOUR\par
EXTRACT(MINUTE ...            MINUTE\par
EXTRACT(SECOND ...            SECOND            \par
\par
The SQL Library\par
\par
Before we finish discussing temporal values, it's time to add something to our\par
SQL library. To be worthy of addition to the SQL library, a routine must (a)\par
be good clean SQL, (b) be callable from C and Delphi, (c) be actually useful\par
in C and Delphi because it does something that those languages can't and (d)\par
have nothing at all do with "databases" -- it should be available for use just\par
like any general function library.\par
\par
Our addition to the SQL library for this chapter will check dates for SQL\par
validity. Here it is.\par
\par
/* proleptic test -- test whether the DBMS uses a proleptic calendar\par
   Pass:   Nothing\par
   Return: 0 DBMS uses standard SQL with proleptic Gregorian calendar\par
           1 DBMS uses standard SQL with corrected Gregorian calendar\par
           2 DBMS has deviant date calculator\par
           3 DBMS does not understand standard SQL syntax */\par
int proleptic_test (void *)\par
\{\par
  int x;\par
  VALUES(DATE '1999-12-31');\par
  SQLBindCol\par
  SQLFetch(&x);\par
  if (sqlcode==100 no data) return (3);\par
  if (x==...) return (0);\par
  if (x==...) return (1);\par
  return (2); \}\par
\par
/* date_valid_test -- test whether a date is valid\par
   Pass:   A string containing a date in the format yyyy-mm-dd\par
   Return: 0 date is valid\par
           <0     date is not valid\par
           >0     date is valid but a warning was set */\par
int date_valid_test (char *szdate)\par
\{\par
  char      tmp[128];\par
  strcpy(tmp,"VALUES (DATE '");\par
  strcat(tmp,szdate);\par
  strcat(tmp,"');");\par
  return (SQLExecDirect(-1,tmp)); \}\par
\page\par
Chapter 9 -- Boolean values\par
\par
In SQL, a Boolean value -- either TRUE, FALSE or UNKNOWN -- is a truth value.\par
A Boolean value may be a <literal>, the value of a parameter or a host\par
language variable or the result of any expression or argument (including a\par
possibly qualified <Column name> or the result of an SQL predicate or search\par
condition) that evaluates to a truth value. Boolean values are stored in the\par
Boolean <data type>: BOOLEAN.\par
\par
<Boolean literal>s\par
\par
A <Boolean literal> is one of these three words:\par
      ## TRUE\par
      ## FALSE\par
      ## UNKNOWN\par
Its <data type> is BOOLEAN. A <Boolean literal> of TRUE represents the truth\par
value TRUE, a <Boolean literal> of FALSE represents the truth value FALSE and\par
a <Boolean literal> of UNKNOWN represents the truth value UNKNOWN.\par
\par
If you want to restrict your code to Core SQL, don't use <Boolean literal>s.\par
\par
Boolean <data type>s\par
\par
A Boolean <data type> is defined by a descriptor that contains one piece of information:\par
      ## The <data type>'s name: BOOLEAN.\par
\par
BOOLEAN:\par
The required syntax for a BOOLEAN <data type> specification is:\par
\par
BOOLEAN <data type> ::=\par
BOOLEAN\par
\par
BOOLEAN defines a set of truth values: either TRUE, FALSE or UNKNOWN (as the null value).\par
\par
The SQL Standard doesn't differentiate between BOOLEAN's null value (that is,\par
UNKNOWN) and the UNKNOWN truth value that is returned by an SQL predicate,\par
search condition or by any argument or expression that returns a Boolean value\par
-- it allows both to be used interchangeably to mean the same thing. Warning:\par
by saying that UNKNOWN and NULL are the same thing, one is saying that the\par
answers "I don't know" and "I know that the data is missing" are the same\par
thing. The drafters of the SQL Standard apparently forgot the distinction, and\par
they have been justly criticized for this error.\par
\par
If you want to restrict your code to Core SQL, don't define any BOOLEAN <data type>s.\par
\par
Now that we've described SQL's Boolean <data type>, let's look at some example\par
SQL statements that put it to use.\par
\par
These SQL statements make a Table with three Boolean Columns, insert a row,\par
then search for a pair of equal Column values.\par
\par
   CREATE TABLE Logicals (\par
      boolean_1 BOOLEAN,\par
      boolean_2 BOOLEAN,\par
      boolean_3 BOOLEAN);\par
\par
   INSERT INTO Logicals (\par
      boolean_1,\par
      boolean_2,\par
      boolean_3)\par
   VALUES (TRUE,FALSE,UNKNOWN);\par
\par
   SELECT boolean_1\par
   FROM   Logicals\par
   WHERE  boolean_1 = boolean_3;\par
\par
Boolean Operations\par
\par
A Boolean value is compatible with, and comparable to, all other Boolean\par
values and all SQL truth values (for example, the truth values returned by an\par
SQL predicate) -- that is, all truth values are mutually comparable and\par
mutually assignable. Truth values may not be directly compared with, or\par
directly assigned to, any other <data type> class, though implicit type\par
conversions can occur in expressions, SELECTs, INSERTs, DELETEs and UPDATEs.\par
Explicit truth value type conversions can be forced with the CAST operator.\par
\par
CAST:\par
In SQL, CAST is a scalar operator that converts a given scalar value to a\par
given scalar <data type>. The required syntax for the CAST operator is:\par
\par
CAST (<cast operand> AS <cast target>)\par
\par
   <cast operand> ::= scalar_expression\par
\par
   <cast target> ::= <Domain name> | <data type>\par
\par
The CAST operator converts values of a source <data type> into values of a\par
target <data type>, where each <data type> is an SQL pre-defined <data type>\par
(data conversions between UDTs are done with a user-defined cast). The source\par
<data type>, or <cast operand>, can be any expression that evaluates to a\par
single value. The target <data type>, or <cast target>, is either an SQL\par
predefined <data type> specification or the name of a Domain whose defined\par
<data type> is the SQL predefined <data type> that you want to convert the\par
value of "scalar_expression" into. (If you use CAST (... AS <Domain name>),\par
your current <AuthorizationID> must have the USAGE Privilege on that Domain.)\par
\par
It isn't, of course, possible to convert the values of every <data type> into\par
the values of every other <data type>. For Boolean values, the rules are:\par
      ## CAST (NULL AS <data type>) and CAST (Boolean_source_is_a_null_value AS <data type>)\par
both result in a CAST result of NULL.\par
      ## You can CAST a Boolean source to these targets: fixed length\par
character string, variable length character string, CLOB, NCLOB and Boolean.\par
You can also CAST a Boolean source to a UDT target or a <reference type>\par
target if a user-defined cast exists for this purpose and your current\par
<AuthorizationID> has the EXECUTE Privilege on that user-defined cast.\par
\par
When you CAST a Boolean value to a Boolean target, the result of the CAST is the source value.\par
\par
When you CAST a Boolean value to a fixed length character string target, there are four possibilities:\par
      ## The source value is TRUE and the fixed length of the target is at\par
least four characters. In this case, the result of the CAST is 'TRUE', padded\par
on the right with spaces, if necessary, to make it the exact fixed length of the target.\par
      ## The source value is FALSE and the fixed length of the target is at\par
least five characters. In this case, the result of the CAST is 'FALSE', padded\par
on the right with spaces, if necessary, to make it the exact fixed length of the target.\par
      ## The source value is UNKNOWN. As already stated, the result of the CAST is NULL.\par
      ## The fixed length of the target is less than the length of the source\par
value. In this case, the CAST will fail: your DBMS will return the SQLSTATE\par
error 22018 "data exception-invalid character value for cast".\par
\par
When you CAST a Boolean value to a variable length character string, CLOB or\par
NCLOB target, there are four possibilities:\par
      ## The source value is TRUE and the maximum length of the target is at\par
least four characters. In this case, the result of the CAST is 'TRUE'.\par
      ## The source value is FALSE and the fixed length of the target is at\par
least five characters. In this case, the result of the CAST is 'FALSE'.\par
      ## The source value is UNKNOWN. As already stated, the result of the CAST is NULL.\par
      ## The maximum length of the target is less than the length of the\par
source value. In this case, the CAST will fail: your DBMS will return the\par
SQLSTATE error 22018 "data exception-invalid character value for cast".\par
\par
[Obscure Rule] The result of a CAST to a character string target has the\par
COERCIBLE coercibility attribute; its Collation is the default Collation for\par
the target's Character set.\par
\par
When you CAST a Boolean value to a UDT or a <reference type> target, your DBMS\par
invokes the user defined cast routine, with the source value as the routine's\par
argument. The CAST result is the value returned by the user defined cast.\par
\par
If you want to restrict your code to Core SQL, don't use <Domain name> as a\par
CAST target: CAST only to a <data type>.\par
\par
Assignment:\par
In SQL, the TRUE and FALSE truth values may be assigned to any Boolean target\par
and the UNKNOWN truth value may be assigned to any Boolean target that isn't\par
constrained by a NOT NULL Constraint.\par
\par
Comparison:\par
SQL provides the usual scalar comparison operators -- = and <> and < and <=\par
and > and >= -- to perform operations on truth values. All of them will be\par
familiar; there are equivalent operators in other computer languages. In SQL,\par
TRUE is greater than FALSE. If any of the comparands are the UNKNOWN truth\par
value or are NULL, the result of the operation is UNKNOWN. For example:\par
\par
   TRUE = \{result is FALSE\}\par
\par
returns FALSE.\par
\par
   TRUE <> \{result is NULL\}\par
\par
returns UNKNOWN.\par
\par
SQL also provides three quantifiers -- ALL, SOME, ANY -- which you can use\par
along with a comparison operator to compare a truth value with the collection\par
of truth values returned by a <table subquery>. Place the quantifier after the\par
comparison operator, immediately before the <table subquery>. For example:\par
\par
   SELECT occurrence_boolean\par
   FROM   Boolean_Example\par
   WHERE  occurrence_boolean = ALL (\par
      SELECT char_column\par
      FROM   Table_1\par
      WHERE  char_column LIKE '%e');\par
\par
ALL returns TRUE either (a) if the collection is an empty set (i.e.: if it\par
contains zero rows) or (b) if the comparison operator returns TRUE for every\par
value in the collection. ALL returns FALSE if the comparison operator returns\par
FALSE for at least one value in the collection.\par
\par
SOME and ANY are synonyms. They return TRUE if the comparison operator returns\par
TRUE for at least one value in the collection. They return FALSE either (a) if\par
the collection is an empty set or (b) if the comparison operator returns FALSE\par
for every value in the collection. (The search condition "= ANY (collection)"\par
is equivalent to "IN (collection)".)\par
\par
Other Operations:\par
With SQL, you have several other operations that you can perform on truth\par
values, or on other values to get a truth value result.\par
\par
## Boolean operators\par
SQL provides the usual scalar Boolean operators -- AND and OR and NOT and IS -\par
- to perform operations on Boolean operands. Each returns a Boolean result, or\par
truth value. All of them will be familiar; there are equivalent operators in\par
other computer languages. If any of the operands are the UNKNOWN truth value\par
or are NULL, the result of the operation is UNKNOWN. Here is the syntax\par
allowed for Boolean expressions:\par
\par
<boolean value expression> ::=\par
<boolean term> |\par
<boolean value expression> OR <boolean term>\par
\par
   <boolean term> ::=\par
   [ NOT ] <boolean test> |\par
   <boolean term> AND [ NOT ] <boolean test>\par
\par
      <boolean test> ::=\par
      boolean_argument [ IS [ NOT ] \{TRUE | FALSE | UNKNOWN\} ]\par
\par
A Boolean expression operates on one or more operands that evaluate to a truth\par
value -- that is, the "boolean_argument" shown in this syntax diagram is\par
either a <Boolean literal>, the value of a parameter or a host language\par
variable or the result of any expression or argument (including a possibly\par
qualified <Column name> or -- most often -- the result of an SQL predicate or\par
search condition) that evaluates to a truth value. The result is also a truth\par
value, derived by applying the given Boolean operator(s) to the\par
"boolean_argument" result.\par
\par
IS is a monadic Boolean operator. It tests for a condition: is the result of\par
the expression TRUE, is it FALSE or is it UNKNOWN? You use the <Boolean test>\par
to influence a search condition result, since its effect is to change a\par
Boolean value (which is TRUE or FALSE or UNKNOWN) to either TRUE or FALSE. For\par
example, consider these SQL statements, which create a Table that contains\par
four rows:\par
\par
   CREATE TABLE Boolean_Test (\par
      column_1 SMALLINT);\par
\par
   INSERT INTO Boolean_Test (column_1)\par
   VALUES (5);\par
\par
   INSERT INTO Boolean_Test (column_1)\par
   VALUES (NULL);\par
\par
   INSERT INTO Boolean_Test (column_1)\par
   VALUES (0);\par
\par
   INSERT INTO Boolean_Test (column_1)\par
   VALUES (10);\par
\par
Row 1 of the Table BOOLEAN_TEST contains 5, row 2 contains NULL, row 3\par
contains 0 and row 4 contains 10. Normally, of course, a search for equality\par
doesn't find NULLs -- so the result of this SQL statement:\par
\par
   SELECT column_1\par
   FROM   Boolean_Test\par
   WHERE  column_1 = 5;\par
\par
is row 1 and the result of this SQL statement:\par
\par
   SELECT column_1\par
   FROM   Boolean_Test\par
   WHERE  column_1 <> 5;\par
\par
is row 3 and row 4. If you add a <Boolean test>, though, you can override the\par
comparison's usual result. Thus, the result of this SQL statement:\par
\par
   SELECT column_1\par
   FROM   Boolean_Test\par
   WHERE  (column_1 = 5 IS UNKNOWN);\par
\par
is row 2 -- it returns the rows where the search condition is UNKNOWN, rather\par
than the rows where it is TRUE. The result of this SQL statement:\par
\par
   SELECT column_1\par
   FROM   Boolean_Test\par
   WHERE (column_1 = 5 IS FALSE);\par
\par
is row 3 and row 4 -- it returns only the rows where the search condition is\par
FALSE. The result of this SQL statement:\par
\par
   SELECT column_1\par
   FROM   Boolean_Test\par
   WHERE (column_1 = 5 IS TRUE);\par
\par
is row 1 -- it returns the rows where the search condition is TRUE. Since this\par
is the same result you'd get without the <Boolean test>, adding it is\par
redundant. Finally, the result of this SQL statement:\par
\par
   SELECT column_1\par
   FROM   Boolean_Test\par
   WHERE (column_1 = 5 IS NOT FALSE);\par
\par
is row 1 and row 2 -- it returns the rows where the search condition is either\par
TRUE or UNKNOWN. Table 9-1 shows how the result of a Boolean IS operation is determined.\par
\par
<<<INSERT CHAP9_T1.DOC HERE>>>\par
\par
NOT is a monadic Boolean operator. It negates the result of a Boolean\par
expression (except in the case of NULLs) -- that is:\par
      ## NOT ( TRUE ) returns FALSE.\par
      ## NOT ( FALSE ) returns TRUE.\par
      ## NOT ( UNKNOWN ) returns UNKNOWN.\par
\par
AND is a dyadic Boolean operator. It increases the number of conditions that\par
must be met by a value to be included in a search: the result is TRUE only if\par
both conditions are TRUE. For example, the result of this SQL statement:\par
\par
   SELECT column_1\par
   FROM   Boolean_Test\par
   WHERE (column_1 > 0 AND column_1 < 10);\par
\par
is row 1. Table 9-2 shows how the result of a Boolean AND operation is determined.\par
\par
<<<INSERT CHAP9_T2.DOC HERE>>>\par
\par
OR is a dyadic Boolean operator. It decreases the number of conditions that\par
must be met by a value to be included in a search: the result is TRUE if\par
either condition is TRUE. For example, the result of this SQL statement:\par
\par
   SELECT column_1\par
   FROM   Boolean_Test\par
   WHERE (column_1 > 0 OR column_1 < 10);\par
\par
is row 1 and row 3. Table 9-3 shows how the result of a Boolean OR operation is determined.\par
\par
<<<INSERT CHAP9_T3.DOC HERE>>>\par
\par
\par
The precedence of the Boolean operators and their effect on Boolean values is\par
as follows:\par
\par
   Precedence   Operator   Effect on Boolean value(s)\par
   1.           IS         overrides normal result\par
   2.           NOT        negates result\par
   3.           AND        combines, with logical AND\par
   4.           OR         combines, with logical inclusive OR\par
\par
The precedence shown determines evaluation order, unless you use parentheses\par
to force a different order. Although SQL's three-valued logic can complicate\par
things if we use contrived and unlikely examples, the normal situation is\par
straightforward for any speaker of a human tongue. When we hear the English\par
expression "Martians are vicious and dishonest but not stupid", we know we\par
could search them with the SQL expression "x = 'vicious' AND x = 'dishonest'\par
AND x <> 'stupid'". The correct application of the Boolean operators turns out\par
to be an intuitive calculation for most people. The most common error is to\par
forget what the operator precedence is, and that can be corrected easily:\par
always use parentheses if the search condition contains two different Boolean operators.\par
\par
If you want to restrict your code to Core SQL, don't use the optional truth\par
value Boolean test (i.e.: don't use the constructs "boolean_argument" IS TRUE,\par
"boolean_argument" IS FALSE or "boolean_argument" IS UNKNOWN) and don't use\par
"boolean_argument" unless it's an SQL predicate or it's enclosed in parentheses.\par
\par
## Scalar functions\par
SQL provides no scalar functions that return or operate on a Boolean value.\par
\par
## Set functions\par
SQL provides eight set functions that operate on Booleans: EVERY, ANY, SOME,\par
COUNT(*), COUNT, MAX, MIN and GROUPING. We'll discuss them all in our chapter\par
on set functions.\par
\par
## Predicates\par
Every SQL predicate returns a Boolean value. Since none of them operate\par
strictly on truth values, we won't discuss them here. Look for them in our\par
chapters on search conditions and the various other <data type>s.\par
\par
\par
Table 9-1:\par
Truth Values for the Boolean IS Operator\par
\par
If a Boolean  ... and the     ... then the\par
value is:     operator is:    result is:\par
TRUE          IS TRUE         TRUE\par
TRUE          IS FALSE        FALSE\par
TRUE          IS UNKNOWN      FALSE\par
FALSE         IS TRUE         FALSE\par
FALSE         IS FALSE        TRUE\par
FALSE         IS UNKNOWN      FALSE\par
UNKNOWN       IS TRUE         FALSE\par
UNKNOWN       IS FALSE        FALSE\par
UNKNOWN       IS UNKNOWN      TRUE\par
TRUE          IS NOT TRUE     FALSE\par
TRUE          IS NOT FALSE    TRUE\par
TRUE          IS NOT UNKNOWN  TRUE\par
FALSE         IS NOT TRUE     TRUE\par
FALSE         IS NOT FALSE    FALSE\par
FALSE         IS NOT UNKNOWN  TRUE\par
UNKNOWN       IS NOT TRUE     TRUE\par
UNKNOWN       IS NOT FALSE    TRUE\par
UNKNOWN       IS NOT UNKNOWN  FALSE\par
\par
\par
Table 9-2:\par
Truth Values for the Boolean AND Operator\par
\par
If the first        ... and the second   ... then the\par
Boolean value is:   Boolean value is:    result is:\par
TRUE                TRUE                 TRUE\par
TRUE                FALSE                FALSE\par
TRUE                UNKNOWN              UNKNOWN\par
FALSE               TRUE                 FALSE\par
FALSE               FALSE                FALSE\par
FALSE               UNKNOWN              FALSE\par
UNKNOWN             TRUE                 UNKNOWN\par
UNKNOWN             FALSE                FALSE\par
UNKNOWN             UNKNOWN              UNKNOWN\par
\par
\par
Table 9-3:\par
Truth Values for the Boolean OR Operator\par
\par
If the first        ... and the second   ... then the\par
Boolean value is:   Boolean value is:    result is:\par
TRUE                TRUE                 TRUE\par
TRUE                FALSE                TRUE\par
TRUE                UNKNOWN              TRUE\par
FALSE               TRUE                 TRUE\par
FALSE               FALSE                FALSE\par
FALSE               UNKNOWN              UNKNOWN\par
UNKNOWN             TRUE                 TRUE\par
UNKNOWN             FALSE                UNKNOWN\par
UNKNOWN             UNKNOWN              UNKNOWN\par
\page\par
Chapter 10 -- Collection types\par
\par
[Obscure Rule] applies for this entire chapter.\par
\par
In SQL, a <collection type> is an array: a composite constructed SQL <data type>.\par
\par
Collection <data type>s\par
\par
A <collection type> is defined by a descriptor that contains three pieces of information:\par
      ## The <data type>'s name: ARRAY.\par
      ## The maximum number of elements in the array.\par
      ## The array's element <data type> specification.\par
\par
ARRAY:\par
The required syntax for a <collection type> specification is:\par
\par
<collection type> ::=\par
<data type> <array specification>\par
\par
   <array specification> ::=\par
   ARRAY[unsigned integer] | ARRAY??(unsigned integer??)\par
\par
A <collection type> specification defines an array: it consists of an element\par
<data type> specification followed by an indication of the array's maximum\par
element size. For example, both of these <collection type> specifications\par
define an array of up to ten numbers, all of which must fall into the range\par
supported by SQL's SMALLINT <data type>:\par
\par
   SMALLINT ARRAY[10]\par
\par
   SMALLINT ARRAY??(10??)\par
\par
A <collection type> may not specify, either directly or indirectly (for\par
example, via a Domain), a <data type> of REF or ARRAY. All other SQL <data type>s are supported.\par
\par
It is important to note that the square brackets in the <collection type>'s\par
syntax diagrams should not be read as if they are BNF brackets -- that is,\par
they don't mean that ARRAY can optionally be followed by an integer. Instead,\par
you use either square brackets or trigraphs to delimit the integer that\par
specifies the size of the array. We'll use square brackets in the rest of our examples.\par
\par
An array is an ordered collection of elements. There are some similarities\par
between SQL ARRAYs and C or Pascal arrays, but there are also some significant\par
differences: (a) SQL ARRAYs are only "vectors", so an array of an array is not\par
supported and (b) SQL ARRAYs are variable size: the specification defines an\par
array's maximum size, rather than its exact size. In earlier SQL versions\par
there was no support for ARRAYs. In part, this lack of support was due to a\par
well-known principle of database design, the rule of first normal form: "A\par
field (a column/row intersection) may have only one atomic value." If rows\par
contain arrays, they violate this principle, so a well-designed database\par
doesn't define arrays all over the place.\par
\par
[Obscure Rule] A <collection type> is a subtype of a <data type> if (a) both\par
are arrays and (b) the element <data type> of the first array is a subtype of\par
the element <data type> of the second array.\par
\par
ARRAY <element reference>:\par
An <element reference> returns an element of an array. The required syntax for an <element reference> is:\par
\par
<element reference> ::=\par
array_argument[numeric_argument] |\par
array_argument??(numeric_argument??)\par
\par
An <element reference> allows you to access a specific element of an array. It\par
operates on two arguments: the first must evaluate to an array and the second\par
must evaluate to an integer. (The integer refers to the ordinal position of\par
the element in the array: the first element in an array is element number 1,\par
the second element is element number 2 and so on.) If either portion of an\par
element reference is NULL, that element is also NULL. Here are two equivalent\par
examples of an <element reference>:\par
\par
   array_column[4]\par
\par
   array_column??(4??)\par
\par
In each case, the reference would return the fourth element of the array.\par
\par
If "numeric_argument" is a negative number, or if it is greater than the\par
number of elements in the array, the <element reference> will fail: your DBMS\par
will return the SQLSTATE error 2202E "data exception-array element error".\par
\par
<array value constructor>:\par
An <array value constructor> is used to construct an array. The required syntax for an <array value constructor> is:\par
\par
<array value constructor> ::=\par
ARRAY[element_expression [ \{,element_expression\}... ]] |\par
ARRAY??(element_expression [ \{,element_expression\}... ]??)\par
\par
An <array value constructor> allows you to assign values to the elements of an\par
array. An "element_expression" may be any expression that evaluates to a\par
scalar value with a <data type> that is assignable to the array's element\par
<data type>. The result is an array whose n-th element value is the value of\par
the n-th element_expression you specify. Here are two equivalent examples of an <array value constructor>:\par
\par
   ARRAY['hello','bob','and','sally']\par
\par
   ARRAY??('hello','bob','and','sally'??)\par
\par
These examples both construct an array with four elements. The first element\par
has a value of 'hello', the second has a value of 'bob', the third has a value\par
of 'and' and the fourth has a value of 'sally'. Both <array value\par
constructor>s would be valid for this <collection type> specification:\par
\par
   VARCHAR(5) ARRAY[4]\par
\par
An <array value constructor> serves the same purpose for an array as a\par
<literal> does for a predefined <data type>. It has the same format as the\par
<collection type>'s ARRAY specification -- that is, ARRAY[ ] or ARRAY??( ??) -\par
- but instead of a number inside the size delimiters, it contains comma-\par
delimited values of the correct <data type> (these are called array elements\par
in SQL, though in other languages, an instance of an array is called an\par
"occurrence"). For example, if your <collection type> specification is:\par
\par
   INT ARRAY[3]\par
\par
a valid <array value constructor> would be:\par
\par
   ARRAY[20,10,52]\par
\par
And if your <collection type> specification is:\par
\par
   BIT(4) ARRAY[3]\par
\par
a valid <array value constructor> would be:\par
\par
   ARRAY[B'1011',B'0011',B'0110']\par
\par
The number of elements in an <array value constructor> may vary from zero\par
elements (for example ARRAY[], an empty specification) to any number of elements up to the array's maximum size.\par
\par
If you want to restrict your code to Core SQL, don't define any ARRAY <data type>s and don't use any of SQL's array syntax.\par
\par
Collection Operations\par
\par
An array is compatible with, and comparable to, any array with a compatible\par
element <data type> -- that is, arrays are mutually comparable and mutually\par
assignable only if their element <data type>s are mutually comparable and\par
mutually assignable. Arrays may not be directly compared with, or directly\par
assigned to, any other <data type> class, though implicit type conversions can\par
occur in expressions, SELECTs, INSERTs, DELETEs and UPDATEs. Explicit array\par
type conversions can be forced with the CAST operator.\par
\par
CAST:\par
In SQL, CAST is a scalar operator that converts a given scalar value to a\par
given scalar <data type>. The required syntax for the CAST operator is:\par
\par
CAST (<cast operand> AS <cast target>)\par
\par
   <cast operand> ::= scalar_expression\par
\par
   <cast target> ::= <Domain name> | <data type>\par
\par
The CAST operator converts values of a source <data type> into values of a\par
target <data type>, where each <data type> is an SQL pre-defined <data type>\par
(data conversions between UDTs are done with a user-defined cast). The source\par
<data type>, or <cast operand>, can be any expression that evaluates to a\par
single value. The target <data type>, or <cast target>, is either an SQL\par
predefined <data type> specification or the name of a Domain whose defined\par
<data type> is the SQL predefined <data type> that you want to convert the\par
value of "scalar_expression" into. (If you use CAST (... AS <Domain name>),\par
your current <AuthorizationID> must have the USAGE Privilege on that Domain.)\par
\par
It isn't, of course, possible to convert the values of every <data type> into\par
the values of every other <data type>. For <collection type>s, the rules are:\par
      ## CAST (NULL AS <data type>) and CAST (array_source_is_a_null_value AS <data type>)\par
both result in a CAST result of NULL.\par
      ## You can CAST a <collection type> source only to a <collection type>\par
target whose element <data type> is an appropriate CAST target for the source's element <data type>.\par
\par
When you CAST an array to an array target, you're actually asking your DBMS to\par
CAST the value of the source element <data type> to the target element <data\par
type>, so the CAST implied therein must be a legal CAST -- see our\par
descriptions of CAST for each predefined SQL <data type>. Your source may be\par
an empty array -- that is, <cast operand> may be ARRAY[] or ARRAY??(??). In\par
this case, the result of the CAST is an empty array whose element <data type>\par
is the target element <data type>. Otherwise, the result of the CAST is an\par
array with the same number of elements as the source and the target element <data type>.\par
\par
Assignment:\par
In SQL, when an array is assigned to an array target, the assignment is done\par
one element at a time -- that is, the source value's first element is assigned\par
to the target's first element, the source's next element is assigned to the\par
target's next element, and so on. Two arrays are assignable if their element\par
<data type>s are mutually assignable.\par
\par
When an array is taken from SQL-data to be assigned to an array target, if the\par
number of elements in the source array equals the maximum number of elements\par
in the target array, assignment is straightforward: the value of each element\par
of the source is assigned to the corresponding element of the target. If the\par
maximum number of elements in the target array is less than the number of\par
elements in the source array, then assignment of as many of the source element\par
values to the target elements as is possible occurs and your DBMS will return\par
the SQLSTATE warning 0102F "warning-array data, right truncation". If the\par
maximum number of elements in the target array is greater than the number of\par
elements in the source array, then assignment of each of the source element\par
values to the target elements occurs and the size of the target for that row\par
becomes the number of elements assigned. (Note that this doesn't mean that the\par
maximum size of the target for other assignments lessens.)\par
\par
[Obscure Rule] Since only SQL accepts null values, if your source is NULL,\par
then your target's value is not changed. Instead, your DBMS will set its\par
indicator parameter to -1, to indicate that an assignment of the null value\par
was attempted. If your target doesn't have an indicator parameter, the\par
assignment will fail: your DBMS will return the SQLSTATE error 22002 "data\par
exception-null value, no indicator parameter". We'll talk more about indicator\par
parameters in our chapters on SQL binding styles.\par
\par
When an array is assigned to a SQL-data array target, if the number of\par
elements in the source array equals the maximum number of elements in the\par
target array, assignment is straightforward: the value of each element of the\par
source is assigned to the corresponding element of the target. If the maximum\par
number of elements in the target array is less than the number of elements in\par
the source array, but the extra source elements are all NULL, then the value\par
of each non-null element of the source is assigned to the corresponding\par
element of the target. If the maximum number of elements in the target array\par
is less than the number of elements in the source array and the extra source\par
elements are not all NULL, the assignment will fail: your DBMS will return the\par
SQLSTATE error 2202F "data exception-array data, right truncation". If the\par
maximum number of elements in the target array is greater than the number of\par
elements in the source array, then assignment of each of the source element\par
values to the target elements occurs and the size of the target for that row\par
becomes the number of elements assigned. (Note, once again, that this doesn't\par
mean that the maximum size of the target for other assignments lessens.)\par
\par
[Obscure Rule] There are two ways to assign a null value to an SQL-data\par
target. Within SQL, you can use the <keyword> NULL in an INSERT or an UPDATE\par
statement to indicate that the target should be set to NULL; that is, if your\par
source is NULL, your DBMS will set your target to NULL. Outside of SQL, if\par
your source has an indicator parameter that is set to -1, your DBMS will set\par
your target to NULL (regardless of the value of the source). (An indicator\par
parameter with a value less than -1 will cause an error: your DBMS will return\par
the SQLSTATE error 22010 "data exception-invalid indicator parameter value".)\par
\par
Comparison:\par
SQL provides only two scalar comparison operators -- = and <> -- to perform\par
operations on arrays. Both will be familiar; there are equivalent operators in\par
other computer languages. Two arrays are comparable if their element <data\par
type>s are mutually comparable. During comparison, the elements of the\par
comparands are compared pairwise in element order -- that is, the first\par
element of the first array is compared to the first element of the second\par
array, the second element of the first array is compared to the second element\par
of the second array, and so on. The two arrays are equal if (a) they both have\par
the same number of elements and (b) each pair of elements are equal. If any of\par
the comparands are NULL, the result of the operation is UNKNOWN. For example:\par
\par
   ARRAY[1] <> ARRAY[2]\par
\par
returns TRUE.\par
\par
   array_column = \{array result is NULL\}\par
\par
returns UNKNOWN.\par
\par
Other Operations:\par
With SQL, you have several other operations that you can perform on <collection type>s.\par
\par
## Scalar functions\par
SQL provides two scalar functions that return a <collection type>: the <array concatenation function> and the <cardinality expression>.\par
\par
<array concatenation function> --\par
The required syntax for an <array concatenation function> is:\par
\par
<array concatenation function> ::=\par
CONCATENATE(array_argument_1 \{ , | WITH \} array_argument_2)\par
\par
CONCATENATE operates on two operands, both of which must evaluate to an array.\par
It joins the arrays together in the order given and returns an array value\par
that consists of every element of "array_argument_1" followed by every element\par
of "array_argument_2". If either operand is NULL, CONCATENATE returns NULL.\par
For this function, you can use either a comma or the <keyword> WITH to\par
separate your operands. Here are two equivalent examples of array concatenations:\par
\par
   CONCATENATE(array_column,ARRAY['element_1','element_2'])\par
\par
   CONCATENATE(array_column WITH ARRAY['element_1','element_2'])\par
\par
[Obscure Rule] There are various details about the precise characteristics of\par
the elements in the result array; if you're interested, see "Rules of\par
Aggregation", in our description of the CASE expression in our chapter on simple search conditions.\par
\par
If you want to restrict your code to Core SQL, don't use CONCATENATE.\par
\par
<cardinality expression> --\par
The required syntax for a <cardinality expression> is:\par
\par
<cardinality expression> ::=\par
CARDINALITY (array_argument)\par
\par
CARDINALITY operates on an argument that evaluates to an array. It counts the\par
number of elements in the array and returns this as an exact numeric integer.\par
If the argument is NULL, CARDINALITY returns NULL. Here is an example:\par
\par
   CARDINALITY(ARRAY[10,20,30,40])\par
   --returns 4\par
\par
[NON-PORTABLE] The precision of CARDINALITY's result is non-standard because\par
the SQL Standard requires implementors to define the result's precision.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book gives\par
the result of CARDINALITY an INTEGER <data type>.\par
\par
If you want to restrict your code to Core SQL, don't use CARDINALITY.\par
\par
## Set functions\par
SQL provides three set functions that operate on a <collection type>:\par
COUNT(*), COUNT and GROUPING. Since none of these operate exclusively with\par
array arguments, we won't discuss them here; look for them in our chapter on set functions.\par
\par
## Predicates\par
In addition to the comparison operators, SQL provides four other predicates\par
that operate on arrays: the <null predicate>, the <exists predicate>, the\par
<quantified predicate> and the <distinct predicate>. Each will return a\par
boolean value: either TRUE, FALSE or UNKNOWN. None of these operate strictly\par
on arrays, so we won't discuss them here. Look for them in our chapters on search conditions.\par
\par
Comprehensive Example\par
\par
Now that we've described SQL's <collection type>, let's look at some example SQL statements that put it to use.\par
\par
For our example, we've chosen a street address: a plausible choice for an\par
array because its subdivisions ("lines") are not meaningful -- e.g.: we don't\par
require that the fourth line of a street address must contain a city name.\par
Here is an SQL statement that creates a Table with three Columns, the third of which is an array:\par
\par
   CREATE TABLE Mailouts (\par
      given_name CHAR(5),\par
      surname CHAR(5),\par
      street_address CHAR(20) ARRAY[5]);\par
\par
In this Table definition, ARRAY[5] indicates that the STREET_ADDRESS Column is an array which occurs up to 5 times.\par
\par
This SQL statement adds a row to the MAILOUTS Table:\par
\par
   INSERT INTO TABLE Mailouts (\par
     given_name,\par
     surname,\par
     street_address)\par
   VALUES (\par
     'Jean',                               -- given_name\par
     'Boyer',                              -- surname\par
     ARRAY['line#1','line#2','line#3']);   -- street_address\par
\par
In this INSERT statement, ARRAY['line#1','line#2','line#3'] is an <array value\par
constructor> that specifies the values for the first three elements of the\par
STREET_ADDRESS Column array. The two possible remaining elements are not\par
provided with values, so they aren't constructed for this row.\par
\par
An element of an ARRAY can be updated using an <element reference>. For\par
example, this SQL statement would change the rows in the MAILOUTS Table by\par
updating the second element of every STREET_ADDRESS value:\par
\par
   UPDATE Mailouts SET\par
     street_address[2] = 'line#2 after update';\par
\par
This example uses a <character string literal> to change the value of\par
STREET_ADDRESS's second element. (Remember that the <data type> of the array -- and\par
therefore of each of the array's elements -- is CHAR(20), so any assignment of a compatible character string value would be accepted.)\par
The result is that the second array element contains the string 'line#2 after update' and the other elements are unchanged.\par
We could have achieved the same result by assigning an <array value constructor> to the STREET_ADDRESS Column as a whole, as in this example:\par
\par
   UPDATE Mailouts SET\par
      street_address = ARRAY['line#1','line #2 after update','line#3'];\par
\par
Note however: if you assign a 2-element <array value constructor> to a\par
3-element array, the result is a 2-element array -- not a 3-element array with\par
the final element unchanged. That is, if the above example was:\par
\par
   UPDATE Mailouts SET\par
      street_address = ARRAY['line#1','line #2 after update'];\par
\par
the result in the STREET_ADDRESS Column would be 'line#1','line #2 after update' rather than 'line#1','line #2 after update','line#3'.\par
\par
** TIP: To avoid "array element error", ensure all occurrences of an array are fixed size -- pad with NULLs if necessary.\par
\par
Both of the above examples updated the value of an existing array element.\par
It's also possible to place a value into an element that hasn't been\par
constructed for the row yet. For example, this SQL statement:\par
\par
   UPDATE Mailouts SET\par
      street_address[5] = 'line#5';\par
\par
has a two-fold effect: as the UPDATE explicitly requires, it creates element\par
number five for the row, placing the string 'line#5' into it, and it creates\par
element number four for the row, placing the null value into it (since the\par
UPDATE statement doesn't provide an explicit value for the fourth element and\par
since the fifth element can't exist unless the first four also exist).\par
\par
Here is an example of a query on the MAILOUTS Table:\par
\par
   SELECT given_name, surname, street_address\par
   FROM   Mailouts\par
   WHERE  street_address <> ARRAY[];\par
\par
In this SELECT statement, the STREET_ADDRESS Column is being referred to as a\par
whole in both the <select list> and the WHERE clause. We could also have used\par
an <element reference> (e.g.: street_address[3]) in either clause, to refer to\par
a specific element of the Column (this is true in most situations). Our sample\par
query searches for all rows of the MAILOUTS Table where STREET_ADDRESS is not\par
an empty array; TRUE for the row we inserted earlier.\par
\par
This SQL statement uses CONCATENATE to query the MAILOUTS Table:\par
\par
   SELECT CONCATENATE(street_address WITH ARRAY['line#4','line#5'])\par
   FROM   Mailouts;\par
\par
In this example, we've used CONCATENATE to join the elements of two arrays:\par
one array-Column reference and one <array value constructor>. The resulting is\par
an array containing five elements: three from the STREET_ADDRESS Column and\par
two from the <array value constructor> (in that order). Each element of the\par
result is a CHAR string.\par
\par
Illegal Operations:\par
SQL places a number of restrictions on where you may validly use arrays. These\par
are worth pointing out, since most of the language is orthogonal in this respect.\par
      ## You may not use arrays in a JOIN Column list, as a grouping Column or\par
in a Constraint definition (for UNIQUE or PRIMARY KEY or FOREIGN KEY\par
Constraints -- Constraints are illegal in most predicates and can't contain REFs or ARRAYs.\par
      ## Be very careful with <element reference>s: the fact that an array is\par
defined as "ARRAY[5]" does not guarantee that array element "[4]" exists.\par
Above all, it is a mistake to assume that an <element reference> is allowed\par
wherever a <Column reference> is allowed -- SQL's rules aren't there to help\par
you break the rules of database design.\par
\page\par
Chapter 11 -- Row types\par
\par
[Obscure Rule] applies for this entire chapter.\par
\par
In SQL, a <row type> is a row of data: a composite constructed SQL <data\par
type>. A row in a Table is an instance of a <row type> and every row of the\par
same Table has the same type -- the intent is to provide a <data type> that\par
can represent the rows of a Table, so that complete rows can be stored in\par
variables, passed as arguments to routines and returned by functions.\par
\par
Row <data type>s\par
\par
A <row type> is defined by a descriptor that contains three pieces of information:\par
      ## The <data type>'s name: ROW.\par
      ## The <data type>'s degree: the number of Fields that belong to the row.\par
      ## A descriptor for every Field that belongs to the row. The Field\par
descriptor contains the name of the Field, the Field's ordinal position in the\par
<row type>, the Field's <data type> and nullability attribute (or, if the\par
Field is based on a Domain, the name of that Domain), the Field's Character\par
set and default Collation (for character string <data type>s) and the Field's\par
<reference scope check> (for <reference type>s).\par
\par
ROW:\par
The required syntax for a <row type> specification is:\par
\par
<row type> ::=\par
ROW (<Field definition> [ \{,<Field definition>\}... ])\par
\par
   <Field definition> ::=\par
   <Field name> \{<data type> | <Domain name>\}\par
      [ <reference scope check> ]\par
      [ COLLATE <Collation name> ]\par
\par
A <row type> specification defines a row of data: it consists of a sequence of\par
one or more parenthesized \{<Field name>,<data type>\} pairs, known as Fields.\par
The degree of a row is the number of Fields it contains. A value of a row\par
consists of one value for each of its Fields, while a value of a Field is a\par
value of the Field's <data type>. Each Field in a row must have a unique name.\par
Here is an example of a <row type> specification:\par
\par
   ROW (field_1 INT, field_2 DATE, field_3 INTERVAL(4) YEAR)\par
\par
A <Field name> identifies a Field and is either a <regular identifier> or a\par
<delimited identifier> that is unique (for all Fields and Columns) within the\par
Table it belongs to. You can define a Field's <data type> either by putting a\par
<data type> specification after <Field name> or by putting a <Domain name>\par
after the <Field name>. (The <data type> of a Field can be any type other than\par
a <reference type> -- in particular, it can itself be a <row type>.) For\par
example, consider this SQL statement, which creates a Domain, called DOMAIN_1,\par
whose defined <data type> is DATE:\par
\par
   CREATE DOMAIN Domain_1 AS DATE;\par
\par
Based on this definition, these two <row type> specifications are equivalent -- both define a row with one Field (called FIELD_1) whose defined <data type> is DATE:\par
\par
   ROW (field_1 DATE)\par
\par
   ROW (field_1 domain_1)\par
\par
[Obscure Rule] If the <data type> of a Field is CHAR, VARCHAR or CLOB, the\par
Character set that the Field's values must belong to is determined as follows:\par
      ## If the <Field definition> contains a <data type> specification that\par
includes a CHARACTER SET clause, the Field's Character set is the Character\par
set named. Your current <AuthorizationID> must have the USAGE Privilege on that Character set.\par
      ## If the <Field definition> does not include a <data type>\par
specification, but the Field is based on a Domain whose definition includes a\par
CHARACTER SET clause, the Field's Character set is the Character set named.\par
      ## If the <Field definition> does not include any CHARACTER SET clause\par
at all -- either through a <data type> specification or through a Domain\par
definition -- the Field's Character set is the Character set named in the\par
DEFAULT CHARACTER SET clause of the CREATE SCHEMA statement that defines the Schema that the Field belongs to.\par
\par
For example, the effect of these two SQL statements:\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob\par
      DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN1;\par
\par
   CREATE TABLE Table_1 (\par
      column_1 ROW(\par
         field_1 CHAR(10),\par
         field_2 INT));\par
\par
is to create a Table in Schema BOB. The Table has a Column with a ROW <data\par
type>, containing two Fields. The character string Field's set of valid values\par
are fixed length character strings, exactly 10 characters long, all of whose\par
characters must be found in the INFORMATION_SCHEMA.LATIN1 Character set -- the\par
Schema's default Character set. The effect of these two SQL statements:\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob\par
      DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN1;\par
\par
   CREATE TABLE Table_1 (\par
      column_1 ROW(\par
         field_1 CHAR(10) CHARACTER SET INFORMATION_SCHEMA.SQL_CHARACTER,\par
         field_2 INT));\par
\par
is to create the same Table with one difference: this time, the character\par
string Field's values must consist only of characters found in the\par
INFORMATION_SCHEMA.SQL_CHARACTER Character set -- the explicit Character set\par
specification in CREATE TABLE constrains the Field's set of values. The\par
Schema's default Character set does not.\par
\par
[Obscure Rule] If the <data type> of a Field is CHAR, VARCHAR, CLOB, NCHAR,\par
NCHAR VARYING or NCLOB, and your <Field definition> does not include a COLLATE\par
clause, the Field has a coercibility attribute of COERCIBLE -- but if your\par
<Field definition> includes a COLLATE clause, the Field has a coercibility\par
attribute of IMPLICIT. In either case, the Field's default Collation is determined as follows:\par
      ## If the <Field definition> includes a COLLATE clause, the Field's\par
default Collation is the Collation named. Your current <AuthorizationID> must\par
have the USAGE Privilege on that Collation.\par
      ## If the <Field definition> does not include a COLLATE clause, but does\par
contain a <data type> specification that includes a COLLATE clause, the\par
Field's default Collation is the Collation named. Your current\par
<AuthorizationID> must have the USAGE Privilege on that Collation.\par
      ## If the <Field definition> does not include a COLLATE clause, but the\par
Field is based on a Domain whose definition includes a COLLATE clause, the\par
Field's default Collation is the Collation named.\par
      ## If the <Field definition> does not include any COLLATE clause at all\par
-- either explicitly, through a <data type> specification or through a Domain\par
definition -- the Field's default Collation is the default Collation of the Field's Character set.\par
\par
[Obscure Rule] Although a <row type> specification may not include a Field\par
with a <reference type> as its <data type>, it is possible to have a row with\par
such a Field because a row of a Table and a row of a query result are both\par
considered to be <row type>s as well. In such cases, if the <data type> of a\par
Field is REF(UDT), your current <AuthorizationID> must have the USAGE\par
Privilege on that UDT. If the <data type> of a Field includes REF with a\par
<scope clause>, your <Field definition> must also include a <reference scope\par
check> clause, to indicate whether references are to be checked or not (don't\par
add a <reference scope check> clause under any other circumstances). In this\par
case, you may also add the optional <reference scope check action> clause, to\par
indicate the action to be taken when the Field is the subject of a DELETE\par
statement. If you omit the <reference scope check action> clause, it defaults to ON DELETE RESTRICT.\par
      ## If a Field is defined with REFERENCES ARE CHECKED, and a <scope\par
clause> naming one or more Tables is included in the <Field definition>, then\par
there is an implied DEFERRABLE INITIALLY IMMEDIATE Constraint on the Field\par
which checks that the Field's values are also found in the corresponding Field\par
of the system generated Column of each Table named in the <scope clause>. In\par
this case, if the <reference scope check action> is SET NULL then, prior to\par
deleting any rows from the Table that owns this Field, your DBMS will (a)\par
execute a SET CONSTRAINT statement that sets the implied Constraint's\par
constraint check time to DEFERRED, (b) DELETE the rows as required, (c) set\par
the value of the system generated Column in each Table named in the <scope\par
clause> to NULL, for each row that matched the deleted rows and (d) execute a\par
SET CONSTRAINT statement that sets the implied Constraint's constraint check time to IMMEDIATE.\par
      ## [Obscure Rule] If the <data type> of a Field in a row is a UDT, then\par
the current <AuthorizationID> must have the USAGE Privilege on that UDT.\par
      ## A <row type> is a subtype of a <data type> if (a) both are <row\par
type>s with the same degree and (b) for every pair of corresponding <Field\par
definition>s, the <Field name>s are the same and the <data type> of the Field\par
in the first <row type> is a supertype of the <data type> of the Field in the second <row type>.\par
\par
<row reference>:\par
A <row reference> returns a row. The required syntax for a <row reference> is:\par
\par
<row reference> ::=\par
ROW \{<Table name> | <query name> | <Correlation name>\}\par
\par
A row of data values belonging to a Table (or a query result, which is also a\par
Table) is also considered to be a <row type>. In a Table, each Column of a\par
data row corresponds to a Field of the <row type>: the Column and Field have\par
the same ordinal positions in the Table and <row type>, respectively. A <row\par
reference> allows you to access a specific row of a Table or a query result.\par
Here is an example of a <row reference> that would return a row of a Table named TABLE_1:\par
\par
   ROW(Table_1)\par
\par
<Field reference>:\par
A <Field reference> returns a Field of a row. The required syntax for a <Field reference> is:\par
\par
<Field reference> ::=\par
row_argument.<Field name>\par
\par
A <Field reference> allows you to access a specific Field of a row. It\par
operates on two arguments: the first must evaluate to a <row type> and the\par
second must be the name of a Field belonging to that row. If the value of\par
"row_argument" is NULL, then the specified Field is also NULL. If\par
"row_argument" has a non-null value, the value of the Field reference is the\par
value of the specified Field in "row_argument". Here is an example of a <Field\par
reference> that would return the value of a Field named FIELD_1 that belongs\par
to a row of TABLE_1:\par
\par
   ROW(Table_1).field_1\par
\par
<row value constructor>:\par
An <row value constructor> is used to construct a row of data. The required syntax for a <row value constructor> is:\par
\par
<row value constructor> ::=\par
element_expression |\par
[ ROW ] (element_expression [ \{,element_expression\}... ]) |\par
( <query expression> )\par
\par
   element_expression ::=\par
   element_expression |\par
   NULL |\par
   ARRAY[] |\par
   ARRAY??(??) |\par
   DEFAULT\par
\par
A <row value constructor> allows you to assign values to the Fields of a row,\par
using either a list of element_expressions of the result of a subquery. An\par
"element_expression" may be any expression that evaluates to a scalar value\par
with a <data type> that is assignable to the corresponding Field's <data\par
type>. A subquery -- ( <query expression> ) -- is discussed in our chapter on\par
complex queries. The result is a row whose n-th Field value is the value of\par
the n-th element_expression (or whose value is the value of the subquery) you\par
specify. If your "element_expression" is NULL, the corresponding Field is\par
assigned the null value. If your "element_expression" is ARRAY[] or\par
ARRAY??(??), the corresponding Field is assigned an empty array. If your\par
"element_expression" is DEFAULT, the corresponding Field is assigned its\par
default value. Here is an example of a <row value constructor>:\par
\par
   ROW ('hello',567,DATE '1994-07-15',NULL,DEFAULT,ARRAY[])\par
\par
This example constructs a row with six Fields. The first Field has a character\par
string value of 'hello', the second has a numeric value of '567', the third\par
has a date value of '1994-07-15', the fourth has a null value, the fifth has a\par
value that is the fifth Field's default value and the sixth has a value that\par
is an empty array. This <row value constructor> would be valid for this <row type> specification:\par
\par
   ROW (\par
     field_1 CHAR(5),\par
     field_2 SMALLINT,\par
     field_3 DATE,\par
     field_4 BIT(4),\par
     field_5 domain_1,\par
     field_6 INT ARRAY[4])\par
\par
A <row value constructor> serves the same purpose for a row as a <literal>\par
does for a predefined <data type>. It has the same format as the <row type>'s\par
ROW specification -- that is, ROW( ) -- but instead of a series of <Field\par
definition>s inside the size delimiters, it contains comma-delimited values of\par
the correct <data type> for each Field. For example, if your <row type> specification is:\par
\par
   ROW (field_1 INT, field_2 CHAR(5), field_3 BIT(4))\par
\par
a valid <row value constructor> would be:\par
\par
   ROW(20,'hello',B'1011')\par
\par
If you construct a row with a subquery, the row takes on the <data type> of\par
the subquery's result. An empty subquery result constructs a one-Field row\par
whose value is NULL. A non-empty subquery result constructs a one-Field row\par
whose value is the subquery result.\par
\par
If you want to restrict your code to Core SQL, don't use the ROW <data type>\par
or <row reference>s and <Field reference>s and, when using a <row value\par
constructor>, don't use ARRAY[] or ARRAY??(??) as an "element_expression",\par
don't construct a row with more than one Field, don't use the ROW <keyword> in\par
front of your element_expression and don't use a subquery to construct your row.\par
\par
Row Operations\par
\par
A row is compatible with, and comparable to, any row with compatible Fields --\par
that is, rows are mutually comparable and mutually assignable only if they\par
have the same number of Fields and each corresponding pair of Fields are\par
mutually comparable and mutually assignable. Rows may not be directly compared\par
with, or directly assigned to, any other <data type> class, though implicit\par
type conversions of their Fields can occur in expressions, SELECTs, INSERTs,\par
DELETEs and UPDATEs. Explicit row type conversions are not possible.\par
\par
Assignment:\par
In SQL, when a <row type> is assigned to a <row type> target, the assignment\par
is done one Field at a time -- that is, the source's first Field value is\par
assigned to the target's first Field, the source's second Field value is\par
assigned to the target's second Field, and so on. Assignment of a <row type>\par
to another <row type> is possible only if (a) both <row type>s have the same\par
number of Fields and (b) each corresponding pair of Fields have <data type>s\par
that are mutually assignable.\par
\par
[Obscure Rule] Since only SQL accepts null values, if your source is NULL,\par
then your target's value is not changed. Instead, your DBMS will set its\par
indicator parameter to -1, to indicate that an assignment of the null value\par
was attempted. If your target doesn't have an indicator parameter, the\par
assignment will fail: your DBMS will return the SQLSTATE error 22002 "data\par
exception-null value, no indicator parameter". Going the other way, there are\par
two ways to assign a null value to an SQL-data target. Within SQL, you can use\par
the <keyword> NULL in an INSERT or an UPDATE statement to indicate that the\par
target should be set to NULL; that is, if your source is NULL, your DBMS will\par
set your target to NULL. Outside of SQL, if your source has an indicator\par
parameter that is set to -1, your DBMS will set your target to NULL\par
(regardless of the value of the source). (An indicator parameter with a value\par
less than -1 will cause an error: your DBMS will return the SQLSTATE error\par
22010 "data exception-invalid indicator parameter value".) We'll talk more\par
about indicator parameters in our chapters on SQL binding styles.\par
\par
Comparison:\par
SQL provides the usual scalar comparison operators -- = and <> and < and <=\par
and > and >= -- to perform operations on rows. All of them will be familiar;\par
there are equivalent operators in other computer languages. Two rows are\par
comparable if (a) both have the same number of Fields and (b) each\par
corresponding pair of Fields have <data type>s that are mutually comparable.\par
During comparison, the Fields of the comparands are compared pairwise in Field\par
order -- that is, the first Field of the first row is compared to the first\par
Field of the second row, the second Field of the first row is compared to the\par
second Field of the second row, and so on. The two rows are equal if (a) they\par
both have the same number of Fields and (b) each pair of Fields are equal. If\par
any of the comparands are NULL, the result of the operation is UNKNOWN. For\par
example:\par
\par
   ROW(20,'hello',B'1011' <> ROW(12,'goodbye','B'1011')\par
\par
returns TRUE.\par
\par
ROW(20,'hello') = ROW(NULL,'hello')\par
\par
returns UNKNOWN.\par
\par
SQL also provides three quantifiers -- ALL, SOME, ANY -- which you can use\par
along with a comparison operator to compare a row value with the collection of\par
values returned by a <table subquery>. Place the quantifier after the\par
comparison operator, immediately before the <table subquery>. For example:\par
\par
   SELECT row_column\par
   FROM   Table_1\par
   WHERE  row_column < ALL (\par
      SELECT row_column\par
      FROM   Table_2);\par
\par
ALL returns TRUE either (a) if the collection is an empty set (i.e.: if it\par
contains zero rows) or (b) if the comparison operator returns TRUE for every\par
value in the collection. ALL returns FALSE if the comparison operator returns\par
FALSE for at least one value in the collection.\par
\par
SOME and ANY are synonyms. They return TRUE if the comparison operator returns\par
TRUE for at least one value in the collection. They return FALSE either (a) if\par
the collection is an empty set or (b) if the comparison operator returns FALSE\par
for every value in the collection. (The search condition "= ANY (collection)"\par
is equivalent to "IN (collection)".)\par
\par
Other Operations:\par
With SQL, you have several other operations that you can perform on <row type>s.\par
\par
## Scalar functions\par
All of SQL's scalar functions return a row with one Field: its value is the\par
result of the function. We discuss the scalar functions in our other <data\par
type> chapters and won't repeat the information here.\par
\par
## Set functions\par
SQL provides three set functions that operate on a <row type>: COUNT(*), COUNT\par
and GROUPING. Since none of these operate exclusively with row arguments, we\par
won't discuss them here; look for them in our chapter on set functions.\par
\par
## Predicates\par
In addition to the comparison operators, SQL provides twelve other predicates\par
that operate on rows: the <between predicate>, the <in predicate>, the <like\par
predicate>, the <null predicate>, the <exists predicate>, the <unique\par
predicate>, the <match predicate>, the <overlaps predicate>, the <similar\par
predicate>, the <quantified predicate>, the <distinct predicate> and the <type\par
predicate>. Each will return a boolean value: either TRUE, FALSE or UNKNOWN.\par
Look for the <like predicate> and the <similar predicate> in our chapter on\par
character strings, the <overlaps predicate> in our chapter on temporal values,\par
the <type predicate> in our chapter on UDTs and the rest in our chapters on\par
search conditions.\par
\par
Comprehensive Example\par
\par
Now that we've described SQL's <row type>, let's look at some example SQL statements that put it to use.\par
\par
Here is an SQL statement that creates a Table with three Columns, the third of which is a <row type>:\par
\par
   CREATE TABLE Lineage (\par
     name CHAR(5),\par
     status CHAR(10),\par
     last_litter ROW(dog CHAR(5),mated DATE,pups SMALLINT));\par
\par
In this Table definition, ROW(...) indicates that the LAST_LITTER Column is a\par
<row type> with three Fields.\par
\par
This SQL statement adds a row to the LINEAGE Table:\par
\par
   INSERT INTO TABLE Lineage (\par
     name,\par
     status,\par
     last_litter)\par
   VALUES (\par
     'Spot',                               -- name\par
     'Field Dog',                          -- status\par
     ROW('Fido',DATE '1994-07-15',6));     -- last_litter\par
\par
In this INSERT statement, ROW('Fido',DATE '1994-07-15',6) is a <row value\par
constructor> that specifies the values for the three Fields of the LAST_LITTER Column <row type>.\par
\par
A Field of a <row type> can be updated using a <Field reference>. For example,\par
this SQL statement would change the rows in the LINEAGE Table by updating the\par
third Field of every LAST_LITTER value:\par
\par
   UPDATE Lineage SET\par
     last_litter.pups = 5;\par
\par
This example uses a <numeric literal> to change the value of LAST_LITTER's\par
third Field. The result is that the third Field contains the number '5' and\par
the other Fields are unchanged. We could have achieved the same result by\par
assigning a <row value constructor> to the LAST_LITTER Column as a whole, as in this example:\par
\par
   UPDATE Lineage SET\par
     last_litter = ROW('Fido',DATE '1994-07-15',5);\par
\par
Here is an example of a query on the LINEAGE Table:\par
\par
   SELECT name, status, last_litter\par
   FROM   Lineage\par
   WHERE  last_litter.dog = 'Fido';\par
\par
In this SELECT statement, the LAST_LITTER Column is referred to as a whole in\par
the <select list>, but only the value of its first Field is referred to in the\par
WHERE clause. The result is the entire row we inserted earlier.\par
\page\par
Chapter 12 -- Reference types\par
\par
[Obscure Rule] applies for this entire chapter.\par
\par
In SQL, a <reference type> is a pointer: a scalar constructed SQL <data type>.\par
\par
Reference <data type>s\par
\par
A <reference type> is defined by a descriptor that contains three pieces of information:\par
      ## The <data type>'s name: REF.\par
      ## The name of the UDT that the <reference type> is based on. (The UDT is known as the referenced type.)\par
      ## The scope of the <reference type>: a (possibly empty) list of the names of the Base tables that make up the <reference type>'s scope.\par
\par
REF:\par
The required syntax for a <reference type> specification is:\par
\par
<reference type> ::=\par
REF (<UDT name>) [ VALUES ARE SYSTEM GENERATED ] [ SCOPE <Table name list> ]\par
\par
   <Table name list> ::=\par
   (<Table name> [ \{,<Table name>\}... ]) |\par
   <Table name>\par
\par
A <reference type> specification defines a pointer: its value is a value that\par
references some site. (A site either does or does not have a REF value.) For\par
example, this REF specification defines a <reference type> based on a UDT (the\par
"referenced type") called MY_UDT:\par
\par
   REF(my_udt)\par
\par
If you're putting a REF specification in an SQL-Schema statement, the\par
<AuthorizationID> that owns the containing Schema must have the USAGE\par
Privilege on "<UDT name>". If you're putting a REF specification in any other\par
SQL statement, then your current <AuthorizationID> must have the USAGE Privilege on "<UDT name>".\par
\par
For each site that has a REF value and is defined to hold a value of the\par
referenced UDT, there is exactly one REF value -- at any time, it is distinct\par
from the REF value of any other site in your SQL-environment. The <data type>\par
of the REF value is REF(UDT).\par
      ## [NON-PORTABLE] The data type and size of a REF value in an\par
application program must be some number of octets but is non-standard because\par
the SQL Standard requires implementors to define the octet-length of a REF value.\par
\par
A REF value might have a scope: it determines the effect of a dereference\par
operator on that value. A REF value's scope is a list of Base table names and\par
consists of every row in every one of those Base tables. The optional SCOPE\par
clause of a <reference type> specification identifies REF's scope. Each Table\par
named in the SCOPE clause must be a referenceable Base table with a structured\par
type that is the same as the structured type of the UDT that REF is based on.\par
The SCOPE clause can name either a single Table, or it may include a\par
parenthesized list of <Table name>s. Here are two examples:\par
\par
   CREATE TABLE Table_1 (\par
      column_1 SMALLINT,\par
      column_2 REF(my_udt) SCOPE Table_1);\par
\par
   CREATE TABLE Table_1 (\par
      column_1 SMALLINT,\par
      column_2 REF(my_udt) SCOPE (Table_1, Table_2));\par
\par
If you omit the SCOPE clause, the scope defaults to the Table that owns the\par
Column you're defining. For example, these two SQL statements are equivalent:\par
\par
   CREATE TABLE Table_1 (\par
      column_1 SMALLINT,\par
      column_2 REF(my_udt));\par
\par
   CREATE TABLE Table_1 (\par
     column_1 SMALLINT,\par
     column_2 REF(my_udt) SCOPE Table_1);\par
\par
If your REF specification includes the optional VALUES ARE SYSTEM GENERATED\par
clause, then REF must be the <data type> specified in a <Column definition> of\par
a persistent Base table, as in this SQL statement:\par
\par
   CREATE TABLE Table_1 (\par
      column_1 SMALLINT,\par
      column_2 REF(my_udt) VALUES ARE SYSTEM GENERATED);\par
\par
The <Column definition> must be for the only system-generated Column of its\par
Table and will be constrained to accept only unique, non-null values. Further,\par
the Column's Table may not have a proper subtable that is a referenceable Base table.\par
\par
If your REF specification includes the optional VALUES ARE SYSTEM GENERATED\par
clause, it may also include the optional SCOPE clause, to specify the scope of\par
the <reference type>, as in:\par
\par
   CREATE TABLE Table_1 (\par
      column_1 SMALLINT,\par
      column_2 REF(my_udt) VALUES ARE SYSTEM GENERATED SCOPE Table_1);\par
\par
A <reference type> is a subtype of a <data type> if (a) both are <reference\par
type>s and (b) the UDT referenced by the first <reference type> is a subtype\par
of the UDT referenced by the second <reference type>.\par
\par
If you want to restrict your code to Core SQL, don't use the REF <data type>.\par
\par
Reference Operations\par
\par
A <reference type> is compatible with, and comparable to, all other <reference\par
type>s of the same referenced type -- that is, <reference type>s are mutually\par
comparable and mutually assignable if they are based on the same UDT.\par
\par
CAST:\par
In SQL, CAST is a scalar operator that converts a given scalar value to a\par
given scalar <data type>. The required syntax for the CAST operator is:\par
\par
CAST (<cast operand> AS <cast target>)\par
\par
   <cast operand> ::= scalar_expression\par
\par
   <cast target> ::= <Domain name> | <data type>\par
\par
The CAST operator converts values of a source <data type> into values of a\par
target <data type>, where each <data type> is an SQL pre-defined <data type>\par
(data conversions between UDTs are done with a user-defined cast). The source\par
<data type>, or <cast operand>, can be any expression that evaluates to a\par
single value. The target <data type>, or <cast target>, is either an SQL\par
predefined <data type> specification or the name of a Domain whose defined\par
<data type> is the SQL predefined <data type> that you want to convert the\par
value of "scalar_expression" into. (If you use CAST (... AS <Domain name>),\par
your current <AuthorizationID> must have the USAGE Privilege on that Domain.)\par
\par
It isn't, of course, possible to convert the values of every <data type> into\par
the values of every other <data type>. For <reference type>s, the rules are:\par
      ## CAST (NULL AS <data type>) and CAST (ref_source_is_a_null_value AS\par
<data type>) both result in a CAST result of NULL.\par
      ## You can CAST a <reference type> source to a UDT target and to any SQL\par
predefined <data type> target, except for <collection type>s and <row type>s,\par
provided that a user-defined cast exists for this purpose and your current\par
<AuthorizationID> has the EXECUTE Privilege on that user-defined cast.\par
\par
When you CAST a <reference type> to any legal target, your DBMS invokes the\par
user defined cast routine, with the source value as the routine's argument.\par
The CAST result is the value returned by the user defined cast.\par
\par
Assignment:\par
In SQL, when a <reference type> is assigned to a <reference type> target, the\par
assignment is straightforward -- however, assignment is possible only if your\par
source's UDT is a subtype of the UDT of your target.\par
\par
[Obscure Rule] Since only SQL accepts null values, if your source is NULL,\par
then your target's value is not changed. Instead, your DBMS will set its\par
indicator parameter to -1, to indicate that an assignment of the null value\par
was attempted. If your target doesn't have an indicator parameter, the\par
assignment will fail: your DBMS will return the SQLSTATE error 22002 "data\par
exception-null value, no indicator parameter". Going the other way, there are\par
two ways to assign a null value to an SQL-data target. Within SQL, you can use\par
the <keyword> NULL in an INSERT or an UPDATE statement to indicate that the\par
target should be set to NULL; that is, if your source is NULL, your DBMS will\par
set your target to NULL. Outside of SQL, if your source has an indicator\par
parameter that is set to -1, your DBMS will set your target to NULL\par
(regardless of the value of the source). (An indicator parameter with a value\par
less than -1 will cause an error: your DBMS will return the SQLSTATE error\par
22010 "data exception-invalid indicator parameter value".) We'll talk more\par
about indicator parameters in our chapters on SQL binding styles.\par
\par
Comparison:\par
SQL provides only two scalar comparison operators -- = and <> -- to perform\par
operations on <reference type>s. Both will be familiar; there are equivalent\par
operators in other computer languages. Two REF values are comparable if\par
they're both based on the same UDT. If either of the comparands are NULL, the\par
result of the operation is UNKNOWN.\par
\par
Other Operations:\par
With SQL, you have several other operations that you can perform on <reference type>s.\par
\par
## Scalar functions\par
SQL provides two scalar functions that operate on or return a <reference\par
type>: the <dereference operation> and the <reference resolution>.\par
\par
<dereference operation> --\par
The required syntax for a <dereference operation> is:\par
\par
<dereference operation> ::=\par
reference_argument -> <Attribute name>\par
\par
The <dereference operation> operates on two operands: the first must evaluate\par
to a <reference type> that has at least one Table in its scope and the second\par
must be the name of an Attribute of the <reference type>'s UDT. The\par
<dereference operation> allows you to access a Column of the row identified by\par
a REF value: it returns a result whose <data type> is the <data type> of\par
"<Attribute name>" and whose value is the union of the values of the system-\par
generated Columns of each Table in the <reference type>'s scope, where the\par
system-generated Column is equal to "reference_argument" -- that is, given a\par
REF value, the <dereference operation> returns the value at the site\par
referenced by that REF value. If the REF value doesn't identify a site\par
(perhaps because the site it once identified has been destroyed), the <dereference operation> returns NULL.\par
\par
If you want to restrict your code to Core SQL, don't use the <dereference operation>.\par
\par
<reference resolution> --\par
The required syntax for a <reference resolution> is:\par
\par
<reference resolution> ::=\par
DEREF (reference_argument)\par
\par
DEREF operates on any expression that evaluates to a <reference type> that has\par
at least one Table in its scope. It returns the value referenced by a REF\par
value. Your current <AuthorizationID> must have the SELECT Privilege on every\par
Table in "reference_argument"'s scope, as well as on every subtable of those Tables.\par
\par
If you want to restrict your code to Core SQL, don't use DEREF.\par
\par
## Set functions\par
SQL provides three set functions that operate on a <reference type>: COUNT(*),\par
COUNT and GROUPING. Since none of these operate exclusively with REF\par
arguments, we won't discuss them here; look for them in our chapter on set functions.\par
\par
## Predicates\par
In addition to the comparison operators, SQL provides eight other predicates\par
that operate on <reference type>s: the <between predicate>, the <in\par
predicate>, the <null predicate>, the <exists predicate>, the <unique\par
predicate>, the <match predicate>, the <quantified predicate> and the\par
<distinct predicate>. Each will return a boolean value: either TRUE, FALSE or\par
UNKNOWN. Since none of them operates strictly on <reference type>s, we won't\par
discuss them here. Look for them in our chapters on search conditions.\par
\page\par
Chapter 13 -- NULLs\par
\par
"The problem isn't what they don't know. It's what they do know that ain't so."\par
   -- Ronald Reagan\par
\par
Suppose we make a list of US presidents from memory:\par
\par
YEAR OF ELECTION       NAME\par
?                      Fillmore\par
1860                   Lincoln\par
?                      Johnson\par
1880                   ?\par
1952                   Eisenhower\par
1980                   Reagan\par
\par
We have no idea when Fillmore was elected. We know that somebody was elected in 1880 (Americans hold elections every four years), but we can't remember who. As for Johnson (the Andrew, not the Lyndon) he wasn't elected;\par
he just took over for a while after Lincoln's assassination. Now let's "query" this list:\par
      ## How many presidents are there? Either 5 or 6 (it depends, maybe the guy elected in 1880 was Fillmore).\par
      ## Is Lincoln the first president? Probably. The best answer would be "yes".\par
      ## Was Eisenhower elected in 1880? Probably not. But suppose he was elected once in 1880 and then again in 1952? Our list doesn't tell us.\par
\par
At this point, you might be thinking that we have a bad "database". But technically we don't: none of the data is "bad". This is what a bad database looks like:\par
\par
YEAR OF ELECTION        NAME\par
0000                    Fillmore\par
1860                    Lincoln\par
9999                    Johnson\par
1880                    (unknown)\par
1952                    Eisenhower\par
1980                    Reagan\par
\par
Here, where we previously had question marks, we've filled in some "default" values: 0000 means "don't know", 9999 means "not applicable", (unknown) means "don't know". Now if we query our list, we get some certain answers:\par
      ## How many presidents are there? Obviously 6.\par
      ## Is Lincoln the first president? No -- Fillmore's date (0000) is less than Lincoln's (1860).\par
      ## Was Eisenhower elected in 1880? No -- 'Eisenhower' is not equal to '(unknown)'.\par
Now that's a bad database. The problem is that our "default" values have no special significance to our DBMS, so it applied its regular operators and spewed out definite-looking answers. But it was actually right the first time:\par
there are no definite answers, and a good DBMS would reflect that.\par
\par
This example teaches us three things: (a) that Ronald Reagan was a sage, (b) that some data can be "unknown" (a data collection failure) or "not applicable" (a database definition anomaly), and (c) that it's better to admit\par
the deficiencies in a way that the DBMS can account for. This is unpleasant and mathematically unsound, but it's what we've got.\par
\par
Representing Missing Data with NULL\par
\par
Those missing values that we represented with question marks in our list are what SQL calls NULLs. The NULL value is an amorphous thing, but it does have certain properties which we now enumerate.\par
      ## NULL is a value. Oh, it's true that it represents missing data, but that doesn't mean that it is missing data -- you can put NULL into Columns and you can take it out again. Those operations are only possible with values,\par
therefore NULL is a value.\par
      ## NULL belongs to a Domain. We know that because all values belong to\par
Domains. Therefore, whatever the missing value is in our YEAR Column, it must\par
be an integer -- just like all the other values in that Column. And whatever\par
the missing value is in our NAME Column, it must be a character string -- just\par
like all the other values in that Column. We might not know what its <data\par
type> is by looking at it, but every NULL does have a <data type> -- and every <data type> has a null value.\par
      ## As we stressed when describing each <data type>, whenever you compare\par
NULL with another value, even another NULL, you cannot say whether it is "less\par
than" or "greater than" or "equal to" that other value. There are some times,\par
though, when your DBMS might simply ignore NULLs, or pretend that NULL equals NULL, because in some contexts it won't matter.\par
      ## NULL cannot be represented by a <literal>. Take, for instance, the\par
SMALLINT <data type>. SMALLINT stands for the scale-zero (integral) values\par
between -65535 and +65535. Can you use any of those values to mean NULL? No --\par
because if you did, you would have a number that is less than or greater than\par
or equal to another number in the same set. That is what you're trying to avoid.\par
      ## The null value is designated by the keyword NULL in some SQL\par
contexts. Since NULL is, strictly speaking, a <specification> rather than a\par
<literal>, you can use NULL to denote the null value in SQL statements, but\par
you can't use it everywhere that a <literal> is allowed. For example, you can't do this:\par
\par
   SELECT NULL FROM Widgets;\par
\par
because your DBMS wouldn't be able to guess what the <data type> is.\par
\par
The Meaning of NULL\par
\par
"The cat is neither alive nor dead."\par
   -- Erwin Schr\rdblquote dinger\par
\par
Pay close attention to what these two definitions don't say:\par
      ## NULL. An SQL keyword. Used for specifying missing (absent) values, for any <data type>.\par
      ## UNKNOWN. An SQL keyword. One of three values in a truth table (the other two are TRUE and FALSE). A value in a Boolean <data type>.\par
\par
There is no suggestion that NULL and UNKNOWN are synonyms (except as values\par
for <data type> BOOLEAN). Ordinarily, the two <keyword>s are used in different\par
contexts, although they have a close association with each other (because the\par
usual result of comparing something with NULL is the truth value UNKNOWN).\par
\par
Speaking informally, we can say that a value is NULL "because it's unknown".\par
But there are several possible reasons for a datum to be missing, including\par
nuances of unknownness, and including a quite distinct reason: inapplicability.\par
Different people distinguish different reasons for nullness, but we believe that all the reasons can be squeezed into two large groups.\par
In order of importance, they are:\par
      ## Group 1 -- the NULL / UNKNOWN group. The particular reason might be\par
displayed or explained as "secret", "figure not available", "to be announced",\par
"impossible to calculate", "partly unknown", "uncertain" or "pending". The\par
assumption behind all these words is: there is a value, and the entity\par
possesses the value, but we can't say precisely what the value is right now.\par
      ## Group 2 -- the NULL / NOT APPLICABLE group. The particular reason\par
might be displayed or explained as "undefined", "moot", "quantum uncertain",\par
"irrelevant", "none" or "n/a". The assumption behind all these words is: there\par
is a value, but the entity does not possess the value. Warning: if you have\par
lots of NULL / NOT APPLICABLE values, that might signal a flaw in your\par
database design. Most commonly there is a broken linkage, as in:\par
\par
   Table: Books\par
      Column: Date_Due\par
\par
The Date_Due is properly an attribute of the book's transaction status (only); therefore for all books which are not out, the Date_Due has to be NULL.\par
\par
The distinction between "unknown" and "not applicable" is an old one. Here is ISO's suggested coding scheme for sex:\par
   0 = UNKNOWN\par
   1 = MALE\par
   2 = FEMALE\par
   9 = NOT APPLICABLE\par
\par
So much for what NULL means: it's a representation of a value that's missing,\par
either because we don't know it or because it doesn't apply. We can help this\par
definition along if we delimit things NULL doesn't mean.\par
      ## NULL doesn't mean NaN (Not a Number). NaN means the value is outside\par
the numeric Domain, and we've already shown that NULLs are in the Domain.\par
Therefore, NULL does not mean Nan, or anything similar such as the result of\par
overflow, the result of underflow, a date that's not representable with the\par
Gregorian calendar, the square root of -1 ... in short, an illegitimate value\par
is not a null value. There is no way to store an illegitimate value, but there is a way to store NULL.\par
      ## NULL doesn't mean zero. It's confusing that C manuals say that NULL\par
is zero, but there is no reason to worry about that. Back in Al-Khwarezm's\par
day, there was much hullaballoo over the number zero -- the objection being\par
"how can there be a number which is no number?"\par
      ## NULL doesn't mean '' (empty string). This has often been used in the\par
past for "unknown"s -- but we can't let that confuse us, since we know that\par
NULL is not the same as any value in the Domain of character strings.\par
\par
Three-Valued Logic\par
\par
Most logical systems rest on two values: is/isn't, yes/no, 0/1, TRUE/FALSE.\par
SQL's system is more like: true/false/unknown, is/isn't/could-be,\par
yes/no/maybe, 0/1/?, TRUE/FALSE/UNKNOWN. The  UNKNOWN truth value will\par
generally result from a comparison that involves a null value. SQL's\par
three-valued logical system is a departure from the tried-and-true paths of\par
other programming languages. We will encounter some tricky features and surprises.\par
\par
The original rule is: any scalar comparison returns the UNKNOWN truth value if\par
one of the operands is NULL. The combinatory rules can most easily be shown\par
with truth tables; see our chapter on the BOOLEAN <data type> if you need to refresh your memory.\par
\par
Predicates:\par
We've already said that NULL can't be used with a regular comparison\par
predicate: "WHERE X = NULL" and "WHERE X <> NULL" are both illegal SQL\par
constructs. There's a logical reason for this. The expression "X = NULL" has a\par
NULL operand, therefore (that's the rule!) the result of the expression is\par
always UNKNOWN. SQL does, however, support a predicate that will return TRUE\par
when X is NULL, and FALSE when X is not NULL: this is the <null predicate>.\par
\par
<null predicate> --\par
The required syntax for a <null predicate> is:\par
\par
<null predicate> ::=\par
expression IS [NOT] NULL\par
\par
A <null predicate> tests a value to see whether it is NULL and returns either\par
TRUE or FALSE. IS NULL searches for null values. IS NOT NULL searches for non-\par
null values. The predicate's expression argument can be any expression which evaluates to either a single value or a row.\par
\par
IS NULL is TRUE if every value resulting from "expression" is NULL. IS NOT\par
NULL is TRUE if no value resulting from "expression" is NULL. This is\par
straightforward if the expression is a scalar value like a <Column name>. If\par
there's a null value in the Column, then "<Column name> IS NULL" is TRUE and\par
"<Column name> IS NOT NULL" is FALSE. If the expression results in a row\par
value, then things are less straightforward. Certainly, if x and y are both\par
NULL then "(x,y) IS NULL" is TRUE and "(x,y) IS NOT NULL" is FALSE. And if\par
neither x nor y are NULL, then "(x,y) IS NULL" is FALSE and "(x,y) IS NOT\par
NULL" is TRUE. So far so good. The surprise is that, if only one of x and y is\par
NULL, then "(x,y) IS NULL" is FALSE and "(x,y) IS NOT NULL" is also FALSE.\par
\par
If you want to restrict your code to Core SQL, don't use this expression: "NULL IS NULL" or this expression: "NULL IS NOT NULL".\par
\par
Nullability\par
\par
There are times when you'll want to ensure that a null value can't be put in a\par
Column. The obvious case is when it's a primary key: in our example at the\par
beginning of this chapter, the '?' symbol makes no sense for a NAME -- first,\par
because then we can't tell how many distinct presidents there are for sure and\par
second, because then there's no real value for what's supposed to be the\par
identifying piece of information. To force "non nullability" for a value, you\par
can use a NOT NULL Constraint when defining the Object that the value will be assigned to.\par
\par
There are some who argue that a NOT NULL Constraint should be used as a matter\par
of course. We'd rather think that it's a matter of choice. But anyway, NOT\par
NULL is a common <Column Constraint>. We'll discuss it in our chapter on\par
Constraints and Assertions. For now, just keep in mind that all Columns have a\par
nullability characteristic of either "possibly nullable" or "known not\par
nullable": it determines (a) whether an attempt to INSERT the null value into\par
the Column will fail and (b) whether a SELECT from the Column can ever return\par
the null value. The "possibly nullable" characteristic allows both; the "known\par
not nullable" characteristic" disallows both.\par
\par
If you're a programmer, it's useful to know whether a Column is possibly\par
nullable because that will tell you whether NULL indicators are needed in your\par
code. A Column's nullability characteristic is "possibly nullable" unless one of these situations apply:\par
      ## A Column's nullability characteristic is "known not\par
nullable" if a non-deferrable Constraint/Assertion on the Column evaluates to\par
"Column IS NOT NULL" or if the Column is based on a Domain and a\par
non-deferrable Constraint/Assertion on that Domain evaluates to "VALUE IS NOT NULL".\par
      ## A Column's nullability characteristic is "known not\par
nullable" if a non-deferrable Constraint on the Column is a PRIMARY KEY Constraint.\par
\par
The Duplicate Loophole\par
\par
"Identification for duplicate removal is at a lower level of detail than equality testing in the evaluation of retrieval conditions. Hence it is possible to adopt a different rule."\par
   -- E.F. Codd\par
\par
Here is a syllogism, based on of some of the things we've said so far:\par
      ## 1. Two values are equal if an equality comparison (=) returns TRUE.\par
      ## 2. If either value is NULL, an equality comparison returns UNKNOWN.\par
      ## 3. Therefore a null value is never equal to a null value.\par
Well, we've said those things several times and we won't go back on them. But -- we will introduce a teensy loophole:\par
      ## 4. However, a null value is a duplicate of a null value.\par
\par
That is, while we'll never say that NULL equals NULL, we will say that NULL duplicates NULL.\par
And it goes without saying that, as well, two values are duplicates if they are equal.\par
There are several operations that this loophole will affect. Specifically:\par
      ## GROUP BY -- If you "GROUP BY column_5" and every COLUMN_5 value is NULL, you end up with only one group.\par
      ## DISTINCT -- If the values before a DISTINCT operation are the set \{7,33,NULL,15,7,NULL\}, then the values afterwards are the set \{7,33,NULL,15\}.\par
      ## UNION -- As with DISTINCT, if the values before a UNION operation are the set \{7,33,NULL,15,7,NULL\}, then the values afterwards are the set \{7,33,NULL,15\}.\par
      ## EXCEPT -- As with DISTINCT, if the values before an EXCEPT operation are the set \{7,33,NULL,15,7,NULL\}, then the values afterwards are the set \{7,33,NULL,15\}.\par
      ## INTERSECT -- As with DISTINCT, if the values before an INTERSECT operation are the set \{7,33,NULL,15,7,NULL\}, then the values afterwards are the set \{7,33,NULL,15\}.\par
\par
Fun with NULLs\par
\par
There are many operations which are affected by the presence of NULLs. Our choice has been to describe the exceptional situation when we describe the operation.\par
So this is just a quick summary; for full effects read the appropriate section in another chapter.\par
\par
NULL specification:\par
The NULL specification can be used, as if it's a <literal, in these situations only:\par
      ## In an UPDATE ... SET clause, to specify a "value" to assign to a Column, i.e.: UPDATE ... SET ... = NULL\par
      ## In an INSERT ... VALUES clause, to specify a "value" to assign to a Column, i.e.: INSERT ... VALUES(NULL)\par
      ## To specify a default "value" for a Column or Domain, i.e.: DEFAULT NULL\par
      ## To specify a FOREIGN KEY Constraint rule, i.e.: ON UPDATE SET NULL, ON DELETE SET NULL\par
      ## As a CAST source, i.e.: CAST (NULL AS ...)\par
      ## As a CASE result, i.e.: CASE ... THEN NULL ... END, CASE ELSE NULL END\par
      ## In a row or Table constructor.\par
\par
Set Functions:\par
NULLs are ignored during most set functions and an appropriate warning is issued ("null value eliminated").\par
\par
Searches:\par
WHERE clauses and HAVING clauses are "satisfied" if the result of the search\par
condition is TRUE. Since WHERE rejects both UNKNOWN and FALSE, the expression\par
"WHERE column_1 = column_1" is functionally equivalent to "WHERE column_1 IS NOT NULL".\par
\par
Constraints:\par
A CHECK Constraint is "satisfied" (not violated) if the result of the search\par
condition is either TRUE or UNKNOWN. Notice the difference here between "what satisfies a search" and "what satisfies a Constraint".\par
\par
Scalar operators and functions:\par
The rule for almost any operator or scalar function is that if a significant\par
operand is NULL, the result of the whole operation is NULL. For example, "5 + [null-value]"\par
returns NULL and "UPPER([null-value])" returns NULL. Not only that, but a NULL trumps a zero -- "[null-value] / 0" returns NULL\par
(not a division-by-zero error) and "0 * [null-value]" returns NULL (not zero).\par
The only exceptions to this rule are the COALESCE and NULLIF functions (see CASE expression in our chapter on simple search conditions),\par
which are specifically designed to convert null values.\par
\par
Sorts:\par
For the ORDER BY clause, NULLs are considered to be either higher than all non-null values, or lower than all non-null values (it's implementation-defined, so will vary from DBMS to DBMS).\par
\par
UNIQUE predicate:\par
NULLs cannot equal anything else, so can't stop UNIQUE from being TRUE. For example, a series of rows containing \{1,NULL,2,NULL,3\} is UNIQUE. UNIQUE never returns UNKNOWN.\par
\par
<reference type>s:\par
If a REF value involves no site, perhaps because it has been destroyed, NULL is returned.\par
\par
SQL/CLI:\par
In our chapters on the Call Level Interface, you'll notice that many functions return blank (or zero) when the situation screams for a NULL return. You'll just have to get used to inconsistencies.\par
\par
Problems For Optimizers\par
\par
If you were to write a DBMS optimizer, you'd want to take advantage of certain\par
"transformation rules". Usually these rules depend on two-valued logic, for\par
instance the idea that everything is "either A or not-A". We will give only\par
one example, which we think is the most famous one.\par
\par
The Transitivity Rule states: IF A = B AND B = C THEN A = C. Therefore, a DBMS should detect situations of this nature:\par
\par
   SELECT ...\par
   FROM   t1,t2\par
   WHERE  (t1.column1 = t2.column1 AND t2.column2 = 5);\par
\par
and -- since the join "(t1.column1 = t2.column1)" might be expensive -- consider replacing the query with this apparently equivalent (and valid) one:\par
\par
   SELECT ...\par
   FROM   t1,t2\par
   WHERE (t1.column1 = 5 AND t2.column2 = 5);\par
\par
However, if the DBMS encounters the similar-looking SQL statement:\par
\par
   SELECT ...\par
   FROM   t1,t2\par
   WHERE (t1.column1 = t2.column1 AND t2.column2 = 5) IS NOT FALSE;\par
\par
the transform will not be valid. If T2.COLUMN2 is NULL, then there will be a\par
difference between what the original query returns as opposed to what the\par
"transformed" query would return (UNKNOWN versus FALSE). Therefore a major\par
optimization becomes too dangerous to try. This is not usually a serious worry\par
because the usual query involves a WHERE alone, which means that UNKNOWNs are\par
filtered out the same way that FALSEs are. But occasionally you'll help your\par
optimizer by ensuring that Columns which will be used in complex queries are always not nullable.\par
\par
Nulloclasts vs. Nullodules\par
\par
If you know any Byzantine history at all, you know about the hundred-year\par
struggle between the Iconoclasts ("smashers of icons") and the Iconodules\par
("slaves of icons"). It is disgusting to use a metaphor for that struggle --\par
by referring to Nulloclasts ("NULL smashers") and Nullodules ("NULL slaves") -\par
- because NULL is a Latin word, while clast and dule are Greek suffixes. It's a good metaphor, though.\par
\par
The Nulloclast position:\par
The champion on this side is C. J. Date, possibly the best known database\par
pundit, and author of several books which contain zero howling errors (a\par
remarkable feat in this field). Here are selected quotes from C.J.Date's "An\par
introduction to database systems", sixth edition:\par
      ## "... in our opinion, NULLs -- and the entire theory of three-valued logic on which they are based -- are fundamentally misguided ..."\par
      ## "... it is our general opinion that NULLs are such a bad idea that it is not worth wrecking the whole relational model over them, just because some suitable target tuple sometimes does not exist for some particular foreign key ..."\par
      ## "... NULLs and [three-valued logic] undermine the entire foundation of the relational model."\par
      ## "... SQL manages to introduce a number of additional flaws, over and above the flaws that are inherent in three-valued logic per se"\par
      ## "Our recommendation to DBMS users would thus be to ignore the vendor's [three-valued logic] support entirely, and to use a disciplined 'default values' scheme instead (thereby staying firmly in two-valued logic)."\par
\par
(Incidentally, Date -- and sure he is an honourable man -- specifically decries some of the things we've said here:\par
      ## We used the term "null value" -- and an absence of value is not a value.\par
      ## We said that nulls are in Domains -- and that leads logical complications: all attribute integrity checks would succeed, for instance, because null is part of the Domain.)\par
\par
The Nullodule position:\par
The defenders include E.F. Codd, the founder of relational theory. (In fact Mr\par
Codd favours the idea that there should be more than one NULL class, and\par
therefore a four-valued logic.) But we will just quote from Jim Melton, editor of the SQL Standard:\par
      ## "Some notable database personalities have strongly urged the SQL\par
standards committee to abandon the notion of NULL values in favour of default values."\par
\par
But -- summarizing here -- in practice, we don't worry that in the expression\par
"x = 5", x is a "different kind of thing" than 5 because we know that x\par
represents an integer value. And by the way, after a series of back-and-forth\par
persecutions, a few revolts and several thousand deaths -- the Iconodules won.\par
\page\par
Chapter 14 -- SQL Cluster\par
\par
The SQL Standard describes the concepts on which SQL is based in terms of\par
Objects, such as Tables. Each SQL Object is defined in terms of the\par
characteristics (e.g.: its name) that describe it; the Standard calls this the\par
Object's descriptor. Some Objects are dependent on other Objects, e.g.: a\par
Column is dependent on the Table it belongs to. If an Object is dropped (i.e.:\par
destroyed), then every Object dependent on it is also dropped. The following\par
diagram shows the main SQL Object hierarchy, illustrating, for example, that a\par
Cluster can contain one or more Catalogs; Catalogs can contain one or more\par
Schemas; Schemas can contain one or more Domains, Tables, Character sets, etc.\par
\par
=========\par
=Cluster=\par
=========\par
     |\par
============\par
=Catalog(s)=\par
============\par
     |\par
===========\par
=Schema(s)=\par
===========\par
     |\par
===========\par
=Domain(s)=\par
==================\par
     =or Table(s)=\par
===========================\par
          =or Assertion(s)=\par
====================================\par
               =or Character set(s)=\par
=====================================\par
                    =or Collation(s)=\par
============================================\par
                         =or Translation(s)=\par
============================================\par
\par
(There are several other SQL Objects; this diagram shows only the major ones.)\par
\par
In this chapter, we'll describe SQL Clusters in detail, and show you the syntax to use to create, alter and destroy them.\par
\par
Cluster\par
\par
An SQL Cluster is the group of Catalogs available to an SQL-session at any\par
point in time; that is, it contains all the SQL-data you may access through a\par
given SQL-server. The Objects that belong to a Cluster are known as Cluster\par
Objects; that is, they depend on some Cluster. Every Cluster Object has a name\par
that must be unique (among Objects of its name class) within the Cluster it belongs to. The Cluster Object name classes are:\par
      ## <AuthorizationID>s and Roles.\par
      ## Catalogs.\par
A Cluster may consist of zero or more of these Cluster Objects. The Cluster's\par
name implicitly qualifies the names of the Objects that belong to it, and\par
cannot be explicitly stated. Three SQL statements relate to Clusters: CONNECT, SET CONNECTION and DISCONNECT.\par
\par
[NON-PORTABLE] SQL does not include any CREATE CLUSTER, OPEN CLUSTER, ADD TO\par
CLUSTER or DROP CLUSTER statements. The method you'll use to access a Cluster\par
with your DBMS is thus non-standard because the SQL Standard requires\par
implementors to define what the physical aspects of a Cluster are, whether any\par
Catalog can be part of more than one Cluster at a time, how a Cluster comes\par
into being, how it may be accessed and how it may be destroyed.\par
\par
[OCELOT Implementation] applies for the rest of this chapter.\par
\par
The OCELOT DBMS that comes with this book considers a Cluster to be a directory on your storage device, e.g.: this would represent a Cluster on an MS-DOS hard drive:\par
   C:\\CLUSTER\par
\par
Each Cluster directory contains two files and zero or more subdirectories. The\par
first file, called CLUSTER, contains the current definition of all the\par
lower-level SQL Objects contained within the Catalogs that make up the\par
Cluster. The second file, called CLUSTER.BAK, contains the definitions as they\par
were prior to the last COMMIT statement issued during a SQL-session. Any\par
subdirectories in the Cluster directory represent SQL Catalogs. OCELOT does\par
not allow a Catalog to be part of multiple Clusters.\par
\par
OCELOT's method of creating and connecting to Clusters depends on the way you\par
choose to begin a SQL session.\par
      ## If the first SQL statement in your SQL-session is a CONNECT\par
statement, the DBMS will search for a CLUSTER file on a directory whose name\par
matches the CONNECT statement's <SQL-server name>. If a CLUSTER file is found\par
on the correct directory, the file will be opened. If the correct directory is\par
found but there is no CLUSTER file on it, a CLUSTER file will be created on\par
that directory, and then opened. If no directory with the correct name is\par
found, the directory will be created, then a CLUSTER file will be created on\par
that directory, and opened.\par
      ## If the first SQL statement in your SQL-session is not a CONNECT\par
statement, the DBMS will open a CLUSTER file on a directory named OCELOT.\par
\par
To drop a Cluster, simply delete the CLUSTER file from your storage device.\par
\par
Cluster names:\par
A <SQL-server name> identifies a Cluster. The required syntax for a <SQL-server name> is:\par
\par
<SQL-server name> ::=\par
string\par
\par
An <SQL-server name> has a maximum length of 128 octets and is either a\par
<character string literal>, the name of a host character string parameter or a\par
reference to an SQL character string parameter that conforms to the rules for an <identifier>.\par
\par
NON-PORTABLE] A <SQL-server name> must be unique (for all Clusters) within an\par
SQL-environment, but is non-standard because the SQL Standard requires\par
implementors to define what a <SQL-server name> may be and which Character set it belongs to.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
defines a <SQL-server name> as any <identifier> belonging to the SQL_TEXT\par
Character set that also follows the rules for a directory name on the\par
operating system in use; generally it may include [drive:] and \\upper-level name.\par
\par
Here are some examples of possible <SQL-server name>s:\par
\par
   'CLUSTER_1'\par
   -- a <SQL-server name> that is a <character string literal>\par
\par
   :CLUSTER_1\par
   -- a <SQL-server name> that is a host parameter name\par
\par
   CLUSTER_1\par
   -- a <SQL-server name> that is an SQL parameter name\par
\page\par
Chapter 15 -- SQL Authorizationid\par
\par
In this chapter, we'll describe SQL <AuthorizationID>s in detail, and show you the syntax to use to create, alter and destroy them.\par
\par
<AuthorizationID>\par
\par
A Cluster may contain zero or more <AuthorizationID>s. An SQL\par
<AuthorizationID>, or Authorization Identifier, is a character string which\par
identifies a user or a Role -- and the set of Privileges belonging to that\par
user or Role. (A user is either an actual person or an application program\par
that has access to SQL-data.) Thus, an <AuthorizationID> is not only an\par
<identifier>, but an SQL Object in its own right. <AuthorizationID>s are\par
dependent on some Cluster -- the <AuthorizationID> must be unique within the\par
Cluster the <AuthorizationID> belongs to -- and are created, dropped and\par
mapped to real users using implementation-defined methods. The Objects that\par
may belong to an <AuthorizationID> are called Privileges; they depend on some\par
<AuthorizationID>. An <AuthorizationID> may have the use of zero or more Privileges.\par
\par
Role:\par
Large organization may have hordes of users with the same Privileges on the\par
same Objects. For instance, circulation assistants are all allowed to do the\par
circulation process. In SQL-92, the solutions were unsatisfactory:\par
      ## If each circulation assistant had a different <AuthorizationID>, then\par
there were too many Objects in the Catalog and granting/revoking was a major chore.\par
      ## If all circulation assistants had the same <AuthorizationID>, some\par
other method had to be devised so that one could distinguish which assistant really did what.\par
\par
In SQL3 there is a major improvement: Roles. An SQL Role is a named bundle of\par
zero or more Privileges. Granting a Role to an <AuthorizationID> allows that\par
<AuthorizationID> to use every Privilege granted to that Role. There is a\par
many-to-many relationship between user <AuthorizationID>s and Roles: a user\par
may be granted the use of many Roles and the use of the same Role may be\par
granted to many user <AuthorizationID>s. The use of a Role may also be granted to another Role.\par
\par
An <AuthorizationID> is defined by a descriptor that contains three pieces of information:\par
      ## The <AuthorizationID> string itself.\par
      ## Whether the <AuthorizationID> identifies a user or a Role.\par
      ## A Privilege descriptor for every Privilege granted to the\par
<AuthorizationID>. At any point in time, an <AuthorizationID> has the use of\par
every Privilege granted to PUBLIC, every Privilege directly granted to that\par
<AuthorizationID> and every Privilege granted to every Role that has been\par
granted to that <AuthorizationID>. (Since a Role may be granted to another\par
Role, all dependent Role Privileges are also available to the <AuthorizationID>.\par
\par
[NON-PORTABLE] SQL does not include any CREATE AUTHID, MAP AUTHID or DROP\par
AUTHID statements. The methods you'll use with your DBMS to create and drop\par
<AuthorizationID>s and to identify the real-life user an <AuthorizationID>\par
represents are non-standard because the SQL Standard requires implementors to\par
define how an <AuthorizationID> comes into being, how it may be destroyed, how\par
it maps to users of SQL-data and what constitutes a valid <AuthorizationID>.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
"creates" an <AuthorizationID> automatically when it is used in a CONNECT\par
statement, a CREATE SCHEMA statement, a MODULE statement, a SET SESSION\par
AUTHORIZATION statement or a GRANT statement. <AuthorizationID>s are "dropped"\par
if they own no Objects and all their Privileges have been revoked.\par
\par
The SQL Standard identifies six types of <AuthorizationID>:\par
      ## The SQL-session <AuthorizationID> is the user <AuthorizationID> for\par
an SQL-session. Initially, it is the user <AuthorizationID> that started a\par
given SQL-session and is determined from the USER clause of the CONNECT\par
statement. The SQL-session <AuthorizationID> may never be NULL -- if the\par
CONNECT ... USER clause names a Role instead of a user <AuthorizationID>, the\par
SQL-session <AuthorizationID> is set to a default value by your DBMS. You can\par
change the SQL-session <AuthorizationID> with the SET SESSION AUTHORIZATION\par
statement. The user function SESSION_USER returns the value of the current\par
SQL-session <AuthorizationID>.\par
      ## The context of an SQL-session includes its current user and its\par
current Role: together, they determine the Privileges available to execute SQL\par
statements in the SQL-session and one of them is always the "current\par
<AuthorizationID>". Either one of current user or current Role may be NULL at\par
any time, but they may not both be NULL at the same time -- the non-null\par
identifier is the SQL-session's current <AuthorizationID>. At the beginning of\par
every SQL-session, the current user is set to the value of the SQL-session\par
<AuthorizationID> and the current Role is set to the Role that started the\par
SQL-session -- it is determined from the CONNECT statement: if CONNECT ...\par
USER specifies a <Role name>, the Role identified by that <Role name> becomes\par
the current Role; otherwise, the current Role is NULL. You can change the\par
current role with the SET ROLE statement. The equivalent user functions\par
CURRENT_USER and USER return the value of the current user <AuthorizationID>.\par
The user function CURRENT_ROLE returns the value of the current Role <AuthorizationID>.\par
      ## The Module <AuthorizationID> is the owner of a given Module and is\par
the current <AuthorizationID> when the Module's SQL procedures are executed.\par
The Module <AuthorizationID> may either be specifically identified (in the\par
MODULE statement) or it will default to the current SQL-session <AuthorizationID>.\par
      ## The Schema <AuthorizationID> is the owner of a given Schema and may\par
either be specifically identified (in the CREATE SCHEMA statement) or it will\par
default to the current Module <AuthorizationID>, if there is one. If the\par
Module you're running doesn't have an explicit owner either, the Schema\par
<AuthorizationID> defaults to the current SQL-session <AuthorizationID>.\par
      ## The current <AuthorizationID> is the <AuthorizationID> whose\par
Privileges are checked prior to the execution of an SQL statement. If the\par
current <AuthorizationID> doesn't have the required Privilege to perform an\par
operation on SQL-data, the SQL statement will fail. For direct SQL, the\par
SQL-session <AuthorizationID> is always the current <AuthorizationID>.\par
\par
To create a Role and grant its use to an initial <AuthorizationID>, use the\par
CREATE ROLE statement. To destroy a Role, use the DROP ROLE statement. To\par
grant Privileges to a user or a Role, or to grant the use of a Role to an\par
<AuthorizationID>, use the GRANT statement. To revoke Privileges from a user\par
or a Role, or to revoke the use of a Role from an <AuthorizationID>, use the\par
REVOKE statement or the DROP ROLE statement. To change the current SQL-session\par
<AuthorizationID>, use the SET SESSION AUTHORIZATION statement. And to change\par
the current Role, use the SET ROLE statement.\par
\par
If you want to restrict your code to Core SQL, don't use Roles at all.\par
\par
<AuthorizationID>s and Role names:\par
An <AuthorizationID> identifies a user or a Role. A <Role name> identifies a Role. The required syntax for an <AuthorizationID> or <Role name> is:\par
\par
<AuthorizationID> ::=\par
user name | <Role name>\par
\par
An <AuthorizationID> is a <regular identifier> or a <delimited identifier>, no\par
more than 128 octets long, that is unique (for all <AuthorizationID>s and\par
Roles) within the Cluster it belongs to. Typically, an <AuthorizationID> is a\par
Christian name (e.g.: BOB or SAM, identifying a user) or a department name\par
(e.g.: DOCUMENTATION, identifying a Role) and, most often, has a one-to-one\par
relationship to some user (i.e.: each user has only one <AuthorizationID>).\par
\par
The <regular identifier> -- PUBLIC -- is a valid <AuthorizationID> only in the\par
GRANT statement and the REVOKE statement. PUBLIC is the SQL special grantee,\par
used as an "all-purpose" grantee, to enable system-wide Privileges to be\par
granted to and/or revoked from all current and future <AuthorizationID>s with\par
a single SQL statement. Every <AuthorizationID> always has the use of every\par
Privilege granted to PUBLIC. The <delimited identifier> -- "PUBLIC" -- is never a valid <AuthorizationID>.\par
\par
The <delimited identifier> -- "_SYSTEM" -- is a valid <AuthorizationID> only\par
when you're looking at INFORMATION_SCHEMA. "_SYSTEM" is the SQL special\par
grantor, used (by your DBMS) as an "all-purpose" grantor, to enable\par
Object-wide Privileges to be granted to an <AuthorizationID> that creates an\par
Object, or to revoke cascading, system-wide Privileges from an\par
<AuthorizationID> that drops an Object. (In the case of a DROP, "_SYSTEM" is\par
also the grantee that revokes all related Privileges from all other <AuthorizationID>s.)\par
\par
[NON-PORTABLE] Except for the cases (PUBLIC, "PUBLIC", "_SYSTEM") noted\par
earlier, what your DBMS will recognize as a valid <AuthorizationID> is non-\par
standard because the SQL Standard requires implementors to define what a valid <AuthorizationID> is.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book will accept any SQL_TEXT <identifier> as an <AuthorizationID>.\par
\par
CREATE ROLE statement\par
\par
The CREATE ROLE statement defines new Role. The required syntax for the CREATE ROLE statement is:\par
\par
CREATE ROLE <Role name> [ WITH ADMIN <grantor> ]\par
\par
   <grantor> ::= CURRENT_USER | CURRENT_ROLE\par
\par
The CREATE ROLE statement specifically defines an <AuthorizationID> to be a\par
Role, rather than a user: this is necessary since otherwise your DBMS could\par
mistake <Role name> for a user name which appears in similar contexts. <Role\par
name> is an <AuthorizationID> that is unique within your SQL-environment and\par
CREATE ROLE automatically grants the use of the new Role to the current\par
<AuthorizationID> WITH ADMIN OPTION (that is, the current <AuthorizationID>\par
gets the use of the new Role and may pass this use on to others).\par
\par
[NON-PORTABLE] Whether you can use CREATE ROLE is non-standard because the SQL\par
Standard requires implementors to define what Privilege (if any) is needed to execute CREATE ROLE.\par
\par
The optional WITH ADMIN clause decides which <AuthorizationID> (either the\par
current user or the current Role) gets the use of this Role: CURRENT_USER is\par
the <AuthorizationID> of the current user and CURRENT_ROLE is the\par
<AuthorizationID> of the current Role. If you omit the clause, it defaults to\par
WITH ADMIN CURRENT_USER -- but if CURRENT_USER is NULL, the clause defaults to\par
WITH ADMIN CURRENT_ROLE. If you specify WITH ADMIN CURRENT_USER and the\par
current <AuthorizationID> is a <Role name>, or if you specify WITH ADMIN\par
CURRENT_ROLE and the current <Role name> is NULL, the GRANT statement will\par
fail: your DBMS will return the SQLSTATE error 0L000 "invalid grantor". Here are two examples:\par
\par
   CREATE ROLE assistants_role WITH ADMIN CURRENT_USER;\par
   -- creates a Role, identified by the <AuthorizationID> ASSISTANTS_ROLE, for the current user\par
\par
   CREATE ROLE assistants_role WITH ADMIN CURRENT_ROLE;\par
   -- creates a Role, identified by the <AuthorizationID> ASSISTANTS_ROLE, for the current Role\par
\par
If you want to restrict your code to Core SQL, don't use the CREATE ROLE statement.\par
\par
Privilege\par
\par
An SQL Privilege allows an <AuthorizationID> to perform a given action on a\par
specific Table, Column, Domain, Character set, Collation, Translation,\par
Trigger, SQL-invoked routine or UDT. Privileges are dependent on some\par
<AuthorizationID> or Role, are created and granted with the GRANT statement\par
and are destroyed with the REVOKE statement and the DROP ROLE statement. A\par
Privilege is defined by a descriptor that contains five pieces of information:\par
      ## The name of the Object that the Privilege acts on.\par
      ## The <AuthorizationID> that granted the Privilege.\par
      ## The <AuthorizationID> that may use the Privilege.\par
      ## The action (either INSERT, UPDATE, DELETE, SELECT, REFERENCES, USAGE, UNDER, TRIGGER or EXECUTE) that may be taken on the specified Object.\par
      ## Whether the Privilege is grantable by the grantee.\par
\par
<privileges>:\par
The required syntax for a Privilege specification is:\par
\par
<privileges> ::=\par
<object privileges> ON <Object name>\par
\par
   <Object name> ::=\par
   [ TABLE ] <Table name> |\par
   DOMAIN <Domain name>  |\par
   CHARACTER SET <Character set name> |\par
   COLLATION <Collation name> |\par
   TRANSLATION <Translation name> |\par
   TYPE <UDT name> |\par
   <specific routine designator>\par
\par
   <object privileges> ::=\par
   ALL PRIVILEGES |\par
   <action> [ \{,<action>\}... ]\par
\par
      <action> ::=\par
      DELETE |\par
      SELECT [ (<Column name> [ \{,<Column name>\} ... ]) ] |\par
      INSERT [ (<Column name> [ \{,<Column name>\} ... ]) ] |\par
      UPDATE [ (<Column name> [ \{,<Column name>\} ... ]) ] |\par
      REFERENCES [ (<Column name> [ \{,<Column name>\} ... ]) ] |\par
      TRIGGER |\par
      UNDER |\par
      USAGE |\par
      EXECUTE\par
\par
The Privilege specification specifies one or more Privileges for a specific Object. Not all Privileges are valid for every Object.\par
\par
ALL PRIVILEGES is a shorthand: it means every Privilege the grantor has on\par
"<Object name>". If "<Object name>" identifies a temporary Table, ALL\par
PRIVILEGES is the only valid Privilege specification. Here's an example:\par
\par
   ALL PRIVILEGES ON TABLE Table_1\par
\par
In theory, you could substitute ALL PRIVILEGES for USAGE or EXECUTE, but\par
there's never a good reason to do so. Traditionally, ALL PRIVILEGES\par
substitutes for the combination of Table Privileges: SELECT, INSERT, UPDATE,\par
DELETE and perhaps TRIGGER or REFERENCES. The closest analogous construct is\par
the * in "SELECT * ...", then. And similar objections to using it apply:\par
      ## You can't tell by reading the SQL code what Privileges are in fact being granted.\par
      ## Because ALL PRIVILEGES is a shorthand, it might mean something different the next time you use it (because somebody might have in the interim granted additional Privileges to the current user).\par
      ## If the current user has only one Privilege, you will not be warned that all the other potentially applicable Privileges are not being granted.\par
You should prefer to be explicit about what you're granting: if you depend on\par
a complex system of defaults you'll miss something. These considerations don't\par
apply to temporary Tables since, for them, ALL PRIVILEGES really does mean all\par
of: SELECT, INSERT, UPDATE, DELETE, TRIGGER, REFERENCES.\par
\par
A SELECT, INSERT, UPDATE, REFERENCES, DELETE or TRIGGER Privilege is called a\par
Table Privilege: it allows the specified action on the entire Table named in\par
the Privilege's descriptor -- including on any Columns that are subsequently\par
added to that Table. You may not grant the TRIGGER Table Privilege on anything\par
but a Base table. You may not grant the other Table Privileges on a declared\par
LOCAL TEMPORARY Table, or on any other Object. Note that the <keyword> TABLE\par
is noise; it may be omitted from the Privilege specification. Here are two equivalent examples:\par
\par
   DELETE ON TABLE Table_1\par
\par
   DELETE ON Table_1\par
\par
Both of these Privilege specifications define a Privilege that deletes rows\par
from TABLE_1. Here's an example of a Privilege specification that defines a\par
Privilege that selects values from every Column of TABLE_1:\par
\par
   SELECT ON TABLE Table_1\par
\par
And here's an example of a Privilege specification that defines a Privilege that enables a Trigger to operate on every Column of TABLE_1:\par
\par
   TRIGGER ON TABLE Table_1\par
\par
A SELECT(<Column name> list), INSERT(<Column name> list), UPDATE(<Column name>\par
list) or REFERENCES(<Column name> list) is called a Column Privilege: it\par
allows the specified action only on the Columns actually named when the\par
Privilege is granted. You may not grant Column Privileges on the Columns of a\par
declared LOCAL TEMPORARY Table or on any other Object. Again, the <keyword>\par
TABLE is noise; it may be omitted from the Privilege specification. Here are two equivalent examples:\par
\par
   UPDATE(column_1,column_3) ON TABLE Table_1\par
\par
   UPDATE(column_1,column_3) ON Table_1\par
\par
Both of these Privilege specifications define a Privilege that updates the\par
values of TABLE_1.COLUMN_1 and TABLE_1.COLUMN_3. Here's an example of a\par
Privilege specification that defines a Privilege that inserts values into TABLE_1.COLUMN_2:\par
\par
   INSERT(column_2) ON TABLE Table_1\par
\par
And here's an example of a Privilege specification that defines a Privilege\par
that enables TABLE_1.COLUMN_3 to be named in a Constraint or Assertion definition:\par
\par
   REFERENCES(column_3) ON TABLE Table_1\par
\par
Every Privilege you have on a Table that is the basis for an updatable View is\par
also granted to you on that View. For example, if you have the INSERT and\par
SELECT Privileges on a Table and create an updatable View based on that Table,\par
you will also have the INSERT and SELECT Privileges on the View. If your Table\par
Privileges are grantable Privileges, your Privileges on the View will also be grantable.\par
\par
An UNDER Privilege is called an UNDER Privilege: it allows that action on the\par
UDT named in the Privilege's descriptor. The <UDT name> may either identify a\par
structured type or it may specify a <Table name>. You may not grant an UNDER\par
Privilege on any other Object. Here's an example:\par
\par
   UNDER ON TYPE bob.bob_udt\par
\par
A USAGE Privilege is called a USAGE Privilege: it allows the use of the\par
Domain, UDT, Character set, Collation or Translation named in the Privilege's\par
descriptor. You may not grant a USAGE Privilege on any other Object. Here's two examples:\par
\par
   USAGE ON DOMAIN domain_1\par
\par
   USAGE ON CHARACTER SET bob.charset_1\par
\par
When a Catalog is "created", your DBMS grants the USAGE Privilege on all\par
INFORMATION_SCHEMA Character sets, Collations and Translations to PUBLIC WITH\par
GRANT OPTION, so you always have the use of those Objects. If for some reason\par
you should ever create a new character-related Object, do the same -- there is\par
no point being secretive here.\par
\par
An EXECUTE Privilege is called an EXECUTE Privilege: it allows the SQL-invoked\par
routine named in the Privilege's descriptor to be executed. You may not grant\par
an EXECUTE Privilege on any other Object. Here's an example:\par
\par
   EXECUTE ON SPECIFIC ROUTINE some_routine\par
\par
(We define <specific routine designator> in our chapter on UDTs.)\par
\par
Note that if two Privileges are identical except that one is a grantable\par
Privilege and the other is not, the grantable Privilege takes precedence and\par
both Privileges are set to grantable Privileges. Your DBMS will then eliminate\par
the redundant duplicate Privilege.\par
\par
If you want to restrict your code to Core SQL, don't specify the UNDER\par
Privilege, don't specify the SELECT Privilege as a Column Privilege (that is,\par
with a <Column name> list) and don't specify the INSERT Privilege as a Column Privilege.\par
\par
GRANT statement\par
\par
The GRANT statement defines both Privilege grants and Role authorizations and\par
so has two different syntaxes. The first is identified as the <grant privilege\par
statement> and the second as the <grant role statement>.\par
\par
<grant privilege statement>:\par
The required syntax for the <grant privilege statement> form of the GRANT statement is:\par
\par
<grant privilege statement> ::=\par
GRANT <privileges> TO <grantee> [ \{,<grantee>\}... ] [ WITH GRANT OPTION ]\par
[ FROM <grantor> ]\par
\par
   <grantee> ::= PUBLIC | <AuthorizationID>\par
\par
   <grantor> ::= CURRENT_USER | CURRENT_ROLE\par
\par
The <grant privilege statement> grants one or more Privileges on a given\par
Object to one or more grantees, including (possibly) PUBLIC. The grantor of\par
the Privileges must, of course, hold those Privileges as grantable Privileges.\par
\par
We've already shown you the syntax for the <privileges> Privilege\par
specification; it's used exactly that way in this form of the GRANT statement.\par
Here are some examples:\par
\par
   GRANT SELECT ON TABLE Table_1 TO PUBLIC;\par
\par
   GRANT INSERT(column_1,column_5) ON Table_1 TO sam;\par
\par
   GRANT ALL PRIVILEGES ON TABLE Table_1 TO PUBLIC, bob, sam;\par
\par
   GRANT USAGE ON DOMAIN domain_1 TO bob;\par
\par
   GRANT EXECUTE ON SPECIFIC ROUTINE some_routine TO sam;\par
\par
If your <grantee> is PUBLIC, you're granting the Privilege to a list of\par
<grantee>s that contains all of the <AuthorizationID>s in the Cluster -- now\par
and in the future. If your <grantee> is one or more <AuthorizationID>s, you're\par
granting the Privilege only to those <AuthorizationID>s. (Remember that an\par
<AuthorizationID> may identify either a user or a Role.)\par
\par
When you grant a SELECT, UPDATE or REFERENCES Table Privilege on a Base table that has subtables, the effect is two-fold:\par
      ## The specified Privilege is granted on every Column of the Base table named.\par
      ## The specified Privilege is also granted on the inherited Column(s) of each of that Base table's subtables.\par
\par
The optional FROM clause names the grantor of the Privileges: CURRENT_USER is\par
the <AuthorizationID> of the current user and CURRENT_ROLE is the\par
<AuthorizationID> of the current Role. If you omit the clause, it defaults to\par
FROM CURRENT_USER -- but if CURRENT_USER is NULL, the clause defaults to FROM\par
CURRENT_ROLE. If you specify FROM CURRENT_USER and the current\par
<AuthorizationID> is a <Role name>, or if you specify FROM CURRENT_ROLE and\par
the current <Role name> is NULL, the GRANT statement will fail: your DBMS will\par
return the SQLSTATE error 0L000 "invalid grantor". Here are two examples:\par
\par
   GRANT UPDATE(column_1,column_5) ON Table_1 TO sam FROM CURRENT_USER;\par
\par
   GRANT DELETE ON Table_1 TO PUBLIC FROM CURRENT_ROLE;\par
\par
The optional WITH GRANT OPTION clause defines a grantable Privilege: one that\par
the grantee may, in turn, grant to other <AuthorizationID>s. If you omit the\par
clause, the grantee will not be able to pass the Privilege on to others. Here are two examples:\par
\par
   GRANT REFERENCES(column_4,column_5) ON Table_1 WITH GRANT OPTION\par
      TO bob,sam FROM CURRENT_USER;\par
\par
   GRANT TRIGGER Table_1 WITH GRANT OPTION\par
      TO PUBLIC FROM CURRENT_ROLE;\par
\par
If the GRANT statement isn't able to successfully create a Privilege\par
descriptor for every one of its Privilege specifications, your DBMS will\par
return the SQLSTATE warning 01007 "warning-privilege not granted".\par
\par
If you want to restrict your code to Core SQL, don't use the FROM <grantor> clause with the GRANT statement.\par
\par
<grant role statement>:\par
The required syntax for the <grant role statement> form of the GRANT statement is:\par
\par
<grant role statement> ::=\par
GRANT <Role name> [ \{,<Role name>\}... ] TO <grantee> [ \{,<grantee>\}... ]\par
[ WITH ADMIN OPTION ]\par
[ FROM <grantor> ]\par
\par
   <grantee> ::= PUBLIC | <AuthorizationID>\par
\par
   <grantor> ::= CURRENT_USER | CURRENT_ROLE\par
\par
The <grant role statement> grants the use of one or more Roles to one or more\par
grantees, including (possibly) PUBLIC. The grantor of the Roles must, of\par
course, hold those Roles as grantable Roles (that is, WITH ADMIN OPTION).\par
<Role name> must be an <AuthorizationID> that identifies a Role.\par
\par
If your <grantee> is PUBLIC, you're granting the use of <Role name> to a list\par
of <grantee>s that contains all of the <AuthorizationID>s in the Cluster --\par
now and in the future. If your <grantee> is one or more <AuthorizationID>s,\par
you're granting the use of the Role only to those <AuthorizationID>s. Keep in\par
mind that an <AuthorizationID> may identify either a user or a Role -- this\par
means you can grant the use of a Role not only to a user, but to another Role.\par
Be careful with this last option: SQL doesn't allow you to grant the use of a\par
Role to a Role that already has the use of that Role -- that is, no cycles of\par
Role grants are allowed. Note that if two Role grants are identical except\par
that one is a grantable Role and the other is not, the grantable Role takes\par
precedence and both Roles are set to grantable Roles. Your DBMS will then\par
eliminate the redundant duplicate Role grant.\par
\par
The optional FROM clause names the grantor of the Roles: CURRENT_USER is the\par
<AuthorizationID> of the current user and CURRENT_ROLE is the\par
<AuthorizationID> of the current Role. If you omit the clause, it defaults to\par
FROM CURRENT_USER -- but if CURRENT_USER is NULL, the clause defaults to FROM\par
CURRENT_ROLE. If you specify FROM CURRENT_USER and the current\par
<AuthorizationID> is a <Role name>, or if you specify FROM CURRENT_ROLE and\par
the current <Role name> is NULL, the GRANT statement will fail: your DBMS will\par
return the SQLSTATE error 0L000 "invalid grantor". For example, in this SQL\par
statement, the current user is granting the use of the ASSISTANTS_ROLE Role to every <AuthorizationID>:\par
\par
   GRANT assistants_role TO PUBLIC FROM CURRENT_USER;\par
\par
In this SQL statement, the current Role is granting the use of the ASSISTANTS_ROLE and the BOSSES_ROLE Role to the "bob" and "joe" <AuthorizationID>s:\par
\par
   GRANT assistants_role, bosses_role TO bob, joe FROM CURRENT_ROLE;\par
\par
The optional WITH ADMIN OPTION clause defines a grantable Role: one that the\par
grantee may, in turn, grant the use of to other <AuthorizationID>s. If you\par
omit the clause, the grantee will not be able to pass the use of the Role on\par
to others. Here are two examples:\par
\par
   GRANT assistants_role TO PUBLIC FROM CURRENT_USER WITH ADMIN OPTION;\par
\par
   GRANT assistants_role, bosses_role TO bob, joe\par
     FROM CURRENT_ROLE WITH ADMIN OPTION;\par
\par
If you want to restrict your code to Core SQL, don't use the <grant role\par
statement> form of the GRANT statement and don't grant any grantable\par
Privileges on your Objects to others users -- Core SQL only allows the owner\par
of an Object to hold a grantable Privilege.\par
\par
Data Control\par
\par
You need explicit permission to perform any action on any SQL Object. SQL's\par
security system is discretionary (meaning that your rights vary depending on\par
the action and on the Object). If you try to violate security, what usually\par
happens is an error message. It's not a sophisticated system, but there is\par
some complexity when we get into details and definitions. Here's a simple GRANT statement:\par
\par
   GRANT INSERT                           -- action\par
     ON  Books                            -- Object\par
     TO  joe;                             -- user\par
\par
After this SQL statement is executed, the user named "joe" will be able to use\par
the INSERT statement on the Table named "Books". SQL's security system boils\par
down to this: you can let people access data with GRANT statements, or you can\par
refuse to do so. The combination \{action plus Object\} is a Privilege. The\par
action is usually a verb, the Object is usually a Table and the user is usually a person.\par
\par
Action and Object:\par
What action is possible depends on what the Object is. Here is a chart of the\par
Object types which can be in GRANT statements, and the applicable actions for them:\par
\par
OBJECT              ACTION(S)\par
Base table          SELECT, INSERT, UPDATE, DELETE, TRIGGER, REFERENCES\par
View                SELECT, INSERT, UPDATE, DELETE, REFERENCES\par
Column              SELECT, INSERT, UPDATE, REFERENCES\par
Domain              USAGE\par
Character Set       USAGE\par
Collation           USAGE\par
Translation         USAGE\par
SQL-invoked routine EXECUTE\par
UDT                 UNDER\par
\par
Except for USAGE, the GRANT actions correspond to verbs that are used in SQL statements, for example:\par
\par
   UPDATE Integer_Tables SET\par
      integer_1 = CAST('1' AS INFORMATION_SCHEMA.CARDINAL_NUMBER);\par
\par
For this SQL statement to be possible, the current <AuthorizationID> must have these Privileges:\par
      ## The UPDATE Privilege on Table INTEGER_TABLES and/or the UPDATE Privilege on Column INTEGER_TABLES.INTEGER_1.\par
      ## The USAGE Privilege on Domain INFORMATION_SCHEMA.CARDINAL_NUMBER.\par
\par
User:\par
A user is an <AuthorizationID>. It's important to remember that users are\par
outside the "database" -- the effect is that <AuthorizationID>s are\par
unqualified names, that there are no CREATE USER / DROP user statements in\par
standard SQL and that some important questions depend on your operating\par
system. An easy way to appreciate this is to remember that "joe" is still\par
"joe" even if you switch to a different Schema in a different Catalog. Other points about users:\par
      ## All DBMS operations are done on behalf of some user.\par
      ## All Objects are owned by some user.\par
      ## Users may be people ("Sam Brown" / "Joe") or jobs ("VP Marketing" / "Tellers") or departments ("Acquisitions" / "Front Office") or robots ("Consolidate Report program", "Internet spider"). DBMSs can't distinguish between these categories.\par
\par
In a security context, we're concerned with the user's authorization to ask for certain acts to be performed. That's where the GRANT statement comes in.\par
\par
Owners:\par
Consider this SQL statement:\par
\par
   CREATE SCHEMA Sally_Schema AUTHORIZATION Sally\par
      CREATE Table Sally_Dates (date_1 DATE, date_2 DATE);\par
\par
(The question "who may execute a CREATE SCHEMA statement?" is a tough one.\par
It's implementor-defined, which might mean "anybody at all", but more likely\par
means "some special database administrator who exists when you first install\par
the DBMS". Though the question is important, it rarely is going to come up.)\par
\par
In this example, a user named Sally is the owner of SALLY_SCHEMA. Therefore,\par
by definition, Sally is the owner of all Objects within that Schema -- right\par
now, this includes Table SALLY_DATES and the Columns DATE_1 and DATE_2.\par
** TRAP: You'll often hear that the "owner of a Table" is "the user who\par
created the Table". Technically that's wrong. Suppose another user, Joe, was\par
able to create a Table and store it in Sally's schema:\par
\par
   CREATE Table Sally_Schema.Joe_Dates (\par
      date_1 DATE, date_2 DATE);\par
\par
Joe is the creator of Table JOE_DATES -- but the owner is Sally, because Sally\par
owns the Schema. The distinction between creators and owners is trivial for\par
SQL-92 users because it is illegal to create Objects in a Schema that you\par
don't own. It is legal in SQL3, though -- so don't let old definitions mix you up.\par
\par
As the Schema owner, Sally now has the power to CREATE, ALTER or DROP all\par
Objects in the Schema. Sally alone has this power -- she cannot delegate it --\par
so a Schema owner's CREATE/ALTER/DROP power is a right, not a Privilege. This\par
power exists, but we will not trouble with it further because it does not\par
involve the GRANT statement.\par
\par
Sally also has a full set of all Privileges that apply for each Object in her\par
Schema. For example, Sally has the USAGE Privilege for all of her Schema's\par
Domains, Character sets, Collation and Translations and she has SELECT,\par
UPDATE, INSERT, DELETE, REFERENCES and TRIGGER Table Privileges for all of her\par
Schema's Base Tables. Sally's set of Privileges stems automatically from her\par
ownership of the Schema. Technically it is considered that she was "granted"\par
these powers by a pseudo-user named "_SYSTEM", but for practical purposes she\par
is the ultimate authority. She cannot lose her right to do these operations.\par
She can, however, pass on any or all of her Privileges to any other user. This\par
ability is called the GRANT OPTION, because Sally has the option of granting\par
the Privileges she holds. Sally also may pass on the grant option itself.\par
\par
GRANTs on Tables:\par
Let's follow what a DBMS does with a GRANT statement, using a series of\par
examples based on SALLY_SCHEMA. Here's a GRANT statement for that Schema\par
(assume Sally is the current <AuthorizationID>):\par
\par
   GRANT SELECT, INSERT ON Sally_Dates TO joe WITH GRANT OPTION;\par
\par
Given this SQL statement, a DBMS acts as follows:\par
      ## It determines that Sally owns the Schema, therefore she has a full\par
set of Privileges on Table SALLY_DATES. There is no need to find a Privilege\par
descriptor to see whether she may grant Privileges.\par
      ## It determines that Joe does not exist, so it silently creates a user\par
named Joe. Even if Joe has not made his existence known before, that would be\par
no reason to believe he does not exist. (We're making some assumptions here\par
for the sake of the example. This would be the usual case, but your DBMS might\par
require you to execute some form of (non-standard) CREATE USER statement or it\par
may have some operating-system dependent check on whether Joe exists.)\par
      ## It creates these six new Privilege descriptors:\par
\par
GRANTOR GRANTEE OBJECT  NAME         ACTION   GRANT_OPTION\par
Sally   Joe     Table   Sally_Dates  SELECT   YES\par
Sally   Joe     Table   Sally_Dates  INSERT   YES\par
Sally   Joe     Column  date_1       SELECT   YES\par
Sally   Joe     Column  date_1       INSERT   YES\par
Sally   Joe     Column  date_2       SELECT   YES\par
Sally   Joe     Column  date_2       INSERT   YES\par
\par
The four "Column Privilege" descriptors may surprise you a bit since the GRANT\par
statement syntax doesn't include COLUMN as an Object. But since it does allow\par
Column Privileges to be defined, the effect is that a GRANT on a Table\par
creates, not only a Privilege descriptor for that Table, but also a Privilege\par
descriptor for every applicable Column of that Table.\par
\par
Now, suppose that time passes and the current <AuthorizationID> becomes Joe, who executes this GRANT statement:\par
\par
   GRANT INSERT, UPDATE ON Sally_Dates TO Sam;\par
\par
Given this SQL statement, a DBMS acts as follows:\par
      ## It determines that Joe does not own the Schema, so it looks through\par
the Privilege descriptors to see if there are any where grantee = 'Joe',\par
Object = 'Table', Name = 'Sally_Dates' and grant_option = YES. It finds INSERT\par
Privileges but it does not find UPDATE Privileges, so it returns the SQLSTATE\par
warning 01007 "warning-privilege not granted" and it creates these three new\par
Privilege descriptors:\par
\par
GRANTOR GRANTEE OBJECT  NAME        ACTION   GRANT_OPTION\par
Joe     Sam     Table   Sally_Dates INSERT   NO\par
Joe     Sam     Column  date_1      INSERT   NO\par
Joe     Sam     Column  date_2      INSERT   NO\par
\par
More time passes and Sally is once again the current <AuthorizationID>. She does this:\par
\par
   GRANT INSERT ON Sally_Dates TO Sam;\par
\par
   GRANT INSERT(date_1) ON Sally_Dates TO bob;\par
\par
Given this SQL statement, a DBMS acts as follows:\par
      ## Once again it sees that Sally owns the Schema and so has full Privileges, all grantable.\par
      ## It creates these five new Privilege descriptors:\par
\par
GRANTOR GRANTEE OBJECT  NAME        ACTION   GRANT_OPTION\par
Sally   Sam     Table   Sally_Dates INSERT   NO\par
Sally   Sam     Column  date_1      INSERT   NO\par
Sally   Sam     Column  date_2      INSERT   NO\par
Sally   Bob     Table   Sally_Dates INSERT   NO\par
Sally   Bob     Column  date_1      INSERT   NO\par
\par
These Privilege descriptors for Same are not duplicates of the ones that were\par
created earlier, when Joe granted Sam the same Privileges, therefore the DBMS\par
makes new Privilege descriptors. Later, however, Sally repeats this GRANT:\par
\par
   GRANT INSERT ON Sally_Dates TO Sam;\par
\par
In this final case, nothing happens: there are already Privilege descriptors\par
with the same \{grantor, grantee, Object, name, action\} and duplicates will not\par
be added to INFORMATION_SCHEMA. Your DBMS will return "okay" after creating zero new rows.\par
\par
A related example -- trivial but worth making because older SQL books describe\par
it incorrectly -- concerns the question: what if the last example had\par
contained the WITH GRANT OPTION clause? In that case, the grant_option field\par
for the last two Privilege descriptors would have been changed from NO to YES.\par
\par
In the end, we have fourteen new Privilege descriptors. Sally has the same\par
powers of ownership as before, Joe can INSERT INTO Sally_Dates or SELECT FROM\par
Sally_Dates, Sam can INSERT INTO Sally_Dates and Bob can INSERT INTO\par
Sally_Dates.date_1. Joe's Privileges are WITH GRANT OPTION, Sam's and Bob's\par
are not. We have been at some pains to show that the result is both Table and\par
Column Privilege descriptors, and no two Privilege descriptors can be exact\par
duplicates. There can, however, be considerable overlap, as is seen by the\par
fact that Sam has two sets of INSERT Privileges on the same Object -- one with\par
grantee=Sally and the other with grantee=Joe.\par
\par
** TRAP: it is a delusion to believe that Bob may now execute this SQL statement:\par
\par
   INSERT INTO Sally_Dates (date_1) VALUES (CURRENT_DATE);\par
\par
because to do this, Bob needs the INSERT Privilege for both Column DATE_1 and\par
Column DATE_2 -- INSERT statements create whole rows. So it's useless to\par
"GRANT INSERT(Column-list)" unless (a) you expect that somebody else will\par
grant access on the other Columns or (b) your (Column-list) contains the names\par
of all Columns in the Table, but you don't want to just "GRANT INSERT ON\par
<Table name>" because that would give access not only to all Columns currently\par
in the Table, but to all Columns which will ever be in the Table (including\par
Columns added by future ALTER TABLE statements).\par
\par
If Sally does this:\par
\par
   GRANT UPDATE(date_1) ON Sally_Dates TO Sam;\par
\par
the effect is that Sam can do this:\par
\par
   UPDATE Sally_Dates SET date_1 = 'DATE '1994-07-15';\par
\par
but Sam can't do this:\par
\par
   UPDATE Sally_Dates SET date_2 = 'DATE '1994-07-15';\par
\par
There are times when such fine-tuning of controls is desirable.\par
\par
If Sally does this:\par
\par
   GRANT SELECT(date_1) ON Sally_Dates TO Sam;\par
\par
the effect is that Sam can do this:\par
\par
   SELECT date_1 FROM Sally_Dates;\par
\par
   SELECT COUNT(*) FROM Sally_Dates;\par
\par
but he can't specifically SELECT the second Column.\par
\par
** TRAP: If SELECT(Column-list) Privileges are granted, the recipients should\par
avoid using "SELECT * ...". The "SELECT * ..." statement will suddenly cease\par
to work for them if new Columns are added to the Table.\par
\par
We would never recommend by-Column granting, without first looking at the alternative: granting on a View.\par
\par
GRANTs on Views:\par
By definition, a View is a Table. So the considerations specific to "GRANTs on\par
Views" have nothing to do with syntax -- the syntax is the same as for any\par
Table -- but with the effect. Specifically, let's see what would occur if Joe\par
owns a View of Table SALLY_DATES.\par
\par
Joe cannot create anything in Sally's Schema -- only the Schema owner can\par
legally issue CREATE statements for Schema Objects -- so to make the example\par
possible we have to start by giving Joe his own Schema. It's convenient to\par
make Joe's View at the same time. Here's the SQL statement to do it:\par
\par
   CREATE Schema Joe_Schema AUTHORIZATION Joe\par
      CREATE View Joe_Views AS\par
         SELECT date_1,date_2 FROM Sally_Schema.Sally_Dates;\par
\par
To do this, Joe will need the SELECT Privilege on the Columns of Table\par
SALLY_DATES in SALLY_SCHEMA -- we gave these to him earlier. Naturally, the\par
rules don't let Joe gain new Privileges by owning a View. He can DROP this\par
View (that's his power as an owner and he can SELECT FROM or INSERT INTO this\par
View (those are the grantable Privileges he holds on DALLY_DATES) -- and that's all. He cannot do this:\par
\par
   UPDATE Joe_Views SET date_1 = CURRENT_DATE;\par
\par
because UPDATE is not a Privilege he holds on SALLY_DATES, and ultimately, an\par
UPDATE on the View will UPDATE the Table. Now assume that Joe creates another View:\par
\par
   CREATE View Joe_Views_2 AS\par
      SELECT date_1 FROM Joe_Views WHERE date_1 > DATE '1994-01-03';\par
\par
and then does a GRANT to Sam:\par
\par
   GRANT INSERT, SELECT ON Joe_Views_2 TO Sam;\par
\par
... a beautiful example of why Views are useful for security systems. Here,\par
Joe has restricted Sam's access not only to a particular Column of a Table,\par
but to particular rows of that Table. He has done more than is possible with\par
by-Column granting -- and he has done it more cleanly.\par
\par
GRANTs on Procedures:\par
The sad news is that the most useful GRANT of all is one that hardly anyone\par
can use yet. It depends on the existence of procedures, which are an SQL3\par
Object. Only GRANTs on procedures can bring us real-word examples like this:\par
\par
Think of a bank. Tellers in the bank do not have Privileges on Tables, or on\par
Columns within Tables. If we give them UPDATE Privileges on customer accounts,\par
they'll be able to do anything at all to the accounts (too dangerous); if we\par
don't, they won't be able to do anything at all (too restrictive). What\par
everyone -- managers, tellers and customers -- wants is a Privilege that\par
allows a specific combination of operations. For example, let Joe transfer\par
money -- that is, let him withdraw from one account and deposit to another\par
account, provided that the  total of the transaction balances out to $0.00.\par
You could define this situation in a program using syntax like this:\par
\par
   CREATE PROCEDURE Transfer_Procedure\par
     ... INSERT\par
     ... UPDATE\par
     ... CHECK\par
     ... CASE\par
     ...;\par
\par
And then you could allow Joe to use the procedure with:\par
\par
   GRANT EXECUTE ON Transfer_Procedure TO Joe;\par
\par
Almost always, restricting based on an SQL verb (INSERT / UPDATE / DELETE) is\par
vague. Administrators of non-imaginary institutions would prefer finer tuning:\par
they want to restrict actions based on entire SQL statements or, more often,\par
on combinations of SQL statements. Since procedure granting will give them\par
that, eventually they'll throw away the old grants on Tables / Columns / Views, and GRANT EXECUTE will become the norm.\par
\par
Constraints:\par
If a user names a Column within a Constraint or Assertion definition, that\par
means he/she/it REFERENCES the Column. (Don't be misled by the appearance of\par
the <keyword> REFERENCES in FOREIGN KEY Constraint definitions; in this\par
context we're talking about any kind of Constraint. And don't be misled by the\par
appearance of the <keyword> SELECT inside some complex CHECK Constraints; the\par
action here is REFERENCES so the SELECT Privilege is irrelevant for\par
Constraints.) Here's an example -- Sally (who owns the Table SALLY_DATES) may issue this GRANT statement:\par
\par
   GRANT REFERENCES ON Sally_Dates TO Joe;\par
\par
This means that Joe can now create a Constraint or Assertion that uses the Columns of SALLY_DATES -- for example:\par
\par
   CREATE ASSERTION joe_constraint CHECK (\par
      Joe_Views.date_1 <> DATE '1999-12-31');\par
\par
Not only does this Assertion limit the values of JOE_VIEWS, it also limits the\par
values of SALLY_DATES, since that is the Table that the View is based on.\par
Obviously, Joe should not be able to set limits on Sally's data unless she\par
specifically allows him to -- thus, the REFERENCES Privilege.\par
\par
REVOKE statement\par
\par
By the time we finish setting up a Catalog and granting appropriate Privileges\par
to our users, we probably have several thousand Privilege descriptors in\par
INFORMATION_SCHEMA -- more than the count for all other Schema Objects\par
combined. Maintaining them is made easier by the fact that when an Object is\par
dropped, the DBMS will silently destroy all associated Privilege descriptors.\par
That leaves only the problem: how do we adjust for the occasional necessity to\par
remove a Privilege descriptor due to a change in status of a particular user\par
(or Role)? The problem does not occur frequently, but can be mightily\par
cumbersome: the SQL Standard devotes about 40 pages to it. We have managed to\par
simplify the description somewhat, by focussing on the two "essentials" of the process:\par
      ## What we are trying to do is reverse the effects of a GRANT statement, using a REVOKE statement -- the clauses of which have almost the same syntax as GRANT's clauses.\par
      ## What we are really doing is deleting Privilege descriptor rows from INFORMATION SCHEMA.\par
\par
The REVOKE statement destroys both Privilege descriptors and Role\par
authorizations and so has two different syntaxes. The first is identified as\par
the <revoke privilege statement> and the second as the <revoke role\par
statement>. The required syntax for the REVOKE statement is:\par
\par
<revoke privilege statement> ::=\par
REVOKE [ GRANT OPTION FOR ] <privileges> FROM <grantee> [ \{,<grantee>\}... ]\par
[ FROM \{CURRENT_USER | CURRENT_ROLE\} ] \{RESTRICT | CASCADE\}\par
\par
<revoke role statement> ::=\par
REVOKE [ ADMIN OPTION FOR ] <Role name> [ \{,<Role name>\}... ]\par
FROM <grantee> [ \{,<grantee>\}... ]\par
[ FROM \{CURRENT_USER | CURRENT_ROLE\} ]\par
\{RESTRICT | CASCADE\}\par
\par
   <grantee> ::= PUBLIC | <AuthorizationID>\par
\par
The <revoke privilege statement> revokes one or more Privileges on a given\par
Object from one or more grantees, including (possibly) PUBLIC, while the\par
<revoke role statement> revokes the use of one or more Roles from one or more\par
grantees. Only the grantor of the Privileges (or the Roles) may revoke them.\par
\par
We've already shown you the syntax for the <privileges> Privilege\par
specification; it's used exactly that way in the <revoke privilege statement>\par
form of the REVOKE statement. Here are some examples:\par
\par
   REVOKE SELECT ON TABLE Table_1 FROM PUBLIC CASCADE;\par
\par
   REVOKE INSERT(column_1,column_5) ON Table_1 FROM sam CASCADE;\par
\par
   REVOKE ALL PRIVILEGES ON TABLE Table_1 FROM PUBLIC CASCADE;\par
\par
   REVOKE USAGE ON DOMAIN domain_1 FROM bob CASCADE;\par
\par
   REVOKE EXECUTE ON SPECIFIC ROUTINE some_routine FROM sam CASCADE;\par
\par
And here's an example of the <revoke role statement> form of REVOKE:\par
\par
   REVOKE assistants_role FROM PUBLIC CASCADE;\par
\par
In both cases, if your <grantee> is PUBLIC, you're revoking the Privilege (or\par
the use of the Role) from a list of <grantee>s that contains all of the\par
<AuthorizationID>s in the Cluster. If your <grantee> is one or more\par
<AuthorizationID>s, you're revoking the Privilege (or the use of the Role)\par
only from those <AuthorizationID>s. (Remember that an <AuthorizationID> may\par
identify either a user or a Role.)\par
\par
Remember that, for Tables, GRANT creates Privilege descriptors for both the\par
Table and its Columns. Well, when you REVOKE a Table Privilege, all by-Column\par
Privileges for that Table disappear too -- and, in the case of SELECT and\par
UPDATE and REFERENCES, the SELECT and/or UPDATE and/or REFERENCES Privilege on\par
all Columns inherited from that Table in each of its subtables also disappear.\par
The effect is a bit strange: when you revoke a Table Privilege, you lose the\par
Column Privilege (even if it was granted separately) and when you revoke a\par
Column Privilege, you lose that Column Privilege -- even if it resulted from a\par
Table Privilege GRANT.\par
\par
The optional FROM clause names the grantor of the Privileges or the Role\par
you're revoking: CURRENT_USER is the <AuthorizationID> of the current user and\par
CURRENT_ROLE is the <AuthorizationID> of the current Role. If you omit the\par
clause, it defaults to FROM CURRENT_USER -- but if CURRENT_USER is NULL, the\par
clause defaults to FROM CURRENT_ROLE. If you specify FROM CURRENT_USER and the\par
current <AuthorizationID> is a <Role name>, or if you specify FROM\par
CURRENT_ROLE and the current <Role name> is NULL, the GRANT statement will\par
fail: your DBMS will return the SQLSTATE error 0L000 "invalid grantor". Here are two examples:\par
\par
   REVOKE UPDATE ON Table_1 FROM sam FROM CURRENT_USER CASCADE;\par
   -- revokes the UPDATE Privilege on TABLE_1 from Sam only if the current user granted that Privilege in the first place\par
\par
   REVOKE assistants_role FROM PUBLIC FROM CURRENT_ROLE CASCADE;\par
  -- revokes the use of the ASSISTANTS_ROLE Role from PUBLIC only if the current Role granted the use of that Role in the first place\par
\par
The optional GRANT OPTION FOR (<revoke privilege statement>) and ADMIN OPTION\par
FOR (<revoke role statement>) clauses allow you to revoke only the\par
grantability of a Privilege or a Role. For example, consider these SQL statements:\par
\par
   GRANT UPDATE ON TABLE Table_1 TO sam WITH GRANT OPTION;\par
\par
   REVOKE GRANT OPTION FOR UPDATE ON Table_1 FROM sam CASCADE;\par
\par
The first SQL statement allows Sam to update TABLE_1, and to pass this\par
Privilege on to others. The second SQL statement revokes the latter ability:\par
Sam can still update TABLE_1, but may no longer pass the Privilege on. Here's another example:\par
\par
   GRANT assistants_role TO bob WITH ADMIN OPTION;\par
\par
   REVOKE WITH ADMIN OPTION FOR assistants_role FROM bob CASCADE;\par
\par
The first SQL statement allows Bob to use all of the Privileges belonging to\par
the ASSISTANTS_ROLE Role, and to pass the use of this Role on to others. The\par
second SQL statement revokes the latter ability: Bob can still use the Role's\par
Privileges, but may no longer pass that use on.\par
\par
The GRANT/ADMIN option clauses have another effect. Suppose that a user holds\par
a Privilege on a Table WITH GRANT OPTION, and does so, also with GRANT OPTION.\par
The second user can now do the same for a third user, and so on -- for example:\par
\par
   GRANT DELETE ON TABLE Sally_Dates TO joe WITH GRANT OPTION;\par
   -- assume Sally does this\par
\par
   GRANT DELETE ON TABLE Sally_Dates TO sam WITH GRANT OPTION;\par
   -- assume Joe does this\par
\par
   GRANT DELETE ON TABLE Sally_Dates TO bob WITH GRANT OPTION;\par
   -- assume Sam does this\par
\par
What should happen if Sally now does:\par
\par
   REVOKE DELETE ON TABLE Sally_Dates FROM joe;\par
\par
Here, we've deliberately left off RESTRICT/CASCADE for the sake of the\par
example, so let's assume that the SQL statement works: Joe no longer has the\par
DELETE Privilege on SALLY_DATES. The Privileges handed down from Joe to Sam,\par
and from Sam to Bob, are now called "abandoned Privileges": they are dependent\par
on Joe's DELETE Privilege -- and Joe doesn't have it any more. This is where\par
the RESTRICT/CASCADE <keyword>s come in.\par
      ## If your REVOKE statement specifies CASCADE, the REVOKE succeeds --\par
and it cascades down to revoke any Privileges that would otherwise be\par
abandoned. In our example, that means both Sam and Bob would no longer have\par
the DELETE Privilege on SALLY_DATES either.\par
      ## If your REVOKE statement specifies RESTRICT, the REVOKE succeeds only\par
if the Privilege being revoked has no dependent Privileges. In our example,\par
that means the REVOKE statement would fail.\par
The same holds true for revoking the use of a Role.\par
\par
Objects can also become "abandoned" when a Privilege or the use of a Role is\par
revoked. For example, remember that Joe holds the SELECT Privilege on\par
SALLY_DATES and, with this, was able to create his View, JOE_VIEWS. Now suppose Sally does this:\par
\par
   REVOKE SELECT ON Sally_Dates FROM joe CASCADE;\par
\par
The effect is that, not only does Joe lose his ability to SELECT from\par
SALLY_DATES, but that JOE_VIEWS is dropped! The reason is that, in effect,\par
JOE_VIEWS is nothing but a SELECT that Joe does  from SALLY_DATES, and since\par
such SELECTs are no longer allowed, the View may no longer exist. If, on the\par
other hand, Sally does this:\par
\par
   REVOKE SELECT ON Sally_Dates FROM joe RESTRICT;\par
\par
the effect is that the REVOKE statement fails: Sally may not revoke Joe's\par
ability to SELECT from SALLY_DATES because this would mean that JOE_VIEWS\par
would be abandoned -- and this is not allowed. The same holds true for any\par
Object that anyone was able to create only because they held some required\par
Privilege (or were able to use a Role that held that Privilege): if REVOKE ...\par
RESTRICT is used, the statement will fail but if REVOKE ... CASCADE is used,\par
the statement will not only revoke but drop all Objects that would otherwise be abandoned.\par
\par
If the REVOKE statement isn't able to find a Privilege descriptor for every\par
one of its Privilege specifications, your DBMS will return the SQLSTATE warning 01006 "warning-privilege not revoked".\par
\par
If you want to restrict your code to Core SQL, don't use the <revoke role\par
statement> form of the REVOKE statement and don't use REVOKE ... CASCADE or\par
the GRANT OPTION FOR clause. Also, when revoking, make sure that your current\par
<AuthorizationID> is the owner of the Schema that owns the Object you're revoking Privileges for.\par
\par
DROP ROLE statement\par
\par
The DROP ROLE statement destroys a Role. The required syntax for the DROP ROLE statement is:\par
\par
DROP ROLE <Role name>\par
\par
The <Role name> must identify an existing Role for which an enabled\par
<AuthorizationID> has the WITH ADMIN OPTION. That is, only an\par
<AuthorizationID> with the WITH ADMIN OPTION on a Role may drop it. The effect of DROP ROLE <Role name>, e.g.:\par
\par
   DROP ROLE assistants_role;\par
\par
is that the Role named ASSISTANTS_ROLE will be destroyed and that your DBMS\par
will also do this for every <AuthorizationID> that was granted use of the Role:\par
\par
   REVOKE assistants_role FROM <AuthorizationID> RESTRICT;\par
\par
If you want to restrict your code to Core SQL, don't use the DROP ROLE statement.\par
\par
What Privileges do I Have?\par
\par
Earlier in this chapter, we said that every Privilege is defined by a\par
descriptor stored in INFORMATION_SCHEMA. You can thus find out what Privileges\par
you have by querying the appropriate Views therein (see our chapter on SQL\par
Catalogs). Each "Privilege descriptor" View includes Columns for grantor,\par
grantee, Object, <Object name> and is_grantable -- the basic Privilege\par
description stuff. You might think that this makes things fairly\par
straightforward -- but take note! There is deep trickiness implied by\par
simple-sounding questions like: may Joe may SELECT from SALLY_DATES?\par
\par
The first trickiness is that it is not enough to look for "Grantee = 'Joe'".\par
Joe may have a Privilege due to his ROLE, and at any rate, Joe is a member of\par
the PUBLIC. So when searching for Joe's Privileges, the conditions should\par
include "Grantee = 'PUBLIC' and Grantee = 'whatever Role Joe may be able to use'".\par
\par
The second trickiness is that it is not enough to look for "Object =\par
'Sally_Dates' in the TABLE_PRIVILEGES View. Joe may have a Privilege on only\par
one Column, so you have to search the COLUMN_PRIVILEGES View too. And even if\par
you do find that Joe does have the SELECT Privilege, that might not be enough\par
-- he might also need separate USAGE Privileges for the UDT, the Character set\par
and the Collation associated with each Column in the Table. And even if you\par
find that Joe doesn't have the SELECT Privilege, the answer may be\par
insufficient -- he might have the SELECT Privilege on a View of the Table, or\par
he might be able to get all the data he needs using a procedure.\par
\par
** TIP: Explain these trickinesses to other users at your site, then ask them\par
to observe these limits:\par
      ## Number of by-Column GRANTs = 0.\par
      ## Number of Roles = 1 (not including PUBLIC).\par
      ## Number of Views = 1 per Table.\par
      ## Number of USAGE GRANTs = 1 (that is, one GRANT only, to PUBLIC).\par
\par
Violating the security system\par
\par
Each of the following depends on a "hole" in the Standard SQL security wall.\par
Perhaps the vendor of your particular DBMS hasn't plugged the hole. What fun it would be to find out ...\par
\par
If you have the SELECT Privilege WITH GRANT OPTION on a single Table: Suppose\par
the grantor of your Privilege is Sally. Why not reciprocate and GRANT your\par
Privilege back to her? The advantage is that later, if Sally tries to revoke\par
your Privilege and forgets to say CASCADE, she will fail because there is now\par
a chain of Privilege descriptors, terminating with her.\par
\par
If your database is stored on a local microcomputer: The DBMS can't block your\par
access to the file -- usually its only line of defense is encryption or\par
proprietary formatting (Microsoft Access and dBASE IV use variations of this\par
defense). If you know what the Table and Column names are, you can go to\par
another computer and make a database with the same structure but different\par
data. Then copy your file over the legitimate one. This is a "cuckoo's egg" violation.\par
\par
If your database is stored on a distant server: There's still a chance that\par
the client receives complete row copies for local filtering. Start a long\par
query, then turn your computer off. Start it up again and look for temporary\par
unclosed files, probably in the \\windows\\temp directory.\par
\par
Here is a security hole that is opened up by the REFERENCES Privilege: Sally creates a Table --\par
\par
   CREATE TABLE Sally_1 ( column1 SMALLINT);\par
\par
Sally lets Joe reference her Table --\par
\par
   GRANT REFERENCES ON Sally_1 TO joe;\par
\par
Joe creates a Table --\par
\par
   CREATE TABLE Joe_1 (column_1 INT REFERENCES Sally_1);\par
\par
Joe lets Sam update his Table --\par
\par
   GRANT UPDATE ON Joe_1 to Sam;\par
\par
Now, even though Sam has no Privileges at all on Sally's Table, he can find out what's in it! All he has to do is:\par
\par
   UPDATE Joe_Schema.Joe_1 SET\par
      column_1 = :x;\par
\par
in a loop, for "x" = all possible SMALLINT values. If, and only if, UPDATE succeeds, then the value of "x" is in Sally's Table.\par
\par
User functions\par
\par
The SQL Standard defines four types of <AuthorizationID> whose values can be\par
obtained through the use of the scalar user functions USER, CURRENT_USER,\par
SESSION_USER, SYSTEM_USER and CURRENT_ROLE: each returns an SQL_TEXT character\par
string whose value represents an <AuthorizationID>.\par
\par
[NON-PORTABLE] The result of a user function is non-standard because the SQL\par
Standard requires implementors to define whether the result string is fixed\par
length or variable length and the result string's fixed length or maximum length (as applicable).\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book has\par
each user function return a variable length SQL_TEXT string. The result has a maximum length of 128 octets.\par
\par
The required syntax for a user function is:\par
\par
user function ::=\par
USER |\par
CURRENT_USER |\par
SESSION_USER |\par
SYSTEM_USER |\par
CURRENT_ROLE\par
\par
A user function returns an SQL_TEXT character string with the COERCIBLE coercibility attribute.\par
\par
CURRENT_USER returns the <AuthorizationID> of the current user. This is either\par
the user specified in the CONNECT statement that began the SQL-session\par
(assuming it was a user, and not a Role that began the session) or a default\par
<AuthorizationID> set by your DBMS. CURRENT_USER will be NULL if the current\par
<AuthorizationID> is a <Role name>. USER is a synonym for CURRENT_USER that may be used in Core SQL.\par
\par
CURRENT_ROLE returns the <AuthorizationID> of the current Role. This is either\par
the Role specified in the CONNECT statement that began the SQL-session\par
(assuming it was a Role, and not a user that began the session; otherwise\par
NULL) or the Role specified in the most recent SET ROLE statement issued for\par
the SQL-session. CURRENT_ROLE will be NULL if the current <AuthorizationID> is\par
a user, rather than a Role.\par
\par
SESSION_USER returns the <AuthorizationID> of the SQL-session user. This is\par
either the user specified in the CONNECT statement that began the SQL-session\par
(assuming it was a user, and not a Role that began the session; otherwise a\par
default <AuthorizationID> set by your DBMS) or the user specified in the most\par
recent SET SESSION AUTHORIZATION statement issued for the SQL-session. In most\par
cases, the SQL-session <AuthorizationID> is the same as the current <AuthorizationID>.\par
\par
[NON-PORTABLE] SYSTEM_USER returns an <AuthorizationID> that represents the\par
operating system user who executed the SQL-client Module that contains the\par
SYSTEM_USER function call and is thus non-standard because the SQL Standard\par
requires implementors to define their system user.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book has a SYSTEM_USER called OCELOT.\par
\par
The current <AuthorizationID> is the user or Role against which Privilege\par
checking is done to see whether an SQL operation is allowable. For example, prior to executing this SQL statement:\par
\par
   SELECT * FROM Table_1;\par
\par
your DBMS will check to see that the current <AuthorizationID> has the SELECT\par
Privilege on that Table. If the current <AuthorizationID> has the Privilege,\par
the SELECT is performed. If the current <AuthorizationID> does not have the\par
Privilege, the SELECT is disallowed.\par
\par
The SQL-session <AuthorizationID> is the <AuthorizationID> that is used as the\par
default <AuthorizationID> whenever a SQL operation which requires an\par
<AuthorizationID> is not provided with an explicit <AuthorizationID>\par
specification. For example, when executing this SQL statement:\par
\par
   CREATE SCHEMA bob;\par
\par
your DBMS effectively executes this SQL statement:\par
\par
   CREATE SCHEMA bob AUTHORIZATION SESSION_USER;\par
\par
If you want to restrict your code to Core SQL, don't use CURRENT_USER, SESSION_USER, SYSTEM_USER or CURRENT_ROLE.\par
\par
Dialects\par
\par
Many vendors have added their own Privileges to the SQL Standard's set. For example:\par
      ## IBM's DB2 has a SYSADM (system  administrator) who can CREATE and\par
DROP in any Schema, and who can create Schemas (one of the implementor-defined\par
areas in the Standard). Several other vendors also have similar "super user"\par
Privileges which are not associated with any particular Object.\par
      ## Sybase has a CONNECT Privilege; other vendors allow connection by anyone, but new users can't do anything without further Privileges.\par
      ## The most popular non-standard Privilege is GRANT ALTER (which sometimes allows users to both alter and drop Tables).\par
      ## DBMSs which allow non-standard Objects allow non-standard Privileges\par
to go with them; thus GRANT INDEX is common, and DB2 also has access controls\par
for tablespaces and indexspaces (which are somewhat like "files").\par
\par
On the other hand, older DBMSs may fail to support the REFERENCES Privilege.\par
They allow Constraints to be defined by anyone who has the appropriate SELECT Privileges instead.\par
\par
A few SQL3 features are already fairly common. Sybase, Microsoft SQL Server\par
and Informix allow "GRANT SELECT (Column-name list) ...". Oracle has had a\par
CREATE ROLE statement since version 7.0; Sybase and Microsoft SQL Server also\par
allow Roles but they use non-standard terms and syntax.\par
\par
As for syntax: the majority of DBMSs will let you specify more than just one\par
"Object" in both GRANT and REVOKE statements. This leads to ambiguities --\par
what is "GRANT UPDATE(column1) ON Tables_1, Tables_2" supposed to do? And is\par
it proper if the different Objects are in different Catalogs? And what if\par
different Privileges apply for different Objects? You're on safer ground if\par
you just ignore this sort of enhancement.\par
\par
The biggest variations involve the ways that the DBMS can identify and\par
acknowledge users. If your operating system has a list of valid users and\par
passwords (something you'll notice if you have to "log in" to your computer),\par
then your DBMS can get the user by querying the OS (Ingres, Informix and DB2\par
do this). Alternatively, or in addition, your DBMS might require you to supply\par
both a user ID and a password when you CONNECT (Oracle and Sybase do this). In\par
the former case, the user's name is probably limited to as few as eight\par
characters because the OS has more restrictions than the DBMS does. In the\par
latter case, there is probably a non-standard CREATE USER statement and a\par
"user" Object stored inside the database.\par
\par
Finally, you will see some DBMSs skimping on their obligation to store\par
Privilege descriptors for owners. A quick glance at the\par
INFORMATION_SCHEMA.COLUMN_PRIVILEGES View should tell you whether your DBMS is\par
one of these.\par
\page\par
Chapter 16 -- SQL Catalog\par
\par
In this chapter, we'll describe SQL Catalogs in detail, and show you the\par
syntax to use to create, alter and destroy them.\par
\par
Catalog\par
\par
A Cluster may contain zero or more Catalogs. An SQL Catalog is a named group\par
of Schemas, one of which must be an Ur-Schema named INFORMATION_SCHEMA. (The\par
INFORMATION_SCHEMA Schema is a set of Views and Domains that contain the\par
descriptions of all the SQL-data belonging to that Catalog.) Catalogs are\par
dependent on some Cluster -- the <Catalog name> must be unique within the\par
Cluster the Catalog belongs to -- and are created and dropped using\par
implementation-defined methods. \par
\par
Schemas are known as Catalog Objects and, as already stated, a Catalog may\par
consist of one or more Schemas. The Catalog's name qualifies the names of the\par
Schemas that belong to it, and can either be explicitly stated, or a default\par
name will be supplied by your DBMS.\par
\par
[NON-PORTABLE] SQL does not include any CREATE CATALOG, OPEN CATALOG or DROP\par
CATALOG statements. The method you'll use to access a Catalog with your DBMS\par
is thus non-standard because the SQL Standard requires implementors to define\par
how a Catalog comes into being, how it may be accessed and how it may be destroyed.\par
\par
[OCELOT Implementation] applies for the rest of this section.\par
\par
The OCELOT DBMS that comes with this book considers a Catalog to  be either a\par
directory on your storage device (not necessarily the same device used to\par
store the enclosing Cluster) or a subdirectory within the Cluster directory,\par
e.g.: either of these following would represent a Catalog:\par
   C:\\CATALOG \par
   C:\\CLUSTER\\CATALOG \par
\par
OCELOT's method of creating and connecting to Catalogs depends on the way you\par
choose to begin a SQL session.\par
      ## When you run a Module defined with a MODULE statement that includes\par
an explicit <Catalog name> in the SCHEMA clause or AUTHORIZATION clause, the\par
DBMS will search, on the default Cluster directory, for a subdirectory with a\par
name that matches that <Catalog name>. If the subdirectory can't be found, the\par
DBMS will search for a directory with the same name. If the directory can't be\par
found, it will be created and opened.\par
      ## If the MODULE statement doesn't provide an explicit <Catalog name>,\par
or if you're not running a Module, the DBMS will open a subdirectory or directory named OCELOT.\par
\par
Catalog names:\par
A <Catalog name> identifies a Catalog and is never explicitly\par
qualified with the name of the SQL-server (or Cluster) it belongs to. The\par
required syntax for a <Catalog name> is:\par
\par
<Catalog name> ::=\par
string\par
\par
[NON-PORTABLE] A <Catalog name> is a <regular identifier> or <delimited\par
identifier> that is unique (for all Catalogs) within the Cluster it belongs\par
to, but is non-standard because the SQL Standard requires implementors to\par
define what a <Catalog name> may be. \par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
requires a <Catalog name> to follow the rules for a directory name or a\par
subdirectory name on the operating system in use; generally it may include\par
[drive:] and [\\upper-level name(s)] and \\name. The <SQL-server name> which\par
implicitly qualifies an OCELOT <Catalog name> identifies the Cluster that the\par
Catalog belongs to, and is the same as the <SQL-server name> argument of the\par
most recent CONNECT TO statement issued for the SQL-session during which the\par
Catalog was created.\par
\par
Here is an example of a possible <Catalog name>:\par
\par
   CATALOG_1\par
\par
If you want to restrict your code to Core SQL, don't use explicit <Catalog name>s.\par
\par
The Information Schema\par
\par
Every Catalog in your SQL-environment contains a Schema called\par
INFORMATION_SCHEMA: it contains a series of Views, Assertions and Domains --\par
together, they allow you to look at (but not change) the description of every\par
Object that belongs to the Catalog, as though it was regular SQL-data. The\par
SELECT Privilege is granted to PUBLIC WITH GRANT OPTION on every View in\par
INFORMATION_SCHEMA; the intent is that you will only be able to see those rows\par
that describe Objects on which you have Privileges. The USAGE Privilege is\par
also granted to PUBLIC WITH GRANT OPTION on every Domain in INFORMATION_SCHEMA. \par
\par
INFORMATION_SCHEMA also contains the definition of every built-in SQL\par
function, that is, every function that you can use as part of SQL (for\par
example: ABS, CHAR_LENGTH, CARDINALITY, etc.). The EXECUTE Privilege is\par
granted to PUBLIC on each one.\par
\par
(Note: The INFORMATION_SCHEMA Views are based on the Tables of an Ur-Schema\par
called DEFINITION_SCHEMA, but the Standard doesn't require it to actually\par
exist -- its purpose is merely to provide a data model to support\par
INFORMATION_SCHEMA. If DEFINITION_SCHEMA did exist though, its Base tables\par
would describe all the Objects and SQL-data available to an SQL-server at any\par
time -- that is, DEFINITION_SCHEMA would describe an SQL Cluster.)\par
\par
[NON-PORTABLE] The total number of Views in INFORMATION_SCHEMA, and their\par
exact definition, is non-standard because the SQL Standard allows implementors\par
to add additional Views, as well as to add additional Columns to the Standard-\par
defined Views, to describe additional, implementation-defined features.\par
However, except for one exception, the View descriptions that follow must all\par
be supported by your SQL DBMS.\par
\par
In SQL, INFORMATION_SCHEMA is the Schema that contains the Information Schema\par
Tables, Assertions and Domains. It is considered to have been created by a\par
CREATE SCHEMA statement that includes an AUTHORIZATION clause showing an\par
<AuthorizationID> of INFORMATION_SCHEMA. A Standard INFORMATION_SCHEMA\par
contains one Base table, one Assertion, four Domains and 52 Views. Their descriptions follow.\par
\par
INFORMATION_SCHEMA Base tables:\par
\par
## INFORMATION_SCHEMA.INFORMATION_SCHEMA_CATALOG_NAME\par
\par
Definition:\par
CREATE TABLE INFORMATION_SCHEMA_CATALOG_NAME (\par
      CATALOG_NAME SQL_IDENTIFIER,\par
      CONSTRAINT INFORMATION_SCHEMA_CATALOG_NAME_PRIMARY_KEY\par
            PRIMARY KEY (CATALOG_NAME),\par
      CONSTRAINT INFORMATION_SCHEMA_CATALOG_NAME_CHECK\par
            CHECK ((SELECT COUNT(*) FROM INFORMATION_SCHEMA_CATALOG_NAME)=1))\par
\par
The INFORMATION_SCHEMA_CATALOG_NAME Base table identifies the Catalog that\par
contains this Information Schema; the CATALOG_NAME Column contains the name of\par
the relevant Catalog.\par
\par
INFORMATION_SCHEMA Assertions:\par
\par
## INFORMATION_SCHEMA.INFORMATION_SCHEMA_CATALOG_NAME_CARDINALITY\par
\par
Definition:\par
CREATE ASSERTION INFORMATION_SCHEMA_CATALOG_NAME_CARDINALITY\par
      CHECK (1=(SELECT COUNT(*) FROM INFORMATION_SCHEMA_CATALOG_NAME))\par
\par
The INFORMATION_SCHEMA_CATALOG_NAME_CARDINALITY Assertion ensures that there\par
is exactly one row in the INFORMATION_SCHEMA_CATALOG_NAME Table.\par
\par
INFORMATION_SCHEMA Domains:\par
\par
## INFORMATION_SCHEMA.CARDINAL_NUMBER\par
\par
Definition:\par
CREATE DOMAIN CARDINAL_NUMBER AS INTEGER\par
      CONSTRAINT CARDINAL_NUMBER_DOMAIN_CHECK \par
            CHECK (VALUE >= 0)\par
\par
The set of CARDINAL_NUMBER values includes all non-negative numbers that are\par
less than your DBMS's defined maximum for INTEGER values. (Note: This is\par
probably an error in the Standard: CARDINAL_NUMBER should include all\par
non-negative numbers that are less than or equal to your DBMS's defined\par
maximum for INTEGER values.)\par
\par
## INFORMATION_SCHEMA.CHARACTER_DATA\par
\par
Definition:\par
CREATE DOMAIN CHARACTER_DATA AS CHARACTER VARYING(ML)\par
      CHARACTER SET SQL_TEXT\par
\par
The set of CHARACTER_DATA values includes all character strings, from zero to\par
ML characters long, that belong to the SQL_TEXT Character set. (ML is replaced\par
by your DBMS's defined maximum length for a variable-length character string.)\par
\par
## INFORMATION_SCHEMA.SQL_IDENTIFIER\par
\par
Definition:\par
CREATE DOMAIN SQL_IDENTIFIER AS CHARACTER VARYING(L)\par
      CHARACTER SET SQL_TEXT\par
\par
The set of SQL_IDENTIFIER values includes all character strings, from one to L\par
characters long, that are valid <regular identifier>s and <delimited\par
identifier> bodies. (L is replaced by your DBMS's defined maximum length for a\par
<regular identifier> and <delimited identifier> body.\par
\par
## INFORMATION_SCHEMA.TIME_STAMP\par
\par
Definition:\par
CREATE DOMAIN TIME_STAMP AS TIMESTAMP(2) DEFAULT CURRENT_TIMESTAMP(2)\par
\par
The set of TIME_STAMP values includes an SQL timestamp value.\par
\par
INFORMATION_SCHEMA Views:\par
\par
## INFORMATION_SCHEMA.ADMINISTRABLE_ROLE_AUTHORIZATIONS\par
\par
This View has the following Columns:\par
\par
Name              Domain                  Nullable?\par
GRANTEE           SQL_IDENTIFIER          no\par
ROLE_NAME         SQL_IDENTIFIER          no\par
IS_GRANTABLE      CHARACTER_DATA          no\par
\par
ADMINISTRABLE_ROLE_AUTHORIZATIONS shows the role authorizations that the\par
current user may grant to others.\par
      ## GRANTEE and ROLE_NAME uniquely identify a role authorization which\par
the current user may use.\par
      ## IS_GRANTABLE is 'YES' (the role authorization is grantable).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ADMINISTRABLE_ROLE_AUTHORIZATIONS.\par
\par
## INFORMATION_SCHEMA.APPLICABLE_ROLES\par
\par
This View has the following Columns:\par
\par
Name              Domain                  Nullable?\par
GRANTEE           SQL_IDENTIFIER          no    \par
ROLE_NAME         SQL_IDENTIFIER          no\par
IS_GRANTABLE      CHARACTER_DATA          no\par
\par
APPLICABLE_ROLES shows the role authorizations that the current user may use. \par
      ## GRANTEE and ROLE_NAME uniquely identify a role authorization that the current user may use.\par
      ## IS_GRANTABLE is either 'YES' (the role authorization is grantable) or 'NO' (the role authorization is not grantable).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.APPLICABLE_ROLES.\par
\par
## INFORMATION_SCHEMA.ASSERTIONS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
CONSTRAINT_CATALOG      SQL_IDENTIFIER          no\par
CONSTRAINT_SCHEMA       SQL_IDENTIFIER          no\par
CONSTRAINT_NAME         SQL_IDENTIFIER          no\par
IS_DEFERRABLE           CHARACTER_DATA          no\par
INITIALLY_DEFERRED      CHARACTER_DATA          no\par
\par
ASSERTIONS shows the Assertions in this Catalog that are owned by the current user. \par
      ## CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME uniquely\par
identify an Assertion owned by the current user.\par
      ## IS_DEFERRABLE is either 'YES' (the Assertion is DEFERRABLE) or 'NO'\par
(the Assertion is NOT DEFERRABLE).\par
      ## INITIALLY_DEFERRED is either 'YES' (the Assertion is INITIALLY\par
DEFERRED) or 'NO' (the Assertion is INITIALLY IMMEDIATE).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ASSERTIONS.\par
\par
## INFORMATION_SCHEMA.CHARACTER_SETS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
CHARACTER_SET_CATALOG   SQL_IDENTIFIER          no\par
CHARACTER_SET_SCHEMA    SQL_IDENTIFIER          no\par
CHARACTER_SET_NAME      SQL_IDENTIFIER          no\par
FORM_OF_USE             SQL_IDENTIFIER          no\par
NUMBER_OF_CHARACTERS    CARDINAL_NUMBER         no\par
DEFAULT_COLLATE_CATALOG SQL_IDENTIFIER          no\par
DEFAULT_COLLATE_SCHEMA  SQL_IDENTIFIER          no\par
DEFAULT_COLLATE_NAME    SQL_IDENTIFIER          no\par
\par
CHARACTER_SETS shows the Character sets in this Catalog that the current user has Privileges on.\par
      ## CHARACTER_SET_CATALOG, CHARACTER_SET_SCHEMA, CHARACTER_SET_NAME\par
uniquely identify a Character set that the current user may use.\par
      ## FORM_OF_USE is a zero-length string. (Note: This may be an error in\par
the Standard. FORM_OF_USE should probably name the Form-of-use for the Character set.)\par
      ## NUMBER_OF_CHARACTERS is a zero-length string. (Note: This is an error\par
in the Standard. NUMBER_OF_CHARACTERS must be a number and therefore should\par
probably show the number of characters in the Character set.)\par
      ## DEFAULT_COLLATE_CATALOG, DEFAULT_COLLATE_SCHEMA, DEFAULT_COLLATE_NAME\par
uniquely identify the Character set's default Collation.\par
\par
## INFORMATION_SCHEMA.CHECK_CONSTRAINTS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
CONSTRAINT_CATALOG      SQL_IDENTIFIER          no\par
CONSTRAINT_SCHEMA       SQL_IDENTIFIER          no\par
CONSTRAINT_NAME         SQL_IDENTIFIER          no\par
CHECK_CLAUSE            CHARACTER_DATA          yes\par
\par
CHECK_CONSTRAINTS shows the CHECK Constraints in this Catalog that are owned\par
by the current user. (This category includes the user's Domain Constraints,\par
Assertions and some Table Constraints.\par
      ## CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME uniquely\par
identify a CHECK Constraint owned by the current user.\par
      ## CHECK_CLAUSE shows the Constraint's CHECK clause in full. It will be\par
NULL if the CHECK clause was too long to be stored.\par
\par
## INFORMATION_SCHEMA.COLLATIONS\par
\par
This View has the following Columns:\par
\par
Name                    Domain            Nullable?\par
COLLATION_CATALOG       SQL_IDENTIFIER    no\par
COLLATION_SCHEMA        SQL_IDENTIFIER    no\par
COLLATION_NAME          SQL_IDENTIFIER    no\par
CHARACTER_SET_CATALOG   SQL_IDENTIFIER    no\par
CHARACTER_SET_SCHEMA    SQL_IDENTIFIER    no\par
CHARACTER_SET_NAME      SQL_IDENTIFIER    no\par
PAD_ATTRIBUTE           CHARACTER_DATA    no\par
COLLATION_TYPE          CHARACTER_DATA    no\par
COLLATION_DEFINITION    CHARACTER_DATA    no\par
COLLATION_DICTIONARY    CHARACTER_DATA    no\par
\par
COLLATIONS shows the Collations in this Catalog that the current user has Privileges on.\par
      ## COLLATION_CATALOG, COLLATION_SCHEMA, COLLATION_NAME uniquely identify\par
a Collation that the current user may use.\par
      ## CHARACTER_SET_CATALOG, CHARACTER_SET_SCHEMA, CHARACTER_SET_NAME\par
uniquely identify the Character set for the Collation.\par
      ## PAD_ATTRIBUTE is either 'NO PAD' (the Collation has the NO PAD\par
attribute) or 'SPACE' (the Collation has the PAD SPACE attribute).\par
      ## COLLATION_TYPE, COLLATION_DEFINITION and COLLATION_DICTIONARY are\par
zero-length strings. To date, the Standard makes no use of these fields.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.COLLATIONS.\par
\par
## INFORMATION_SCHEMA.COLUMNS\par
\par
This View has the following Columns:\par
\par
Name                                Domain                  Nullable?\par
TABLE_CATALOG                       SQL_IDENTIFIER          no\par
TABLE_SCHEMA                        SQL_IDENTIFIER          no\par
TABLE_NAME                          SQL_IDENTIFIER          no\par
COLUMN_NAME                         SQL_IDENTIFIER          no\par
ORDINAL_POSITION                    CARDINAL_NUMBER         no\par
COLUMN_DEFAULT                      CHARACTER_DATA          yes\par
IS_NULLABLE                         CHARACTER_DATA          no\par
DATA_TYPE                           CHARACTER_DATA          no\par
CHARACTER_MAXIMUM_LENGTH            CARDINAL_NUMBER         yes\par
CHARACTER_OCTET_LENGTH              CARDINAL_NUMBER         yes\par
NUMERIC_PRECISION                   CARDINAL_NUMBER         yes\par
NUMERIC_PRECISION_RADIX             CARDINAL_NUMBER         yes\par
NUMERIC_SCALE                       CARDINAL_NUMBER         yes\par
DATETIME_PRECISION                  CARDINAL_NUMBER         yes\par
INTERVAL_TYPE                       CHARACTER_DATA          yes\par
INTERVAL_PRECISION                  CARDINAL_NUMBER         yes\par
CHARACTER_SET_CATALOG               SQL_IDENTIFIER          yes\par
CHARACTER_SET_SCHEMA                SQL_IDENTIFIER          yes\par
CHARACTER_SET_NAME                  SQL_IDENTIFIER          yes\par
COLLATION_CATALOG                   SQL_IDENTIFIER          yes\par
COLLATION_SCHEMA                    SQL_IDENTIFIER          yes\par
COLLATION_NAME                      SQL_IDENTIFIER          yes\par
DOMAIN_CATALOG                      SQL_IDENTIFIER          yes\par
DOMAIN_SCHEMA                       SQL_IDENTIFIER          yes\par
DOMAIN_NAME                         SQL_IDENTIFIER          yes\par
USER_DEFINED_TYPE_CATALOG           SQL_IDENTIFIER          yes\par
USER_DEFINED_TYPE_SCHEMA            SQL_IDENTIFIER          yes\par
USER_DEFINED_TYPE_NAME              SQL_IDENTIFIER          yes\par
CHECK_REFERENCES                    CHARACTER_DATA          yes\par
CHECK_ACTION                        CHARACTER_DATA          yes\par
\par
COLUMNS shows the Columns in this Catalog that the current user has Privileges on.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely\par
identify a Column that the current user may use.\par
      ## ORDINAL_POSITION shows the position of the Column in its Table: the\par
first Column has ordinal position 1, the second Column has ordinal position 2,\par
etc. Warning: the position can change if ALTER TABLE is used to add or drop a Column.\par
      ## COLUMN_DEFAULT shows the Column's default value (presumably the DBMS\par
will CAST the value to a character string if it must). It will be NULL if the\par
Column was defined without a DEFAULT clause (and presumably if it was defined\par
with DEFAULT NULL) or if the Column's default value comes only from a Domain.\par
COLUMN_DEFAULT will be 'TRUNCATED' if the default value was too long to be stored.\par
      ## IS_NULLABLE is either 'YES' (the Column is possibly nullable) or 'NO'\par
(the Column is known not nullable).\par
      ## DATA_TYPE shows the Column's <data type>: either 'BINARY LARGE\par
OBJECT', 'BIT', 'BIT VARYING', 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER\par
LARGE OBJECT', 'INTEGER', 'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'DOUBLE\par
PRECISION', 'FLOAT', 'DATE', 'TIME', 'TIME WITH TIME ZONE', 'TIMESTAMP',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL', 'BOOLEAN', 'USER-DEFINED TYPE' -- or\par
something else, such as an implementation-defined data type.\par
      ## CHARACTER_MAXIMUM_LENGTH shows the Column's maximum length in\par
characters (for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT') or\par
in bits (for 'BIT', 'BIT VARYING', 'BINARY LARGE OBJECT'). For other <data\par
type>s, CHARACTER_MAXIMUM_LENGTH is NULL.\par
      ## CHARACTER_OCTET_LENGTH shows the Column's maximum length in octets\par
(for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT', 'BIT', 'BIT\par
VARYING', 'BINARY LARGE OBJECT'). For other <data type>s, CHARACTER_OCTET_LENGTH is NULL.\par
      ## NUMERIC_PRECISION shows the Column's precision (for 'INTEGER',\par
'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'FLOAT', 'DOUBLE PRECISION', 'DATE',\par
'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE',\par
'INTERVAL'). For other <data type>s, NUMERIC_PRECISION is NULL.\par
      ## NUMERIC_PRECISION_RADIX is either 2 or 10, depending on your DBMS\par
(for 'INTEGER', 'SMALLINT, 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL'), 10 (for 'NUMERIC', 'DECIMAL'), 2 (for\par
'REAL', 'FLOAT', 'DOUBLE PRECISION'. For other <data type>s, NUMERIC_PRECISION_RADIX is NULL.\par
      ## NUMERIC_SCALE is either 0 (for 'INTEGER', 'SMALLINT') or shows the\par
Column's scale (for 'NUMERIC', 'DECIMAL'). For other <data type>s, NUMERIC_SCALE is NULL.\par
      ## DATETIME_PRECISION shows the Column's fractional-seconds precision\par
(for 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE',\par
'INTERVAL'). For other <data type>s, DATETIME_PRECISION is NULL.\par
      ## INTERVAL_TYPE shows the Column's interval type (for 'INTERVAL'):\par
either 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'SECOND', 'YEAR TO MONTH',\par
'DAY TO HOUR', 'DAY TO MINUTE', 'DAY TO SECOND', 'HOUR TO MINUTE', 'HOUR TO\par
SECOND', 'MINUTE TO SECOND'. For other <data type>s, INTERVAL_TYPE is NULL.\par
      ## INTERVAL_PRECISION shows the Column's precision for the interval\par
leading field (for 'INTERVAL'). For other <data type>s, INTERVAL_PRECISION is NULL.\par
      ## CHARACTER_SET_CATALOG, CHARACTER_SET_SCHEMA, CHARACTER_SET_NAME\par
uniquely identify the Character set the Column values belong to (for\par
'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT'). For other <data\par
type>s, these fields are NULL.\par
      ## COLLATION_CATALOG, COLLATION_SCHEMA, COLLATION_NAME uniquely identify\par
the Column's default Collation (for 'CHARACTER', 'CHARACTER VARYING',\par
'CHARACTER LARGE OBJECT'). For other <data type>s, these fields are NULL.\par
      ## DOMAIN_CATALOG, DOMAIN_SCHEMA, DOMAIN_NAME uniquely identify the\par
Domain that the Column depends on. If no Domain was used in the Column definition, these fields are NULL.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA,\par
USER_DEFINED_TYPE_NAME uniquely identify the UDT that the Column depends on.\par
If the Column doesn't use a UDT, these fields are NULL.\par
      ## CHECK_REFERENCES is NULL if the Column is part of a View or if its\par
<data type> is not a reference type. Otherwise, CHECK_REFERENCES is 'YES'\par
(reference values are checked) or 'NO' (reference values are not checked).\par
      ## CHECK_ACTION is NULL if the Column is part of a View or if its <data\par
type> is not a reference type. Otherwise, CHECK_ACTION is 'RESTRICT'\par
(<reference scope check action> is RESTRICT) or 'SET NULL' (<reference scope\par
check action> is SET NULL).\par
\par
## INFORMATION_SCHEMA.COLUMN_DOMAIN_USAGE\par
\par
This View has the following Columns:\par
\par
Name              Domain                  Nullable?\par
DOMAIN_CATALOG    SQL_IDENTIFIER          no\par
DOMAIN_SCHEMA     SQL_IDENTIFIER          no\par
DOMAIN_NAME       SQL_IDENTIFIER          no\par
TABLE_CATALOG     SQL_IDENTIFIER          no\par
TABLE_SCHEMA      SQL_IDENTIFIER          no    \par
TABLE_NAME        SQL_IDENTIFIER          no\par
COLUMN_NAME       SQL_IDENTIFIER          no\par
\par
COLUMN_DOMAIN_USAGE shows the Columns that depend on Domains in this Catalog,\par
where the Domains are owned by the current user.\par
      ## DOMAIN_CATALOG, DOMAIN_SCHEMA, DOMAIN_NAME uniquely identify a Domain owned by the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely identify a Column that depends on the Domain.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.COLUMN_DOMAIN_USAGE.\par
\par
## INFORMATION_SCHEMA.COLUMN_PRIVILEGES\par
\par
This View has the following Columns:\par
\par
Name              Domain            Nullable?\par
GRANTOR           SQL_IDENTIFIER    no\par
GRANTEE           SQL_IDENTIFIER    no\par
TABLE_CATALOG     SQL_IDENTIFIER    no\par
TABLE_SCHEMA      SQL_IDENTIFIER    no\par
TABLE_NAME        SQL_IDENTIFIER    no\par
COLUMN_NAME       SQL_IDENTIFIER    no\par
PRIVILEGE_TYPE    CHARACTER_DATA    no\par
IS_GRANTABLE      CHARACTER_DATA    no\par
\par
COLUMN_PRIVILEGES shows the Privileges on Columns belonging to Tables in this\par
Catalog, where the Privileges are either available to, or granted by, the current user.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role)\par
who granted the Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the user (or perhaps the Role)\par
who may use the Privilege. By definition, if GRANTOR isn't CURRENT_USER, then\par
GRANTEE is either CURRENT_USER or 'PUBLIC'.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely\par
identify a Column belonging to a Table in this Catalog.\par
      ## PRIVILEGE_TYPE shows the Privilege granted: either 'INSERT', 'UPDATE', 'REFERENCES', 'SELECT'.\par
      ## IS_GRANTABLE is either 'YES' (Privilege was granted WITH GRANT OPTION) or 'NO' (Privilege was not granted WITH GRANT OPTION).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.COLUMN_PRIVILEGES.\par
\par
## INFORMATION_SCHEMA.COLUMN_USER_DEFINED_TYPE_USAGE\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
USER_DEFINED_TYPE_CATALOG     SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_SCHEMA      SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_NAME        SQL_IDENTIFIER          no\par
TABLE_CATALOG                 SQL_IDENTIFIER          no\par
TABLE_SCHEMA                  SQL_IDENTIFIER          no\par
TABLE_NAME                    SQL_IDENTIFIER          no\par
COLUMN_NAME                   SQL_IDENTIFIER          no\par
\par
COLUMN_USER_DEFINED_TYPE_USAGE shows the Columns that depend on a UDT in this\par
Catalog, where the UDT is owned by the current user.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME uniquely identify a UDT that belongs to the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely identify a Column that depends on the UDT.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.COLUMN_USER_DEFINED_TYPE_USAGE.\par
\par
## INFORMATION_SCHEMA.CONSTRAINT_COLUMN_USAGE\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
COLUMN_NAME             SQL_IDENTIFIER          no\par
CONSTRAINT_CATALOG      SQL_IDENTIFIER          no\par
CONSTRAINT_SCHEMA       SQL_IDENTIFIER          no\par
CONSTRAINT_NAME         SQL_IDENTIFIER          no\par
\par
CONSTRAINT_COLUMN_USAGE shows the Columns used by any Constraint or Assertion\par
in this Catalog, where the Constraint or Assertion is owned by the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely identify a Column that appears in a Constraint/Assertion.\par
      ## CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME uniquely identify the Constraint/Assertion that uses the Column. The Constraint/Assertion is owned by the current user.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.CONSTRAINT_COLUMN_USAGE.\par
\par
## INFORMATION_SCHEMA.CONSTRAINT_TABLE_USAGE\par
\par
This View has the following Columns:\par
\par
Name                    Domain            Nullable?\par
TABLE_CATALOG           SQL_IDENTIFIER    no\par
TABLE_SCHEMA            SQL_IDENTIFIER    no\par
TABLE_NAME              SQL_IDENTIFIER    no\par
CONSTRAINT_CATALOG      SQL_IDENTIFIER    no\par
CONSTRAINT_SCHEMA       SQL_IDENTIFIER    no\par
CONSTRAINT_NAME         SQL_IDENTIFIER    no\par
\par
CONSTRAINT_TABLE_USAGE shows the Tables used by any Constraint or Assertion in\par
this Catalog, where the Constraint or Assertion is owned by the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify a Table that appears in a Constraint/Assertion.\par
      ## CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME uniquely identify the Constraint/Assertion that uses the Table. The Constraint/Assertion is owned by the current user.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.CONSTRAINT_TABLE_USAGE.\par
\par
## INFORMATION_SCHEMA.DIRECT_SUPERTABLES\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
SUPERTABLE_NAME         SQL_IDENTIFIER          no\par
\par
DIRECT_SUPERTABLES shows the direct subtables in this Catalog that are related\par
to a supertable, where the subtables are owned by the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify a Table owned by the current user.\par
      ## SUPERTABLE_NAME identifies the related supertable for the Table.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.DIRECT_SUPERTABLES.\par
\par
## INFORMATION_SCHEMA.DOMAINS\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
DOMAIN_CATALOG                SQL_IDENTIFIER          no\par
DOMAIN_SCHEMA                 SQL_IDENTIFIER          no\par
DOMAIN_NAME                   SQL_IDENTIFIER          no\par
DATA_TYPE                     CHARACTER_DATA          no\par
CHARACTER_MAXIMUM_LENGTH      CARDINAL_NUMBER         yes\par
CHARACTER_OCTET_LENGTH        CARDINAL_NUMBER         yes\par
COLLATION_CATALOG             SQL_IDENTIFIER          yes\par
COLLATION_SCHEMA              SQL_IDENTIFIER          yes\par
COLLATION_NAME                SQL_IDENTIFIER          yes\par
CHARACTER_SET_CATALOG         SQL_IDENTIFIER          yes\par
CHARACTER_SET_SCHEMA          SQL_IDENTIFIER          yes\par
CHARACTER_SET_NAME            SQL_IDENTIFIER          yes\par
NUMERIC_PRECISION             CARDINAL_NUMBER         yes\par
NUMERIC_PRECISION_RADIX       CARDINAL_NUMBER         yes\par
NUMERIC_SCALE                 CARDINAL_NUMBER         yes\par
DATETIME_PRECISION            CARDINAL_NUMBER         yes\par
INTERVAL_TYPE                 CHARACTER_DATA          yes\par
INTERVAL_PRECISION            CARDINAL_NUMBER         yes\par
DOMAIN_DEFAULT                CHARACTER_DATA          yes\par
USER_DEFINED_TYPE_CATALOG     SQL_IDENTIFIER          yes\par
USER_DEFINED_TYPE_SCHEMA      SQL_IDENTIFIER          yes\par
USER_DEFINED_TYPE_NAME        SQL_IDENTIFIER          yes\par
\par
DOMAINS shows the Domains in this Catalog that the current user has Privileges on.\par
      ## DOMAIN_CATALOG, DOMAIN_SCHEMA, DOMAIN_NAME uniquely identify a Domain\par
that the current user may use, either because of a USAGE Privilege directly on\par
the Domain or because of a Privilege on any Column that depends on the Domain.\par
      ## DATA_TYPE shows the Domain's <data type>: either 'BINARY LARGE\par
OBJECT', 'BIT', 'BIT VARYING', 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER\par
LARGE OBJECT', 'INTEGER', 'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'DOUBLE\par
PRECISION', 'FLOAT', 'DATE', 'TIME', 'TIME WITH TIME ZONE', 'TIMESTAMP',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL', 'BOOLEAN', 'USER-DEFINED TYPE' -- or\par
something else, such as an implementation-defined data type.\par
      ## CHARACTER_MAXIMUM_LENGTH shows the Domain's maximum length in\par
characters (for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT') or\par
in bits (for 'BIT', 'BIT VARYING', 'BINARY LARGE OBJECT'). For other <data\par
type>s, CHARACTER_MAXIMUM_LENGTH is NULL.\par
      ## CHARACTER_OCTET_LENGTH shows the Domain's maximum length in octets\par
(for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT', 'BIT', 'BIT\par
VARYING', 'BINARY LARGE OBJECT'). For other <data type>s, CHARACTER_OCTET_LENGTH is NULL.\par
      ## COLLATION_CATALOG, COLLATION_SCHEMA, COLLATION_NAME uniquely identify\par
the Domain's default Collation (for 'CHARACTER', 'CHARACTER VARYING',\par
'CHARACTER LARGE OBJECT'). For other <data type>s, these fields are NULL.\par
      ## CHARACTER_SET_CATALOG, CHARACTER_SET_SCHEMA, CHARACTER_SET_NAME\par
uniquely identify the Character set the Domain values belong to (for\par
'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT'). For other <data type>s, these fields are NULL.\par
      ## NUMERIC_PRECISION shows the Domain's precision (for 'INTEGER',\par
'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'FLOAT', 'DOUBLE PRECISION', 'DATE',\par
'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE',\par
'INTERVAL'). For other <data type>s, NUMERIC_PRECISION is NULL.\par
      ## NUMERIC_PRECISION_RADIX is either 2 or 10, depending on your DBMS\par
(for 'INTEGER', 'SMALLINT, 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL'), 10 (for 'NUMERIC', 'DECIMAL'), 2 (for\par
'REAL', 'FLOAT', 'DOUBLE PRECISION'. For other <data type>s, NUMERIC_PRECISION_RADIX is NULL.\par
      ## NUMERIC_SCALE is either 0 (for 'INTEGER', 'SMALLINT') or shows the\par
Domain's scale (for 'NUMERIC', 'DECIMAL'). For other <data type>s, NUMERIC_SCALE is NULL.\par
      ## DATETIME_PRECISION shows the Domain's fractional-seconds precision\par
(for 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE',\par
'INTERVAL'). For other <data type>s, DATETIME_PRECISION is NULL.\par
      ## INTERVAL_TYPE shows the Domain's interval type (for 'INTERVAL'):\par
either 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'SECOND', 'YEAR TO MONTH',\par
'DAY TO HOUR', 'DAY TO MINUTE', 'DAY TO SECOND', 'HOUR TO MINUTE', 'HOUR TO\par
SECOND', 'MINUTE TO SECOND'. For other <data type>s, INTERVAL_TYPE is NULL.\par
      ## INTERVAL_PRECISION shows the Domain's precision for the interval\par
leading field (for 'INTERVAL'). For other <data type>s, INTERVAL_PRECISION is NULL.\par
      ## DOMAIN_DEFAULT shows the Domain's default value (presumably the DBMS\par
will CAST the value to a character string if it must). It will be NULL if the\par
Domain was defined without a DEFAULT clause (and presumably if it was defined\par
with DEFAULT NULL). DOMAIN_DEFAULT will be 'TRUNCATED' if the default value was too long to be stored.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME uniquely identify the UDT that the Domain depends on. If the Domain doesn't use a UDT, these fields are NULL.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.DOMAINS.\par
\par
## INFORMATION_SCHEMA.DOMAIN_CONSTRAINTS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
CONSTRAINT_CATALOG      SQL_IDENTIFIER          no\par
CONSTRAINT_SCHEMA       SQL_IDENTIFIER          no\par
CONSTRAINT_NAME         SQL_IDENTIFIER          no\par
DOMAIN_CATALOG          SQL_IDENTIFIER          no\par
DOMAIN_SCHEMA           SQL_IDENTIFIER          no\par
DOMAIN_NAME             SQL_IDENTIFIER          no\par
IS_DEFERRABLE           CHARACTER_DATA          no\par
INITIALLY_DEFERRED      CHARACTER_DATA          no\par
\par
DOMAIN_CONSTRAINTS shows the Domain Constraints (i.e.: the Constraints defined\par
on Domains in this Catalog) that are owned by the current user.\par
      ## CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME uniquely identify a Domain Constraint owned by the current user.\par
      ## DOMAIN_CATALOG, DOMAIN_SCHEMA, DOMAIN_NAME uniquely identify the Domain that uses the Constraint.\par
      ## IS_DEFERRABLE is either 'YES' (the Constraint is DEFERRABLE) or 'NO' (the Constraint is NOT DEFERRABLE).\par
      ## INITIALLY_DEFERRED is either 'YES' (the Constraint is INITIALLY DEFERRED) or 'NO' (the Constraint is INITIALLY IMMEDIATE).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.DOMAIN_CONSTRAINTS.\par
\par
## INFORMATION_SCHEMA.DOMAIN_USER_DEFINED_TYPE_USAGE\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
USER_DEFINED_TYPE_CATALOG     SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_SCHEMA      SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_NAME        SQL_IDENTIFIER          no\par
DOMAIN_CATALOG                SQL_IDENTIFIER          no\par
DOMAIN_SCHEMA                 SQL_IDENTIFIER          no\par
DOMAIN_NAME                   SQL_IDENTIFIER          no\par
\par
DOMAIN_USER_DEFINED_TYPE_USAGE shows the Domains that depend on UDTs in this\par
Catalog, where the UDT is owned by the current user.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME uniquely identify a UDT owned by the current user.\par
      ## DOMAIN_CATALOG, DOMAIN_SCHEMA, DOMAIN_NAME uniquely identify a Domain that uses the UDT.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.DOMAIN_USER_DEFINED_TYPE_USAGE.\par
\par
## INFORMATION_SCHEMA.ENABLED_ROLES\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
ROLE_NAME               SQL_IDENTIFIER          no\par
\par
ENABLED_ROLES shows the enabled roles for the current SQL-session.\par
      ## ROLE_NAME uniquely identifies an enabled Role.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ENABLED_ROLES.\par
\par
## INFORMATION_SCHEMA.KEY_COLUMN_USAGE\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
CONSTRAINT_CATALOG      SQL_IDENTIFIER          no\par
CONSTRAINT_SCHEMA       SQL_IDENTIFIER          no\par
CONSTRAINT_NAME         SQL_IDENTIFIER          no\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
COLUMN_NAME             SQL_IDENTIFIER          no\par
ORDINAL_POSITION        CARDINAL_NUMBER         no\par
\par
KEY_COLUMN_USAGE shows the Columns in this Catalog that are keys in Constraints owned by the current user.\par
      ## CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME uniquely identify a Constraint owned by the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely identify a Column that is a key in the Constraint.\par
      ## ORDINAL_POSITION is the position of the Column within the Constraint.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.KEY_COLUMN_USAGE.\par
\par
## INFORMATION_SCHEMA.METHOD_SIGNATURES\par
\par
This View has the following Columns:\par
\par
Name                                Domain                  Nullable?\par
USER_DEFINED_TYPE_CATALOG           SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_SCHEMA            SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_NAME              SQL_IDENTIFIER          no\par
METHOD_CATALOG                      SQL_IDENTIFIER          no\par
METHOD_SCHEMA                       SQL_IDENTIFIER          no\par
METHOD_NAME                         SQL_IDENTIFIER          no\par
DATA_TYPE                           CHARACTER_DATA          no\par
CHARACTER_MAXIMUM_LENGTH            CARDINAL_NUMBER         yes\par
CHARACTER_OCTET_LENGTH              CARDINAL_NUMBER         yes\par
COLLATION_CATALOG                   SQL_IDENTIFIER          yes\par
COLLATION_SCHEMA                    SQL_IDENTIFIER          yes\par
COLLATION_NAME                      SQL_IDENTIFIER          yes\par
NUMERIC_PRECISION                   CARDINAL_NUMBER         yes\par
NUMERIC_PRECISION_RADIX             CARDINAL_NUMBER         yes\par
NUMERIC_SCALE                       CARDINAL_NUMBER         yes\par
DATETIME_PRECISION                  CARDINAL_NUMBER         yes\par
INTERVAL_TYPE                       CHARACTER_DATA          yes\par
INTERVAL_PRECISION                  CARDINAL_NUMBER         yes\par
RETURN_USER_DEFINED_TYPE_CATALOG    SQL_IDENTIFIER          yes\par
RETURN_USER_DEFINED_TYPE_SCHEMA     SQL_IDENTIFIER          yes\par
RETURN_USER_DEFINED_TYPE_NAME       SQL_IDENTIFIER          yes\par
METHOD_LANGUAGE                     CHARACTER_DATA          yes\par
PARAMETER_STYLE                     CHARACTER_DATA          yes\par
IS_DETERMINISTIC                    CHARACTER_DATA          yes\par
SQL_DATA_ACCESS                     CHARACTER_DATA          yes\par
IS_NULL_CALL                        CHARACTER_DATA          yes\par
METHOD_SIGNATURE_CREATED            TIME_STAMP              yes\par
METHOD_SIGNATURE_LAST_ALTERED       TIME_STAMP              yes\par
\par
METHOD_SIGNATURES shows the SQL-invoked routines in this Catalog that the current user has Privileges on.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME, METHOD_CATALOG, METHOD_SCHEMA, METHOD_NAME uniquely identify a SQL-invoked routine that the current user may use.\par
      ## DATA_TYPE shows the routine's result <data type>: either 'BINARY\par
LARGE OBJECT', 'BIT', 'BIT VARYING', 'CHARACTER', 'CHARACTER VARYING',\par
'CHARACTER LARGE OBJECT', 'INTEGER', 'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL',\par
'DOUBLE PRECISION', 'FLOAT', 'DATE', 'TIME', 'TIME WITH TIME ZONE',\par
'TIMESTAMP', 'TIMESTAMP WITH TIME ZONE', 'INTERVAL', 'BOOLEAN', 'USER-DEFINED\par
TYPE' -- or something else, such as an implementation-defined data type.\par
      ## CHARACTER_MAXIMUM_LENGTH shows the routine's result maximum length in\par
characters (for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT') or\par
in bits (for 'BIT', 'BIT VARYING', 'BINARY LARGE OBJECT'). For other <data type>s, CHARACTER_MAXIMUM_LENGTH is NULL.\par
      ## CHARACTER_OCTET_LENGTH shows the routine's result maximum length in\par
octets (for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT', 'BIT',\par
'BIT VARYING', 'BINARY LARGE OBJECT'). For other <data type>s, CHARACTER_OCTET_LENGTH is NULL.\par
      ## COLLATION_CATALOG, COLLATION_SCHEMA, COLLATION_NAME uniquely identify\par
the routine's result default Collation (for 'CHARACTER', 'CHARACTER VARYING',\par
'CHARACTER LARGE OBJECT'). For other <data type>s, these fields are NULL.\par
      ## NUMERIC_PRECISION shows the routine's result precision (for\par
'INTEGER', 'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'FLOAT', 'DOUBLE\par
PRECISION', 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP\par
WITH TIME ZONE', 'INTERVAL'). For other <data type>s, NUMERIC_PRECISION is NULL.\par
      ## NUMERIC_PRECISION_RADIX is either 2 or 10, depending on your DBMS\par
(for 'INTEGER', 'SMALLINT, 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL'), 10 (for 'NUMERIC', 'DECIMAL'), 2 (for\par
'REAL', 'FLOAT', 'DOUBLE PRECISION'. For other <data type>s, NUMERIC_PRECISION_RADIX is NULL.\par
      ## NUMERIC_SCALE is either 0 (for 'INTEGER', 'SMALLINT') or shows the\par
routine's result scale (for 'NUMERIC', 'DECIMAL'). For other <data type>s, NUMERIC_SCALE is NULL.\par
      ## DATETIME_PRECISION shows the routine's result fractional-seconds\par
precision (for 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH\par
TIME ZONE', 'INTERVAL'). For other <data type>s, DATETIME_PRECISION is NULL.\par
      ## INTERVAL_TYPE shows the routine's result interval type (for\par
'INTERVAL'): either 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'SECOND', 'YEAR\par
TO MONTH', 'DAY TO HOUR', 'DAY TO MINUTE', 'DAY TO SECOND', 'HOUR TO MINUTE',\par
'HOUR TO SECOND', 'MINUTE TO SECOND'. For other <data type>s, INTERVAL_TYPE is NULL.\par
      ## INTERVAL_PRECISION shows the routine's result precision for the\par
interval leading field (for 'INTERVAL'). For other <data type>s, INTERVAL_PRECISION is NULL.\par
      ## RETURN_USER_DEFINED_TYPE_CATALOG, RETURN_USER_DEFINED_TYPE_SCHEMA,\par
RETURN_USER_DEFINED_TYPE_NAME uniquely identify a UDT that the routine uses.\par
If no UDT is used, these fields are NULL.\par
      ## METHOD_LANGUAGE shows the language the routine is written in: either\par
'SQL', 'ADA', 'C', 'COBOL', 'FORTRAN', 'MUMPS', 'PASCAL', 'PLI'.\par
      ## If METHOD_LANGUAGE is 'SQL', then PARAMETER_STYLE is NULL. If\par
METHOD_LANGUAGE is any other language, then PARAMETER_STYLE is either 'SQL'\par
(the method signature specified PARAMETER STYLE SQL) or 'GENERAL' (the method\par
signature specified PARAMETER STYLE GENERAL).\par
      ## If METHOD_LANGUAGE is 'SQL', then IS_DETERMINISTIC is NULL. If\par
METHOD_LANGUAGE is any other language, then IS_DETERMINISTIC is either 'YES'\par
(the method is deterministic) or 'NO' (the method is possibly not deterministic).\par
      ## SQL_DATA_ACCESS is either 'NONE' (the SQL-invoked routine does not\par
possibly contain SQL), 'CONTAINS' (the SQL-invoked routine possibly contains\par
SQL), ' READS' (the SQL-invoked routine possibly reads SQL-data) or 'MODIFIES'\par
(the SQL-invoked routine possibly modifies SQL-data).\par
      ## IS_NULL_CALL is either 'YES' (the SQL-invoked routine is a null-call\par
function) or 'NO' (the SQL-invoked routine is not a null-call function).\par
      ## METHOD_SIGNATURE_CREATED shows the CURRENT_TIMESTAMP from the time\par
the SQL-invoked method signature was created.\par
      ## METHOD_SIGNATURE_LAST_ALTERED shows the CURRENT_TIMESTAMP from the\par
time the SQL-invoked method signature was last altered. (This will be the same\par
as the METHOD_SIGNATURE_CREATED value if the routine hasn't been altered.)\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.METHOD_SIGNATURES.\par
\par
## INFORMATION_SCHEMA.METHOD_SIGNATURE_PARAMETERS\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
USER_DEFINED_TYPE_CATALOG     SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_SCHEMA      SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_NAME        SQL_IDENTIFIER          no\par
METHOD_CATALOG                SQL_IDENTIFIER          no\par
METHOD_SCHEMA                 SQL_IDENTIFIER          no\par
METHOD_NAME                   SQL_IDENTIFIER          no\par
ORDINAL_POSITION              CARDINAL_NUMBER         no\par
PARAMETER_MODE                CHARACTER_DATA          yes\par
IS_RESULT                     CHARACTER_DATA          yes\par
AS_LOCATOR                    CHARACTER_DATA          yes\par
PARAMETER_NAME                SQL_IDENTIFIER          yes\par
DATA_TYPE                     CHARACTER_DATA          no\par
CHARACTER_MAXIMUM_LENGTH      CARDINAL_NUMBER         yes\par
CHARACTER_OCTET_LENGTH        CARDINAL_NUMBER         yes\par
COLLATION_CATALOG             SQL_IDENTIFIER          yes\par
COLLATION_SCHEMA              SQL_IDENTIFIER          yes\par
COLLATION_NAME                SQL_IDENTIFIER          yes\par
CHARACTER_SET_CATALOG         SQL_IDENTIFIER          no\par
CHARACTER_SET_SCHEMA          SQL_IDENTIFIER          no\par
CHARACTER_SET_NAME            SQL_IDENTIFIER          no\par
NUMERIC_PRECISION             CARDINAL_NUMBER         yes\par
NUMERIC_PRECISION_RADIX       CARDINAL_NUMBER         yes\par
NUMERIC_SCALE                 CARDINAL_NUMBER         yes\par
DATETIME_PRECISION            CARDINAL_NUMBER         yes\par
INTERVAL_TYPE                 CHARACTER_DATA          yes\par
INTERVAL_PRECISION            CARDINAL_NUMBER         yes\par
USER_DEFINED_TYPE_NAME        SQL_IDENTIFIER          yes\par
\par
METHOD_SIGNATURE_PARAMETERS shows the parameters of the SQL-invoked methods in this Catalog that the current user has Privileges on.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME uniquely identify the UDT that a parameter is associated with.\par
      ## METHOD_CATALOG, METHOD_SCHEMA, METHOD_NAME uniquely identify the SQL-invoked method that contains the parameter.\par
      ## ORDINAL_POSITION shows the ordinal position of the parameter in its SQL-invoked method.\par
      ## PARAMETER_MODE is either 'IN' (the parameter is an input parameter),\par
'OUT' (the parameter is an output parameter) or 'INOUT' (the parameter is both\par
an input and an output parameter).\par
      ## IS_RESULT is either 'YES' (the parameter is the RESULT parameter of a\par
type-preserving function) or 'NO' (the parameter is not the RESULT parameter of a type-preserving function).\par
      ## AS_LOCATOR is either 'YES' (the parameter is passed AS LOCATOR) or 'NO' (the parameter is not passed AS LOCATOR).\par
      ## PARAMETER_NAME is the name of the parameter, if it was specified when\par
the SQL-invoked routine was created. Otherwise, PARAMETER_NAME is NULL.\par
      ## DATA_TYPE shows the parameter's <data type>: either 'BINARY LARGE\par
OBJECT', 'BIT', 'BIT VARYING', 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER\par
LARGE OBJECT', 'INTEGER', 'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'DOUBLE\par
PRECISION', 'FLOAT', 'DATE', 'TIME', 'TIME WITH TIME ZONE', 'TIMESTAMP',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL', 'BOOLEAN', 'USER-DEFINED TYPE' -- or\par
something else, such as an implementation-defined data type.\par
      ## CHARACTER_MAXIMUM_LENGTH shows the parameter's maximum length in\par
characters (for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT') or\par
in bits (for 'BIT', 'BIT VARYING', 'BINARY LARGE OBJECT'). For other <data\par
type>s, CHARACTER_MAXIMUM_LENGTH is NULL.\par
      ## CHARACTER_OCTET_LENGTH shows the parameter's maximum length in octets\par
(for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT', 'BIT', 'BIT\par
VARYING', 'BINARY LARGE OBJECT'). For other <data type>s, CHARACTER_OCTET_LENGTH is NULL.\par
      ## COLLATION_CATALOG, COLLATION_SCHEMA, COLLATION_NAME uniquely identify\par
the parameter's default Collation (for 'CHARACTER', 'CHARACTER VARYING',\par
'CHARACTER LARGE OBJECT'). For other <data type>s, these fields are NULL.\par
      ## CHARACTER_SET_CATALOG, CHARACTER_SET_SCHEMA, CHARACTER_SET_NAME\par
uniquely identify the Character set on which the parameter's default Collation is defined.\par
      ## NUMERIC_PRECISION shows the parameter's precision (for 'INTEGER',\par
'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'FLOAT', 'DOUBLE PRECISION', 'DATE',\par
'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE',\par
'INTERVAL'). For other <data type>s, NUMERIC_PRECISION is NULL.\par
      ## NUMERIC_PRECISION_RADIX is either 2 or 10, depending on your DBMS\par
(for 'INTEGER', 'SMALLINT, 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL'), 10 (for 'NUMERIC', 'DECIMAL'), 2 (for\par
'REAL', 'FLOAT', 'DOUBLE PRECISION'. For other <data type>s, NUMERIC_PRECISION_RADIX is NULL.\par
      ## NUMERIC_SCALE is either 0 (for 'INTEGER', 'SMALLINT') or shows the\par
parameter's scale (for 'NUMERIC', 'DECIMAL'). For other <data type>s, NUMERIC_SCALE is NULL.\par
      ## DATETIME_PRECISION shows the parameter's fractional-seconds precision\par
(for 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE',\par
'INTERVAL'). For other <data type>s, DATETIME_PRECISION is NULL.\par
      ## INTERVAL_TYPE shows the parameter's interval type (for 'INTERVAL'):\par
either 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'SECOND', 'YEAR TO MONTH',\par
'DAY TO HOUR', 'DAY TO MINUTE', 'DAY TO SECOND', 'HOUR TO MINUTE', 'HOUR TO\par
SECOND', 'MINUTE TO SECOND'. For other <data type>s, INTERVAL_TYPE is NULL.\par
      ## INTERVAL_PRECISION shows the parameter's precision for the interval\par
leading field (for 'INTERVAL'). For other <data type>s, INTERVAL_PRECISION is NULL.\par
      ## USER_DEFINED_TYPE_NAME names the UDT that the parameter uses. If no UDT is used, this field is NULL.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.METHOD_SIGNATURE_PARAMETERS.\par
\par
## INFORMATION_SCHEMA.PARAMETERS\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
SPECIFIC_CATALOG              SQL_IDENTIFIER          no\par
SPECIFIC_SCHEMA               SQL_IDENTIFIER          no\par
SPECIFIC_NAME                 SQL_IDENTIFIER          no\par
ORDINAL_POSITION              CARDINAL_NUMBER         no\par
PARAMETER_MODE                CHARACTER_DATA          yes\par
IS_RESULT                     CHARACTER_DATA          yes\par
AS_LOCATOR                    CHARACTER_DATA          yes\par
PARAMETER_NAME                SQL_IDENTIFIER          yes\par
DATA_TYPE                     CHARACTER_DATA          no\par
CHARACTER_MAXIMUM_LENGTH      CARDINAL_NUMBER         yes\par
CHARACTER_OCTET_LENGTH        CARDINAL_NUMBER         yes\par
COLLATION_CATALOG             SQL_IDENTIFIER          yes\par
COLLATION_SCHEMA              SQL_IDENTIFIER          yes\par
COLLATION_NAME                SQL_IDENTIFIER          yes\par
CHARACTER_SET_CATALOG         SQL_IDENTIFIER          no\par
CHARACTER_SET_SCHEMA          SQL_IDENTIFIER          no\par
CHARACTER_SET_NAME            SQL_IDENTIFIER          no\par
NUMERIC_PRECISION             CARDINAL_NUMBER         yes\par
NUMERIC_PRECISION_RADIX       CARDINAL_NUMBER         yes\par
NUMERIC_SCALE                 CARDINAL_NUMBER         yes\par
DATETIME_PRECISION            CARDINAL_NUMBER         yes\par
INTERVAL_TYPE                 CHARACTER_DATA          yes\par
INTERVAL_PRECISION            CARDINAL_NUMBER         yes\par
USER_DEFINED_TYPE_NAME        SQL_IDENTIFIER          yes\par
\par
PARAMETERS shows the parameters of the SQL-invoked routines in this Catalog that the current user has Privileges on.\par
      ## SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME uniquely identify\par
the SQL-invoked routine that contains the parameter being described.\par
      ## ORDINAL_POSITION shows the ordinal position of the parameter in its SQL-invoked routine.\par
      ## PARAMETER_MODE is either 'IN' (the parameter is an input parameter),\par
'OUT' (the parameter is an output parameter) or 'INOUT' (the parameter is both\par
an input and an output parameter).\par
      ## IS_RESULT is either 'YES' (the parameter is the RESULT parameter of a\par
type-preserving function) or 'NO' (the parameter is not the RESULT parameter\par
of a type-preserving function).\par
      ## AS_LOCATOR is either 'YES' (the parameter is passed AS LOCATOR) or\par
'NO' (the parameter is not passed AS LOCATOR).\par
      ## PARAMETER_NAME is the name of the parameter, if it was specified when\par
the SQL-invoked routine was created. Otherwise, PARAMETER_NAME is NULL.\par
      ## DATA_TYPE shows the parameter's <data type>: either 'BINARY LARGE\par
OBJECT', 'BIT', 'BIT VARYING', 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER\par
LARGE OBJECT', 'INTEGER', 'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'DOUBLE\par
PRECISION', 'FLOAT', 'DATE', 'TIME', 'TIME WITH TIME ZONE', 'TIMESTAMP',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL', 'BOOLEAN', 'USER-DEFINED TYPE' -- or\par
something else, such as an implementation-defined data type.\par
      ## CHARACTER_MAXIMUM_LENGTH shows the parameter's maximum length in\par
characters (for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT') or\par
in bits (for 'BIT', 'BIT VARYING', 'BINARY LARGE OBJECT'). For other <data\par
type>s, CHARACTER_MAXIMUM_LENGTH is NULL.\par
      ## CHARACTER_OCTET_LENGTH shows the parameter's maximum length in octets\par
(for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT', 'BIT', 'BIT\par
VARYING', 'BINARY LARGE OBJECT'). For other <data type>s, CHARACTER_OCTET_LENGTH is NULL.\par
      ## COLLATION_CATALOG, COLLATION_SCHEMA, COLLATION_NAME uniquely identify\par
the parameter's default Collation (for 'CHARACTER', 'CHARACTER VARYING',\par
'CHARACTER LARGE OBJECT'). For other <data type>s, these fields are NULL.\par
      ## CHARACTER_SET_CATALOG, CHARACTER_SET_SCHEMA, CHARACTER_SET_NAME\par
uniquely identify the Character set on which the parameter's default Collation is defined.\par
      ## NUMERIC_PRECISION shows the parameter's precision (for 'INTEGER',\par
'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'FLOAT', 'DOUBLE PRECISION', 'DATE',\par
'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE',\par
'INTERVAL'). For other <data type>s, NUMERIC_PRECISION is NULL.\par
      ## NUMERIC_PRECISION_RADIX is either 2 or 10, depending on your DBMS\par
(for 'INTEGER', 'SMALLINT, 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL'), 10 (for 'NUMERIC', 'DECIMAL'), 2 (for\par
'REAL', 'FLOAT', 'DOUBLE PRECISION'. For other <data type>s, NUMERIC_PRECISION_RADIX is NULL.\par
      ## NUMERIC_SCALE is either 0 (for 'INTEGER', 'SMALLINT') or shows the\par
parameter's scale (for 'NUMERIC', 'DECIMAL'). For other <data type>s, NUMERIC_SCALE is NULL.\par
      ## DATETIME_PRECISION shows the parameter's fractional-seconds precision\par
(for 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE',\par
'INTERVAL'). For other <data type>s, DATETIME_PRECISION is NULL.\par
      ## INTERVAL_TYPE shows the parameter's interval type (for 'INTERVAL'):\par
either 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'SECOND', 'YEAR TO MONTH',\par
'DAY TO HOUR', 'DAY TO MINUTE', 'DAY TO SECOND', 'HOUR TO MINUTE', 'HOUR TO\par
SECOND', 'MINUTE TO SECOND'. For other <data type>s, INTERVAL_TYPE is NULL.\par
      ## INTERVAL_PRECISION shows the parameter's precision for the interval\par
leading field (for 'INTERVAL'). For other <data type>s, INTERVAL_PRECISION is NULL.\par
      ## USER_DEFINED_TYPE_NAME names the UDT that the parameter uses. If no UDT is used, this field is NULL.\par
\par
## INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
CONSTRAINT_CATALOG            SQL_IDENTIFIER          no\par
CONSTRAINT_SCHEMA             SQL_IDENTIFIER          no\par
CONSTRAINT_NAME               SQL_IDENTIFIER          no\par
UNIQUE_CONSTRAINT_CATALOG     SQL_IDENTIFIER          no\par
UNIQUE_CONSTRAINT_SCHEMA      SQL_IDENTIFIER          no\par
UNIQUE_CONSTRAINT_NAME        SQL_IDENTIFIER          no\par
MATCH_OPTION                  CHARACTER_DATA          no\par
UPDATE_RULE                   CHARACTER_DATA          no\par
DELETE_RULE                   CHARACTER_DATA          no\par
\par
REFERENTIAL_CONSTRAINTS shows the FOREIGN KEY Constraints in this Catalog,\par
where the Constraints are owned by the current user.\par
      ## CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME uniquely\par
identify a FOREIGN KEY Constraint owned by the current user.\par
      ## UNIQUE_CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, UNIQUE_CONSTRAINT_NAME\par
uniquely identify the UNIQUE Constraint or PRIMARY KEY Constraint that\par
contains the key which this FOREIGN KEY Constraint references.\par
      ## MATCH_OPTION will be one of: 'NONE' (no match type defined),\par
'PARTIAL' (match type of PARTIAL defined) or 'FULL' (match type of FULL defined).\par
      ## UPDATE_RULE shows the referential action that will take place on\par
UPDATE: either 'CASCADE' (referential action of CASCADE defined), 'SET NULL'\par
(referential action of SET NULL defined), 'SET DEFAULT' (referential action of\par
SET DEFAULT defined), 'RESTRICT' (referential action of RESTRICT defined) or\par
'NO ACTION' (referential action of NO ACTION defined).\par
      ## DELETE_RULE shows the referential action that will take place on\par
DELETE: either 'CASCADE' (referential action of CASCADE defined), 'SET NULL'\par
(referential action of SET NULL defined), 'SET DEFAULT' (referential action of\par
SET DEFAULT defined), 'RESTRICT' (referential action of RESTRICT defined) or\par
'NO ACTION' (referential action of NO ACTION defined).\par
\par
## INFORMATION_SCHEMA.ROLE_COLUMN_GRANTS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
GRANTOR                 SQL_IDENTIFIER          no\par
GRANTEE                 SQL_IDENTIFIER          no\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
COLUMN_NAME             SQL_IDENTIFIER          no\par
PRIVILEGE_TYPE          CHARACTER_DATA          no\par
\par
ROLE_COLUMN_GRANTS shows the Privileges on Columns in this Catalog that currently enabled Roles may use.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role) who granted this Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the Role that may use the Privilege. \par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely identify the Column to which the Privilege applies.\par
      ## PRIVILEGE_TYPE shows the Privilege granted: either 'INSERT', 'UPDATE', 'REFERENCES' or 'SELECT'.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ROLE_COLUMN_GRANTS.\par
\par
## INFORMATION_SCHEMA.ROLE_ROUTINE_GRANTS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
GRANTOR                 SQL_IDENTIFIER          no\par
GRANTEE                 SQL_IDENTIFIER          no\par
SPECIFIC_CATALOG        SQL_IDENTIFIER          no\par
SPECIFIC_SCHEMA         SQL_IDENTIFIER          no\par
SPECIFIC_NAME           SQL_IDENTIFIER          no\par
PRIVILEGE_TYPE          CHARACTER_DATA          no\par
IS_GRANTABLE            CHARACTER_DATA          no\par
\par
ROLE_ROUTINE_GRANTS shows the Privileges on SQL-invoked routines in this Catalog that currently enabled Roles may use.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role) who granted this EXECUTE Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the Role that may use the Privilege. \par
      ## SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME uniquely identify the SQL-invoked routine to which the Privilege applies.\par
      ## PRIVILEGE_TYPE shows the Privilege granted: 'EXECUTE'.\par
      ## IS_GRANTABLE is either 'YES' (Privilege was granted WITH GRANT OPTION) or 'NO' (Privilege was not granted WITH GRANT OPTION).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ROLE_ROUTINE_GRANTS.\par
\par
## INFORMATION_SCHEMA.ROLE_TABLE_GRANTS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
GRANTOR                 SQL_IDENTIFIER          no\par
GRANTEE                 SQL_IDENTIFIER          no\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
PRIVILEGE_TYPE          CHARACTER_DATA          no\par
\par
ROLE_TABLE_GRANTS shows the Privileges on Tables in this Catalog that currently enabled Roles may use.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role) who granted this Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the Role that may use the Privilege. \par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify the Table to which the Privilege applies.\par
      ## PRIVILEGE_TYPE shows the Privilege granted: either 'DELETE', 'INSERT', 'UPDATE', 'REFERENCES', 'TRIGGER' or 'SELECT'.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ROLE_TABLE_GRANTS.\par
\par
## INFORMATION_SCHEMA.ROLE_USAGE_GRANTS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
GRANTOR                 SQL_IDENTIFIER          no\par
GRANTEE                 SQL_IDENTIFIER          no\par
OBJECT_CATALOG          SQL_IDENTIFIER          no\par
OBJECT_SCHEMA           SQL_IDENTIFIER          no\par
OBJECT_NAME             SQL_IDENTIFIER          no\par
OBJECT_TYPE             CHARACTER_DATA          no\par
IS_GRANTABLE            CHARACTER_DATA          no\par
\par
ROLE_USAGE_GRANTS shows the USAGE Privileges on Objects in this Catalog that currently enabled Roles may use.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role) who granted this Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the Role that may use the Privilege. \par
      ## OBJECT_CATALOG, OBJECT_SCHEMA, OBJECT_NAME, OBJECT_TYPE uniquely identify the Object -- either a Domain, Character set, Collation or Translation -- that the Role may use.\par
      ## IS_GRANTABLE is either 'YES' (Privilege was granted WITH GRANT OPTION) or 'NO' (Privilege was not granted WITH GRANT OPTION).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ROLE_USAGE_GRANTS.\par
\par
## INFORMATION_SCHEMA.ROLE_USER_DEFINED_TYPE_GRANTS\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
GRANTOR                       SQL_IDENTIFIER          no\par
GRANTEE                       SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_CATALOG     SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_SCHEMA      SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_NAME        SQL_IDENTIFIER          no\par
PRIVILEGE_TYPE                CHARACTER_DATA          no\par
IS_GRANTABLE                  CHARACTER_DATA          no\par
\par
ROLE_USER_DEFINED_TYPE_GRANTS shows the Privileges on UDTs in this Catalog that currently enabled Roles may use.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role) who granted this Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the Role that may use the Privilege. \par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME uniquely identify the UDT the Role may use.\par
      ## PRIVILEGE_TYPE shows the Privilege granted: 'TYPE USAGE'.\par
      ## IS_GRANTABLE is either 'YES' (Privilege was granted WITH GRANT OPTION) or 'NO' (Privilege was not granted WITH GRANT OPTION).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ROLE_USER_DEFINED_TYPE_GRANTS.\par
\par
## INFORMATION_SCHEMA.ROUTINES\par
\par
This View has the following Columns:\par
\par
Name                                Domain                  Nullable?\par
SPECIFIC_CATALOG                    SQL_IDENTIFIER          no\par
SPECIFIC_SCHEMA                     SQL_IDENTIFIER          no\par
SPECIFIC_NAME                       SQL_IDENTIFIER          no\par
ROUTINE_CATALOG                     SQL_IDENTIFIER          yes\par
ROUTINE_SCHEMA                      SQL_IDENTIFIER          yes\par
ROUTINE_NAME                        SQL_IDENTIFIER          yes\par
ROUTINE_TYPE                        CHARACTER_DATA          no\par
MODULE_CATALOG                      SQL_IDENTIFIER          yes\par
MODULE_SCHEMA                       SQL_IDENTIFIER          yes\par
MODULE_NAME                         SQL_IDENTIFIER          yes\par
USER_DEFINED_TYPE_CATALOG           SQL_IDENTIFIER          yes\par
USER_DEFINED_TYPE_SCHEMA            SQL_IDENTIFIER          yes\par
USER_DEFINED_TYPE_NAME              SQL_IDENTIFIER          yes\par
DATA_TYPE                           CHARACTER_DATA          no\par
CHARACTER_MAXIMUM_LENGTH            CARDINAL_NUMBER         yes\par
CHARACTER_OCTET_LENGTH              CARDINAL_NUMBER         yes\par
COLLATION_CATALOG                   SQL_IDENTIFIER          yes\par
COLLATION_SCHEMA                    SQL_IDENTIFIER          yes\par
COLLATION_NAME                      SQL_IDENTIFIER          yes\par
NUMERIC_PRECISION                   CARDINAL_NUMBER         yes\par
NUMERIC_PRECISION_RADIX             CARDINAL_NUMBER         yes\par
NUMERIC_SCALE                       CARDINAL_NUMBER         yes\par
DATETIME_PRECISION                  CARDINAL_NUMBER         yes\par
INTERVAL_TYPE                       CHARACTER_DATA          yes\par
INTERVAL_PRECISION                  CARDINAL_NUMBER         yes\par
TYPE_USER_DEFINED_TYPE_CATALOG      SQL_IDENTIFIER          yes\par
TYPE_USER_DEFINED_TYPE_SCHEMA       SQL_IDENTIFIER          yes\par
TYPE_USER_DEFINED_TYPE_NAME         SQL_IDENTIFIER          yes\par
ROUTINE_BODY                        CHARACTER_DATA          no\par
ROUTINE_DEFINITION                  CHARACTER_DATA          yes\par
EXTERNAL_NAME                       SQL_IDENTIFIER          yes\par
EXTERNAL_LANGUAGE                   CHARACTER_DATA          yes\par
PARAMETER_STYLE                     CHARACTER_DATA          yes\par
IS_DETERMINISTIC                    CHARACTER_DATA          yes\par
SQL_DATA_ACCESS                     CHARACTER_DATA          no\par
SQL_PATH                            CHARACTER_DATA          yes\par
SCHEMA_LEVEL_ROUTINE                CHARACTER_DATA          yes\par
MAX_DYNAMIC_RESULT_SETS             CARDINAL_NUMBER         yes\par
ROUTINE_CREATED                     TIME_STAMP              yes\par
ROUTINE_LAST_ALTERED                TIME_STAMP              yes\par
\par
ROUTINES shows the SQL-invoked routines in this Catalog that the current user has Privileges on.\par
      ## SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_CATALOG,\par
ROUTINE_SCHEMA, ROUTINE_NAME uniquely identify an SQL-invoked routine that the\par
current user has Privileges on. Among the routines in this View, you will find all the functions which your DBMS defined in advance: the SQL built-in functions, e.g.: "ABS", "BIT_LENGTH", "CHARACTER_LENGTH", "CHAR_LENGTH", "LOWER", "MOD", "OCTET_LENGTH", "POSITION", "SUBSTRING", "UPPER".\par
      ## ROUTINE_TYPE is either 'PROCEDURE' (the SQL-invoked routine is an\par
SQL-invoked procedure), 'FUNCTION' (the SQL-invoked routine is an SQL-invoked\par
function that is not an SQL-invoked method) or 'METHOD' (the SQL-invoked routine is an SQL-invoked method).\par
      ## MODULE_CATALOG, MODULE_SCHEMA, MODULE_NAME are all NULL.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME uniquely identify the UDT that this SQL-invoked routine is a method of. If the routine is not defined as a method of a UDT, these fields are NULL.\par
      ## DATA_TYPE shows the routine's result <data type>: either 'BINARY\par
LARGE OBJECT', 'BIT', 'BIT VARYING', 'CHARACTER', 'CHARACTER VARYING',\par
'CHARACTER LARGE OBJECT', 'INTEGER', 'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL',\par
'DOUBLE PRECISION', 'FLOAT', 'DATE', 'TIME', 'TIME WITH TIME ZONE',\par
'TIMESTAMP', 'TIMESTAMP WITH TIME ZONE', 'INTERVAL', 'BOOLEAN', 'USER-DEFINED\par
TYPE' -- or something else, such as an implementation-defined data type.\par
      ## CHARACTER_MAXIMUM_LENGTH shows the routine's result maximum length in\par
characters (for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT') or\par
in bits (for 'BIT', 'BIT VARYING', 'BINARY LARGE OBJECT'). For other <data\par
type>s, CHARACTER_MAXIMUM_LENGTH is NULL.\par
      ## CHARACTER_OCTET_LENGTH shows the routine's result maximum length in\par
octets (for 'CHARACTER', 'CHARACTER VARYING', 'CHARACTER LARGE OBJECT', 'BIT',\par
'BIT VARYING', 'BINARY LARGE OBJECT'). For other <data type>s, CHARACTER_OCTET_LENGTH is NULL.\par
      ## COLLATION_CATALOG, COLLATION_SCHEMA, COLLATION_NAME uniquely identify\par
the routine's result default Collation (for 'CHARACTER', 'CHARACTER VARYING',\par
'CHARACTER LARGE OBJECT'). For other <data type>s, these fields are NULL.\par
      ## NUMERIC_PRECISION shows the routine's result precision (for\par
'INTEGER', 'SMALLINT', 'NUMERIC', 'DECIMAL', 'REAL', 'FLOAT', 'DOUBLE\par
PRECISION', 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP\par
WITH TIME ZONE', 'INTERVAL'). For other <data type>s, NUMERIC_PRECISION is NULL.\par
      ## NUMERIC_PRECISION_RADIX is either 2 or 10, depending on your DBMS\par
(for 'INTEGER', 'SMALLINT, 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL'), 10 (for 'NUMERIC', 'DECIMAL'), 2 (for\par
'REAL', 'FLOAT', 'DOUBLE PRECISION'. For other <data type>s, NUMERIC_PRECISION_RADIX is NULL.\par
      ## NUMERIC_SCALE is either 0 (for 'INTEGER', 'SMALLINT') or shows the\par
routine's result scale (for 'NUMERIC', 'DECIMAL'). For other <data type>s, NUMERIC_SCALE is NULL.\par
      ## DATETIME_PRECISION shows the routine's result fractional-seconds\par
precision (for 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH\par
TIME ZONE', 'INTERVAL'). For other <data type>s, DATETIME_PRECISION is NULL.\par
      ## INTERVAL_TYPE shows the routine's result interval type (for\par
'INTERVAL'): either 'YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'SECOND', 'YEAR\par
TO MONTH', 'DAY TO HOUR', 'DAY TO MINUTE', 'DAY TO SECOND', 'HOUR TO MINUTE',\par
'HOUR TO SECOND', 'MINUTE TO SECOND'. For other <data type>s, INTERVAL_TYPE is NULL.\par
      ## INTERVAL_PRECISION shows the routine's result precision for the interval leading field (for 'INTERVAL'). For other <data type>s, INTERVAL_PRECISION is NULL.\par
      ## TYPE_USER_DEFINED_TYPE_CATALOG, TYPE_USER_DEFINED_TYPE_SCHEMA,\par
TYPE_USER_DEFINED_TYPE_NAME uniquely identify a UDT that the routine uses. If no UDT is used, these fields are NULL.\par
      ## ROUTINE_BODY is either 'SQL' (the SQL-invoked routine is an SQL\par
routine) or 'EXTERNAL' (the SQL-invoked routine is an external routine).\par
      ## If this SQL-invoked routine is an SQL routine that is not part of an\par
SQL-server Module definition, ROUTINE_DEFINITION shows the routine body. If\par
the routine body was too big to be stored, or if this is not an SQL routine\par
that doesn't belong to an SQL-server Module definition, ROUTINE_DEFINITION is NULL.\par
      ## If this SQL-invoked routine is an external routine (i.e.: ROUTINE_BODY is 'EXTERNAL'), EXTERNAL_NAME shows its external name. If ROUTINE_BODY is 'SQL', EXTERNAL_NAME is NULL.\par
      ## If this SQL-invoked routine is an external routine (i.e.:\par
ROUTINE_BODY is 'EXTERNAL'), EXTERNAL_LANGUAGE shows the language it's written\par
in: either 'ADA', 'C', 'COBOL','FORTRAN', 'MUMPS', 'PASCAL' or 'PLI'. If\par
ROUTINE_BODY is 'SQL', EXTERNAL_LANGUAGE is NULL.\par
      ## If this SQL-invoked routine is an external routine (i.e.:\par
ROUTINE_BODY is 'EXTERNAL'), PARAMETER_STYLE shows its SQL parameter passing\par
style: either 'SQL' or 'GENERAL'. If ROUTINE_BODY is 'SQL', PARAMETER_STYLE is NULL.\par
      ## If this SQL-invoked routine is an external routine (i.e.:\par
ROUTINE_BODY is 'EXTERNAL'), IS_DETERMINISTIC is either 'YES' (routine was\par
defined as DETERMINISTIC) or 'NO' (routine was not defined as DETERMINISTIC).\par
If ROUTINE_BODY is 'SQL', IS_DETERMINISTIC is NULL.\par
      ## SQL_DATA_ACCESS is either 'NONE' (the SQL-invoked routine does not\par
possibly contain SQL), 'CONTAINS' (the SQL-invoked routine possibly contains\par
SQL), ' READS' (the SQL-invoked routine possibly reads SQL-data) or 'MODIFIES'\par
(the SQL-invoked routine possibly modifies SQL-data).\par
      ## If this SQL-invoked routine is an SQL routine, SQL_PATH shows the SQL-path of the Schema that contains it. Otherwise, SQL_PATH is NULL.\par
      ## SCHEMA_LEVEL_ROUTINE is either 'YES' (this is a Schema-level routine)\par
or 'NO' (this is not a Schema-level routine).\par
      ## If this is an SQL-invoked procedure that was defined by an\par
SQL-invoked routine containing a <maximum dynamic result sets> clause in its\par
definition, MAX_DYNAMIC_RESULT_SETS shows that value. Otherwise, MAX_DYNAMIC_RESULT_SETS is zero.\par
      ## ROUTINE_CREATED shows the CURRENT_TIMESTAMP from the time this SQL-invoked routine was created.\par
      ## ROUTINE_LAST_ALTERED shows the CURRENT_TIMESTAMP from the time this\par
SQL-invoked routine was last altered. (This will be the same as the\par
ROUTINE_CREATED value if the routine hasn't been altered.)\par
\par
## INFORMATION_SCHEMA.ROUTINE_COLUMN_USAGE\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
SPECIFIC_CATALOG        SQL_IDENTIFIER          no\par
SPECIFIC_SCHEMA         SQL_IDENTIFIER          no\par
SPECIFIC_NAME           SQL_IDENTIFIER          no\par
ROUTINE_CATALOG         SQL_IDENTIFIER          yes\par
ROUTINE_SCHEMA          SQL_IDENTIFIER          yes\par
ROUTINE_NAME            SQL_IDENTIFIER          yes\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
COLUMN_NAME             SQL_IDENTIFIER          no\par
\par
ROUTINE_COLUMN_USAGE shows the Columns on which SQL-invoked routines in this Catalog depend, where the Columns are owned by the current user.\par
      ## SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_CATALOG,\par
ROUTINE_SCHEMA, ROUTINE_NAME uniquely identify an SQL-invoked routine.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely\par
identify a Column that is owned by the current user and upon which this routine depends.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ROUTINE_COLUMN_USAGE.\par
\par
## INFORMATION_SCHEMA.ROUTINE_PRIVILEGES\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
GRANTOR                 SQL_IDENTIFIER          no\par
GRANTEE                 SQL_IDENTIFIER          no\par
SPECIFIC_CATALOG        SQL_IDENTIFIER          no\par
SPECIFIC_SCHEMA         SQL_IDENTIFIER          no\par
SPECIFIC_NAME           SQL_IDENTIFIER          no\par
ROUTINE_CATALOG         SQL_IDENTIFIER          yes\par
ROUTINE_SCHEMA          SQL_IDENTIFIER          yes\par
ROUTINE_NAME            SQL_IDENTIFIER          yes\par
PRIVILEGE_TYPE          CHARACTER_DATA          no\par
IS_GRANTABLE            CHARACTER_DATA          no\par
\par
ROUTINE_PRIVILEGES shows the Privileges on SQL-invoked routines in this\par
Catalog, where the Privileges are either available to, or granted by, the\par
current user.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role) who granted the Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the user (or perhaps the Role)\par
who may use the Privilege. By definition, if GRANTOR isn't CURRENT_USER, then\par
GRANTEE is either CURRENT_USER or 'PUBLIC'.\par
      ## SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_CATALOG,\par
ROUTINE_SCHEMA, ROUTINE_NAME uniquely identify the SQL-invoked routine that this Privilege applies to.\par
      ## PRIVILEGE_TYPE shows the Privilege granted: 'EXECUTE'.\par
      ## IS_GRANTABLE is either 'YES' (Privilege was granted WITH GRANT OPTION) or 'NO' (Privilege was not granted WITH GRANT OPTION).\par
\par
## INFORMATION_SCHEMA.ROUTINE_TABLE_USAGE\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
SPECIFIC_CATALOG        SQL_IDENTIFIER          no\par
SPECIFIC_SCHEMA         SQL_IDENTIFIER          no\par
SPECIFIC_NAME           SQL_IDENTIFIER          no\par
ROUTINE_CATALOG         SQL_IDENTIFIER          yes\par
ROUTINE_SCHEMA          SQL_IDENTIFIER          yes\par
ROUTINE_NAME            SQL_IDENTIFIER          yes\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
\par
ROUTINE_TABLE_USAGE shows the Tables on which SQL-invoked routines in this\par
Catalog depend, where the Tables are owned by the current user.\par
      ## SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME, ROUTINE_CATALOG,\par
ROUTINE_SCHEMA, ROUTINE_NAME uniquely identify an SQL-invoked routine in this Catalog.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify a Table that is owned by the current user and upon which this routine depends.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.ROUTINE_TABLE_USAGE.\par
\par
## INFORMATION_SCHEMA.SCHEMATA\par
\par
This View has the following Columns:\par
\par
Name                             Domain                  Nullable?\par
CATALOG_NAME                     SQL_IDENTIFIER          no\par
SCHEMA_NAME                      SQL_IDENTIFIER          no\par
SCHEMA_OWNER                     SQL_IDENTIFIER          no\par
DEFAULT_CHARACTER_SET_CATALOG    SQL_IDENTIFIER          no\par
DEFAULT_CHARACTER_SET_SCHEMA     SQL_IDENTIFIER          no\par
DEFAULT_CHARACTER_SET_NAME       SQL_IDENTIFIER          no\par
SQL_PATH                         CHARACTER_DATA          yes\par
\par
SCHEMATA shows the Schemas in this Catalog that are owned by the current user.\par
      ## CATALOG_NAME, SCHEMA_NAME uniquely identify a Schema owned by the user.\par
      ## SCHEMA_OWNER shows the <AuthorizationID> of the current user. This was the Schema owner specified in the Schema definition.\par
      ## DEFAULT_CHARACTER_SET_CATALOG, DEFAULT_CHARACTER_SET_SCHEMA,\par
DEFAULT_CHARACTER_SET_NAME uniquely identify the Character set that was\par
specified by a DEFAULT CHARACTER SET clause in the Schema definition. This is\par
the default Character set for the Columns and Domains belonging to this Schema.\par
      ## SQL_PATH shows the contents of the Schema definition's PATH clause,\par
if there was one. If PATH was omitted, or if its value was too large to be\par
stored, SQL_PATH is NULL.\par
\par
## INFORMATION_SCHEMA.SQL_FEATURES\par
\par
This View has the following Columns:\par
\par
Name              Domain            Nullable?\par
FEATURE_ID        CHARACTER_DATA    no\par
FEATURE_NAME      CHARACTER_DATA    no\par
SUB_FEATURE_ID    CHARACTER_DATA    no\par
SUB_FEATURE_NAME  CHARACTER_DATA    no\par
IS_SUPPORTED      CHARACTER_DATA    no\par
IS_VERIFIED_BY    CHARACTER_DATA    yes\par
FEATURE_COMMENTS  CHARACTER_DATA    yes\par
\par
SQL_FEATURES shows all the SQL Standard-defined features and subfeatures (see\par
Appendix B -- SQL Taxonomy for a list of these), and marks the ones your DBMS supports.\par
      ## FEATURE_ID, SUB_FEATURE_ID uniquely identify an SQL feature or\par
subfeature. If SUB_FEATURE_ID is zero, this is a feature; otherwise this is a subfeature.\par
      ## FEATURE_NAME is the name assigned to the feature by the Standard.\par
      ## SUB_FEATURE_NAME is the name assigned to the subfeature by the\par
Standard. If SUB_FEATURE_NAME is a zero-length string, this is a feature; otherwise this is a subfeature.\par
      ## IS_SUPPORTED is either 'YES' (the DBMS fully supports this\par
feature/subfeature) or 'NO' (the DBMS doesn't fully support this\par
feature/subfeature). Note: if IS_SUPPORTED is 'YES' for a feature, then it\par
must also be 'YES' for every subfeature of that feature.\par
      ## If your DBMS has had its conformance claim for this\par
feature/subfeature independently tested, IS_VERIFIED_BY identifies the\par
conformance test used to verify the claim. If no such verification exists,\par
IS_VERIFIED_BY is NULL. (Note: if IS_SUPPORTED is 'NO' or NULL, IS_VERIFIED_BY\par
must be NULL.)\par
      ## FEATURE_COMMENTS is either NULL, or shows any implementer's comments that are pertinent to this feature/subfeature.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.SQL_FEATURES.\par
\par
## INFORMATION_SCHEMA.SQL_IMPLEMENTATION_INFO\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
IMPLEMENTATION_INFO_ID        CHARACTER_DATA          no\par
IMPLEMENTATION_INFO_NAME      CHARACTER_DATA          no\par
INTEGER_VALUE                 CARDINAL_NUMBER         yes\par
CHARACTER_VALUE               CHARACTER_DATA          yes\par
IMPLEMENTATION_INFO_COMMENTS  CHARACTER_DATA          yes\par
\par
SQL_IMPLEMENTATION_INFO lists all the information items that the SQL Standard\par
states are "implementor-defined" and shows your DBMS's defined value for each one.\par
      ## IMPLEMENTATION_INFO_ID uniquely identifies an implementor-defined information item.\par
      ## IMPLEMENTATION_INFO_NAME shows the name for this IMPLEMENTATION_INFO_ID.\par
      ## INTEGER_VALUE and CHARACTER_VALUE show your DBMS's defined value for\par
this item. Depending on the item's type, one field will contain a value and\par
the other will be NULL. If INTEGER_VALUE is zero, or CHARACTER_VALUE is a\par
zero-length string, then your DBMS's value for this item is not known. If both\par
fields are NULL, then the value for this item is not applicable for your DBMS,\par
probably because the feature is not supported.\par
      ## IMPLEMENTATION_INFO_COMMENTS is either NULL, or shows any implementer's comments that are pertinent to this item.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.SQL_IMPLEMENTATION_INFO.\par
\par
## INFORMATION_SCHEMA.SQL_SIZING\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
SIZING_ID               CARDINAL_NUMBER         no\par
SIZING_NAME             CHARACTER_DATA          no\par
SUPPORTED_VALUE         CARDINAL_NUMBER         yes\par
SIZING_COMMENTS         CHARACTER_DATA          yes\par
\par
SQL_SIZING lists all the sizing items defined in the SQL Standard and shows\par
the size supported by your DBMS for each one.\par
      ## SIZING_ID uniquely identifies a sizing item defined in the SQL Standard.\par
      ## SIZING_NAME shows the name for this SIZING_ID.\par
      ## SUPPORTED_VALUE shows the maximum size your DBMS supports for this\par
item. If SUPPORTED_VALUE is NULL, then your DBMS doesn't support any features\par
that use this item. If SUPPORTED_VALUE is zero, then your DBMS either doesn't\par
place a limit on this item or can't determine the item's limit.\par
      ## SIZING_COMMENTS is either NULL, or shows any implementer's comments that are pertinent to this item.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.SQL_SIZING.\par
\par
## INFORMATION_SCHEMA.SQL_SIZING_PROFILES\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
SIZING_ID                     CARDINAL_NUMBER         no\par
SIZING_NAME                   CHARACTER_DATA          no\par
PROFILE_ID                    CHARACTER_DATA          no\par
REQUIRED_VALUE                CARDINAL_NUMBER         yes\par
SIZING_PROFILES_COMMENTS      CHARACTER_DATA          yes\par
\par
SQL_SIZING_PROFILES lists all the sizing items defined in the SQL Standard and\par
shows the size required by one or more profiles of the Standard.\par
      ## SIZING_ID, PROFILE_ID uniquely identify a sizing item for a given profile.\par
      ## SIZING_NAME is the name for this SIZING_ID.\par
      ## REQUIRED_VALUE shows the minimum size that this profile requires for\par
this item. If REQUIRED_VALUE is NULL, then the item isn't used by any features\par
supported by this profile. If REQUIRED_VALUE is zero, then this profile doesn't set a limit for the item.\par
      ## SIZING_PROFILES_COMMENTS is either NULL, or shows any implementer's comments that are pertinent to this item within this profile.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.SQL_SIZING_PROFILES.\par
\par
## INFORMATION_SCHEMA.SQL_LANGUAGES\par
\par
This View has the following Columns:\par
\par
Name                                Domain            Nullable?\par
SQL_LANGUAGE_SOURCE                 CHARACTER_DATA    no\par
SQL_LANGUAGE_YEAR                   CHARACTER_DATA    yes\par
SQL_LANGUAGE_CONFORMANCE            CHARACTER_DATA    yes\par
SQL_LANGUAGE_INTEGRITY              CHARACTER_DATA    yes\par
SQL_LANGUAGE_IMPLEMENTATION         CHARACTER_DATA    yes\par
SQL_LANGUAGE_BINDING_STYLE          CHARACTER_DATA    yes\par
SQL_LANGUAGE_PROGRAMMING_LANGUAGE   CHARACTER_DATA    yes\par
\par
SQL_LANGUAGES shows the SQL conformance levels, options and dialects supported by your DBMS.\par
      ## SQL_LANGUAGE_SOURCE shows the name of the source of your DBMS's SQL\par
language definition. For SQL defined by the SQL Standard, this is 'ISO 9075'.\par
If your DBMS supports some other version of SQL, SQL_LANGUAGE_SOURCE must show\par
some implementation-defined value, as must all of the Columns in this View.\par
We'll ignore this possibility when discussing the rest of the Columns.\par
      ## SQL_LANGUAGE_YEAR shows the year that the supported version of the\par
SQL Standard was approved: either '1987', '1989', '1992' or '1998'. It may not be NULL.\par
      ## SQL_LANGUAGE_CONFORMANCE shows the level of SQL Standard conformance\par
your DBMS claims: for '1987' and '1989', either '1' or '2'; for '1992', either\par
'ENTRY', 'INTERMEDIATE' or 'FULL'; and for '1998', 'CORE'. It may not be NULL.\par
      ## SQL_LANGUAGE_INTEGRITY shows whether the 1989 SQL Standard integrity\par
features are fully supported by your DBMS: for '1989', either 'YES' (SQL-89\par
integrity features fully supported) or 'NO' (SQL-89 integrity features not\par
fully supported); it may not be NULL. For '1987', '1992' and '1998', SQL_LANGUAGE_INTEGRITY must be NULL.\par
      ## SQL_LANGUAGE_IMPLEMENTATION is NULL if SQL_LANGUAGE_SOURCE is 'ISO\par
9075'. If your DBMS supports some other version of SQL, SQL_LANGUAGE_IMPLEMENTATION shows some implementation-defined value.\par
      ## SQL_LANGUAGE_BINDING_STYLE shows the binding style supported by your\par
DBMS: either 'MODULE' (SQL-client Module support), 'EMBEDDED' (embedded SQL\par
support) or 'DIRECT' (direct SQL invocation support). It may not be NULL.\par
Note: if your DBMS supports more than one binding style, there will be a\par
separate row in the View for each one.\par
      ## SQL_LANGUAGE_PROGRAMMING_LANGUAGE shows the host language supported\par
by your DBMS for this binding style: (a) for 'DIRECT', this Column is NULL;\par
(b) for '1987' and '1989' and either 'EMBEDDED' or 'MODULE', either 'COBOL',\par
'FORTRAN', 'PASCAL' or 'PLI' and (c) for '1992' and either 'EMBEDDED' or\par
'MODULE', either 'ADA', 'C', 'COBOL', 'FORTRAN', 'MUMPS', 'PASCAL' or 'PLI'.\par
Note: if your DBMS supports more than one host language for this binding\par
style, there will be a separate row in the View for each one.\par
\par
## INFORMATION_SCHEMA.TABLES\par
\par
This View has the following Columns:\par
\par
Name              Domain                  Nullable?\par
TABLE_CATALOG     SQL_IDENTIFIER          no\par
TABLE_SCHEMA      SQL_IDENTIFIER          no\par
TABLE_NAME        SQL_IDENTIFIER          no\par
TABLE_TYPE        CHARACTER_DATA          no\par
\par
TABLES shows the Tables (i.e.: Base tables and Views) in this Catalog that the\par
current user has Privileges on.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify a Table\par
which the current user may use -- i.e.: CURRENT_USER (or PUBLIC) has any\par
Privilege on the Table or on any Column of the Table.\par
      ## TABLE_TYPE is either: 'BASE TABLE' (for a persistent Base table),\par
'VIEW' (for a View), 'LOCAL TEMPORARY' (for a local temporary Table) or\par
'GLOBAL TEMPORARY' (for a global temporary Table). Note: instead of 'BASE\par
TABLE' some DBMSs will return 'TABLE' because (for some reason or other) Delphi expects 'TABLE' here.\par
\par
## INFORMATION_SCHEMA.TABLE_CONSTRAINTS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
CONSTRAINT_CATALOG      SQL_IDENTIFIER          no\par
CONSTRAINT_SCHEMA       SQL_IDENTIFIER          no\par
CONSTRAINT_NAME         SQL_IDENTIFIER          no\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
CONSTRAINT_TYPE         CHARACTER_DATA          no\par
IS_DEFERRABLE           CHARACTER_DATA          no\par
INITIALLY_DEFERRED      CHARACTER_DATA          no\par
\par
TABLE_CONSTRAINTS shows the Table Constraints in this Catalog, where the Constraints are owned by the current user.\par
      ## CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME uniquely identify a Constraint owned by the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify the Table to which this Constraint applies.\par
      ## CONSTRAINT_TYPE is either: 'UNIQUE', 'PRIMARY KEY', 'FOREIGN KEY' or 'CHECK'.\par
      ## IS_DEFERRABLE is either 'YES' (the Constraint is DEFERRABLE) or 'NO' (the Constraint is NOT DEFERRABLE).\par
      ## INITIALLY_DEFERRED is either 'YES' (the Constraint is INITIALLY DEFERRED) or 'NO' (the Constraint is INITIALLY IMMEDIATE).\par
\par
## INFORMATION_SCHEMA.TABLE_PRIVILEGES\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
GRANTOR                 SQL_IDENTIFIER          no\par
GRANTEE                 SQL_IDENTIFIER          no\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
PRIVILEGE_TYPE          CHARACTER_DATA          no\par
IS_GRANTABLE            CHARACTER_DATA          no\par
\par
TABLE_PRIVILEGES shows the Privileges on Tables in this Catalog, where the\par
Privileges are either available to, or granted by, the current user.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role) who granted the Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the user (or perhaps the Role)\par
who may use the Privilege. By definition, if GRANTOR isn't CURRENT_USER, then\par
GRANTEE is either CURRENT_USER or 'PUBLIC'.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify a Table in this Catalog.\par
      ## PRIVILEGE_TYPE shows the Privilege granted: either 'INSERT', 'UPDATE', 'REFERENCES', 'DELETE', 'TRIGGER' or 'SELECT'.\par
      ## IS_GRANTABLE is either 'YES' (Privilege was granted WITH GRANT OPTION) or 'NO' (Privilege was not granted WITH GRANT OPTION).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.TABLE_PRIVILEGES.\par
\par
## INFORMATION_SCHEMA.TRANSFORMS\par
\par
This View has the following Columns:\par
\par
Name                          Domain                  Nullable?\par
USER_DEFINED_TYPE_CATALOG     SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_SCHEMA      SQL_IDENTIFIER          no\par
USER_DEFINED_TYPE_NAME        SQL_IDENTIFIER          no\par
SPECIFIC_CATALOG              SQL_IDENTIFIER          yes\par
SPECIFIC_SCHEMA               SQL_IDENTIFIER          yes   \par
SPECIFIC_NAME                 SQL_IDENTIFIER          yes\par
GROUP_NAME                    SQL_IDENTIFIER          no\par
TRANSFORM_TYPE                CHARACTER_DATA          no\par
\par
TRANSFORMS shows the transforms on UDTs in this Catalog, where the transforms may be used by the current user.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME uniquely identify the UDT to which this transform applies.\par
      ## SPECIFIC_CATALOG, SPECIFIC_SCHEMA, SPECIFIC_NAME uniquely identify the SQL-invoked routine that acts as the transform function for this transform.\par
      ## GROUP_NAME is the name of the transform group.\par
      ## TRANSFORM_TYPE is either: 'TO SQL' (the transform is a to-sql function) or 'FROM SQL' (the transform is a from-sql function).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.TRANSFORMS.\par
\par
## INFORMATION_SCHEMA.TRANSLATIONS\par
\par
This View has the following Columns:\par
\par
Name                                Domain                  Nullable?\par
TRANSLATION_CATALOG                 SQL_IDENTIFIER          no\par
TRANSLATION_SCHEMA                  SQL_IDENTIFIER          no\par
TRANSLATION_NAME                    SQL_IDENTIFIER          no\par
SOURCE_CHARACTER_SET_CATALOG        SQL_IDENTIFIER          no\par
SOURCE_CHARACTER_SET_SCHEMA         SQL_IDENTIFIER          no\par
SOURCE_CHARACTER_SET_NAME           SQL_IDENTIFIER          no\par
TARGET_CHARACTER_SET_CATALOG        SQL_IDENTIFIER          no\par
TARGET_CHARACTER_SET_SCHEMA         SQL_IDENTIFIER          no\par
TARGET_CHARACTER_SET_NAME           SQL_IDENTIFIER          no\par
TRANSLATION_DEFINITION              CHARACTER_DATA          no\par
\par
TRANSLATIONS shows the Translations in this Catalog that the current user has Privileges on.\par
      ## TRANSLATION_CATALOG, TRANSLATION_SCHEMA, TRANSLATION_NAME uniquely identify a Translation that the current user may use.\par
      ## SOURCE_CHARACTER_SET_CATALOG, SOURCE_CHARACTER_SET_SCHEMA, SOURCE_CHARACTER_SET_NAME uniquely identify the Character set named in the FOR clause of the Translation definition.\par
      ## TARGET_CHARACTER_SET_CATALOG, TARGET_CHARACTER_SET_SCHEMA, TARGET_CHARACTER_SET_NAME uniquely identify the Character set named in the TO clause of the Translation definition.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.TRANSLATIONS.\par
\par
## INFORMATION_SCHEMA.TRIGGERED_UPDATE_COLUMNS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
TRIGGER_CATALOG         SQL_IDENTIFIER          no\par
TRIGGER_SCHEMA          SQL_IDENTIFIER          no\par
TRIGGER_NAME            SQL_IDENTIFIER          no\par
EVENT_OBJECT_CATALOG    SQL_IDENTIFIER          no\par
EVENT_OBJECT_SCHEMA     SQL_IDENTIFIER          no\par
EVENT_OBJECT_TABLE      SQL_IDENTIFIER          no\par
EVENT_OBJECT_COLUMN     SQL_IDENTIFIER          no\par
\par
TRIGGERED_UPDATE_COLUMNS shows the Columns in this Catalog that are referenced\par
by the explicit UPDATE trigger event Columns of a Trigger in this Catalog, where the Trigger is owned by the current user.\par
      ## TRIGGER_CATALOG, TRIGGER_SCHEMA, TRIGGER_NAME uniquely identify a Trigger with a trigger event of UPDATE. The Trigger is owned by the current user.\par
      ## EVENT_OBJECT_CATALOG, EVENT_OBJECT_SCHEMA, EVENT_OBJECT_TABLE, EVENT_OBJECT_COLUMN uniquely identify a Column that is affected by the Trigger.\par
\par
## INFORMATION_SCHEMA.TRIGGERS\par
\par
This View has the following Columns:\par
\par
Name                          Domain            Nullable?\par
TRIGGER_CATALOG               SQL_IDENTIFIER    no\par
TRIGGER_SCHEMA                SQL_IDENTIFIER    no\par
TRIGGER_NAME                  SQL_IDENTIFIER    no\par
EVENT_MANIPULATION            CHARACTER_DATA    yes\par
EVENT_OBJECT_CATALOG          SQL_IDENTIFIER    no\par
EVENT_OBJECT_SCHEMA           SQL_IDENTIFIER    no\par
EVENT_OBJECT_TABLE            SQL_IDENTIFIER    no\par
CONDITION_TIMING              CHARACTER_DATA    yes\par
CONDITION_REFERENCE_OLD_TABLE SQL_IDENTIFIER    yes\par
CONDITION_REFERENCE_NEW_TABLE SQL_IDENTIFIER    yes\par
ACTION_ORDER                  CARDINAL_NUMBER   no\par
ACTION_CONDITION              CHARACTER_DATA    yes\par
ACTION_STATEMENT              CHARACTER_DATA    no\par
ACTION_ORIENTATION            CHARACTER_DATA    yes\par
COLUMN_LIST_IS_IMPLICIT       SQL_IDENTIFIER    yes\par
\par
TRIGGERS shows the Triggers in this Catalog, where the Triggers are owned by the current user.\par
      ## TRIGGER_CATALOG, TRIGGER_SCHEMA, TRIGGER_NAME uniquely identify a Trigger that is owned by the current user.\par
      ## EVENT_MANIPULATION is either: 'INSERT' (the trigger event is INSERT),\par
'DELETE' (the trigger event is DELETE) or 'UPDATE' (the trigger event is UPDATE).\par
      ## EVENT_OBJECT_CATALOG, EVENT_OBJECT_SCHEMA, EVENT_OBJECT_TABLE uniquely identify the Table the Trigger acts on.\par
      ## CONDITION_TIMING is either: 'BEFORE' (the trigger action time is BEFORE) or 'AFTER' (the trigger action time is AFTER).\par
      ## CONDITION_REFERENCE_OLD_TABLE shows the <old value correlation name> of the Trigger.\par
      ## CONDITION_REFERENCE_NEW_TABLE shows the <new value correlation name> of the Trigger.\par
      ## ACTION_ORDER shows the ordinal position of the triggered action in\par
the list of all Triggers on the same Table, where the Triggers have the same\par
EVENT_MANIPULATION, CONDITION_TIMING and ACTION_ORIENTATION values.\par
      ## ACTION_CONDITION shows the Trigger's search condition for its triggered action.\par
      ## ACTION_STATEMENT shows the Trigger's statement list for its triggered action.\par
      ## ACTION_ORIENTATION is either: 'ROW' (the trigger action is FOR EACH\par
ROW) or 'STATEMENT' (the trigger action is FOR EACH STATEMENT).\par
      ## COLUMN_LIST_IS_IMPLICIT is either: 'YES' (the trigger event is UPDATE\par
and the trigger Column list is implicit), 'NO' (the trigger event is UPDATE\par
and the trigger Column list is explicit) or NULL (the trigger event is INSERT or DELETE).\par
\par
## INFORMATION_SCHEMA.TRIGGER_COLUMN_USAGE\par
\par
This View has the following Columns:\par
\par
Name              Domain            Nullable?\par
TRIGGER_CATALOG   SQL_IDENTIFIER    no\par
TRIGGER_SCHEMA    SQL_IDENTIFIER    no\par
TRIGGER_NAME      SQL_IDENTIFIER    no\par
TABLE_CATALOG     SQL_IDENTIFIER    no\par
TABLE_SCHEMA      SQL_IDENTIFIER    no\par
TABLE_NAME        SQL_IDENTIFIER    no\par
COLUMN_NAME       SQL_IDENTIFIER    no\par
\par
TRIGGER_COLUMN_USAGE shows the Columns on which Triggers in this Catalog\par
depend, where the Triggers are owned by the current user.\par
      ## TRIGGER_CATALOG, TRIGGER_SCHEMA, TRIGGER_NAME uniquely identify a\par
Trigger that is owned by the current user. The Trigger's trigger event is either 'INSERT' or 'DELETE'.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely\par
identify a Column that this Trigger depends on. The dependence is created by\par
one of two things: either (a) this Column belongs to a Table named in the\par
search condition of this Trigger's triggered action clause or (b) this Column,\par
or the Table it belongs to, is referred to in a triggered SQL statement of this Trigger's definition.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.TRIGGER_COLUMN_USAGE.\par
\par
## INFORMATION_SCHEMA.TRIGGER_TABLE_USAGE\par
\par
This View has the following Columns:\par
\par
Name              Domain            Nullable?\par
TRIGGER_CATALOG   SQL_IDENTIFIER    no\par
TRIGGER_SCHEMA    SQL_IDENTIFIER    no\par
TRIGGER_NAME      SQL_IDENTIFIER    no\par
TABLE_CATALOG     SQL_IDENTIFIER    no\par
TABLE_SCHEMA      SQL_IDENTIFIER    no\par
TABLE_NAME        SQL_IDENTIFIER    no\par
\par
TRIGGER_TABLE_USAGE shows the Tables on which Triggers in this Catalog depend, where the Triggers are owned by the current user.\par
      ## TRIGGER_CATALOG, TRIGGER_SCHEMA, TRIGGER_NAME uniquely identify a Trigger that is owned by the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify a Table\par
that this Trigger depends on. The dependence is created by one of two things:\par
either (a) this Table is named in the search condition of this Trigger's\par
triggered action clause or (b) this Table is referred to in a triggered SQL\par
statement of this Trigger's definition.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.TRIGGER_TABLE_USAGE.\par
\par
## INFORMATION_SCHEMA.TYPE_INFO\par
\par
[NON-PORTABLE] The total number of Views in INFORMATION_SCHEMA is non-standard\par
because the SQL Standard allows vendors to add additional Views to describe\par
additional, implementation-defined features.\par
\par
[OCELOT Implementation] The OCELOT DBMS that comes with this book has one non-\par
standard INFORMATION_SCHEMA View, called INFORMATION_SCHEMA.TYPE_INFO. The\par
Standard defines TYPE_INFO as a temporary make-believe Table, in order to make\par
the CLI SQLGetTypeInfo Catalog function more comprehensible. We decided that,\par
since TYPE_INFO is effectively a metadata Table, it makes sense to describe\par
TYPE_INFO here, rather than in our chapter on SQL/CLI Catalog functions.\par
Though you can't simply select from TYPE_INFO with most DBMSs, you can select\par
the same information using the CLI.\par
\par
This View has the following Columns:\par
\par
Name                    Data Type         Nullable?\par
TYPE_NAME               VARCHAR(128)      no\par
DATA_TYPE               SMALLINT          no\par
COLUMN_SIZE             INTEGER           yes\par
LITERAL_PREFIX          VARCHAR(128       yes\par
LITERAL_SUFFIX          VARCHAR(128)      yes\par
CREATE_PARAMS           VARCHAR(128)      yes\par
NULLABLE                SMALLINT          no\par
CASE_SENSITIVE          SMALLINT          no\par
SEARCHABLE              SMALLINT          no\par
UNSIGNED_ATTRIBUTE      SMALLINT          yes\par
FIXED_PREC_SCALE        SMALLINT          no\par
AUTO_UNIQUE_VALUE       SMALLINT          no\par
LOCAL_TYPE_NAME         VARCHAR(128)      yes\par
MINIMUM_SCALE           INTEGER           yes\par
MAXIMUM_SCALE           INTEGER           yes\par
SQL_DATA_TYPE           SMALLINT          no\par
SQL_DATETIME_SUB        SMALLINT          yes\par
NUM_PREC_RADIX          INTEGER           yes\par
INTERVAL_PRECISION      SMALLINT          yes\par
\par
TYPE_INFO shows a description of every SQL predefined <data type> that the DBMS supports.\par
      ## TYPE_NAME shows the name of this <data type>, either: 'CHARACTER' (or\par
'CHAR'), 'NUMERIC', 'DECIMAL' (or 'DEC'), 'INTEGER' (or 'INT'), 'SMALLINT',\par
'FLOAT', 'REAL', 'DOUBLE PRECISION', 'CHARACTER VARYING' (or 'VARCHAR' or\par
'CHAR VARYING'), 'CLOB', 'CLOB LOCATOR', 'BIT', 'BIT VARYING', 'REF', 'DATE',\par
'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE',\par
'INTERVAL YEAR', 'INTERVAL MONTH', 'INTERVAL DAY', 'INTERVAL HOUR', 'INTERVAL\par
MINUTE', 'INTERVAL SECOND', 'INTERVAL YEAR TO MONTH', 'INTERVAL DAY TO HOUR',\par
'INTERVAL DAY TO MINUTE', 'INTERVAL DAY TO SECOND', 'INTERVAL HOUR TO MINUTE',\par
'INTERVAL HOUR TO SECOND' or 'INTERVAL MINUTE TO SECOND', 'BLOB', 'BLOB\par
LOCATOR', 'ROW TYPE', 'ARRAY', 'ARRAY LOCATOR', 'BOOLEAN', 'USER-DEFINED\par
TYPE', 'USER-DEFINED TYPE LOCATOR'. Most implementations give the name in\par
upper case and use the full name, e.g.: 'DECIMAL' or 'INTEGER' rather than\par
'DEC' or 'INT'. Sometimes an SQL <data type> can map to several data types.\par
For example, the 'NUMERIC' <data type> might also be called 'MONEY' or\par
'SERIAL'. In that case, it's implementation-defined whether TYPE_INFO will\par
contain only one row, or several rows, to describe this <data type.\par
      ## DATA_TYPE shows the Concise Code Value for this <data type>. These values are as follows:\par
            ## For 'CHARACTER' the code is: 1.\par
            ## For 'NUMERIC' the code is: 2.\par
            ## For 'DECIMAL' the code is: 3.\par
            ## For 'INTEGER' the code is: 4.\par
            ## For 'SMALLINT' the code is: 5.\par
            ## For 'FLOAT' the code is: 6.\par
            ## For 'REAL' the code is: 7.\par
            ## For 'DOUBLE PRECISION' the code is: 8.\par
            ## For 'CHARACTER VARYING' the code is: 12. \par
            ## For 'BIT' the code is: 14.\par
            ## For 'BIT VARYING' the code is: 15.\par
            ## For 'BOOLEAN' the code is: 16.\par
            ## For 'USER-DEFINED TYPE' the code is: 17.\par
            ## For 'USER-DEFINED TYPE LOCATOR' the code is: 18.\par
            ## For 'ROW TYPE' the code is: 19.\par
            ## For 'REF' the code is: 20. \par
            ## For 'BLOB' the code is: 30.\par
            ## For 'BLOB LOCATOR' the code is: 31.\par
            ## For 'CLOB' the code is: 40.\par
            ## For 'CLOB LOCATOR' the code is: 41.\par
            ## For 'ARRAY' the code is: 50.\par
            ## For 'ARRAY LOCATOR' the code is: 51.\par
            ## For 'DATE' the code is: 91. \par
            ## For 'TIME' the code is: 92.\par
            ## For 'TIMESTAMP' the code is: 93.\par
            ## For 'TIME WITH TIME ZONE' the code is: 94.\par
            ## For 'TIMESTAMP WITH TIME ZONE' the code is: 95.\par
            ## For 'INTERVAL YEAR' the code is: 101.\par
            ## For 'INTERVAL MONTH' the code is: 102.\par
            ## For 'INTERVAL DAY' the code is: 103.\par
            ## For 'INTERVAL HOUR' the code is: 104.\par
            ## For 'INTERVAL MINUTE' the code is: 105.\par
            ## For 'INTERVAL SECOND' the code is: 106.\par
            ## For 'INTERVAL YEAR TO MONTH' the code is: 107.\par
            ## For 'INTERVAL DAY TO HOUR' the code is: 108.\par
            ## For 'INTERVAL DAY TO MINUTE' the code is: 109.\par
            ## For 'INTERVAL DAY TO SECOND' the code is: 110.\par
            ## For 'INTERVAL HOUR TO MINUTE' the code is: 111.\par
            ## For 'INTERVAL HOUR TO SECOND' the code is: 112.\par
            ## For 'INTERVAL MINUTE TO SECOND' the code is: 113.\par
      ## COLUMN_SIZE shows the size of this <data type>, not including the size of the literal prefix or the literal suffix.\par
            ## For 'CHARACTER', 'CHARACTER VARYING' and 'CLOB' the size is the maximum possible length in characters supported by the DBMS.\par
            ## For 'NUMERIC', 'DECIMAL', 'INTEGER', 'SMALLINT', 'FLOAT', 'REAL' and 'DOUBLE PRECISION' the size is the maximum possible precision supported by the DBMS.\par
            ## For 'BIT', 'BIT VARYING' and 'BLOB' the size is the maximum possible length in bits supported by the DBMS.\par
            ## For 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE' and all the 'INTERVAL' types the size is the\par
maximum possible length in positions supported by the DBMS. 'DATE' is always\par
10, 'TIME' must be at least 15, 'TIMESTAMP' must be at least 26, 'TIME WITH\par
TIME ZONE' must be at least 21, 'TIMESTAMP WITH TIME ZONE' must be at least\par
32, 'INTERVAL YEAR' must be at least 4, 'INTERVAL MONTH', 'INTERVAL DAY',\par
'INTERVAL HOUR' and 'INTERVAL MINUTE' must be at least 2, 'INTERVAL SECOND'\par
must be at least 9, 'INTERVAL YEAR TO MONTH' must be at least 7, 'INTERVAL DAY\par
TO HOUR', 'INTERVAL DAY TO MINUTE' and 'INTERVAL HOUR TO MINUTE' must be at\par
least 5, 'INTERVAL DAY TO SECOND', 'INTERVAL HOUR TO SECOND' and 'INTERVAL MINUTE TO SECOND' must be at least 12.\par
            ## For all other types the size is the null value.\par
      ## LITERAL_PREFIX shows the character string that must precede any\par
literal of this <data type>. If no prefix string is required, LITERAL_PREFIX is NULL.\par
            ## For 'CHARACTER', 'CHARACTER VARYING' and 'CLOB' the prefix is: ' (i.e.: a single quote mark).\par
            ## For 'BIT' and 'BIT VARYING' the prefix is: either X' or B'.\par
            ## For 'BLOB' the prefix is X'.\par
            ## For 'DATE' the prefix is: DATE '. \par
            ## For 'TIME' and 'TIME WITH TIME ZONE' the prefix is: TIME '.\par
            ## For 'TIMESTAMP' and 'TIMESTAMP WITH TIME ZONE' the prefix is: TIMESTAMP '.\par
            ## For all the 'INTERVAL' types the prefix is: INTERVAL '.\par
            ## For all other types the prefix is the null value.\par
      ## LITERAL_SUFFIX shows the character string that must follow any\par
literal of this <data type>. If no suffix string is required, LITERAL_SUFFIX is NULL.\par
            ## For 'CHARACTER', 'CHARACTER VARYING', 'CLOB', 'BIT', 'BIT\par
VARYING', 'BLOB', 'DATE', 'TIME', 'TIME WITH TIME ZONE', 'TIMESTAMP' and\par
'TIMESTAMP WITH TIME ZONE' the suffix is: ' (i.e.: a single quote mark).\par
            ## For 'INTERVAL YEAR' the suffix is: ' YEAR.\par
            ## For 'INTERVAL MONTH' the suffix is: ' MONTH.\par
            ## For 'INTERVAL DAY' the suffix is: ' DAY.\par
            ## For 'INTERVAL HOUR' the suffix is: ' HOUR.\par
            ## For 'INTERVAL MINUTE' the suffix is: ' MINUTE.\par
            ## For 'INTERVAL SECOND' the suffix is: ' SECOND.\par
            ## For 'INTERVAL YEAR TO MONTH' the suffix is: ' YEAR TO MONTH.\par
            ## For 'INTERVAL DAY TO HOUR' the suffix is: ' DAY TO HOUR.\par
            ## For 'INTERVAL DAY TO MINUTE' the suffix is: ' DAY TO MINUTE.\par
            ## For 'INTERVAL DAY TO SECOND' the suffix is: ' DAY TO SECOND.\par
            ## For 'INTERVAL HOUR TO MINUTE' the suffix is: ' HOUR TO MINUTE.\par
            ## For 'INTERVAL HOUR TO SECOND' the suffix is: ' HOUR TO SECOND.\par
            ## For 'INTERVAL MINUTE TO SECOND' the suffix is: ' MINUTE TO SECOND.\par
            ## For all other types the suffix is the null value.\par
      ## CREATE_PARAMS is a list of the names (in order, separated by commas)\par
of size-related attributes which can be used in specifications for this <data\par
type>. If no options exist for this <data type>, CREATE_PARAMS is NULL. The\par
possible names are: 'LENGTH' (for length), 'PRECISION' (for numeric precision,\par
interval leading field precision and fractional seconds precision) or 'SCALE' (for numeric scale).\par
            ## For 'CHARACTER', 'CHARACTER VARYING', 'CLOB', 'BIT', 'BIT VARYING' and 'BLOB', CREATE_PARAMS is 'LENGTH'.\par
            ## For 'NUMERIC' and 'DECIMAL', CREATE_PARAMS is 'PRECISION,SCALE'.\par
            ## For 'FLOAT', 'TIME', 'TIME WITH TIME ZONE', TIMESTAMP' and 'TIMESTAMP WITH TIME ZONE', CREATE_PARAMS is 'PRECISION'.\par
            ## For 'INTERVAL YEAR', 'INTERVAL MONTH', 'INTERVAL DAY', 'INTERVAL HOUR', 'INTERVAL MINUTE', 'INTERVAL YEAR TO MONTH', 'INTERVAL DAY TO HOUR', 'INTERVAL DAY TO MINUTE' and 'INTERVAL HOUR TO MINUTE', CREATE_PARAMS is 'PRECISION'.\par
            ## For 'INTERVAL SECOND', 'INTERVAL DAY TO SECOND', 'INTERVAL HOUR\par
TO SECOND' and 'INTERVAL MINUTE TO SECOND', CREATE_PARAMS is 'PRECISION,PRECISION'.\par
            ## For all other types, CREATE_PARAMS is the null value.\par
      ## NULLABLE shows whether this <data type> may contain NULLs. It is\par
either: '0' ("false") if the <data type> may not contain NULLs, '1' ("true")\par
if the <data type> might contain NULLs, or '2' ("nullable unknown") if it\par
isn't known whether the <data type> might contain NULLs. In Standard SQL, NULLABLE is always '1' for all predefined <data type>s.\par
      ## CASE_SENSITIVE shows, for the 'CHARACTER', 'CHARACTER VARYING' and\par
'CLOB' <data type>s, whether the default collation of the <data type>'s\par
repertoire is case sensitive. If this is so, CASE_SENSITIVE is '1' ("true").\par
If this is not so, and for all other <data type>s, CASE_SENSITIVE is '0'.\par
      ## SEARCHABLE is comprised of two values, and shows the type of\par
predicates that values of this <data type> may be used with. If values based\par
on this <data type> may be used with LIKE, the first value is: '1'; if they\par
can't, the first value is: '0' . If values based on this <data type> may be\par
used with ordinary predicates, the second value is: '2'; if they can't, the\par
second value is: '0'. The two values are added together, thus SEARCHABLE is\par
either: '0', '1', '2' OR '3' for all <data type>s.\par
            ## For 'CHARACTER', 'CHARACTER VARYING', 'CLOB' and 'BLOB',\par
SEARCHABLE is: '3', i.e.: '1' for 'works with LIKE' plus '2' for 'works with ordinary predicates'.\par
            ## For all other predefined <data type>s, SEARCHABLE is: '2',\par
i.e.: '0' for 'doesn't work with LIKE' plus '2' for 'works with ordinary predicates'.\par
      ## UNSIGNED_ATTRIBUTE shows whether this <data type> is a signed type.\par
It is either: '0' for a signed type, '1' for an unsigned type or NULL for all non-numeric types.\par
            ## For 'NUMERIC', 'DECIMAL', 'INTEGER', 'SMALLINT', 'FLOAT',\par
'REAL', 'DOUBLE PRECISION' and all the 'INTERVAL' types, UNSIGNED_ATTRIBUTE is: '0'.\par
            ## For 'ARRAY LOCATOR', 'BLOB LOCATOR', 'CLOB LOCATOR' and 'USER-DEFINED TYPE LOCATOR', UNSIGNED_ATTRIBUTE is: '1'.\par
            ## For all other types, UNSIGNED_ATTRIBUTE is the null value.\par
      ## FIXED_PREC_SCALE shows whether this <data type> is an exact numeric\par
type with a fixed precision and scale. It is: '1' ("true") for 'INTEGER' and\par
'SMALLINT' and '0' ("false") for all other <data type>s. (In Standard SQL,\par
FIXED_PREC_SCALE is '0' for 'DECIMAL' and 'NUMERIC' because these <data type>s\par
have user-specifiable precision and scale.)\par
      ## AUTO_UNIQUE_VALUE shows, for this <data type>, whether any new row is\par
guaranteed to be unique when it is inserted; it is either: '0' ("false") or\par
'1' ("true"). There is no Standard SQL <data type> like this -- for all\par
predefined SQL <data type>s, AUTO_UNIQUE_VALUE is: '0' -- but many\par
implementations have it, naming it something like 'SERIAL'. Watch out: just\par
because it's unique when you INSERT, doesn't mean it remains unique after you UPDATE.\par
      ## [NON-PORTABLE] LOCAL_TYPE_NAME shows an implementation-defined\par
"localized representation" of this <data type>'s TYPE_NAME value. This could\par
mean that the Albanian term for 'CHARACTER VARYING' would appear here; your\par
DBMS should output what would be appropriate in a dialog box. For Standard SQL\par
names, LOCAL_TYPE_NAME and TYPE_NAME would usually be the same.\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
shows the same name in both the TYPE_NAME and the LOCAL_TYPE_NAME Columns for all <data type>s.\par
      ## MINIMUM_SCALE shows the minimum possible value of the scale (for\par
<data type>s that have one) or the minimum possible value of a fractional\par
seconds precision (for <data types> that have one). For <data type>s that have neither, MINIMUM_SCALE is NULL.\par
            ## For 'NUMERIC', 'DECIMAL', 'INTEGER', 'SMALLINT', 'TIME',\par
'TIMESTAMP', 'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE', 'INTERVAL\par
SECOND', 'INTERVAL DAY TO SECOND', 'INTERVAL HOUR TO SECOND' and 'INTERVAL\par
MINUTE TO SECOND', MINIMUM_SCALE is: '0'.\par
            ## For all other types, MINIMUM_SCALE is the null value.\par
      ## MAXIMUM_SCALE shows your DBMS's maximum possible value of the scale\par
(for <data type>s that have one) or the maximum possible value of a fractional\par
seconds precision (for <data types> that have one). For <data type>s that have\par
neither, MAXIMUM_SCALE is NULL.\par
            ## For 'INTEGER' and 'SMALLINT', MAXIMUM_SCALE is '0'.\par
            ## [NON-PORTABLE] For 'NUMERIC', 'DECIMAL', 'TIME', 'TIMESTAMP',\par
'TIME WITH TIME ZONE', 'TIMESTAMP WITH TIME ZONE', 'INTERVAL SECOND',\par
'INTERVAL DAY TO SECOND', 'INTERVAL HOUR TO SECOND' and 'INTERVAL MINUTE TO\par
SECOND', MAXIMUM_SCALE is implementation-defined.\par
                  [OCELOT Implementation] The OCELOT DBMS that comes with this book shows these maximum scale values: \par
                        ## For 'NUMERIC' and 'DECIMAL', MAXIMUM_SCALE is '38'.\par
                        ## For 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE',\par
'TIMESTAMP WITH TIME ZONE', 'INTERVAL SECOND', 'INTERVAL DAY TO SECOND',\par
'INTERVAL HOUR TO SECOND' and 'INTERVAL MINUTE TO SECOND', MAXIMUM_SCALE is '6'.\par
            ## For all other types, MAXIMUM_SCALE is the null value.\par
      ## SQL_DATA_TYPE shows the SQL Data Type Code value. This will be the\par
same as the DATA_TYPE value for all non-temporal <data type>s. There is a\par
correspondence with the SQL_DESC_TYPE field of a descriptor.\par
            ## For 'CHARACTER' the code is: '1'. \par
            ## For 'NUMERIC' the code is: '2'. \par
            ## For 'DECIMAL' the code is: '3'. \par
            ## For 'INTEGER' the code is: '4'. \par
            ## For 'SMALLINT' the code is: '5'. \par
            ## For 'FLOAT' the code is: '6'. \par
            ## For 'REAL' the code is: '7'. \par
            ## For 'DOUBLE PRECISION' the code is: '8'. \par
            ## For 'CHARACTER VARYING' the code is: '12'. \par
            ## For 'BIT' the code is: '14'. \par
            ## For 'BIT VARYING' the code is: '15'. \par
            ## For 'REF' the code is: '20'. \par
            ## For 'DATE', 'TIME', 'TIMESTAMP', 'TIME WITH TIME ZONE' and 'TIMESTAMP WITH TIME ZONE' the code is: '9'. \par
            ## For all the 'INTERVAL' types the code is: '10'.\par
      ## SQL_DATETIME_SUB shows the SQL_DATA-TYPE subtype for the temporal <data type>s. For all the non-temporal <data type>s, this field is NULL.\par
            ## For 'DATE' the code is: '1'. \par
            ## For 'TIME' the code is: '2'. \par
            ## For 'TIMESTAMP' the code is: '3'. \par
            ## For 'TIME WITH TIME ZONE' the code is: '4'. \par
            ## For 'TIMESTAMP WITH TIME ZONE' the code is: '5'. \par
            ## For 'INTERVAL YEAR' the code is: '1'. \par
            ## For 'INTERVAL MONTH' the code is: '2'. \par
            ## For 'INTERVAL DAY' the code is: '3'. \par
            ## For 'INTERVAL HOUR' the code is: '4'. \par
            ## For 'INTERVAL MINUTE' the code is: '5'. \par
            ## For 'INTERVAL SECOND' the code is: '6'. \par
            ## For 'INTERVAL YEAR TO MONTH' the code is: '7'. \par
            ## For 'INTERVAL DAY TO HOUR' the code is: '8'. \par
            ## For 'INTERVAL DAY TO MINUTE' the code is: '9'. \par
            ## For 'INTERVAL DAY TO SECOND' the code is: '10'. \par
            ## For 'INTERVAL HOUR TO MINUTE' the code is: '11'.\par
            ## For 'INTERVAL HOUR TO SECOND' the code is: '12'.\par
            ## For 'INTERVAL MINUTE TO SECOND' the code is: '13'.\par
      ## NUM_PREC_RADIX shows your DBMS's radix of the precision for this\par
<data type> (if there is one). If there is no precision, this field is NULL.\par
For exact numeric <data type>s, the precision's radix will almost always be 10\par
(indeed for ODBC it must be 10), but some implementations declare that\par
SMALLINT and INTEGER have binary radices, respectively 15 and 31 (the number\par
does not include the sign bit). For approximate numeric <data type>s, the\par
precision's radix will usually be 2.\par
            ## [NON-PORTABLE] For 'NUMERIC', 'DECIMAL', 'INTEGER', 'SMALLINT',\par
'FLOAT', 'REAL' and 'DOUBLE PRECISION', NUM_PREC_RADIX is implementation-defined.\par
                  [OCELOT Implementation] The OCELOT DBMS that comes with this book shows these radix values:\par
                        ## For 'NUMERIC' and 'DECIMAL', NUM_PREC_RADIX is:\par
'10'.\par
                        ## For 'INTEGER', 'SMALLINT', 'FLOAT', 'REAL' and 'DOUBLE PRECISION', NUM_PREC_RADIX is: '2'.\par
            ## For all other types, NUM_PREC_RADIX is the null value.\par
      ## INTERVAL_PRECISION shows your DBMS's interval leading field precision\par
for an INTERVAL <data type>. If this is not an INTERVAL, INTERVAL_PRECISION is NULL.\par
            ## [NON-PORTABLE] For all the 'INTERVAL' types, INTERVAL_PRECISION is implementation-defined.\par
                  [OCELOT Implementation] The OCELOT DBMS that comes with this book shows these interval precision values:\par
                        ## For 'INTERVAL YEAR' and 'INTERVAL YEAR TO MONTH, INTERVAL PRECISION is: '4'.\par
                        ## For all other 'INTERVAL' types, INTERVAL_PRECISION is: '2'.\par
\par
## INFORMATION_SCHEMA.USAGE_PRIVILEGES\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
GRANTOR                 SQL_IDENTIFIER          no\par
GRANTEE                 SQL_IDENTIFIER          no\par
OBJECT_CATALOG          SQL_IDENTIFIER          no\par
OBJECT_SCHEMA           SQL_IDENTIFIER          no\par
OBJECT_NAME             SQL_IDENTIFIER          no\par
OBJECT_TYPE             CHARACTER_DATA          no\par
PRIVILEGE_TYPE          CHARACTER_DATA          no\par
IS_GRANTABLE            CHARACTER_DATA          no\par
\par
USAGE_PRIVILEGES shows the USAGE Privileges on Objects (i.e.: Domains,\par
Character sets, Collations  or Translations) in this Catalog, where the\par
Privileges are either available to, or granted by, the current user.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role) who granted the Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the user (or perhaps the Role)\par
who may use the Privilege. By definition, if GRANTOR isn't CURRENT_USER, then\par
GRANTEE is either CURRENT_USER or 'PUBLIC'.\par
      ## OBJECT_CATALOG, OBJECT_SCHEMA, OBJECT_NAME, OBJECT_TYPE uniquely\par
identify an Object in this Catalog. OBJECT_TYPE is either: 'DOMAIN',\par
'CHARACTER SET', 'COLLATION' or 'TRANSLATION'.\par
      ## PRIVILEGE_TYPE shows the Privilege granted: 'USAGE'.\par
      ## IS_GRANTABLE is either 'YES' (Privilege was granted WITH GRANT OPTION) or 'NO' (Privilege was not granted WITH GRANT OPTION).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.USAGE_PRIVILEGES.\par
\par
## INFORMATION_SCHEMA.USER_DEFINED_TYPE_PRIVILEGES\par
\par
This View has the following Columns:\par
\par
Name                          Domain            Nullable?\par
GRANTOR                       SQL_IDENTIFIER    no\par
GRANTEE                       SQL_IDENTIFIER    no\par
USER_DEFINED_TYPE_CATALOG     SQL_IDENTIFIER    no\par
USER_DEFINED_TYPE_SCHEMA      SQL_IDENTIFIER    no\par
USER_DEFINED_TYPE_NAME        SQL_IDENTIFIER    no\par
PRIVILEGE_TYPE                CHARACTER_DATA    no\par
IS_GRANTABLE                  CHARACTER_DATA    no\par
\par
USER_DEFINED_TYPE_PRIVILEGES shows the TYPE USAGE Privileges on UDTs in this\par
Catalog, where the Privileges are either available to, or granted by, the current user.\par
      ## GRANTOR shows the <AuthorizationID> of the user (or perhaps the Role) who granted the Privilege.\par
      ## GRANTEE shows the <AuthorizationID> of the user (or perhaps the Role)\par
who may use the Privilege. By definition, if GRANTOR isn't CURRENT_USER, then\par
GRANTEE is either CURRENT_USER or 'PUBLIC'.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME uniquely identify a UDT in this Catalog.\par
      ## PRIVILEGE_TYPE shows the Privilege granted: 'TYPE USAGE'.\par
      ## IS_GRANTABLE is either 'YES' (Privilege was granted WITH GRANT OPTION) or 'NO' (Privilege was not granted WITH GRANT OPTION).\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.USER_DEFINED_TYPE_PRIVILEGES.\par
\par
## INFORMATION_SCHEMA.USER_DEFINED_TYPES\par
\par
This View has the following Columns:\par
\par
Name                                Domain            Nullable?\par
USER_DEFINED_TYPE_CATALOG           SQL_IDENTIFIER    no\par
USER_DEFINED_TYPE_SCHEMA            SQL_IDENTIFIER    no\par
USER_DEFINED_TYPE_NAME              SQL_IDENTIFIER    no\par
USER_DEFINED_TYPE_CATEGORY          CHARACTER_DATA    no\par
USER_DEFINED_TYPE_ORDER             CHARACTER_DATA    no\par
USER_DEFINED_TYPE_EQUALS_CATALOG    CHARACTER_DATA    yes\par
USER_DEFINED_TYPE_EQUALS_SCHEMA     CHARACTER_DATA    yes\par
USER_DEFINED_TYPE_EQUALS_NAME       CHARACTER_DATA    yes\par
USER_DEFINED_TYPE_RELATIVE_CATALOG  CHARACTER_DATA    yes\par
USER_DEFINED_TYPE_RELATIVE_SCHEMA   CHARACTER_DATA    yes\par
USER_DEFINED_TYPE_RELATIVE_NAME     CHARACTER_DATA    yes\par
USER_DEFINED_TYPE_HASH_CATALOG      CHARACTER_DATA    yes\par
USER_DEFINED_TYPE_HASH_SCHEMA       CHARACTER_DATA    yes\par
USER_DEFINED_TYPE_HASH_NAME         CHARACTER_DATA    yes\par
\par
USER_DEFINED_TYPES shows the UDTs in this Catalog that the current user has Privileges on.\par
      ## USER_DEFINED_TYPE_CATALOG, USER_DEFINED_TYPE_SCHEMA, USER_DEFINED_TYPE_NAME uniquely identify a UDT in this Catalog that the current user has Privileges on.\par
      ## USER_DEFINED_TYPE_CATEGORY is: 'USER-DEFINED TYPE'.\par
      ## USER_DEFINED_TYPE_ORDER is either: 'ORDER FULL' (two values of this\par
UDT may be compared for equality or relative order) or 'EQUALS ONLY' (two\par
values of this UDT may be compared only for equality).\par
      ## USER_DEFINED_TYPE_EQUALS_CATALOG, USER_DEFINED_TYPE_EQUALS_SCHEMA,\par
USER_DEFINED_TYPE_EQUALS_NAME uniquely identify the specific name of the EQUALS function for this UDT.\par
      ## USER_DEFINED_TYPE_RELATIVE_CATALOG, USER_DEFINED_TYPE_RELATIVE_SCHEMA, USER_DEFINED_TYPE_RELATIVE_NAME uniquely identify the specific name of the RELATIVE function for this UDT.\par
      ## USER_DEFINED_TYPE_HASH_CATALOG, USER_DEFINED_TYPE_HASH_SCHEMA,\par
USER_DEFINED_TYPE_HASH_NAME uniquely identify the specific name of the HASH function for this UDT.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.USER_DEFINED_TYPES.\par
\par
## INFORMATION_SCHEMA.VIEWS\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
VIEW_DEFINITION         CHARACTER_DATA          yes\par
CHECK_OPTION            CHARACTER_DATA          no\par
IS_UPDATABLE            CHARACTER_DATA          no\par
\par
VIEWS shows the Views in this Catalog that the current user has Privileges on.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify a View that the current user may use.\par
      ## VIEW_DEFINITION shows the query specification that defines the View.\par
If the expression was too big to be stored, or if the current user doesn't own\par
TABLE_SCHEMA, then VIEW_DEFINITION is NULL.\par
      ## CHECK_OPTION is either: 'CASCADED' (the View definition has a WITH\par
CASCADED CHECK OPTION clause), 'LOCAL' (the View definition has a WITH LOCAL\par
CHECK OPTION clause) or 'NONE' (the View definition has no CHECK OPTION clause).\par
      ## IS_UPDATABLE is either: 'YES' (the View definition simply contains an\par
updatable query specification) or 'NO' (the View definition simply contains a\par
query specification that isn't updatable). If IS_UPDATABLE is 'NO', then CHECK_OPTION must be 'NONE'.\par
\par
## INFORMATION_SCHEMA.VIEW_COLUMN_USAGE\par
\par
This View has the following Columns:\par
\par
Name                    Domain                  Nullable?\par
VIEW_CATALOG            SQL_IDENTIFIER          no\par
VIEW_SCHEMA             SQL_IDENTIFIER          no\par
VIEW_NAME               SQL_IDENTIFIER          no\par
TABLE_CATALOG           SQL_IDENTIFIER          no\par
TABLE_SCHEMA            SQL_IDENTIFIER          no\par
TABLE_NAME              SQL_IDENTIFIER          no\par
COLUMN_NAME             SQL_IDENTIFIER          no\par
\par
VIEW_COLUMN_USAGE shows the Columns on which Views in this Catalog depend,\par
where the Views are owned by the current user.\par
      ## VIEW_CATALOG, VIEW_SCHEMA, VIEW_NAME uniquely identify a View that is owned by the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME uniquely\par
identify a Column which is (explicitly or implicitly) referred to in this View's query specification.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.VIEW_COLUMN_USAGE.\par
\par
## INFORMATION_SCHEMA.VIEW_TABLE_USAGE\par
\par
This View has the following Columns:\par
\par
Name              Domain            Nullable?\par
VIEW_CATALOG      SQL_IDENTIFIER    no\par
VIEW_SCHEMA       SQL_IDENTIFIER    no\par
VIEW_NAME         SQL_IDENTIFIER    no\par
TABLE_CATALOG     SQL_IDENTIFIER    no\par
TABLE_SCHEMA      SQL_IDENTIFIER    no\par
TABLE_NAME        SQL_IDENTIFIER    no\par
\par
VIEW_TABLE_USAGE shows the Tables on which Views in this Catalog depend, where\par
the Views are owned by the current user.\par
      ## VIEW_CATALOG, VIEW_SCHEMA, VIEW_NAME uniquely identify a View that is owned by the current user.\par
      ## TABLE_CATALOG, TABLE_SCHEMA, TABLE_NAME uniquely identify a Table which is referred to in this View's query specification.\par
\par
If you want to restrict your code to Core SQL, do not reference INFORMATION_SCHEMA.VIEW_TABLE_USAGE.\par
\page\par
Chapter 17 -- SQL Schema\par
\par
The SQL Standard describes the concepts on which SQL is based in terms of\par
Objects, such as Tables. Most of these Objects are Schema Objects; that is,\par
they depend on some Schema. In this chapter, we'll describe SQL Schemas in\par
detail, and show you the syntax to use to create, alter and destroy them.\par
\par
Schema\par
\par
A Catalog may contain one or more Schemas. An SQL Schema is a named group of\par
SQL-data that is owned by a particular <AuthorizationID>. Schemas are\par
dependent on some Catalog -- the <Schema name> must be unique within the\par
Catalog the Schema belongs to -- and are created, altered and dropped using\par
the SQL-Schema statements. The Objects that may belong to a Schema are known\par
as Schema Objects; that is, they depend on some Schema. Every Schema Object\par
has a name that must be unique (among Objects of its name class) within the\par
Schema it belongs to. The Schema Object name classes are:\par
      ## Base tables and Views.\par
      ## Domains and UDTs.\par
      ## Constraints and Assertions.\par
      ## Character sets.\par
      ## Collations.\par
      ## Translations.\par
      ## Triggers.\par
      ## SQL-server Modules.\par
      ## SQL-invoked routines.\par
A Schema may consist of zero or more of these Schema Objects. The Schema's\par
name qualifies the names of the Objects that belong to it, and can either be\par
explicitly stated, or a default name will be supplied by your DBMS.\par
\par
A Schema is defined by a descriptor that contains four pieces of information:\par
      ## The <Schema name>, qualified by the <Catalog name> of the Catalog it belongs to.\par
      ## The <AuthorizationID> that owns the Schema and its Objects.\par
      ## The name of the Schema's default Character set.\par
      ## The specification that defines the path for the Schema's SQL-invoked routines.\par
      ## A descriptor for every SQL Object that belongs to the Schema.\par
\par
To create a Schema, use the CREATE SCHEMA statement. It specifies the\par
enclosing Catalog, names the Schema, defines the Schema's default Character\par
set, default path and zero or more Schema Objects, and identifies the Schema's\par
owner. To change an existing Schema, use the appropriate CREATE / DROP / ALTER\par
/ GRANT / REVOKE statements to adjust the Schema's Objects. To destroy a Schema, use the DROP SCHEMA statement.\par
\par
There is a one-to-many association between Schemas and users: one\par
<AuthorizationID> can own many Schemas. For compatibility with the ODBC\par
qualifier structure (database.owner.object) though, we recommend that a\par
<Schema name> be the same as the owning <AuthorizationID> and that each\par
<AuthorizationID> be allowed to own only one Schema in a Cluster.\par
\par
Schema names:\par
A <Schema name> identifies a Schema. The required syntax for a <Schema name> is:\par
\par
<Schema name> ::=\par
[ <Catalog name>. ] unqualified name\par
\par
A <Schema name> is a <regular identifier> or a <delimited\par
identifier> that is unique (for all Schemas) within the Catalog\par
it belongs to. The <Catalog name> which qualifies a <Schema name> names the\par
Catalog that the Schema belongs to, and can either be explicitly stated or a\par
default will be supplied by your DBMS, as follows:\par
      ## If the unqualified <Schema name> is found in a Module, the default\par
qualifier is the name of the Catalog identified in the SCHEMA clause or\par
AUTHORIZATION clause of the MODULE statement that defines that Module.\par
      ## [NON-PORTABLE] If the MODULE statement doesn't provide an explicit\par
<Catalog name>, or if the unqualified <Schema name> is not in a Module, the\par
default <Catalog name> qualifier is non-standard because the SQL Standard\par
requires implementors to define the default qualifier in such cases. Your DBMS\par
will usually define its initial default <Catalog name> as the qualifier, but this is not required.\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
uses its initial default <Catalog name> (OCELOT) as the qualifier in such cases.\par
\par
Here are some examples of <Schema name>s:\par
\par
   SCHEMA_1\par
   --- a <Schema name>\par
\par
   CATALOG_1.SCHEMA_1\par
   -- a qualified <Schema name>\par
\par
Note that the <regular identifier> -- DEFINITION_SCHEMA -- may not be used as a <Schema name>.\par
\par
CREATE SCHEMA statement\par
\par
The CREATE SCHEMA statement names a new Schema, defines the Schema's default\par
Character set, default path and zero or more Schema Objects, and identifies\par
the Schema's owner. The required syntax for the CREATE SCHEMA statement is:\par
\par
CREATE SCHEMA <Schema name clause>\par
   [ DEFAULT CHARACTER SET <Character set name> ]\par
   [ PATH <Schema name> \{,<Schema name>\}... ]\par
   [ <Schema element list> ]\par
\par
   <Schema name clause> ::=\par
   <Schema name> |\par
   AUTHORIZATION <AuthorizationID> |\par
   <Schema name> AUTHORIZATION <AuthorizationID>\par
\par
     <Schema element list> ::=\par
      CREATE DOMAIN statement(s) |\par
      CREATE TABLE statement(s) |\par
      CREATE VIEW statement(s) |\par
      CREATE ASSERTION statement(s) |\par
      CREATE CHARACTER SET statement(s) |\par
      CREATE COLLATION statement(s) |\par
      CREATE TRANSLATION statement(s) |\par
      CREATE TRIGGER statement(s)  |\par
      CREATE TYPE statement)s) |\par
      CREATE PROCEDURE statement(s) |\par
      CREATE FUNCTION statement(s) |\par
      CREATE ROLE statement(s) |\par
      GRANT statement(s)\par
\par
CREATE SCHEMA defines a new Schema. A Schema is owned by the Catalog it belongs to.\par
      ## The <Schema name clause> names the Schema and identifies the\par
<AuthorizationID> that owns it. A <Schema name> that includes an explicit\par
<Catalog name> qualifier belongs to the Catalog named. A <Schema name> that\par
does not include an explicit <Catalog name> qualifier belongs to the\par
SQL-session default Catalog. The <Schema name> must be unique within the Catalog that owns it.\par
\par
The <Schema name clause> may contain either a <Schema name>, an AUTHORIZATION\par
clause, or both. For example, this SQL statement creates a Schema named BOB, owned by <AuthorizationID> BOB:\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob;\par
\par
If <Schema name clause> doesn't include an explicit <Schema name>, the <Schema\par
name> defaults to the value of the AUTHORIZATION clause's <AuthorizationID>.\par
For example, this SQL statement also creates a Schema named BOB, owned by <AuthorizationID> BOB:\par
\par
   CREATE SCHEMA AUTHORIZATION bob;\par
\par
If <Schema name clause> doesn't include an explicit AUTHORIZATION clause, the\par
<AuthorizationID> that owns the Schema defaults to the <Module\par
AuthorizationID> (or, if there is no <Module AuthorizationID>, it defaults to\par
the current SQL-session <AuthorizationID>). Note: The current <AuthorizationID> for the creation of a Schema is normally the\par
<AuthorizationID> named in the AUTHORIZATION clause. If you omit the AUTHORIZATION clause, then the current <AuthorizationID> for the creation of the Schema is the SQL-session <AuthorizationID>.\par
\par
** TRAP: The <AuthorizationID> associated with CREATE SCHEMA does not become\par
the current <AuthorizationID> for subsequent SQL statements, nor does the\par
<Schema name> become the default Schema. Consider these three SQL statements:\par
\par
   CONNECT TO 'cluster_1' AS 'connection_1' USER 'bob';\par
   -- establishes the SQL-session <AuthorizationID> to be BOB\par
\par
   CREATE SCHEMA sam AUTHORIZATION sam\par
      CREATE TABLE sam_1 (column1 INT);\par
   -- creates a Schema named SAM, that contains one Table, both owned by <AuthorizationID> SAM\par
\par
   INSERT INTO sam_1 VALUES (10);\par
   -- fails because the Table can't be found\par
\par
In this example, although the CREATE SCHEMA statement did create the Table\par
we're trying to INSERT into, it did not change the default <AuthorizationID>\par
from BOB to SAM, nor did it change the default Schema from BOB to SAM. Thus,\par
the INSERT fails because the DBMS doesn't recognize a Table named SAM_1\par
associated with <AuthorizationID> BOB in Schema BOB.\par
\par
The optional DEFAULT CHARACTER SET clause names the Schema's default Character\par
set: the Character set assumed for all of this Schema's Column and Domain\par
definitions when they don't include an explicit Character set specification.\par
For example, all three of these SQL statements create a Schema that contains a\par
Domain whose values must belong to the LATIN1 Character set:\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob\par
         DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN1\par
      CREATE DOMAIN char_domain AS CHAR(12)\par
         CHARACTER SET INFORMATION_SCHEMA.LATIN1;\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob\par
         DEFAULT CHARACTER SET INFORMATION_SCHEMA.ASCII_FULL\par
      CREATE DOMAIN char_domain AS CHAR(12)\par
         CHARACTER SET INFORMATION_SCHEMA.LATIN1;\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob\par
         DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN1\par
      CREATE DOMAIN char_domain AS CHAR(12);\par
\par
(In the second example, the explicit CHARACTER SET clause in CREATE DOMAIN overrides the Schema's default Character set specification.)\par
\par
[NON-PORTABLE] If CREATE SCHEMA doesn't include an explicit DEFAULT CHARACTER\par
SET clause, the Schema's default Character set is non-standard because the SQL\par
Standard requires implementors to define it.\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book always uses INFORMATION_SCHEMA.ASCII_FULL as the default Character set.\par
\par
The optional PATH clause names the Schema's default path: the path used to\par
qualify unqualified <Routine name>s that identify <routine invocation>s that\par
are part of this CREATE SCHEMA statement. You must include the name of the\par
Schema being created in the PATH clause and, if you include multiple names,\par
all of the Schemas named must belong to the same Catalog.\par
\par
[NON-PORTABLE] If CREATE SCHEMA doesn't include an explicit PATH clause, the\par
Schema's path specification must include the new Schema's name, but is\par
otherwise non-standard because the SQL Standard requires implementors to\par
define a path specification for the Schema.\par
\par
[NON-PORTABLE] Whether or not you may create a Schema is non-standard because\par
the SQL Standard requires implementors to define what Privilege (if any)\par
allows an <AuthorizationID> to execute CREATE SCHEMA.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows any <AuthorizationID> to execute CREATE SCHEMA.\par
\par
The only separator between the SQL statements that make up the <Schema element\par
list> is white space. For example, this is a single SQL statement that creates a Schema:\par
\par
   CREATE SCHEMA sam AUTHORIZATION sam\par
         DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN1\par
      CREATE DOMAIN dept_domain AS CHAR(3)\par
      CREATE TABLE department (dept dept_domain, name1 CHAR(10))\par
      CREATE TABLE employee (empname CHAR(20), dept dept_domain)\par
      GRANT SELECT ON department TO bob;\par
\par
If you want to restrict your code to Core SQL, don't use a DEFAULT CHARACTER\par
SET clause or a PATH clause in your CREATE SCHEMA statements and don't include\par
any of the following in your <Schema element list>: CREATE ASSERTION\par
statements, CREATE CHARACTER SET statements, CREATE COLLATION statements,\par
CREATE DOMAIN statements, CREATE TRANSLATION statements, CREATE TYPE\par
statements, CREATE ROLE statements or GRANT statements to Roles.\par
\par
DROP SCHEMA statement\par
\par
The DROP SCHEMA statement destroys an entire Schema. The required syntax for the DROP SCHEMA statement is:\par
\par
DROP SCHEMA <Schema name> \{RESTRICT | CASCADE\}\par
\par
The <Schema name> must identify an existing Schema whose owner is either the\par
current <AuthorizationID> or a Role that the current <AuthorizationID> may\par
use. That is, only the <AuthorizationID> that owns the Schema may drop it.\par
\par
The effect of DROP SCHEMA <Schema name> RESTRICT, e.g.:\par
\par
   DROP SCHEMA catalog_1.schema_1 RESTRICT;\par
\par
is that the Schema named CATALOG_1.SCHEMA_1 will be destroyed, providing that\par
(a) it doesn't contain any Objects, (b) it isn't referred to in any SQL\par
routine and (c) it isn't referred to in the path specification of any other\par
Schema. That is, RESTRICT ensures that only an empty Schema, on which nothing else depends, can be destroyed.\par
\par
The effect of DROP SCHEMA <Schema name> CASCADE, e.g.:\par
\par
   DROP SCHEMA catalog_1.schema_1 CASCADE;\par
\par
is that the Schema named CATALOG_1.SCHEMA_1 will be destroyed -- as will all\par
of the Schema's Objects (with a CASCADE drop behaviour for Tables, Views,\par
Domains, Collations, Roles, UDTs and SQL-invoked routines) and any SQL\par
routines (with a CASCADE drop behaviour) and path specifications that depend on this Schema.\par
\par
If you want to restrict your code to Core SQL, don't use the DROP SCHEMA statement.\par
\page\par
Chapter 18 -- SQL Table and View\par
\par
In this chapter, we'll describe SQL Tables in detail, and show you the syntax\par
to use to create, alter and destroy them.\par
\par
A Schema may contain zero or more Tables. An SQL Table is a collection of\par
rows: one header-row of <Column name>s and zero or more rows of data values.\par
(We'll use the word "row" to mean a row of data values from now on; note that\par
a row of a Table is an instance of an SQL <row type>.) Tables are dependent on\par
some Schema -- the <Table name> must be unique within the Schema the Table\par
belongs to -- and are created, altered and dropped using standard SQL\par
statements. The Objects that may belong to a Table are Columns and Table\par
Constraints; they depend on some Table. The number of Columns in a Table is\par
the degree of the Table. The number of rows in a Table is the cardinality of\par
the Table. An empty Table has a cardinality of zero.\par
\par
Tables contain data (as atomic values at the intersection of each row and \par
<Column name>) about a specific entity. Each row of the Table describes a \par
single occurrence of that entity. Rows are the smallest unit of Table \par
insertion and deletion. Table rows are unordered, but an order can be imposed \par
on them during retrieval. Table Columns are ordered, from left to right -- \par
their ordinal position matches the ordinal position of the <Column definition> in the Table's definition.\par
\par
SQL supports two types of Tables: the physically existent, named Base table and the derived, named View. We use the word "Table" to mean both Base tables and Views throughout this book. (SQL also supports the concept of unnamed derived tables -- these are tables which are derived from a <query expression>, so we won't discuss them here.)\par
\par
Base Table\par
\par
A Base table is either a Schema Object (that is, its definition is part of a\par
Schema definition) or a Module Object (that is, its definition is part of a\par
Module definition). Schema Base tables are known as created Base tables and\par
may be either persistent or temporary. Module Base tables are known as\par
declared temporary Tables and may only be temporary.\par
\par
There are two kinds of Schema Base tables: the persistent Base table and the\par
temporary Base table.\par
      ## A persistent Base table is autonomous: it exists in its own right --\par
that is, physically stored records that directly represent the Table actually\par
exist on some data storage device. A persistent Base table contains rows of\par
persistent SQL-data and can be accessed from multiple SQL-sessions. You create\par
persistent Base tables with the CREATE TABLE statement.\par
      ## A temporary Base table is an SQL-session-dependent Table: it can't be\par
accessed from any other SQL-session. There are two types of temporary Base\par
tables: the global temporary Base table, which can be accessed from any\par
SQL-client Module in a single SQL-session, and the created local temporary\par
Base table, which can be accessed only from the SQL-client Module that refers\par
to it. Temporary Base tables are always empty when an SQL-session begins:\par
their rows are all deleted either at the end of a transaction or at the end of\par
the SQL-session (depending on the Table's definition). You create global\par
temporary Base tables with CREATE GLOBAL TEMPORARY TABLE and created local\par
temporary Base tables with CREATE LOCAL TEMPORARY TABLE.\par
\par
There is one kind of Module Base table: the declared local temporary Base table.\par
      ## The declared local temporary Base table is a named Table defined\par
(with the DECLARE TABLE statement) in an SQL-client Module. It is effectively\par
materialized the first time it is referenced in an SQL-session and it persists\par
until that SQL-session ends. A declared local temporary Base table can only be\par
accessed by <externally-invoked procedure>s within the SQL-client Module that\par
contains the Table's declaration. Temporary Base tables are always empty when\par
an SQL-session begins and are always emptied when the SQL-session ends.\par
\par
Subtables and Supertables:\par
In SQL3, a Table can be defined as a direct subtable of one or more\par
supertables, using the optional CREATE TABLE ... UNDER clause. A subtable\par
inherits every Column from its supertables, but may also define Columns of its\par
own. A maximal supertable is a supertable that is not also a subtable: it,\par
together with all its subtables, makes up a subtable family -- thus, a\par
subtable family has exactly one maximal supertable. Any row of a subtable must\par
correspond to exactly one row of each direct supertable, while any row of a\par
supertable corresponds to at most one row of a direct subtable.\par
\par
Any Table which has a subtable or a supertable also has a row identifier (this\par
is implicitly defined). The row identifier type for a Table with supertables\par
is a subtype of the row identifier type defined for each supertable. A value\par
of a row identifier type can be substituted for a value of another row\par
identifier type if (a) both types are the same or (b) the first is a subtype\par
of the second. The rules for the INSERT, DELETE and UPDATE statements ensure\par
that the rows in the Tables of a subtable family are consistent with one\par
another. Specifically:\par
     ## If you INSERT a row into a subtable, your DBMS will INSERT a\par
corresponding row (with the same row identifier, and the same values as the\par
values you provided for the subtable's inherited Columns) into each of that\par
subtable's supertables, cascading upward in the Table hierarchy. Thus, if you\par
INSERT a row into a maximal supertable, it is the only row inserted.\par
     ## If you UPDATE a row of a supertable, all inherited Columns in any\par
corresponding rows of that supertable's subtables are also updated. If you\par
UPDATE a row of a subtable, your DBMS will UPDATE every corresponding row so\par
that their Columns also contain the new values.\par
     ## If you DELETE a row from a Table, your DBMS will also DELETE every\par
corresponding row in the subtable family.\par
\par
For example, consider these SQL statements:\par
\par
   CREATE TABLE people (\par
      given_name VARCHAR(20),\par
      surname VARCHAR(30),\par
      sex CHAR(1),\par
      id_number CHAR(11),\par
      age SMALLINT,\par
      address VARCHAR(50));\par
\par
   CREATE TABLE author UNDER people (\par
      royalty DECIMAL(4,3));\par
\par
   CREATE TABLE customer UNDER people (\par
      title VARCHAR(20),\par
      number SMALLINT,\par
      total DECIMAL(8,2));\par
\par
A row in a subtable is "contained" in its supertables. This means that, for\par
example, a row could exist for a person in the PEOPLE Table without there\par
being a corresponding row in the AUTHOR Table (if the person described isn't\par
also an author). It also means that you could INSERT a row for a new author\par
(one that doesn't correspond to any existing person) into the AUTHOR Table,\par
and your DBMS would automatically create a corresponding row in the PEOPLE\par
Table for that author.\par
\par
A Base table is defined by a descriptor that contains 13 pieces of information:\par
      ## The <Table name>, qualified by the <Schema name> of the Schema it belongs to.\par
      ## The Base table's type: either persistent Base table, global temporary\par
Base table or created local temporary Base table (for Schema Base tables) or\par
(only for Module Base tables)  declared local temporary Base table.\par
      ## The degree of the Table: the number of Columns that belong to the Table.\par
      ## A descriptor for every Column that belongs to the Table.\par
      ## A descriptor for every Constraint that belongs to the Table.\par
      ## [Obscure Rule] The name of the structured type (if any) associated with the Table.\par
      ## [Obscure Rule] Whether the Table's rows have the REF VALUE characteristic.\par
      ## [Obscure Rule] A list (possibly empty) of the names of the Table's direct supertables.\par
      ## [Obscure Rule] A list (possibly empty) of the names of the Table's direct subtables.\par
      ## [Obscure Rule] The Table's row type.\par
      ## [Obscure Rule] A non-empty set of the Table's functional dependencies.\par
      ## [Obscure Rule] A non-empty set of the Table's candidate keys.\par
      ## [Obscure Rule] An identification of the Table's preferred candidate key (this may or may not be defined as the Table's PRIMARY KEY).\par
\par
The data contained in a Base table is always updatable via the SQL statements\par
INSERT, UPDATE and DELETE. To create a Base table, use the CREATE TABLE\par
statement (either as a stand-alone SQL statement or within a CREATE SCHEMA\par
statement). CREATE TABLE specifies the enclosing Schema, names the Table and\par
defines the Table's Columns and Constraints. To change an existing Base table,\par
use the ALTER TABLE statement. To destroy a Base table, use the DROP TABLE statement. To declare a temporary Table for a Module, use the DECLARE TABLE statement.\par
\par
View\par
\par
A View is a named, derived (or "virtual") Table: it doesn't physically exist,\par
although its definition is persistent. Instead, a View is logically derived\par
from one or more existing Tables, and can be thought of as another way of\par
looking at the presented data. Views are either updatable or read-only,\par
depending on their definitions. A View is defined by a descriptor that contains ten pieces of information:\par
      ## The <Table name>, qualified by the <Schema name> of the Schema the View belongs to.\par
      ## The degree of the View: the number of Columns that are part of the View.\par
      ## A descriptor for every Column that is part of the View.\par
      ## The <query expression> that defines how the View is derived.\par
      ## Whether the View is updatable or not.\par
      ## Whether the View definition includes a CHECK OPTION clause and, if so, whether the clause CHECK OPTION CASCADED or CHECK OPTION LOCAL.\par
      ## [Obscure Rule] The name of the structured type (if any) associated with the View.\par
      ## [Obscure Rule] Whether the View's rows have the REF VALUE characteristic.\par
      ## [Obscure Rule] A list (possibly empty) of the names of the View's direct supertables.\par
      ## [Obscure Rule] A list (possibly empty) of the names of the Views's direct subtables.\par
\par
Depending on the View's definition, the data shown through a View may be\par
updatable via the SQL statements INSERT, UPDATE and DELETE. To create a View,\par
use the CREATE VIEW statement (either as a stand-alone SQL statement or within\par
a CREATE SCHEMA statement). CREATE VIEW specifies the enclosing Schema, names\par
the View and its Columns and defines the <query expression> that determines\par
how the View is derived and updated. To change an existing View, destroy and\par
then redefine it. To destroy a View, use the DROP VIEW statement.\par
\par
Table names\par
\par
A <Table name> identifies a Base table or a View. During a transaction, you\par
can represent a Table with a <Correlation name> -- usually to prevent\par
ambiguity and to make your SQL statements easier to read.\par
\par
<Table name>:\par
A <Table name> identifies a Base table or a View. The required syntax for a <Table name> is either:\par
\par
<Table name> ::=\par
[ <Schema name>. ] unqualified name\par
\par
or, for a declared LOCAL TEMPORARY Table only:\par
\par
<Table name> ::=\par
[ MODULE. ] unqualified name\par
\par
A <Table name> is a <regular identifier> or a <delimited identifier> that is unique (for all Base tables and Views) within the Schema it belongs to. \par
The <Schema name> that qualifies a <Table name> names the Schema that the Table belongs to and can either be explicitly stated, or a default will be supplied by your DBMS, as follows:\par
      ## If a <Table name> in a CREATE SCHEMA statement isn't qualified, the default qualifier is the name of the Schema you're creating.\par
      ## If the unqualified <Table name> is found in any other SQL statement\par
in a Module, the default qualifier is the name of the Schema identified in the\par
SCHEMA clause or AUTHORIZATION clause of the MODULE statement which defines that Module.\par
\par
Here are some examples of <Table name>s:\par
\par
   TABLE_1\par
   -- a <Table name>\par
\par
   SCHEMA_1.TABLE_1\par
   -- a simple qualified <Table name>\par
\par
   CATALOG_1.SCHEMA_1.TABLE_1\par
   -- a fully qualified <Table name>\par
\par
   MODULE.TABLE_1 \par
   -- a declared LOCAL TEMPORARY <Table name>\par
\par
<Correlation name>:\par
A <Correlation name> (or alias) identifies a variable that ranges over some\par
Table; that is, a variable whose only permitted values are the rows of a given\par
Table. A <Correlation name> is evaluated as an alternate <Table name> during a\par
transaction and is normally used to prevent ambiguity in complex SQL\par
statements. Once you've defined a <Correlation name> for a Table, you must use\par
it to refer to that Table throughout the entire transaction -- for example,\par
whenever you would normally use the <Table name> to qualify a <Column name>,\par
use the <Correlation name> instead. Since a <Correlation name> is associated\par
with a Table only in the context in which you define it, you can use the same\par
<Correlation name>, for any Table, in other transactions. The required syntax\par
for a <Correlation name> is: \par
\par
<Correlation name> ::= \par
unqualified name\par
\par
A <Correlation name> is a <regular identifier> or a <delimited identifier>\par
that is unique within the Table it represents for the period of a transaction.\par
The scope of a <Correlation name> is either a SELECT statement (or some other\par
query form), a Trigger definition or both (correlation scopes may be nested).\par
Here is an example of a <Correlation name>: \par
\par
   CORRELATION_1\par
   -- a <Correlation name>\par
\par
The syntax required to define a <Correlation name> for a Table is:\par
\par
<Table reference> [ AS ] <Correlation name> \par
   [ (derived <Column name> [ \{,derived <Column name> \}... ]) ]\par
\par
A <Table reference> is a reference to some Table -- this is usually a named\par
Table (that is, a Base table or a View), but could also be an unnamed Table\par
(for example, the result of a join, a subquery or a query expression). Most\par
often, a <Table reference> is just a <Table name> and we'll use only that form\par
for now. Here are two equivalent examples (the <keyword> AS is noise and can be omitted):\par
\par
   SELECT First.column_1, Second.column_1 \par
      FROM Table_1 AS First, Table_1 AS Second \par
      WHERE First.column_2 = Second.column_2;\par
\par
   SELECT First.column_1, Second.column_1 \par
      FROM Table_1 First, Table_1 Second \par
      WHERE First.column_2 = Second.column_2;\par
\par
These SQL statements execute a join of TABLE_1 with itself, over matching\par
COLUMN_2 values. What the SELECTs are doing is looking at all possible pairs\par
of TABLE_1 rows and retrieving the COLUMN_1 values from each row where the\par
COLUMN_2 values are equal to one another. To do so, the DBMS must be able to\par
refer to two rows of TABLE_1 at once -- and this requires that it be able to\par
distinguish between the two references. The <Correlation name> allows the DBMS\par
to do this: it calls the one row FIRST, and the other row SECOND, just like\par
the <Correlation name>s specified in the SQL statements. To further clarify\par
the request, each <Column name> specified is qualified with the appropriate\par
<Correlation name>, so that the DBMS knows which Column belongs to which of\par
the rows it's looking at.\par
\par
Since a <Table reference> can also refer to an unnamed Table that results from\par
a query, it's sometimes necessary (or at least useful) to be able to name the\par
Columns of the <Table reference> result. The optional derived <Column name>\par
list with the AS <Correlation name> clause allows you to do this. Here's an example:\par
\par
   SELECT joined_col_1, joined_col_2 \par
   FROM   (Table_1 NATURAL JOIN Table_2) AS Joined_Table \par
          (joined_col_1, joined_col_2, joined_col_3, joined_col_4) \par
   ...\par
\par
In this example, "Table_1 NATURAL JOIN Table_2" is a <Table reference> that\par
evaluates to the Table resulting from the NATURAL JOIN operation -- and\par
JOINED_TABLE is the <Correlation name> for that result. The Columns of\par
JOINED_TABLE are explicitly given the names JOINED_COL_1, JOINED_COL_2,\par
JOINED_COL_3 and JOINED_COL_4, and these are the names that are used to refer\par
to those Columns throughout the SQL statement. If you use this option, you\par
must specify a unique, unqualified name for every Column of the result Table,\par
even if you're never going to refer to some of the Columns again.\par
\par
Column\par
\par
A Table may contain one or more Columns. An SQL Column is a collection of\par
similar data values that describe the same attribute of the entity that is\par
fully described by the Table that owns the Column. Columns are dependent on\par
some Table -- the <Column name> must be unique within the Table the Column\par
belongs to -- and are created, altered and dropped using standard SQL\par
statements. The Objects that may belong to a Column are Column Constraints;\par
they depend on some Column.\par
\par
Columns are ordered within the Table they belong to, from left to\par
right -- their ordinal position matches the ordinal position of\par
the <Column definition> in the Table's definition. All Columns have a\par
nullability characteristic: it determines (a) whether an attempt to INSERT the\par
null value into the Column will fail and (b) whether a SELECT from the Column\par
can ever return the null value. A Column's nullability characteristic is\par
"possibly nullable" unless one of these situations apply:\par
      ## A Column's nullability characteristic is "known not\par
nullable" if a non-deferrable Constraint/Assertion on the Column evaluates to\par
"Column IS NOT NULL" or if the Column is based on a Domain and a\par
non-deferrable Constraint/Assertion on that Domain evaluates to "VALUE IS NOT NULL". \par
      ## A Column's nullability characteristic is "known not\par
nullable" if a non-deferrable Constraint on the Column is a PRIMARY KEY Constraint. \par
\par
A Column is defined by a descriptor that contains nine pieces of information:\par
      ## The <Column name>, qualified by the <Table name> of the Table it\par
belongs to. (It is possible to have a Column with a default name, rather than\par
a name you defined for it yourself. In this case, the Column's descriptor also\par
indicates that the name is an implementation-dependent, or default, name.)\par
      ## The ordinal position of the Column in its Table. (A Table may contain only one referenceable Column: it must be the first Column in the Table.)\par
      ## The Column's <data type> specification, including its name, length,\par
precision and scale, as applicable (or, if the Column is based on a Domain, the <Domain name>).\par
      ## The name of the Character set that the Column's set of values must belong to (for character string types).\par
      ## The name of the Column's default Collation. (This is the Collation\par
that may be used to compare a character string Column's values in the absence\par
of an explicit COLLATE clause.)\par
      ## Whether reference values must be checked and whether <reference scope\par
check action> specifies RESTRICT or SET NULL (for REF types).\par
      ## Whether the Column is a system-generated Column or not (that is,\par
whether the Column's <data type> is REF with VALUES ARE SYSTEM GENERATED). If\par
it is, the Table that the Column belongs to is a referenceable Base Table.\par
      ## The Column's default value (if any).\par
      ## The Column's nullability characteristic: either "known not nullable" or "possibly nullable".\par
\par
To create a Column, use a <Column definition> in a CREATE TABLE or ALTER TABLE\par
statement. To change or destroy an existing Column, use the ALTER TABLE statement.\par
\par
Column names:\par
A <Column name> identifies a Column. The SQL Standard does not consider a\par
<Column name> to be a qualified name but, in practice, <Column name>s are\par
often qualified to prevent ambiguity in complex SQL statements: this practice\par
is called a <Column reference>. A qualified <Column name> is not allowed in a\par
<Column definition> -- that is, a <Column reference> may not be used to\par
identify a Column in a CREATE TABLE or an ALTER TABLE statement. \par
\par
## <Column name> \par
The required syntax for a <Column name> is: \par
\par
<Column name> ::= \par
unqualified name \par
\par
A <Column name> is a <regular identifier> or a <delimited identifier> that is\par
unique (for all Columns) within the Table it belongs to. Here is an example of\par
a <Column name>: \par
\par
   COLUMN_1\par
   -- a <Column name>\par
\par
## <Column reference>\par
The required syntax for a <Column reference>, valid only outside of a <Column definition> is either: \par
\par
<Column reference> ::= \par
[ Table specification. ] <Column name> \par
\par
   Table specification ::=\par
   <Table name> | \par
   <Correlation name> \par
\par
or, for a declared LOCAL TEMPORARY Table only:\par
\par
<Column reference> ::=\par
MODULE.<Table name>.<Column name>\par
\par
A <Column reference> is a <Column name> qualified by a Table specification, or\par
by "MODULE.<Table name>". The Table specification which qualifies a <Column\par
name> identifies the Table that the Column belongs to, and is either that\par
Table's name or a <Correlation name> that identifies that Table. If you omit\par
the Table specification from a <Column reference>, it will default to the\par
<Table name> of the Table that owns the Column. Here are some examples of <Column reference>s:\par
 \par
   TABLE_1.COLUMN_1 \par
  -- a <Column reference> with a <Table name>\par
\par
   CORRELATION_1.COLUMN_1 \par
   -- a <Column reference> with a <Correlation name>\par
\par
   MODULE.TABLE_1.COLUMN_1\par
   -- a <Column reference> for a declared LOCAL TEMPORARY Table\par
\par
CREATE TABLE statement\par
\par
The CREATE TABLE statement names a new Base table and defines the Table's\par
Columns and Constraints. The required syntax for the CREATE TABLE statement is: \par
\par
CREATE [ \{GLOBAL TEMPORARY | LOCAL TEMPORARY\} ] TABLE <Table name>\par
   <table contents source>\par
   [ ON COMMIT \{PRESERVE ROWS | DELETE ROWS\} ]\par
\par
   <table contents source> ::=\par
   (<table element list>) | \par
   OF <UDT name> [ UNDER <supertable name> [ \{,<supertable name>\}... ] ] [ <table element list> ]\par
\par
      <table element list> ::=\par
      <table element> [ \{,<table element>\}... ] \par
\par
         <table element> ::=\par
         <Column definition> | \par
         <Table Constraint> | \par
         LIKE <Table name> | \par
         <Column name> WITH OPTIONS <column option list>\par
\par
             <Table Constraint> ::=\par
             [ CONSTRAINT <Constraint name> ] \par
             Constraint_type \par
             [ <constraint attributes> ] \par
\par
             <column option list> ::=\par
            [ <scope clause> ]\par
            [ <default clause> ]\par
            [ <Column Constraint>... ]\par
            [ COLLATE <Collation name> ]\par
\par
CREATE TABLE defines a new persistent Base table. CREATE GLOBAL TEMPORARY\par
TABLE defines a new global temporary Base table. CREATE LOCAL TEMPORARY TABLE\par
defines a new created local temporary Base table. A Table is owned by the\par
Schema it belongs to.\par
      ## The <Table name> identifies the Table and the Schema that it belongs\par
to. A <Table name> that includes an explicit <Schema name> qualifier belongs\par
to the Schema named. A <Table name> that does not include an explicit <Schema\par
name> qualifier belongs to the SQL-session default Schema. The <Table name>\par
must be unique (for all Base tables and Views) within the Schema that owns it.\par
\par
If CREATE TABLE is part of a CREATE SCHEMA statement, the <Table name>, if\par
explicitly qualified, must include the <Schema name> of the Schema being\par
created; that is, it isn't possible to create a Base table belonging to a\par
different Schema from within CREATE SCHEMA. For example, this SQL statement\par
will not return an error because the <Table name> will default to include the\par
qualifying <Schema name>:\par
\par
   CREATE SCHEMA bob \par
      CREATE TABLE Table_1 (column_1 SMALLINT);\par
      -- creates a Table called BOB.TABLE_1 in Schema BOB \par
\par
This SQL statement will not return an error either because the <Table name>\par
explicitly includes a qualifying <Schema name> that matches the name of the\par
Schema being created:\par
\par
   CREATE SCHEMA bob \par
      CREATE TABLE bob.Table_1 (column_1 SMALLINT);\par
      -- creates a Table called BOB.TABLE_1 in Schema BOB \par
\par
But this SQL statement will return an error because the <Table name>\par
explicitly includes a qualifying <Schema name> that is different from the name\par
of the Schema being created:\par
\par
   CREATE SCHEMA bob \par
      CREATE TABLE sam.Table_1 (column_1 SMALLINT);\par
      -- tries to create a Table belonging to Schema SAM inside Schema BOB; illegal syntax\par
\par
[Obscure Rule] In effect, a temporary Table does not exist until it is invoked\par
during an SQL-session. Once invoked, it will only be visible to the\par
SQL-session (or the Module) that invoked it -- that is, the temporary Table\par
will not be visible to other users. At the end of the SQL-session, all\par
temporary Tables invoked during the SQL-session are dropped. Because temporary\par
Tables are materialized only when invoked, the Schema they belong to is\par
actually defined by your DBMS.\par
      ## If you're creating a temporary Table with CREATE GLOBAL TEMPORARY\par
TABLE, the <Table name> may not be explicitly qualified. Because a global\par
temporary Table is distinct within an SQL-session, the Schema it belongs to is\par
a Schema determined by your DBMS -- in effect, it fixes a qualifying <Schema\par
name> for the Table based on the Schema in which the global temporary Table is\par
defined, coupled with the DBMS's name for the SQL-session in which you invoke\par
that Table.\par
      ## If you're creating a temporary Table with CREATE LOCAL TEMPORARY\par
TABLE, the <Table name> may not be explicitly qualified. Because a local\par
temporary Table is distinct within an SQL-client Module within an SQL-session,\par
the Schema it belongs to is a Schema determined by your DBMS -- in effect, it\par
fixes a qualifying <Schema name> for the Table based on the Schema in which\par
the global temporary Table is defined, coupled with the DBMS's name for the\par
SQL-session in which you invoke that Table, coupled with the DBMS's name for\par
the SQL-client Module that refers to that Table.\par
\par
If CREATE TABLE is executed as a stand-alone SQL statement, the current\par
<AuthorizationID> must either be the owner of the Schema that this new Table\par
belongs to, or the Schema's owner must be a Role that the current\par
<AuthorizationID> may use. That is, only the owner of a Schema can create\par
Tables for that Schema. In addition to creating a Table, CREATE TABLE also\par
causes the SQL special grantor, "_SYSTEM", to grant grantable INSERT, SELECT,\par
UPDATE, DELETE, TRIGGER and REFERENCES Privileges on the new Table, as well as\par
grantable SELECT, INSERT, UPDATE and REFERENCES Privileges on every Column in\par
the new Table, to the Schema owner <AuthorizationID> (that is, the\par
<AuthorizationID creating the Table).\par
\par
<table contents source clause>:\par
The <table contents source> clause defines the structure of the Table's\par
contents: it tells you what sort of data the Table contains. This clause is\par
either a list of elements, such as Column and Table Constraint definitions, or\par
an OF clause that defines the UDT structure that makes up the Table. Every\par
<table element list> has to contain at least one <Column definition>.\par
      ## [Obscure Rule] If CREATE TABLE includes the OF clause, then <UDT\par
name> must identify a structured type. If the OF clause also includes the\par
(optional) <table element list>, the list (a) may not contain a LIKE clause\par
and (b) may contain only one <table element> that is a <Column definition>: it\par
must define a Column with a REF <data type> that specifies VALUES ARE SYSTEM\par
GENERATED. The optional UNDER sub-clause in the OF clause contains a list of\par
<Table name>s. Each <Table name> in the list identifies a direct supertable of\par
the Table being created and must therefore belong to the same Schema that owns\par
this new Table. (The Schema owner <AuthorizationID> must have the UNDER\par
Privilege on each supertable named.) A <Table name> may appear in the UNDER\par
list only once. The new Table is a direct subtable of each of its direct\par
supertables: this subtable family must have exactly one maximal supertable.\par
(The effect of CREATE TABLE on the new Table's supertables is that its name is\par
added to the list of direct subtables in each supertable's definition.) If you\par
add the UNDER sub-clause to a CREATE TABLE statement: (a) the structured type\par
identified by <UDT name> must be a direct subtype of the structured type of\par
every direct supertable of the new Table, (b) your Table definition may not\par
include a PRIMARY KEY Constraint, (c) one of the supertables of the new Table\par
must include a UNIQUE Constraint that constrains a Column with a nullability\par
characteristic of "known not nullable" and (d) the Schema owner's\par
<AuthorizationID> is granted grantable SELECT, UPDATE and REFERENCES\par
Privileges for every inherited Column of the new Table. (The grantor of these\par
Privileges is the SQL special grantor, "_SYSTEM".) Note that if a direct\par
supertable of the new Table is a referenceable Base table, then this new Table\par
is also a referenceable Base table. In this case, your OF clause, if it\par
contains a <table element list>, may not include a <Column definition>. If any\par
<table element> contains a <scope clause> the Base table(s) referred to\par
therein must be either (a) persistent Base tables, if CREATE TABLE contains no\par
<table scope>, (b) GLOBAL TEMPORARY Base tables if you're creating a GLOBAL\par
TEMPORARY Base table or (c) created LOCAL TEMPORARY Base tables if you're\par
creating a LOCAL TEMPORARY Base table. For further details, refer to our\par
chapter on User-defined Types.\par
\par
The common form of CREATE TABLE uses a parenthesized <table element list> as\par
its <table contents source> clause. A <table element> is either a <Column\par
definition> (see "<Column definition>" in this chapter , a <Table Constraint>\par
(see our chapter on Constraints and Assertions), a LIKE clause or a <column\par
options> clause. Multiple <table element>s must be separated by commas.\par
\par
The effect of CREATE TABLE <Table name> (<Column definition>,<Column definition>), e.g.:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 DATE);\par
\par
is to create a Table, called TABLE_1, that contains two Columns,\par
called COLUMN_1 and COLUMN_2. At least one Column must be defined in a <table\par
element list>. The row type of the new Table is the set of pairs (<Column\par
name>, <data type>) defined for the Table.\par
\par
The effect of CREATE TABLE <Table name> (<Column definition>,<Table Constraint>), e.g.:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      CONSTRAINT constraint_1 PRIMARY KEY(column_1));\par
\par
is to create a Table, called TABLE_1, that contains one Column,\par
called COLUMN_1, and one <Table Constraint> that defines COLUMN_1 as the\par
Table's primary key. Zero or more <Table Constraint>s may be defined in a\par
<table element list>. If the new Table is a temporary Base table, then all\par
Tables referred to in the new Table's <Table Constraint>s must also be\par
temporary Base tables.\par
\par
The effect of CREATE TABLE <Table name> (LIKE <Table name>) is to create a\par
Table whose <Column definitions>s are copied from another Table. In the LIKE\par
clause, <Table name> identifies the Table whose <Column definition>s you want\par
to copy into the new Table. For example, this SQL statement creates a Table in\par
the usual manner:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 DATE, \par
      column_3 CHAR(8), \par
      CONSTRAINT constraint_1 CHECK (column_1 BETWEEN 50 AND 5000)); \par
\par
And this SQL statement uses the LIKE clause to create another Table with the\par
same <Column definition>s:\par
\par
CREATE TABLE Table_2 (LIKE Table_1); \par
\par
The result is a Table, called TABLE_2, whose structure will be exactly as if\par
it had been defined with this SQL statement:\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT, \par
      column_2 DATE, \par
      column_3 CHAR(8)); \par
\par
Note that the <Table Constraint> from TABLE_1's definition is not recopied\par
into TABLE_2's definition: the LIKE clause copies only <Column definition>s.\par
However, because a <Column Constraint> is effectively replaced by a <Table\par
Constraint> in a Table's definition, the LIKE clause also won't copy any\par
<Column Constraint>s from the existing Table into the new Table. For example,\par
for these two SQL statements:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT NOT NULL, \par
      column_2 DATE, \par
      column_3 CHAR(8)); \par
\par
   CREATE TABLE Table_2 (LIKE Table_1); \par
\par
the result in the first case is a Table, called TABLE_1, whose structure will\par
be exactly as if it had been defined with this SQL statement:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 DATE, \par
      column_3 CHAR(8) \par
      CONSTRAINT CHECK (column_1 IS NOT NULL)); \par
\par
and thus, the result in the second case is a Table, called TABLE_2, whose\par
structure will be exactly as if it had been defined with this SQL statement:\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT, \par
      column_2 DATE, \par
      column_3 CHAR(8)); \par
\par
If CREATE TABLE includes a LIKE clause, the current <AuthorizationID> must\par
have the SELECT Privilege on the Table named.\par
\par
The effect of CREATE TABLE <Table name> (<Column definition,<Column name> WITH\par
OPTIONS <column option list>) is to create a Table containing one or more\par
Columns whose definitions are further outlined by the <column option>(s) chosen.\par
\par
Temporary Tables:\par
If you're creating a temporary Table, you may also use the ON COMMIT clause to\par
specify whether you want the Table to be emptied whenever a COMMIT statement\par
is executed. If you omit the ON COMMIT clause from CREATE TEMPORARY TABLE, it\par
defaults to ON COMMIT DELETE ROWS. For example, these two SQL statements are\par
equivalent:\par
\par
   CREATE GLOBAL TEMPORARY TABLE Table_1 ( \par
      column_1 SMALLINT);\par
\par
   CREATE GLOBAL TEMPORARY TABLE Table_1 ( \par
      column_1 SMALLINT) \par
      ON COMMIT DELETE ROWS;\par
\par
Based on this Table definition, the effect of these two SQL statements:\par
\par
   INSERT INTO Table_1 (column_1) \par
   VALUES(10); \par
\par
   COMMIT;\par
\par
is that TABLE_1 is first materialized and has data inserted into it, and then\par
the rows are deleted. That is, at COMMIT time, your DBMS effectively executes\par
this SQL statement:\par
\par
   DELETE FROM Table_1;\par
\par
since the definition of TABLE_1 states that the Table is to be emptied at\par
COMMIT. On the other hand, the effect of these three SQL statements:\par
\par
   CREATE GLOBAL TEMPORARY TABLE Table_1 ( \par
      column_1 SMALLINT) \par
      ON COMMIT PRESERVE ROWS; \par
\par
   INSERT INTO Table_1 (column_1) \par
   VALUES(10);\par
\par
   COMMIT;\par
\par
is that TABLE_1 is created, materialized and has data inserted into it, and\par
then the rows are committed. That is, at COMMIT time, your DBMS does not\par
delete the rows, since TABLE_1's definition explicitly says not to. (The rows\par
will, however, be deleted at the end of the SQL-session.)\par
\par
If you want to restrict your code to Core SQL, don't create any temporary Base\par
tables, don't use a LIKE clause as a <table element>, don't use an OF clause\par
as a <table element> and don't add a <column scope clause> to any CREATE TABLE\par
statement.\par
\par
<Column definition> \par
\par
A <Column definition> is used to create or alter a Column of a Base table.\par
Used in a CREATE TABLE or an ALTER TABLE statement, it names a Column and\par
defines the Column's <data type>, default value and Constraints. The required\par
syntax for a <Column definition> is: \par
\par
<Column definition> ::= \par
unqualified <Column name> \par
\{ <data type> | <Domain name> \} \par
[ <reference scope check> ]\par
[ DEFAULT default value ] \par
[ <Column Constraint> list ] \par
[ COLLATE <Collation name> ] \par
\par
   <Column Constraint> list ::=\par
   <Column Constraint> [ <Column Constraint> ] \par
\par
      <Column Constraint> ::= \par
      [ CONSTRAINT <Constraint name> ] \par
      Constraint_type \par
      [ <constraint attributes> ] \par
\par
   <reference scope check> ::=\par
   REFERENCES ARE [ NOT ] CHECKED \par
   [ ON DELETE <reference scope check action> ]\par
\par
      <reference scope check action> ::= RESTRICT | SET NULL\par
\par
A <Column definition> defines a new Column for a Base table. A Column is owned\par
by the Table it belongs to. The <Column name> identifies the Column and the\par
Table that it belongs to. A <Column name> in a <Column definition> may not be\par
qualified: it belongs to the Table named in the enclosing CREATE TABLE or\par
ALTER TABLE statement. The <Column name> must be unique within the Table that\par
owns it.\par
\par
<data type>:\par
A Column must be defined to accept a certain type of data. This is done in one\par
of two ways: you can either define a Column with a <data type> specification>\par
or you can define it as being based on a Domain. If you base a Column on a\par
Domain, your current <AuthorizationID> must have the USAGE Privilege on that\par
Domain. The Column's specified <data type> (or the <data type> of the Domain\par
it is based on) constrains the values that can be accepted by the Column. The\par
<data type> specification includes length, precision and scale as applicable.\par
Valid <data type>s are: INT, SMALLINT, NUMERIC(p,s), DECIMAL(p,s), FLOAT(p),\par
REAL, DOUBLE PRECISION, BIT(l), BIT VARYING(l), BLOB(l), CHAR(l), NCHAR(l),\par
VARCHAR(l), NCHAR VARYING(l), CLOB(l), NCLOB(l), DATE, TIME(p), TIME(p) WITH\par
TIME ZONE, TIMESTAMP(p), TIMESTAMP(p) WITH TIME ZONE, INTERVAL <interval\par
qualifier>, BOOLEAN, ARRAY, ROW and REF.\par
\par
The effect of the syntax "CREATE TABLE <Table name> (<Column name> <data\par
type>)" is to define a Column with a <data type> specification. For example,\par
this SQL statement creates a Table with a Column that has a <data type> of\par
DECIMAL(9,2):\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 DEC(9,2));\par
\par
The effect of the syntax "CREATE TABLE <Table name> (<Column name> <Domain\par
name>)" is to define a Column based on a Domain. For example, the effect of\par
these SQL statements is also a Table with a Column that has a <data type> of\par
DECIMAL(9,2):\par
\par
   CREATE DOMAIN domain_1 AS DEC(9,2);\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 domain_1;\par
\par
[Obscure Rule] If the <data type> of a Column is CHAR, VARCHAR or CLOB, the\par
Character set that the Column's values must belong to is determined as\par
follows:\par
      ## If the <Column definition> contains a <data type> specification that\par
includes a CHARACTER SET clause, the Column's Character set is the Character\par
set named. Your current <AuthorizationID> must have the USAGE Privilege on\par
that Character set.\par
      ## If the <Column definition> does not include a <data type>\par
specification, but the Column is based on a Domain whose definition includes a\par
CHARACTER SET clause, the Column's Character set is the Character set named.\par
      ## If the <Column definition> does not include any CHARACTER SET clause\par
at all -- either through a <data type> specification or through a Domain\par
definition -- the Column's Character set is the Character set named in the\par
DEFAULT CHARACTER SET clause of the CREATE SCHEMA statement that defines the\par
Schema that the Column belongs to.\par
\par
For example, the effect of these two SQL statements:\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob \par
      DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN1; \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 CHAR(10)); \par
\par
is to create a Table, with one Column, in Schema BOB. The Column's set of\par
valid values are fixed length character strings, exactly 10 characters long,\par
all of whose characters must be found in the INFORMATION_SCHEMA.LATIN1\par
Character set -- the Schema's default Character set.\par
\par
The effect of these two SQL statements:\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob \par
      DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN1; \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 CHAR(10) CHARACTER SET INFORMATION_SCHEMA.SQL_CHARACTER); \par
\par
is to create the same Table with one difference: this time, its Column's\par
values must consist only of characters found in the INFORMATION_SCHEMA.SQL_CHARACTER Character set -- the explicit Character set specification in CREATE TABLE constrains the Column's set of values. The Schema's default Character set does not.\par
\par
[Obscure Rule] If the <data type> of a Column is CHAR, VARCHAR, CLOB, NCHAR,\par
NCHAR VARYING or NCLOB, and your <Column definition> does not include a\par
COLLATE clause, the Column has a coercibility attribute of COERCIBLE -- but if\par
your <Column definition> includes a COLLATE clause, the Column has a\par
coercibility attribute of IMPLICIT. In either case, the Column's default\par
Collation is determined as follows:\par
      ## If the <Column definition> includes a  COLLATE clause, the Column's\par
default Collation is the Collation named. Your current <AuthorizationID> must\par
have the USAGE Privilege on that Collation.\par
      ## If the <Column definition> does not include a COLLATE clause, but\par
does contain a <data type> specification that includes a COLLATE clause, the\par
Column's default Collation is the Collation named. Your current\par
<AuthorizationID> must have the USAGE Privilege on that Collation.\par
      ## If the <Column definition> does not include a COLLATE clause, but the\par
Column is based on a Domain whose definition includes a COLLATE clause, the\par
Column's default Collation is the Collation named.\par
      ## If the <Column definition> does not include any COLLATE clause at all\par
-- either explicitly, through a <data type> specification or through a Domain\par
definition -- the Column's default Collation is the default Collation of the\par
Column's Character set.\par
\par
[Obscure Rule] If the <data type> of a Column is REF(UDT), your current\par
<AuthorizationID> must have the USAGE Privilege on that UDT. If the <data\par
type> of a Column includes REF with a <scope clause>, your <Column definition>\par
must also include a <reference scope check> clause, to indicate whether\par
references are to be checked or not (don't add a <reference scope check>\par
clause under any other circumstances). In this case, you may also add the\par
optional <reference scope check action> clause, to indicate the action to be\par
taken when the Column is the subject of a DELETE statement. If you omit the\par
<reference scope check action> clause, it defaults to ON DELETE RESTRICT.\par
      ## If a Column is defined with REFERENCES ARE CHECKED and a <scope\par
clause> naming one or more Tables is included in the <Column definition>, then\par
there is an implied DEFERRABLE INITIALLY IMMEDIATE Constraint on the new\par
Column which checks that the Column's values are also found in the system\par
generated Column of each Table named in the <scope clause>. In this case, if\par
the <reference scope check action> is SET NULL then, prior to deleting any\par
rows from the Table that owns this Column, your DBMS will (a) execute a SET\par
CONSTRAINT statement that sets the implied Constraint's constraint check time\par
to DEFERRED, (b) DELETE the rows as required, (c) set the value of the system\par
generated Column in each Table named in the <scope clause> to NULL, for each\par
row that matched the deleted rows and (d) execute a SET CONSTRAINT statement\par
that sets the implied Constraint's constraint check time to IMMEDIATE.\par
\par
DEFAULT clause:\par
The optional DEFAULT clause defines the Column's default value: the value to\par
insert whenever this Column is the target of an INSERT statement that doesn't\par
include an explicit value for it. The DEFAULT options are: DEFAULT <literal>,\par
DEFAULT CURRENT_DATE, DEFAULT CURRENT_TIME(p), DEFAULT CURRENT_TIMESTAMP(p),\par
DEFAULT LOCALTIME(p), DEFAULT LOCALTIMESTAMP(p), DEFAULT USER, DEFAULT\par
CURRENT_USER, DEFAULT SESSION_USER, DEFAULT SYSTEM_USER, DEFAULT CURRENT_PATH,\par
DEFAULT ARRAY[], DEFAULT ARRAY??(??) and DEFAULT NULL -- see "<default\par
clause>", later in this chapter. The DEFAULT clause is optional whether or not\par
the Column is based on a Domain that has a defined default value, so a\par
Column's default value is determined as follows:\par
      ## If a <Column definition> that contains a <data type> specification\par
omits the DEFAULT clause, the Column has no default value.\par
      ## If a <Column definition> that contains a <data type> specification\par
includes the DEFAULT clause, the Column's default value is the default value\par
specified -- that is, the syntax "CREATE TABLE <Table name> (<Column name>\par
DEFAULT default value)" defines a Column with an explicit default value. For\par
example, this SQL statement creates a Table with a Column whose default value\par
is the <character string literal> 'bobby':\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 CHAR(5) DEFAULT 'bobby');\par
\par
      ## If a Column is based on a Domain and the <Column definition> omits\par
the DEFAULT clause, the Column's default value is the Domain's default value.\par
If the Domain has no defined default value, then the Column has no default\par
value either. For example, the effect of these two SQL statements is to define\par
a Column whose default value is the <character string literal> 'bobby' --\par
taken from the Domain that the Column is based on:\par
\par
   CREATE DOMAIN domain_1 AS \par
      CHAR(5) DEFAULT 'bobby';\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 domain_1);\par
\par
If a Column is based on a Domain and the <Column definition> includes the\par
DEFAULT clause, the Column's default value is the default value specified --\par
even if the Domain has a defined default value. The <Column definition>'s\par
DEFAULT clause always over-rides any default value defined for the Domain that\par
a Column is based on. For example, the effect of these two SQL statements is\par
to define a Column whose default value is the <character string literal>\par
'bobby' -- despite the fact that the Domain that the Column is based on has a\par
default value that is the <character string literal> 'sammy':\par
\par
   CREATE DOMAIN domain_1 AS \par
      CHAR(5) DEFAULT 'sammy';\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 domain_1 DEFAULT 'bobby');\par
\par
<Column Constraint>s:\par
The optional <Column Constraint> list clause is used to define zero or more\par
<Constraint>s on the Column: the Constraint rules will restrict the Column's\par
set of valid values -- see our chapter on Constraints and Assertions. (If the\par
Column is based on a Domain, the Column's set of valid values is restricted by\par
both the Domain's Constraints and the Column's Constraints.) All <Constraint\par
name>s must be unique within the Schema that the Column belongs to. The syntax\par
"CREATE TABLE <Table name> (<Column name> <data type> <Column Constraint>,\par
<Column name> <Domain name> <Column Constraint>)" defines a Column whose\par
definition includes a <Column Constraint>. Here is an example:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT NOT NULL, \par
      column_2 domain_1 PRIMARY KEY NOT DEFERRABLE);\par
      -- column_1 excludes null values and column_2 is the Table's primary key\par
\par
The syntax "CREATE TABLE <Table name> (<Column name> <data type> DEFAULT\par
default value <Column Constraint>, <Column name> <Domain name> DEFAULT default\par
value <Column Constraint>)" also defines Columns whose definitions include a\par
<Column Constraint>. Here is an example:\par
\par
   CREATE TABLE Table _1 ( \par
      column_1 SMALLINT DEFAULT 100 \par
         CONSTRAINT constraint_1 PRIMARY KEY NOT DEFERRABLE \par
      column_2 domain1 DEFAULT 'bobby' \par
         CONSTRAINT constraint_2 CHECK (column_2 IS NOT NULL); \par
      -- column_1 is the Table's primary key and column_2 excludes null values\par
\par
A <Column Constraint> is valid only in a <Column definition> because, once\par
defined, <Column Constraint>s logically become <Table Constraint>s of the\par
Table that the Column belongs to. To change or drop a <Column Constraint>, or\par
to add a <Column Constraint> to a Table once CREATE TABLE has been executed,\par
use the ALTER TABLE statement.\par
\par
If you want to restrict your code to Core SQL, don't add a COLLATE clause to\par
your <Column definition>s, don't base your Columns on Domains, don't name your\par
<Column Constraint>s and don't define a <Column Constraint> with a <referential triggered action>. \par
\par
<default clause> \par
\par
A <default clause> defines the default value for a Column, a Domain or an\par
attribute of a UDT. The required syntax for a <default clause> is: \par
\par
<default clause> ::= \par
DEFAULT default value \par
\par
   default value ::=\par
   <literal> | \par
   USER | \par
   CURRENT_USER | \par
   SESSION_USER | \par
   SYSTEM_USER | \par
   CURRENT_PATH | \par
   CURRENT_DATE | \par
   CURRENT_TIME[(p)] | \par
   CURRENT_TIMESTAMP[(p)] | \par
   LOCALTIME[(p)] | \par
   LOCALTIMESTAMP[(p)] | \par
   ARRAY[] | \par
   ARRAY??(??) | \par
   NULL\par
\par
The default value of an Object is the data value that will be inserted into\par
the Object whenever it is the target of an INSERT statement that does not\par
provide an explicit data value for that Object. If the definition of an Object\par
does not include a <default clause>, no default value is assigned to it -- so\par
when the Object is the target of an INSERT statement that does not provide an\par
explicit data value for it, your DBMS will INSERT a null value. (If the Object\par
doesn't allow nulls, the INSERT will, of course, fail.) The <data type> of a\par
default value must match the Object's <data type> (that is, the default value\par
and the Object's <data type> must be mutually assignable).\par
      ## If the <data type> of an Object is a <reference type>, the <default clause> must be "DEFAULT NULL".\par
      ## If the <data type> of an Object is a <collection type>, the <default clause> must be "DEFAULT NULL" or "DEFAULT ARRAY[]" or "DEFAULT ARRAY??(??)" or "DEFAULT <literal>".\par
\par
If a <default clause> is "DEFAULT <literal>", the value represented by the\par
<literal> is the target Object's default value. Here are some examples of\par
<default clause>s with a <literal> as the default value:\par
\par
   CREATE DOMAIN domain_1 AS NCHAR(5) DEFAULT N'sammy'; \par
\par
   CREATE TABLE Table_1 (column_1 VARCHAR(6) DEFAULT 'bob'); \par
\par
   CREATE DOMAIN domain_1 AS BIT VARYING(4) DEFAULT B'0010'; \par
\par
   CREATE TABLE Table_1 (column_1 BIT(16) DEFAULT X'4E2C');\par
      -- If the target Object has a BIT <data type> and the length of your <literal> is less than the defined length of the Object, your DBMS will return the SQLSTATE warning 01008 "warning-implicit zero-bit padding".\par
  \par
   CREATE DOMAIN domain_1 AS SMALLINT DEFAULT 100; \par
\par
   CREATE TABLE Table_1 (column_1 REAL DEFAULT 15000); \par
\par
   CREATE DOMAIN domain_1 AS DATE DEFAULT DATE '1994-07-15'; \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 INTERVAL MONTH DEFAULT INTERVAL '03' MONTH); \par
\par
   CREATE DOMAIN domain_1 AS BOOLEAN DEFAULT FALSE\par
\par
If a <default clause> is "DEFAULT USER", "DEFAULT CURRENT_USER", "DEFAULT\par
SESSION_USER" or "DEFAULT SYSTEM_USER", the value returned by the function is\par
the target Object's default value. In this case, the target Object must have a\par
character string <data type> with a defined length of at least 128 characters\par
and must belong to the SQL_TEXT Character set. Here are some examples of\par
<default clause>s with a <niladic user function> as the default value:\par
\par
   CREATE DOMAIN domain_1 AS \par
      CHAR(128) CHARACTER SET SQL_TEXT DEFAULT CURRENT_USER;\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 VARCHAR(256) CHARACTER SET SQL_TEXT DEFAULT SESSION_USER; \par
\par
If a <default clause> is "DEFAULT CURRENT_PATH", the value returned by the\par
function is the target Object's default value. In this case, the target Object\par
must have a character string <data type> with a defined length of at least\par
1031 characters and must belong to the SQL_TEXT Character set. Here are some\par
examples of <default clause>s with CURRENT_PATH as the default value:\par
\par
   CREATE DOMAIN domain_1 AS \par
      CHAR(1031) CHARACTER SET SQL_TEXT DEFAULT CURRENT_PATH;\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 VARCHAR(2000) CHARACTER SET SQL_TEXT DEFAULT CURRENT_PATH; \par
\par
If a <default clause> is "DEFAULT CURRENT_DATE", "DEFAULT CURRENT_TIME[(p)]",\par
"DEFAULT CURRENT_TIMESTAMP[(p)]", "DEFAULT LOCALTIME[(p)]" or "DEFAULT\par
LOCALTIMESTAMP[(p)]", the value returned by the function is the target\par
Object's default value. In this case, the target Object must have a datetime\par
<data type> that matches the function's <data type>. Here are some examples of\par
<default clause>s with a <datetime value function> as the default value:\par
\par
   CREATE DOMAIN domain_1 AS \par
      DATE DEFAULT CURRENT_DATE;\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 TIME WITH TIME ZONE DEFAULT CURRENT_TIME;\par
\par
   CREATE DOMAIN domain_1 AS \par
      TIMESTAMP(4) DEFAULT CURRENT_TIMESTAMP(4);\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 TIME(4) DEFAULT LOCALTIME(4);\par
\par
If a <default clause> is "DEFAULT ARRAY[]" or "DEFAULT ARRAY??(??)", an empty\par
array value is the target <collection type>'s default value. Here is an\par
example of a <default clause> with an empty array as the default value:\par
\par
   CREATE DOMAIN domain_1 AS \par
      INT ARRAY[3] DEFAULT ARRAY[];\par
\par
If a <default clause> is "DEFAULT NULL", the null value is the target Object's\par
default value. (The Object can't, of course, have a NOT NULL Constraint.) Here\par
is an example of a <default clause> with a null value as the default value:\par
\par
  CREATE TABLE Table_1 ( \par
     column_1 CHAR(15) DEFAULT NULL;\par
\par
[Obscure Rule] If a <default clause> that is part of an SQL-Schema statement\par
defines a default value that can't be represented in INFORMATION_SCHEMA\par
without truncation, your DBMS will return the SQLSTATE warning 0100B\par
"warning-default value too long for information schema".\par
\par
If you want to restrict your code to Core SQL, don't use "DEFAULT CURRENT_PATH" when defining a <default clause>.\par
\par
ALTER TABLE statement\par
\par
The ALTER TABLE statement changes a Base table's definition. The required syntax for the ALTER TABLE statement is: \par
\par
ALTER TABLE <Table name> <alter table action> \par
\par
   <alter table action> ::=\par
   ADD [ COLUMN ] <Column definition> | \par
   ALTER [ COLUMN ] <Column name> SET DEFAULT default value | \par
   ALTER [ COLUMN ] <Column name> DROP DEFAULT | \par
   ALTER [ COLUMN ] <Column name> ADD SCOPE <Table name list> | \par
   ALTER [ COLUMN ] <Column name> DROP SCOPE \{RESTRICT | CASCADE\} | \par
   DROP [ COLUMN ] <Column name> \{RESTRICT | CASCADE\} | \par
   ADD <Table Constraint> | \par
   DROP CONSTRAINT <Constraint name> \{RESTRICT | CASCADE\}\par
\par
    <Table name list> ::=\par
   (<Table name> [ \{,<Table name>\}... ]) | \par
   <Table name>\par
\par
The <Table name> must identify an existing Base table whose owner is either\par
the current <AuthorizationID> or a Role that the current <AuthorizationID> may\par
use. That is, only the <AuthorizationID> that owns the Table may alter it.\par
ALTER TABLE can be used to change a persistent Base table, a GLOBAL TEMPORARY\par
Base table or a created LOCAL TEMPORARY Base table, but you can't use it to\par
change a declared LOCAL TEMPORARY Base table.\par
\par
ADD [ COLUMN ] clause:\par
The effect of ALTER TABLE <Table name> ADD [COLUMN] <Column definition>, e.g.:\par
\par
   ALTER TABLE Table_1 ADD COLUMN \par
      column_1 SMALLINT DEFAULT 150 \par
         CONSTRAINT constraint_1 NOT NULL NOT DEFERRABLE;\par
\par
is that the Table named will increase in size by one Column: the Column\par
defined by the <Column definition>. The <keyword> COLUMN in the ADD [COLUMN]\par
clause is noise and can be omitted. For example, these two SQL statements are equivalent: \par
\par
   ALTER TABLE Table_1 ADD COLUMN \par
      column_1 SMALLINT DEFAULT 150; \par
\par
   ALTER TABLE Table_1 ADD \par
      column_1 SMALLINT DEFAULT 150; \par
\par
Adding a new Column to a Table has a four-fold effect: \par
      ## The degree (i.e.: the number of Columns) of the Table is increased by\par
1; the new Column's ordinal position in the Table is the new degree of the Table. \par
      ## Every <AuthorizationID> that has a SELECT, UPDATE, INSERT or\par
REFERENCES Privilege on all existing Columns of the Table receives a matching\par
set of Privileges on the new Column. The grantor of the new Privilege(s) is\par
the same as the grantor of the previous Privileges(s) and so is the\par
grantability of the new Privilege(s). \par
      ## The value of the new Column for every existing row of the Table is\par
set to its default value. \par
      ## The Column is added to the Column list of every UPDATE Trigger event\par
for all Triggers that act on the Table. However, adding a new Column to a\par
Table has no effect on any existing View definition or Constraint definition\par
that refers to the Table because implicit <Column name>s in these definitions\par
are replaced by explicit <Column name>s the first time the View or Constraint\par
is evaluated.\par
\par
ALTER [ COLUMN ] ... SET DEFAULT clause:\par
The effect of ALTER TABLE <Table name> ALTER [COLUMN] <Column name> SET DEFAULT default value, e.g.:\par
\par
   ALTER TABLE Table_1 ALTER COLUMN \par
      column_1 SET DEFAULT 200;\par
\par
is that the default value of the Column named will be changed. (You can use\par
this version of ALTER TABLE either to add a default value to a <Column\par
definition> or to change a Column's existing default value.) The <keyword>\par
COLUMN in the ALTER [COLUMN] clause is noise and can be omitted. For example,\par
these two SQL statements are equivalent: \par
\par
   ALTER TABLE Table_1 ALTER COLUMN \par
      column_1 SET DEFAULT CURRENT_TIME;\par
\par
   ALTER TABLE Table_1 ALTER \par
      column_1 SET DEFAULT CURRENT_TIME;\par
\par
The ALTER [COLUMN] ... SET DEFAULT options are: DEFAULT <literal>, DEFAULT\par
CURRENT_DATE, DEFAULT CURRENT_TIME(p), DEFAULT CURRENT_TIMESTAMP(p), DEFAULT\par
LOCALTIME(p), DEFAULT LOCALTIMESTAMP(p), DEFAULT USER, DEFAULT CURRENT_USER,\par
DEFAULT SESSION_USER, DEFAULT SYSTEM_USER, DEFAULT CURRENT_PATH, DEFAULT\par
ARRAY[], DEFAULT ARRAY??(??) and DEFAULT NULL -- see "<default clause>",\par
earlier in this chapter.\par
\par
ALTER [ COLUMN ] ... DROP DEFAULT clause:\par
The effect of ALTER TABLE <Table name> ALTER [COLUMN] <Column name> DROP DEFAULT, e.g.:\par
 \par
  ALTER TABLE Table_1 ALTER COLUMN \par
      column_1 DROP DEFAULT;\par
\par
is that the default value of the Column named will be removed from the <Column\par
definition>. (You'll get a syntax error if the Column's definition doesn't\par
include a default value.) The <keyword> COLUMN in the ALTER [COLUMN] clause is\par
noise and can be omitted. For example, these two SQL statements are equivalent: \par
\par
   ALTER TABLE Table_1 ALTER COLUMN \par
      column_1 DROP DEFAULT;\par
\par
   ALTER TABLE Table_1 ALTER \par
      column_1 DROP DEFAULT;\par
\par
ALTER [ COLUMN ] ... ADD SCOPE clause:\par
The effect of ALTER TABLE <Table name> ALTER [COLUMN] <Column name> ADD SCOPE <Table name list>, e.g.:\par
\par
   ALTER TABLE Table_2 ALTER COLUMN \par
      column_1 ADD SCOPE Table_1;\par
\par
is that a non-empty scope is added to the <Column definition> of the Column\par
named. This version of ALTER TABLE can only be used (a) for Columns with a\par
REF(UDT) <data type>, where the <reference type> descriptor includes an empty\par
scope and (b) where the Column named is not the referenceable Column of its\par
Table. (The Tables named in the SCOPE clause must, of course, be referenceable\par
Base tables whose structured type is the same as the structured type of the\par
referenced UDT.) The <keyword> COLUMN in the ALTER [COLUMN] clause is noise\par
and can be omitted. For example, these two SQL statements are equivalent: \par
\par
   ALTER TABLE Table_3 ALTER COLUMN \par
      column_1 ADD SCOPE (Table_1,Table_2);\par
\par
   ALTER TABLE Table_3 ALTER \par
      column_1 ADD SCOPE (Table_1,Table_2);\par
\par
ALTER [ COLUMN ] ... DROP SCOPE clause:\par
The effect of ALTER TABLE <Table name> ALTER [COLUMN] <Column name> DROP SCOPE RESTRICT, e.g.:\par
\par
   ALTER TABLE Table_2 ALTER COLUMN \par
      column_1 DROP SCOPE RESTRICT;\par
\par
is that the SCOPE clause in the definition of the Column named becomes empty,\par
provided that no impacted dereference operation is contained in an SQL\par
routine, in a View definition, in a Constraint or Assertion definition or in\par
the triggered action of a Trigger definition. (An impacted dereference\par
operation is a <dereference operation> that operates on the Column named, a\par
<method reference> that operates on the Column named or a <reference\par
resolution> that operates on the Column named.) That is, RESTRICT ensures that\par
only a scope with no dependent Objects can be made empty. If the Column is\par
operated on by any impacted dereference operation, ALTER TABLE ... DROP SCOPE\par
RESTRICT will fail.\par
\par
The effect of ALTER TABLE <Table name> ALTER [COLUMN] <Column name> DROP SCOPE CASCADE, e.g.:\par
\par
   ALTER TABLE Table_2 ALTER COLUMN \par
      column_1 DROP SCOPE CASCADE;\par
\par
is that the SCOPE clause in the definition of the Column named becomes empty\par
and that all Objects which contain an impacted dereference operation for the\par
Column are also dropped, with the CASCADE drop behaviour (except for\par
Assertions, where this is not applicable). This version of ALTER TABLE can\par
only be used (a) for Columns with a REF(UDT) <data type>, where the <reference\par
type> descriptor includes a SCOPE clause and (b) where the Column named is not\par
the referenceable Column of its Table. The <keyword> COLUMN in the ALTER\par
[COLUMN] clause is noise and can be omitted. For example, these two SQL\par
statements are equivalent: \par
\par
   ALTER TABLE Table_2 ALTER COLUMN \par
      column_1 DROP SCOPE RESTRICT;\par
\par
   ALTER TABLE Table_2 ALTER \par
      column_1 DROP SCOPE RESTRICT;\par
\par
DROP [ COLUMN ] clause:\par
The effect of ALTER TABLE <Table name> DROP [COLUMN] <Column name> RESTRICT, e.g.:\par
\par
   ALTER TABLE Table_1 DROP COLUMN \par
      column_1 RESTRICT;\par
\par
is that the Column named is removed from the definition of the Table that owns\par
it, provided that the Column is not referred to in any View definition, SQL\par
routine, Trigger definition or in any Constraint or Assertion definition (with\par
one exception) -- and, if the Column is the system-generated Column of its\par
Table, provided that the Table is not named in any SCOPE clause. That is,\par
RESTRICT ensures that only a Column with no dependent Objects can be\par
destroyed. If the Column is used by any other Object, ALTER TABLE ... DROP\par
COLUMN RESTRICT will fail. (Note: A Column referred to in a <Table Constraint>\par
of the Table that owns the Column can be dropped despite the RESTRICT\par
<keyword> if it is the only Column that the <Table Constraint> operates on.)\par
The Column named may not be the only Column in its Table, since a Table must\par
always contain at least one Column. If the Table is a typed Base table, the\par
Column named must be the Table's referenceable Column.\par
\par
The effect of ALTER TABLE <Table name> DROP [COLUMN] <Column name> CASCADE, e.g.:\par
\par
   ALTER TABLE Table_1 DROP COLUMN \par
      column_1 CASCADE;\par
\par
is that the Column named is removed from the definition of the Table that owns\par
it and that all Objects which are dependent on the Column are also dropped.\par
The <keyword> COLUMN in the DROP [COLUMN] clause is noise and can be omitted.\par
For example, these two SQL statements are equivalent: \par
\par
   ALTER TABLE Table_1 DROP COLUMN \par
      column_1 RESTRICT;\par
\par
   ALTER TABLE Table_1 DROP \par
      column_1 RESTRICT;\par
\par
Dropping a Column from a Table has a six-fold effect: \par
      ## The degree (i.e.: the number of Columns) of the Table is decreased by\par
1; the ordinal position of each Column that followed this Column in the\par
Table's definition is adjusted accordingly.\par
      ## The INSERT, UPDATE, SELECT and REFERENCES Privileges on the Column\par
are revoked (by the SQL special grantor, "_SYSTEM") from the <AuthorizationID>\par
that owns the Column's Table with a CASCADE drop behaviour, so that the same\par
Privileges are also revoked from all other <AuthorizationID>s. \par
      ## Any Trigger whose definition explicitly includes the Column is\par
dropped and any UPDATE Trigger whose definition includes the Column only\par
implicitly is changed so that it no longer operates on that Column.\par
      ## Any View, Constraint, Assertion or SQL routine whose definition\par
includes the Column is dropped with a CASCADE drop behaviour.\par
      ## If the Column is the system-generated Column of its Table, the\par
Table's definition is changed so that it no longer shows the Table to be a\par
referenceable Base table and the Table is removed from every SCOPE clause that\par
includes it.\par
      ## The data in the Column is destroyed.\par
\par
ADD <Table Constraint> clause:\par
The effect of ALTER TABLE <Table name> ADD <Table Constraint>, e.g.:\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT \par
      constraint_1 CHECK(column_1 IS NOT NULL) NOT DEFERRABLE;\par
\par
is that one <Table Constraint> is added to the definition of the Table named\par
-- see "<Table Constraint>" in our chapter on Constraints and Assertions.\par
\par
DROP CONSTRAINT clause:\par
The effect of ALTER TABLE <Table name> DROP CONSTRAINT <Constraint name> RESTRICT, e.g.:\par
\par
   ALTER TABLE Table_1 DROP CONSTRAINT constraint_1 RESTRICT;\par
\par
is that the Constraint named is removed from the definition of the Table that\par
owns it, provided that the Constraint is not used by any SQL routine, and\par
provided that no other Constraint and no View are dependent on the Constraint.\par
(A FOREIGN KEY Constraint is dependent on the UNIQUE or PRIMARY KEY Constraint\par
that names its referenced Columns and a View is dependent on a Constraint if\par
(a) it's a grouped View that includes a Column which isn't also referred to in\par
a set function and (b) if the Constraint is needed to conclude that there is a\par
known functional dependency between the group and the Column named.) That is,\par
RESTRICT ensures that only a Constraint with no dependent Objects can be\par
dropped. If the Constraint is used by any other Object, ALTER TABLE ... DROP\par
CONSTRAINT will fail.\par
\par
The effect of ALTER TABLE <Table name> DROP CONSTRAINT <Constraint name> CASCADE, e.g.:\par
\par
   ALTER TABLE Table_1 DROP CONSTRAINT constraint_1 CASCADE;\par
\par
is that the Constraint named is removed from the definition of the Table that\par
owns it and that all dependent Constraints, Views and SQL routines are also\par
dropped with a CASCADE drop behaviour. (Note: If the dropped Constraint caused\par
one or more Columns to have the "known not nullable" nullability\par
characteristic, then the affected Columns' nullability characteristic becomes\par
"possibly nullable" unless some other Constraint also constrains them to non-\par
null values.)\par
\par
If you want to restrict your code to Core SQL, don't use ALTER TABLE to drop a\par
Column from a Table, to change a <Column definition> using any of the\par
available options, to add a Constraint to a Table or to drop a Constraint from\par
a Table.\par
\par
DROP TABLE statement\par
\par
The DROP TABLE statement destroys a Base table. The required syntax for the\par
DROP TABLE statement is: \par
\par
DROP TABLE <Table name> \{RESTRICT | CASCADE\} \par
\par
DROP TABLE destroys a Base table and its data. The <Table name> must identify\par
an existing Base table whose owner is either the current <AuthorizationID> or\par
a Role that the current <AuthorizationID> may use. That is, only the\par
<AuthorizationID> that owns the Table may drop it. DROP TABLE can be used to\par
drop a persistent Base table, a GLOBAL TEMPORARY Base table or a created LOCAL\par
TEMPORARY Base table, but you can't use it to drop a declared LOCAL TEMPORARY\par
Base table.\par
\par
The effect of DROP TABLE <Table name> RESTRICT, e.g.:\par
\par
   DROP TABLE Table_1 RESTRICT;\par
\par
is that the Table named is destroyed, provided that the Table (a) has no\par
subtables, (b) is not referred to in any View definition, Assertion\par
definition, Trigger definition or SQL routine, (c) is not referred to in any\par
<Table Constraint> that isn't owned by this Table and (d) doesn't fall within\par
the scope of any other Table or an SQL parameter. That is, RESTRICT ensures\par
that only a Table with no dependent Objects can be destroyed. If the Table is\par
used by any other Object, DROP TABLE ... RESTRICT will fail.\par
\par
The effect of DROP TABLE <Table name> CASCADE, e.g.:\par
\par
   DROP TABLE Table_1 CASCADE;\par
\par
is that the Table named is destroyed.\par
\par
Successfully destroying a Table has a five-fold effect:\par
      ## The Base table named (and all the data it contains) is destroyed. \par
      ## All subtables of the Table are dropped with a CASCADE drop behaviour.\par
      ## For every supertable of the Table, all superrows of the Table's rows\par
are deleted and the Table is removed from the supertable's list of direct\par
subtables.\par
      ## All Privileges held on the Table by the <AuthorizationID> that owns\par
it are revoked (by the SQL special grantor, "_SYSTEM") with a CASCADE revoke\par
behaviour, so that all Privileges held on the Table by any other\par
<AuthorizationID> are also revoked.\par
      ## All SQL routines, Views, Constraints, Assertions and Triggers that\par
depend on the Table are dropped with a CASCADE drop behaviour.\par
\par
If you want to restrict your code to Core SQL, don't use the CASCADE drop\par
behaviour for your DROP TABLE statements.\par
\par
CREATE VIEW statement\par
\par
The CREATE VIEW statement names a new View and defines the query which, when\par
evaluated, determines the rows of data that are shown in the View. The\par
required syntax for the CREATE VIEW statement is: \par
\par
CREATE [ RECURSIVE ] VIEW <Table name> \par
[ (<Column name> [ \{,<Column name>\} ...) ] \par
AS <query expression> \par
[ WITH [ \{CASCADED | LOCAL\} ] CHECK OPTION ]\par
\par
Name clause:\par
CREATE VIEW defines a new derived Table, or View. A View is owned by the\par
Schema it belongs to. \par
      ## The <Table name> identifies the View and the Schema that it belongs\par
to. A <Table name> that includes an explicit <Schema name> qualifier belongs\par
to the Schema named. A <Table name> that does not include an explicit <Schema\par
name> qualifier belongs to the SQL-session default Schema. The <Table name>\par
must be unique (for all Base tables and Views) within the Schema that owns it.\par
\par
If CREATE VIEW is part of a CREATE SCHEMA statement, the <Table name>, if\par
explicitly qualified, must include the <Schema name> of the Schema being\par
created; that is, it isn't possible to create a View belonging to a different\par
Schema from within CREATE SCHEMA. For example, this SQL statement will not\par
return an error because the <Table name> will default to include the\par
qualifying <Schema name>:\par
\par
   CREATE SCHEMA bob \par
      CREATE TABLE Table_1 (column_1 SMALLINT, column_2 CHAR(5))\par
      CREATE VIEW View_1 (column_1) AS \par
         SELECT column_1 FROM Table_1;\par
      -- creates a View called BOB.VIEW_1 in Schema BOB \par
\par
This SQL statement will not return an error either because the\par
<Table name> explicitly includes a qualifying <Schema name> that matches the\par
name of the Schema being created:\par
\par
   CREATE SCHEMA bob \par
      CREATE TABLE bob.Table_1 ( \par
         column_1 SMALLINT, column_2 CHAR(5))\par
      CREATE VIEW bob.View_1 (column_1) AS \par
         SELECT column_1 FROM bob.Table_1;\par
      -- creates a View called BOB.VIEW_1 in Schema BOB \par
\par
But this SQL statement will return an error because the <Table name> explicitly includes a qualifying <Schema name> that is different from the name of the Schema being created:\par
\par
   CREATE SCHEMA bob \par
      CREATE TABLE Table_1 (column_1 SMALLINT, column_2 CHAR(5))\par
      CREATE VIEW sam.View_1 (column_1) AS \par
         SELECT column_1 FROM bob.Table_1;\par
      -- tries to create a View belonging to Schema SAM inside Schema BOB; illegal syntax\par
\par
Privileges:\par
If CREATE VIEW is executed as a stand-alone SQL statement, the current\par
<AuthorizationID> must either be the owner of the Schema that this new View\par
belongs to, or the Schema's owner must be a Role that the current\par
<AuthorizationID> may use. That is, only the owner of a Schema can create\par
Views for that Schema. The current <AuthorizationID> must also have the SELECT\par
Privilege on every Column used in the View's query definition.\par
\par
In addition to creating a View, CREATE VIEW also causes the SQL special\par
grantor, "_SYSTEM", to grant Privileges on the View to the Schema owner\par
<AuthorizationID> (that is, the <AuthorizationID creating the View). Your\par
Privileges on a View stem from your Privileges on the underlying Tables that\par
make up the View. That is, you get the same Privileges on a View that you hold\par
on the Tables/Columns used in the View's query definition -- with the proviso\par
that if you have the UPDATE, INSERT and/or DELETE Privileges on a Table and\par
you're creating a non-updatable View, those Privileges will not cascade. So:\par
when you create a View, "_SYSTEM" will grant you Table Privileges (any of\par
INSERT, SELECT, UPDATE, DELETE and REFERENCES that are applicable) on the new\par
View, as well as Column Privileges (any of SELECT, INSERT, UPDATE and\par
REFERENCES that are applicable) on every Column of the new View. If your\par
Privileges on the underlying Tables are grantable, your Privileges on the View\par
will be too.\par
\par
That is, Views are Tables, but when it comes to Privileges, there are some big\par
differences between the things that happen for Base tables, and the things\par
that happen for Views. The main difference, understandable if you consider\par
that operations on Views are ultimately operations on Base tables, is this:\par
the mere fact that you own a View doesn't mean that you have ALL PRIVILEGES\par
for that View. Usually you either "inherit" View Privileges (because you\par
possess the Privilege on the underlying Table), or you get them explicitly\par
(because someone GRANTs them to you). So:\par
      ## In order to create the View: You must have all Privileges necessary\par
to perform the View's query on the underlying Tables.\par
      ## If you own the View: You have one automatic Privilege -- you may\par
destroy it using the DROP VIEW statement.\par
      ## If you have the SELECT Privilege on every Column that your View is\par
based on, you get the SELECT Privilege on the View, so you may SELECT from the\par
View. If all of your underlying SELECT Privileges are grantable, so is your\par
SELECT Privilege on the View. You inherit REFERENCES Privileges in the same\par
way: if you have the REFERENCES Privilege on every Column that your View is\par
based on, you get the REFERENCES Privilege on the View, so you may use the\par
View in an Assertion.\par
      ## You inherit INSERT, UPDATE and DELETE Privileges in the same way,\par
with a major exception: these Privileges cannot exist if the View is not\par
updatable. That explains why, when you try to update a non-updatable View, the\par
likely error is "Syntax error or access violation" -- the ultimate cause is\par
the non-updatability, but the immediate cause at update time is that you lack\par
the appropriate Privilege.\par
      ## In addition to the inherited Privileges, you may hold Privileges\par
which are explicitly granted to you. If you don't own the View, this is the\par
only way to get Privileges on it -- you do not hold any Privileges on a View\par
you don't own merely because you own an underlying Table.\par
      ## If your Privilege on an underlying Table is revoked, your Privilege\par
on the View you created using that Privilege is also revoked. This may cause\par
the entire View to be destroyed.\par
\par
<Column name> clause:\par
The optional parenthesized <Column name> clause of the CREATE VIEW statement\par
explicitly names the View's Columns. (As is usual with Tables, each Column\par
must have a name that is unique -- for all Columns -- within the View.) If you\par
omit this clause, the View's Columns will inherit the names of the Columns\par
they are based on. For example, consider these two SQL statements:\par
\par
   CREATE TABLE Table_1 (column_1 SMALLINT, column_2 CHAR(5));\par
\par
   CREATE VIEW View_1 AS SELECT column_1 FROM Table_1;\par
\par
Because the <Column name> clause is omitted, the View's Column will be named\par
COLUMN_1 -- just like the Column it's based on. Here's another example:\par
\par
   CREATE TABLE Table_1 (column_1 SMALLINT, column_2 CHAR(5));\par
\par
   CREATE VIEW View_1 (view_column) AS \par
      SELECT column_1 FROM Table_1;\par
\par
Because the <Column name> clause is included, the View's Column will be named\par
VIEW_COLUMN -- even though the Column it's based on has a different name. Note\par
that if you do use the <Column name> clause, you must provide a name for every\par
one of the View's Columns -- it isn't possible to name some, and allow the\par
others to default.\par
\par
There are times when you may not omit the <Column name> clause. You must\par
explicitly name a View's Columns if (a) any of the Columns are derived through\par
the use of a set function, scalar function, <literal> or expression, since\par
none of these have a <Column name> which CREATE VIEW can inherit, (b) the same\par
name would be inherited for more than one of the View's Columns, usually the\par
case when the View is derived from a join of multiple Tables or (c) when\par
you're defining a RECURSIVE View (see below). Here's an example that shows a\par
View definition where the <Column name> clause is mandatory because the second\par
and third Columns have no name to inherit:\par
\par
   CREATE VIEW View_1 (view_column_1, view_column_2, view_column_3) AS \par
      SELECT   column_1, column_1+25, 'explanation' \par
      FROM     Table_1;\par
\par
Note, however, that this CREATE VIEW statement would give you the same result:\par
\par
   CREATE VIEW View_1 AS \par
      SELECT   column_1 AS view_column_1, \par
               column_1+25 AS view_column_2, \par
               'explanation' AS view_column_3 \par
      FROM     Table_1;\par
\par
that is, you can also use the AS <Column name> clause in the select list of\par
your View query to provide explicit names for the View's Columns.\par
\par
AS clause:\par
The AS clause of the CREATE VIEW statement defines the query that determines\par
the data you'll see each time you look at the View. At any point in time, a\par
View's data consists of the rows that result if its query definition were\par
evaluated. If the query is updatable, then your View is an updatable View.\par
Normally, a "query" is a form of SELECT statement (it may be also be VALUES or\par
TABLE; we'll define "query" more thoroughly in a later chapter), so you can\par
define a View using pretty well any combination of predicates and search\par
conditions. There are, however, some restrictions:\par
      ## The query may not contain a host variable or SQL parameter reference.\par
      ## The query may not refer to any declared LOCAL TEMPORARY Tables.\par
      ## The query may not use an expression which would result in a View Column with a NO COLLATION coercibility attribute.\par
      ## The query may not include any references to the View you're defining unless you're explicitly defining a RECURSIVE View.\par
\par
A View's Columns inherit their <data type> and other attributes and Constraints from the Columns they're based on. \par
\par
[Obscure Rule] If a View's query can't be represented in INFORMATION_SCHEMA\par
without truncation, your DBMS will return the SQLSTATE warning 0100A\par
"warning-query expression too long for information schema". If you define a\par
View with a query that includes a GROUP BY and/or a HAVING clause that isn't\par
in a subquery, the View is known as a grouped View. \par
\par
## Macros and Materializers\par
When materializing a View, your DBMS's problem is to transform the View's\par
query definition into a query on the Base table(s) that the View is based on.\par
There are two ways to do this.\par
\par
The Macro, or Inline, View --\par
The DBMS sees from the View's query that View "V" is based on Base table "T",\par
so it simply replaces all occurrences of V with T, and all occurrences of V's\par
<Column name>s with T's <Column name>s. Thus, for example:\par
\par
   SELECT V.column_1 FROM V WHERE V.column_2 = 7;\par
\par
becomes:\par
\par
   SELECT T.column_1 FROM T WHERE T.column_2 = 7;\par
\par
This is conceptually the same as the way that an assembler handles a macro,\par
hence the name. A good DBMS will do the entire transformation during the\par
prepare stage, outside the runtime path, so it is very unlikely that a View\par
query will be measurably slower than a query on the underlying Table if a\par
macro transform is possible. However, here's an example where it's not possible:\par
\par
   CREATE VIEW View_1 AS \par
      SELECT g, COUNT(*) AS g_count FROM Table_1 GROUP BY g;\par
\par
   SELECT AVG(g_count) FROM View_1 WHERE g_count = 5;\par
\par
This SELECT statement can't work because the macro transform would evaluate to:\par
\par
   SELECT AVG(COUNT(*)) FROM Table_1 WHERE COUNT(*)=5 GROUP BY g;\par
\par
and that's not legal SQL syntax.\par
\par
The Materialized View --\par
The DBMS makes a hidden "temporary Base table" with the same definition as the\par
Columns in the View, and then populates the temporary Table using the View's\par
query. Thus it would handle our difficult-to-do-with-a-macro View (above) like this:\par
\par
   CREATE LOCAL TEMPORARY TABLE Some_Table_Name ( \par
      g_count INTEGER);\par
\par
   INSERT INTO g_count \par
      SELECT COUNT(*) FROM Table_1 GROUP BY g;\par
\par
Now the transform is of the Table expression only, so:\par
\par
   SELECT AVG(g_count) FROM View_1 WHERE g_count = 5;\par
\par
becomes:\par
\par
   SELECT AVG(g_count) FROM Some_Table_Name;\par
\par
A materialized View is more flexible and is easier to implement than a macro\par
View because the method of creation is always the same, and because any query\par
expression is transformable. On the negative side of the ledger, it usually\par
takes extra time to populate the temporary Table: the DBMS is not just\par
"selecting from Table A", it's "selecting from Table A and putting the results\par
in Table B, then selecting from Table B". And, if we consider any operation\par
other than SELECT or REFERENCE, we quickly see that the temporary Table is\par
useless -- for example, when we INSERT into a View we want the insertion to\par
happen on the actual Table, not on some ephemeral ad-hoc copy of the actual\par
Base table that disappears when we SELECT again. So, we expect that a good\par
DBMS will use macro Views for simple queries and switch to materialized Views\par
when the going gets rough.\par
\par
## Updatable Views\par
We have seen that, when we SELECT from a View, the DBMS will transform our\par
request into some equivalent request which is a SELECT from the underlying\par
Base table(s). Now, UPDATE or INSERT or DELETE operations ("updates" for\par
short) must also involve a change to the underlying Base tables, otherwise\par
they would be pointless. So, for updates on Views, your DBMS must reverse the\par
transformation. This is often difficult or impossible. The SQL-92 rules for\par
updatability are:\par
      ## The query must be a single "SELECT ..." on a single Table, so Views\par
are not updatable if the SELECT contains select functions (UNION, INTERSECT,\par
EXCEPT, CORRESPONDING) or join operators (JOIN or joining commas as in "FROM\par
a,b,c"). The query may also be "TABLE <Table name" because "TABLE <Table\par
name>" is, at bottom, a SELECT. Rule 1 is relaxed in SQL3, which has the big\par
effect that you can update Views of joins.\par
      ## The select list may contain only <Column name>s and [AS name] clauses. Therefore, this SQL statement defines an updatable View:\par
\par
   CREATE VIEW View_1 AS SELECT a,b,c FROM Table_1;\par
\par
but these SQL statements do not:\par
\par
   CREATE VIEW View_1 AS SELECT a+5 FROM Table_1;\par
\par
   CREATE VIEW View_1 AS SELECT 'x' FROM Table_1;\par
\par
   CREATE VIEW View_1 AS SELECT a COLLATE polish FROM Table_1;\par
\par
(These are all theoretically updatable Views, but our main concern here is\par
with what the SQL Standard regards as updatable). Rule 2 is irritating because\par
many arithmetic and string operations are in fact reversible -- but the DBMS\par
doesn't know it.\par
      ## There must be no implicit or explicit grouping, so the <keyword>s\par
DISTINCT or GROUP BY or HAVING, or any set function, may not appear in the\par
main query (though they may appear in that query's subqueries), nor may any\par
subqueries be correlated subqueries (that is, they may not themselves refer to\par
the Table named in the outer query). Rule 3 cannot be gotten around. For\par
example you can't change the average salary: you have to change the individual\par
salaries (Joke: unless you're the Canadian Anti-Poverty Commission which once\par
announced that "most Canadians make less than the average wage"). However, the\par
rule is syntax-based -- you might find that, in fact, DISTINCT is a no-op\par
(that is, the decision "is it distinct?" is a matter of syntax, not of fact).\par
      ## The query may not refer to the View being defined.\par
      ## If there are multiple levels of View (that is, Views of Views), the\par
above rules must be followed at every level -- that is, if the "single Table"\par
in the query expression is not a Base table, it must be an updatable View.\par
Sometimes, as a very general summation of these rules, people say "a View is\par
updatable only if it represents a subset of the rows and Columns of a single\par
Base table".\par
\par
What actually happens when you update a View? Your DBMS performs the operation\par
on the underlying Base table. For these two SQL statements:\par
\par
   DELETE FROM View_1;\par
\par
   UPDATE View_1 SET column_1 = value;\par
\par
the operation transforms straightforwardly to:\par
\par
   DELETE FROM Table_1;\par
\par
   UPDATE Table SET column_1 = value;\par
\par
For INSERT operations, there is an additional problem if the View is based on\par
only a subset of the Columns of the underlying Base table. In that case, the\par
rest of the Base table's Columns all are set to their default value. For example:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT DEFAULT 12, \par
      column_2 CHAR(5) DEFAULT 'hello');\par
\par
   CREATE VIEW View_1 (view_column) AS\par
      SELECT column_1 FROM Table_1;\par
\par
   INSERT INTO View_1 (view_column) VALUES (28);\par
\par
The result of the INSERT operation on the View is:\par
\par
   INSERT INTO Table_1 (column_1, column_2) \par
      VALUES (28,'hello');\par
\par
WITH CHECK OPTION clause:\par
Consider these two SQL statements:\par
\par
   CREATE VIEW View_1 (view_col_1, view_col_2) AS\par
      SELECT column_1,column_2 FROM Table_1 WHERE column_1 =5;\par
\par
   UPDATE View_1 SET view_col_1=4;\par
\par
The View definition restricts it to those rows of TABLE_1 where COLUMN_1 has a\par
value of 5 -- but as soon as the UPDATE operation succeeds, there will be no\par
such rows. To the user, the apparent effect is that all the rows of VIEW_1\par
"disappear" -- as if they were deleted instead of updated. That is okay and\par
legal, but doesn't it contradict the View idea? That is, if someone is\par
restricted during SELECT to finding only those rows that match the condition\par
"column_1=5", why should he/she/it be allowed to UPDATE or INSERT rows that do\par
not follow the same restriction?\par
\par
The solution is to use the optional WITH CHECK OPTION clause in your updatable\par
View definitions (it is valid only if you are defining an updatable View).\par
Adjust the two SQL statements to:\par
\par
   CREATE VIEW View_1 (view_col_1, view_col_2) AS\par
      SELECT column_1,column_2 FROM Table_1 WHERE column_1 =5\par
      WITH CHECK OPTION;\par
\par
   UPDATE View_1 SET view_col_1=4;\par
\par
and now the UPDATE statement will fail: your DBMS will return the SQLSTATE\par
error 44000 "with check option violation". The effect of WITH CHECK OPTION is\par
to say: "the WHERE clause defines what is in the View and you cannot go\par
outside the bounds of that definition in any INSERT or UPDATE operation".\par
\par
A View's CHECK OPTION is effectively a Constraint. That is, there is a\par
similarity between the two definitions in this example:\par
\par
      -- Constraint on Base table\par
      CREATE TABLE Table_1 (\par
         column_1 INT,\par
         CHECK (column_1<5000));\par
\par
      INSERT INTO Table_1 VALUES(6000);\par
      -- results in error\par
\par
      -- Constraint on View\par
      CREATE TABLE Table_1 (column_1 INT);\par
\par
      CREATE VIEW View_1 AS \par
         SELECT column_1 FROM Table_1  WHERE column_1<5000;\par
\par
      INSERT INTO View_1 VALUES(6000);\par
      -- results in error\par
\par
If WITH CHECK OPTION is included in a View definition, then all INSERT and\par
UPDATE operations on that View will be checked to ensure that every new row\par
satisfies the View's query conditions. Such "View Constraints" are popular,\par
probably because the CREATE VIEW statement has been around for a longer time\par
than the Base table CHECK Constraint. There are a few downsides you should be\par
aware of, though, if you use such View Constraints:\par
      ## You do not have the option of deferring Constraint checking. All\par
checks happen at the end of the INSERT or UPDATE operation.\par
      ## It is somewhat easier to violate a View Constraint than a proper\par
Table Constraint.\par
      ## The SQL Standard does not make it clear what the effect should be if\par
NULLs are used (and therefore make the result of the Constraint check UNKNOWN\par
rather than TRUE or FALSE). For the Base table insertion:\par
\par
   INSERT INTO Table_1 VALUES (NULL);\par
\par
the answer is clear: there is no error and so the INSERT is allowed. Presumably the same is true for the View insertion:\par
\par
   INSERT INTO View_1 VALUES (NULL);\par
\par
but without a guarantee, why risk it?\par
\par
Regardless of the reasons you use WITH CHECK OPTION -- as a general\par
constrainer or as an encapsulation enforcer -- the View must obey these rules:\par
      ## The WHERE clause must be "deterministic" (this only means that you\par
can't use Columns which might change in value, such as CURRENT_TIME. For a\par
more complete explanation, see our chapter on Constraints and Assertions.\par
      ## The View must be updatable.\par
\par
Suppose you create Views within Views within Views, for example:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 INTEGER, \par
      column_2 INTEGER, \par
      column_3 INTEGER,\par
      column_4 INTEGER,\par
      column_5 INTEGER);\par
\par
   CREATE VIEW View_1 AS \par
      SELECT * FROM Table_1 WHERE column_1 <> 0;\par
\par
   CREATE VIEW View_2 AS \par
      SELECT * FROM View_1 WHERE column_2 <> 0 \par
      WITH CASCADED CHECK OPTION;\par
\par
   CREATE VIEW View_3 AS \par
      SELECT * FROM View_2 WHERE column_3 <> 0;\par
\par
   CREATE VIEW View_4 AS \par
      SELECT * FROM View_3 WHERE column_4 <> 0 \par
      WITH LOCAL CHECK OPTION;\par
\par
   CREATE VIEW View_5 AS \par
      SELECT * FROM View_4 WHERE column_5 <> 0;\par
\par
** JARGON: A Table used in the definition of another Table is an "immediately\par
underlying" Table; thus Table TABLE_1 underlies View VIEW_1. Because VIEW_1 is\par
then used in the definition of VIEW_2, we say that VIEW_1 immediately\par
underlies VIEW_2 and that TABLE_1 indirectly underlies VIEW_2. Taken together,\par
both TABLE_1 and VIEW_1 "generally underlie" VIEW_2: one indirectly and the\par
other immediately.\par
\par
Our example contains a variety of WITH CHECK OPTION clauses. To see what their\par
effects are, we will try to do an INSERT for each of the Views. We begin with VIEW_1:\par
\par
   INSERT INTO View_1 VALUES (0,0,0,0,0);\par
\par
This INSERT operation is legal: there is no check option in the View's\par
definition, so the row is inserted into TABLE_1 despite the fact that we won't\par
be able to see that effect by looking at VIEW_1.\par
\par
Here's an INSERT into VIEW_2:\par
\par
   INSERT INTO View_2 VALUES (1,0,1,1,1);\par
\par
This INSERT operation will fail: there is a check option saying that the\par
second column may not be 0. No surprise there, but this will fail too!:\par
\par
   INSERT INTO View_2 VALUES (0,1,1,1,1);\par
\par
When you define a View with WITH CASCADED CHECK OPTION (or with WITH CHECK\par
OPTION; they mean the same thing because CASCADED is the default), then the\par
check applies not only to the View you're updating, but to every View that\par
underlies it -- and VIEW_1 contains a condition that disallows zeros in COLUMN_1.\par
\par
Here are two INSERTs into VIEW_3:\par
\par
   INSERT INTO View_3 VALUES (0,1,1,1,1);\par
\par
   INSERT INTO View_3 VALUES (1,0,1,1,1);\par
\par
These INSERT operations will also fail: although VIEW_3 has no check option,\par
its underlying Views do and so operations on VIEW_3 may not violate their\par
conditions. But, since VIEW_3 has no check option of its own, this INSERT is legal:\par
\par
   INSERT INTO View_3 VALUES (1,1,0,1,1);\par
\par
because there is no check on VIEW_3, or on its underlying Views, that disallows zeros in COLUMN_3.\par
\par
Now, here's an INSERT into VIEW_4:\par
\par
   INSERT INTO View_4 VALUES (0,0,0,1,1);\par
\par
This INSERT operation is legal. For VIEW_4, there is only one check condition\par
in effect -- that COLUMN_4 may not be zero -- and this condition is satisfied\par
by the INSERT. VIEW_3's condition -- that COLUMN_3 may not be zero -- doesn't\par
have to be satisfied because VIEW_4 was defined with WITH LOCAL CHECK OPTION.\par
This means that, while VIEW_4's condition will be checked, the conditions of\par
its immediately underlying View will only be checked if that View was defined\par
with a WITH CHECK OPTION clause (which is not the case for VIEW_3). It also\par
means that the conditions of its indirectly underlying Views (that is, of\par
VIEW_1 and VIEW_2) won't be checked at all, regardless of their WITH CHECK\par
OPTION definitions.\par
\par
Finally, here's an INSERT into VIEW_5:\par
\par
   INSERT INTO View_5 VALUES (0,0,0,1,0);\par
\par
Once again, this INSERT operation is legal: VIEW_5 has no WITH CHECK OPTION\par
clause, and so its condition is not checked. However, the View it's based on\par
(VIEW_4) does have a WITH CHECK OPTION clause, and so this INSERT statement will fail:\par
\par
   INSERT INTO View_5 VALUES (1,1,1,0,1);\par
\par
because VIEW_4's condition is checked for any INSERT or UPDATE operation on\par
VIEW_5. But, since VIEW_4 was defined with WITH LOCAL CHECK OPTION, the View\par
immediately underlying VIEW_4 is the only other View whose conditions will be\par
checked -- and then only if that View was defined with a WITH CHECK OPTION\par
clause. Thus, for this example, operations on VIEW_5 are affected only by the\par
conditions set for VIEW_4 -- COLUMN_1 may be zero, COLUMN_2 may be zero and\par
COLUMN_3 may be zero because the conditions for VIEW_1, VIEW_2 and VIEW_3 don't apply.\par
\par
Our example is fairly complex because we mixed all the possibilities together.\par
In real life, one avoids the complexity by declaring a company policy: always\par
use WITH CASCADED CHECK OPTION.\par
\par
RECURSIVE Views:\par
Here is a contrived, illegal example of two Views that reference each other:\par
\par
   CREATE SCHEMA some_schema \par
      CREATE TABLE Table_1 (column_1 INTEGER) \par
      CREATE VIEW View_1 (view_1_col_1,view_1_col_2,view_1_col_3) AS \par
         SELECT column_1,view_2_col_1,'A' FROM Table_1,View_2 \par
      CREATE VIEW View_2 (view_2_col_1,view_2_col_2,view_2_col_3) AS \par
         SELECT view_1_col_1,column_1,'B' FROM Table_1,View_1;\par
\par
Although the definition of VIEW_1 is legal, the definition of VIEW_2 is not\par
because it defines a recursive View: a View whose query refers to the View\par
being defined -- that is, since VIEW_2 is based on VIEW_1, and since VIEW_1 is\par
based on VIEW_2, ultimately, VIEW_2 is based on itself. We used the CREATE\par
SCHEMA statement for this example because, within CREATE SCHEMA, each Column\par
in each View derives ultimately from either a Base table Column or a\par
<literal>, so recursive Views are possible in theory. In reality, though,\par
current DBMSs don't allow them and neither does the SQL-92 Standard. In SQL3,\par
though, recursion is allowed provided it's explicit and provided that CREATE\par
VIEW includes a <Column name> clause but no WITH CHECK OPTION clause. Thus,\par
with SQL3 only, this SQL statement is possible:\par
\par
   CREATE SCHEMA some_schema \par
      CREATE TABLE Table_1 (column_1 INTEGER) \par
      CREATE VIEW View_1 (view_1_col_1,view_1_col_2,view_1_col_3) AS \par
         SELECT column_1,view_2_col_1,'A' FROM Table_1,View_2 \par
      CREATE RECURSIVE VIEW View_2 (view_2_col_1,view_2_col_2,view_2_col_3) AS\par
         SELECT view_1_col_1,column_1,'B' FROM Table_1,View_1;\par
\par
If you want to restrict your code to Core SQL, don't define any RECURSIVE\par
Views, don't use the EXCEPT, INTERSECT or CORRESPONDING operators in your View\par
queries and don't use the optional CASCADED or LOCAL levels specification in\par
your check clauses -- always define Views only with WITH CHECK OPTION alone.\par
\par
Getting More Out Of Views\par
\par
A View's virtue is that it isn't the whole picture. Something is hidden.\par
Hidden is good. In the following descriptions, which all show Views being put\par
to some useful purpose, the same refrain could be sung each time: Views Hide -- Good.\par
\par
One thing we'd like to hide, or abstract, is the retrieval method. For a mailing list, the method might look like this:\par
\par
   SELECT Customers.given, \par
          Customers.surname, \par
          Customers.city, \par
          Customers.address\par
   FROM   Customers\par
   UNION \par
   SELECT Suppliers.given, \par
          Suppliers.surname, \par
          Suppliers.city, \par
          Suppliers.address\par
   FROM Suppliers;\par
\par
Well, some people, sometimes, need to know that the mailing list is a union of\par
data from two Tables. But when you print your list, all you really want to say\par
is:\par
   \par
   SELECT given, surname, city, address FROM Mailouts;\par
\par
This is not a mere matter of "reducing keystrokes". The idea is to remove\par
information which is not necessary for the task at hand. \par
\par
Another thing we want to hide is details. For example, there are some people\par
who only care about department-level sales figures, as opposed to individual\par
sales. For them we want to say:\par
\par
   CREATE VIEW View_1 AS\par
      SELECT SUM(sales_amount), manager \par
      FROM Sales \par
      GROUP BY manager;\par
\par
... and they can select whatever they like from VIEW_1 (which is an example of\par
a "grouped View").\par
\par
The next thing we want to hide is secrets. We could grant PUBLIC access to\par
some grouped Views, or we could grant PUBLIC access to only certain Columns in\par
certain Tables. In fact, granting on Column-subset Views is the normal way to\par
do a by-Column GRANT (see our chapter on AuthorizationIDs).\par
\par
** Tip: Make a one-row permanent Table with:\par
\par
   CREATE VIEW View_name AS VALUES (1,2,3);\par
\par
To create one-row Tables which you never intend to update, this is more\par
convenient than using the CREATE TABLE statement because you can forget about\par
file storage. If your DBMS doesn't allow the use of the <keyword> VALUES for a\par
View's <query expression>, make your View with a selection from a one-row\par
Table in INFORMATION_SCHEMA, e.g.:\par
\par
   CREATE VIEW View_name AS\par
      SELECT 1,2,3 FROM INFORMATION_SCHEMA.SQL_LANGUAGES;\par
\par
DROP VIEW statement\par
\par
The DROP VIEW statement destroys a View. The required syntax for the DROP VIEW statement is: \par
\par
DROP VIEW <Table name> \{RESTRICT | CASCADE\} \par
\par
DROP VIEW destroys a View, but does not destroy any data: the data in the\par
underlying Tables will remain. The <Table name> must identify an existing View\par
whose owner is either the current <AuthorizationID> or a Role that the current\par
<AuthorizationID> may use. That is, only the <AuthorizationID> that owns the\par
View may drop it.\par
\par
The effect of DROP VIEW <Table name> RESTRICT, e.g.:\par
\par
   DROP VIEW View_1 RESTRICT;\par
\par
is that the View named is destroyed, provided that the View is not referred to\par
in any other View definition and is not referred to in any Constraint\par
definition, Assertion definition, Trigger definition or SQL routine. That is,\par
RESTRICT ensures that only a View with no dependent Objects can be destroyed.\par
If the View is used by any other Object, DROP VIEW ... RESTRICT will fail.\par
\par
The effect of DROP VIEW <Table name> CASCADE, e.g.:\par
\par
   DROP VIEW View_1 CASCADE;\par
\par
is that the View named is destroyed.\par
\par
Successfully destroying a View has a three-fold effect:\par
      ## The View named is destroyed. \par
      ## All Privileges held on the View by the <AuthorizationID> that owns it\par
are revoked (by the SQL special grantor, "_SYSTEM") with a CASCADE revoke\par
behaviour, so that all Privileges held on the View by any other\par
<AuthorizationID> are also revoked.\par
      ## All SQL routines, Views, Constraints, Assertions and Triggers that depend on the View are dropped with a CASCADE drop behaviour.\par
\par
If you want to restrict your code to Core SQL, don't use the CASCADE drop behaviour for your DROP VIEW statements.\par
\par
DECLARE TABLE statement\par
\par
The DECLARE TABLE statement names a new declared local temporary Base table\par
and defines the Table's Columns and Constraints. The required syntax for the\par
DECLARE TABLE statement is: \par
\par
DECLARE LOCAL TEMPORARY TABLE [ MODULE. ]<Table name>\par
   (<table element> [ \{,<table element>\}... ])\par
   [ ON COMMIT \{PRESERVE ROWS | DELETE ROWS\} ]\par
\par
         <table element> ::=\par
         <Column definition> | \par
         <Table Constraint> | \par
         LIKE <Table name> | \par
         <Column name> WITH OPTIONS <column option list>\par
\par
DECLARE LOCAL TEMPORARY TABLE defines a new declared local temporary Base\par
table. You can only use this SQL statement within a MODULE statement. Declared\par
temporary Tables aren't part of the Table metadata in INFORMATION_SCHEMA.\par
\par
In effect, a declared local temporary Table does not exist until it is invoked\par
by an SQL-client Module during an SQL-session. Once invoked, it will only be\par
visible to the Module in which it is declared -- it will not be visible to\par
other users. At the end of the SQL-session, all declared temporary Tables\par
invoked during the SQL-session are dropped.\par
      ## The <Table name> identifies the Table and the Module that it belongs\par
to and must be unique (for all declared local temporary Base tables) within\par
the Module that owns it. Because a declared local temporary Table is distinct\par
within an SQL-client Module within an SQL-session, the Schema it belongs to is\par
a Schema determined by your DBMS, so don't add a qualifying <Schema name> when\par
you declare a temporary Table. (In effect, your DBMS will fix a qualifying\par
<Schema name> for a declared local temporary Table based on the DBMS's name\par
for the SQL-session in which you invoke that Table, coupled with its name for\par
the SQL-client Module that contains that Table's declaration.) Whenever you\par
refer to a declared local temporary Table, you must preface the <Table name> with "MODULE.".\par
\par
The <table element> clause defines the structure of the Table's contents: it\par
tells you what sort of data the Table contains. This clause is contains a list\par
of table elements, such as Column and Table Constraint definitions, that are\par
just like the elements we described for the CREATE TABLE statement -- see\par
those descriptions for detailed information. Every temporary Table declaration\par
has to contain at least one <Column definition>. Here are two equivalent examples:\par
\par
   DECLARE LOCAL TEMPORARY TABLE MODULE.Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 DATE, \par
      column_3 VARCHAR(25),\par
      CONSTRAINT constraint_1 UNIQUE(column_1) \par
      CONSTRAINT constraint_2 CHECK(column_3 IS NOT NULL));\par
\par
   DECLARE LOCAL TEMPORARY TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 DATE, \par
      column_3 VARCHAR(25),\par
      CONSTRAINT constraint_1 UNIQUE(column_1) \par
      CONSTRAINT constraint_2 CHECK(column_3 IS NOT NULL));\par
\par
When you declare a local temporary Table, you may use the ON COMMIT clause to\par
specify whether you want the Table to be emptied whenever a COMMIT statement\par
is executed. If you omit the ON COMMIT clause from DECLARE LOCAL TEMPORARY\par
TABLE, it defaults to ON COMMIT DELETE ROWS. For example, these two SQL\par
statements are equivalent:\par
\par
   DECLARE LOCAL TEMPORARY TABLE Table_1 ( \par
      column_1 SMALLINT);\par
\par
   DECLARE LOCAL TEMPORARY TABLE Table_1 ( \par
      column_1 SMALLINT) \par
      ON COMMIT DELETE ROWS;\par
\par
Based on this Table declaration, the effect of these two SQL statements:\par
\par
   INSERT INTO MODULE.Table_1 (column_1) VALUES(10); \par
\par
   COMMIT;\par
\par
is that TABLE_1 is first materialized and has data inserted into it, and then\par
the rows are deleted. That is, at COMMIT time, your DBMS effectively executes\par
this SQL statement:\par
\par
   DELETE FROM Table_1;\par
\par
since the declaration of TABLE_1 states that the Table is to be emptied at\par
COMMIT. On the other hand, the effect of these three SQL statements:\par
\par
   DECLARE LOCAL TEMPORARY TABLE Table_1 ( \par
      column_1 SMALLINT) \par
      ON COMMIT PRESERVE ROWS; \par
\par
   INSERT INTO MODULE.Table_1 (column_1) VALUES(10);\par
\par
   COMMIT;\par
\par
is that TABLE_1 is declared, materialized and has data inserted into it, and \par
then the rows are committed. That is, at COMMIT time, your DBMS does not\par
delete the rows, since TABLE_1's declaration explicitly says not to. (The rows\par
will, however, be deleted at the end of the SQL-session.)\par
\par
In addition to declaring a Table, DECLARE LOCAL TEMPORARY TABLE also causes\par
the SQL special grantor, "_SYSTEM", to grant non-grantable INSERT, SELECT,\par
UPDATE, DELETE and REFERENCES Privileges on the declared Table, as well as\par
non-grantable SELECT, INSERT, UPDATE and REFERENCES Privileges on every Column\par
in the declared Table, to the current <AuthorizationID>. This ensures that the\par
Table may be materialized, and operated on, by any <AuthorizationID> that can\par
run the Module that contains the Table declaration.\par
\par
If you want to restrict your code to Core SQL, don't use the DECLARE LOCAL TEMPORARY TABLE statement.\par
\par
Dialects\par
\par
Some vendors relax the rules on what may be an updatable View. For example,\par
IBM's DB2 will let you DELETE from Views whose queries contain arithmetic\par
expressions, and will even let you UPDATE such Views provided you don't try to\par
update the Column derived from the expression.\par
\par
Although the Full-SQL syntax for the check option clause is "WITH [\par
\{CASCADED|LOCAL\} ] CHECK OPTION", the majority of vendors only allow the\par
optionless syntax "WITH CHECK OPTION", which is all that's required for Core\par
SQL. In general, the check option is always CASCADED (as required by the\par
Standard), but there was a time when the default was LOCAL so some caution is\par
necessary. Sometimes WITH CHECK OPTION may be illegal even though the View is\par
updatable; for example IBM's DB2 once insisted that there could be no\par
subqueries in the View definition.\par
\page\par
Chapter 19 -- SQL Domain\par
\par
In this chapter, we'll describe SQL Domains in detail, and show you the syntax to use to create, alter and destroy them.\par
\par
Domain\par
\par
A Schema may contain zero or more Domains. An SQL Domain is a named, user-defined set of valid values. Domains are dependent on some Schema -- the\par
<Domain name> must be unique within the Schema the Domain belongs to (it may\par
not be the same as any <UDT name> in its Schema either) -- and are created,\par
altered and dropped using standard SQL statements. The Objects that may belong\par
to a Domain are known as Domain Constraints; they depend on some Domain.\par
\par
A Domain is defined by a descriptor that contains six pieces of information:\par
      ## The <Domain name>, qualified by the <Schema name> of the Schema it belongs to.\par
      ## The Domain's SQL <data type> specification, including its name, length, precision and scale, as applicable.\par
      ## The name of the Character set that the Domain's set of values must belong to (for character string types).\par
      ## The name of the Domain's default Collation. (This is the Collation that may be used to compare a character string Domain's values in the absence of an explicit COLLATE clause.)\par
      ## Whether reference values must be checked and whether <reference scope check action> specifies RESTRICT or SET NULL (for REF types).\par
      ## The Domain's default value (if any).\par
      ## A descriptor for every Constraint that belongs to the Domain.\par
\par
To create a Domain, use the CREATE DOMAIN statement (either as a stand-alone\par
SQL statement or within a CREATE SCHEMA statement). CREATE DOMAIN specifies\par
the enclosing Schema, names the Domain and identifies the Domain's set of\par
valid values. To change an existing Domain, use the ALTER DOMAIN statement. To\par
destroy a Domain, use the DROP DOMAIN statement.\par
\par
There is a one-to-many association between Domains and Columns: one Domain can be used to identify the set of valid values for multiple Columns.\par
\par
Domain names:\par
A <Domain name> identifies a Domain. The required syntax for a <Domain name> is:\par
\par
<Domain name> ::=\par
[ <Schema name>. ] unqualified name\par
\par
A <Domain name> is a <regular identifier> or a <delimited identifier> that is\par
unique (for all Domains and UDTs) within the Schema it belongs to. The <Schema\par
name> which qualifies a <Domain name> names the Schema that the Domain belongs\par
to and can either be explicitly stated, or a default will be supplied by your DBMS as follows:\par
      ## If a <Domain name> in a CREATE SCHEMA statement isn't qualified, the default qualifier is the name of the Schema you're creating.\par
      ## If the unqualified <Domain name> is found in any other SQL statement in a Module, the default qualifier is the name of the Schema identified in the SCHEMA clause or AUTHORIZATION clause of the MODULE statement that defines that Module.\par
\par
Here are some examples of <Domain name>s:\par
\par
   DOMAIN_1\par
   -- a <Domain name>\par
\par
   SCHEMA_1.DOMAIN_1\par
   -- a simple qualified <Domain name>\par
\par
   CATALOG_1.SCHEMA_1.DOMAIN_1\par
   -- a fully qualified <Domain name>\par
\par
CREATE DOMAIN statement\par
\par
The CREATE DOMAIN statement names a new Domain and defines the Domain's set of valid values. The required syntax for the CREATE DOMAIN statement is:\par
\par
CREATE DOMAIN <Domain name> [ AS ] <data type>\par
     [ DEFAULT default value ]\par
     [ <Domain Constraint> list ]\par
     [ COLLATE <Collation name> ]\par
\par
   <Domain constraint> list::=\par
   <Domain Constraint> [ <Domain Constraint>... ]\par
\par
      <Domain constraint> ::=\par
      [ CONSTRAINT <Constraint name> ]\par
      Constraint_type\par
      [ <constraint attributes> ]\par
\par
CREATE DOMAIN defines a new Domain: a named set of valid data values that can\par
be used -- somewhat like a macro -- to replace the <data type> specification\par
in subsequent <Column definition>s. A Domain is owned by the Schema it belongs to.\par
      ## The <Domain name> identifies the Domain and the Schema that it\par
belongs to. A <Domain name> that includes an explicit <Schema name> qualifier\par
belongs to the Schema named. A <Domain name> that does not include an explicit\par
<Schema name> qualifier belongs to the SQL-session default Schema. The <Domain\par
name> must be unique (for all Domains and UDTs) within the Schema that owns it.\par
\par
If CREATE DOMAIN is part of a CREATE SCHEMA statement, the <Domain name>, if\par
explicitly qualified, must include the <Schema name> of the Schema being\par
created; that is, it isn't possible to create a Domain belonging to a\par
different Schema from within CREATE SCHEMA. For example, this SQL statement\par
will not return an error because the <Domain name> will default to include the qualifying <Schema name>:\par
\par
   CREATE SCHEMA bob\par
      CREATE DOMAIN domain_1 AS SMALLINT;\par
   -- creates a Domain called BOB.DOMAIN_1 in Schema BOB\par
\par
This SQL statement will not return an error either because the <Domain name>\par
explicitly includes a qualifying <Schema name> that matches the name of the\par
Schema being created:\par
\par
   CREATE SCHEMA bob\par
      CREATE DOMAIN bob.domain_1 AS SMALLINT;\par
   -- creates a Domain called BOB.DOMAIN_1 in Schema BOB\par
\par
But this SQL statement will return an error because the <Domain name>\par
explicitly includes a qualifying <Schema name> that is different from the name\par
of the Schema being created:\par
\par
   CREATE SCHEMA bob\par
      CREATE DOMAIN sam.domain_1 AS SMALLINT;\par
   -- tries to create a Domain belonging to Schema SAM inside Schema BOB; illegal syntax\par
\par
Privileges:\par
If CREATE DOMAIN is executed as a stand-alone SQL statement, the current\par
<AuthorizationID> must either be the owner of the Schema that this new Domain\par
belongs to, or the Schema's owner must be a Role that the current\par
<AuthorizationID> may use. That is, only the owner of a Schema can create\par
Domains for that Schema. In addition to creating a Domain, CREATE DOMAIN also\par
causes the SQL special grantor, "_SYSTEM", to grant the USAGE Privilege on the\par
new Domain to the Schema owner <AuthorizationID> (that is, the\par
<AuthorizationID creating the Domain). This USAGE Privilege will be grantable\par
if (a) the grantee also has a grantable REFERENCES Privilege for each Column\par
named in the Domain definition and (b) the grantee also has a grantable USAGE\par
Privilege for each Domain, Collation, Character set and Translation named in a\par
<Domain Constraint> in the Domain definition.\par
\par
<data type>:\par
A Domain must be defined to accept a certain type of data. The Domain's <data\par
type> specification constrains the values that can be accepted by the Domain.\par
The <data type> specification includes length, precision and scale as\par
applicable. Valid <data type>s are: INT, SMALLINT, NUMERIC(p,s), DECIMAL(p,s),\par
FLOAT(p), REAL, DOUBLE PRECISION, BIT(l), BIT VARYING(l), BLOB(l), CHAR(l),\par
NCHAR(l), VARCHAR(l), NCHAR VARYING(l), CLOB(l), NCLOB(l), DATE, TIME(p),\par
TIME(p) WITH TIME ZONE, TIMESTAMP(p), TIMESTAMP(p) WITH TIME ZONE, INTERVAL\par
<interval qualifier>, BOOLEAN, ARRAY, ROW and REF.\par
\par
The <keyword> AS in the <data type> clause is noise and can be omitted. For example, these two SQL statements are equivalent:\par
\par
   CREATE DOMAIN domain_1 AS CHAR(10);\par
\par
   CREATE DOMAIN domain_1 CHAR(10);\par
\par
[Obscure Rule] If the <data type> of a Domain is CHAR, VARCHAR or CLOB, the\par
Character set that the Domain's values must belong to is determined as follows:\par
      ## If your CREATE DOMAIN statement includes a CHARACTER SET clause, the\par
Domain's Character set is the Character set named. Your current\par
<AuthorizationID> must have the USAGE Privilege on that Character set.\par
      ## If your CREATE DOMAIN statement does not include a CHARACTER SET\par
clause, the Domain's Character set is the Character set named in the DEFAULT\par
CHARACTER SET clause of the CREATE SCHEMA statement that defines the Schema that the Domain belongs to.\par
\par
For example, the effect of these two SQL statements:\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob\par
      DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN1;\par
\par
   CREATE DOMAIN domain_1 AS CHAR(10);\par
\par
is to create a Domain in Schema BOB. The Domain's set of valid values are\par
fixed length character strings, exactly 10 characters long, all of whose\par
characters must be found in the INFORMATION_SCHEMA.LATIN1 Character set -- the\par
Schema's default Character set. The effect of these two SQL statements:\par
\par
   CREATE SCHEMA bob AUTHORIZATION bob\par
      DEFAULT CHARACTER SET INFORMATION_SCHEMA.LATIN1;\par
\par
   CREATE DOMAIN domain_1 AS CHAR(10)\par
      CHARACTER SET INFORMATION_SCHEMA.SQL_CHARACTER);\par
\par
is to create the same Domain with one difference: this time, its values must\par
consist only of characters found in the INFORMATION_SCHEMA.SQL_CHARACTER\par
Character set -- the explicit Character set specification in CREATE DOMAIN\par
constrains the Domain's set of values. The Schema's default Character set does not.\par
\par
[Obscure Rule] If the <data type> of a Domain is CHAR, VARCHAR, CLOB, NCHAR,\par
NCHAR VARYING or NCLOB, and your CREATE DOMAIN statement does not include a\par
COLLATE clause, the Domain has a coercibility attribute of COERCIBLE -- but if\par
your CREATE DOMAIN statement includes a COLLATE clause, the Domain has a\par
coercibility attribute of IMPLICIT. In either case, the Domain's default\par
Collation is determined as follows:\par
      ## If your CREATE DOMAIN statement includes a COLLATE clause, the\par
Domain's default Collation is the Collation named. Your current\par
<AuthorizationID> must have the USAGE Privilege on that Collation.\par
      ## If your CREATE DOMAIN statement does not include a COLLATE clause,\par
the Domain's default Collation is the default Collation of the Domain's Character set.\par
\par
[Obscure Rule] If the <data type> of a Domain is REF(UDT), your current\par
<AuthorizationID> must have the USAGE Privilege on that UDT. If the <data\par
type> of a Domain includes REF with a <scope clause>, your CREATE DOMAIN\par
statement must also include a <reference scope check> clause, to indicate\par
whether references are to be checked or not (don't add a <reference scope\par
check> clause under any other circumstances). In this case, you may also add\par
the optional <reference scope check action> clause, to indicate the action to\par
be taken whenever a Column based on this Domain is the subject of a DELETE\par
statement. If you omit the <reference scope check action> clause, it defaults to ON DELETE RESTRICT.\par
      ## If a Domain is defined with REFERENCES ARE CHECKED and a <scope\par
clause> naming one or more Tables is included in the CREATE DOMAIN statement,\par
then there is an implied DEFERRABLE INITIALLY IMMEDIATE Constraint on the new\par
Domain which checks that the values of every Column based on the Domain are\par
also found in the system generated Column of each Table named in the <scope\par
clause>. In this case, if the <reference scope check action> is SET NULL then,\par
prior to deleting any rows from the Tables that own a Column based on this\par
Domain, your DBMS will (a) execute a SET CONSTRAINT statement that sets the\par
implied Constraint's constraint check time to DEFERRED, (b) DELETE the rows as\par
required, (c) set the value of the system generated Column in each Table named\par
in the <scope clause> to NULL, for each row that matched the deleted rows and\par
(d) execute a SET CONSTRAINT statement that sets the implied Constraint's\par
constraint check time to IMMEDIATE.\par
\par
DEFAULT clause:\par
The optional DEFAULT clause defines the Domain's default value: the value to\par
insert whenever a Column based on this Domain is the target of an INSERT\par
statement that doesn't include an explicit value for that Column. The DEFAULT\par
options are: DEFAULT <literal>, DEFAULT CURRENT_DATE, DEFAULT CURRENT_TIME(p),\par
DEFAULT CURRENT_TIMESTAMP(p), DEFAULT LOCALTIME(p), DEFAULT LOCALTIMESTAMP(p),\par
DEFAULT USER, DEFAULT CURRENT_USER, DEFAULT SESSION_USER, DEFAULT SYSTEM_USER,\par
DEFAULT CURRENT_PATH, DEFAULT ARRAY[], DEFAULT ARRAY??(??) and DEFAULT NULL --\par
see "<default clause>" in our chapter on Tables. For example, this SQL\par
statement creates a Domain whose default value is the <character string\par
literal> 'bobby':\par
\par
   CREATE DOMAIN domain_1 AS VARCHAR(15)\par
      DEFAULT 'bobby';\par
\par
And this SQL statement creates a Domain whose default value is the value returned by the CURRENT_DATE function:\par
\par
   CREATE DOMAIN domain_1 AS DATE\par
      DEFAULT CURRENT_DATE;\par
\par
<Domain Constraint>s:\par
The optional <Domain Constraint> list clause of CREATE DOMAIN is used to\par
define zero or more <Constraint>s on the Domain: the Constraint rules will\par
restrict the Domain's set of valid values -- see our chapter on Constraints\par
and Assertions. The syntax "CREATE DOMAIN <Domain name> AS <data type> DEFAULT\par
default value <Domain Constraint> <Domain Constraint>" defines a Domain whose\par
definition includes two <Domain Constraint>s. Here is an example:\par
\par
   CREATE DOMAIN domain_1 AS SMALLINT\par
      DEFAULT 150\par
      CONSTRAINT constraint_1\par
         CHECK (VALUE IS NOT NULL) NOT DEFERRABLE\par
      CONSTRAINT constraint_2\par
         CHECK (VALUE BETWEEN -1000 AND 9999) DEFERRABLE INITIALLY IMMEDIATE;\par
\par
In this example, DOMAIN_1 has a default value of 150 and is constrained to\par
accept only integers that fall into SMALLINT's range. The Domain is further\par
constrained (by CONSTRAINT_1) not to accept null values and (by CONSTRAINT_2)\par
to accept only values between -1000 and +9999. Since a <Domain Constraint>'s\par
search condition may not be recursive, this SQL statement will return an error\par
because the <Domain Constraint> refers to the Domain it belongs to:\par
\par
   CREATE DOMAIN domain_1 AS FLOAT\par
      CONSTRAINT constraint_1\par
         CHECK (VALUE IN (domain_1) NOT DEFERRABLE);\par
\par
If you want to restrict your code to Core SQL, don't use the CREATE DOMAIN statement.\par
\par
ALTER DOMAIN statement\par
\par
The ALTER DOMAIN statement changes a Domain's definition. The required syntax for the ALTER DOMAIN statement is:\par
\par
ALTER DOMAIN <Domain name> <alter domain action>\par
\par
   <alter domain action> ::=\par
   SET DEFAULT default value |\par
   DROP DEFAULT |\par
   ADD <Domain Constraint> |\par
   DROP CONSTRAINT <Constraint name>\par
\par
The <Domain name> must identify an existing Domain whose owner is either the\par
current <AuthorizationID> or a Role that the current <AuthorizationID> may\par
use. That is, only the <AuthorizationID> that owns the Domain may alter it.\par
Every Column that is based on the Domain will be affected by the change.\par
\par
SET DEFAULT clause:\par
The effect of ALTER DOMAIN <Domain name> SET DEFAULT default value, e.g.:\par
\par
   ALTER DOMAIN domain_1 SET DEFAULT 200;\par
\par
is that the default value of the Domain named will be changed. (You can use\par
this version of ALTER DOMAIN either to add a default value to a Domain or to\par
change a Domain's existing default value.) The ALTER DOMAIN ... SET DEFAULT\par
options are: DEFAULT <literal>, DEFAULT CURRENT_DATE, DEFAULT CURRENT_TIME(p),\par
DEFAULT CURRENT_TIMESTAMP(p), DEFAULT LOCALTIME(p), DEFAULT LOCALTIMESTAMP(p),\par
DEFAULT USER, DEFAULT CURRENT_USER, DEFAULT SESSION_USER, DEFAULT SYSTEM_USER,\par
DEFAULT CURRENT_PATH, DEFAULT ARRAY[], DEFAULT ARRAY??(??) and DEFAULT NULL --\par
see "<default clause>", in our chapter on Tables.\par
\par
DROP DEFAULT clause:\par
The effect of ALTER DOMAIN <Domain name> DROP DEFAULT, e.g.:\par
\par
   ALTER DOMAIN domain_1 DROP DEFAULT;\par
\par
is that the default value of the Domain named will be removed from the\par
Domain's definition>. (You'll get a syntax error if the Domain's definition\par
doesn't include a default value.) Before removing the default value from the\par
Domain's definition, your DBMS will first check the definitions of every\par
Column based on the Domain for a default value. If a dependent <Column\par
definition> has no default value, your DBMS will add the Domain's default\par
value to the <Column definition>. For example, the effect of this SQL statement:\par
\par
   ALTER domain_1 DROP DEFAULT;\par
\par
is twofold. First, the definition of every Column dependent on DOMAIN_1 will\par
be checked for a Column default value. If none is found, the default value\par
from the Domain definition is added to the <Column definition> to ensure that\par
the Column is not left without a default value for future insertions. The\par
second effect is that the Domain's default value is removed from the definition of DOMAIN_1.\par
\par
ADD <Domain Constraint> clause:\par
The effect of ALTER DOMAIN <Domain name> ADD <Domain Constraint>, e.g.:\par
\par
   ALTER DOMAIN domain_1 ADD CONSTRAINT constraint_1\par
      CHECK(VALUE IS NOT NULL) NOT DEFERRABLE;\par
\par
is that one <Domain Constraint> is added to the definition of the Domain named\par
-- see "<Domain Constraint>" in our chapter on Constraints and Assertions.\par
\par
DROP CONSTRAINT clause:\par
The effect of ALTER DOMAIN <Domain name> DROP CONSTRAINT <Constraint name>, e.g.:\par
\par
   ALTER DOMAIN domain_1 DROP CONSTRAINT constraint_1;\par
\par
is that the Constraint named is removed from the definition of the Domain that\par
owns it. (Note: If the dropped Constraint caused one or more Columns to have\par
the "known not nullable" nullability characteristic, then the affected\par
Columns' nullability characteristic becomes "possibly nullable" unless some\par
other Constraint also constrains them to non-null values.)\par
\par
If you want to restrict your code to Core SQL, don't use the ALTER DOMAIN statement.\par
\par
DROP DOMAIN statement\par
\par
The DROP DOMAIN statement destroys a Domain. The required syntax for the DROP DOMAIN statement is:\par
\par
DROP DOMAIN <Domain name> \{RESTRICT | CASCADE\}\par
\par
The <Domain name> must identify an existing Domain whose owner is either the\par
current <AuthorizationID> or a Role that the current <AuthorizationID> may\par
use. That is, only the <AuthorizationID> that owns the Domain may drop it.\par
\par
The effect of DROP DOMAIN <Domain name> RESTRICT, e.g.:\par
\par
   DROP DOMAIN domain_1 RESTRICT;\par
\par
is that the Domain named is destroyed, provided that (a) no Columns are based\par
on the Domain and (b) that the Domain isn't referred to in any View\par
definition, Constraint or Assertion definition, or SQL routine. That is,\par
RESTRICT ensures that only a Domain with no dependent Objects can be\par
destroyed. If the Domain is used by any other Object, DROP DOMAIN ... RESTRICT will fail.\par
\par
The effect of DROP DOMAIN <Domain name> CASCADE, e.g.:\par
\par
   DROP DOMAIN domain_1 CASCADE;\par
\par
is that the Domain named is destroyed.\par
\par
Successfully dropping a Domain has a five-fold effect:\par
      ## The Domain named is destroyed.\par
      ## All Privileges held on the Domain by the <AuthorizationID> that owns\par
it are revoked (by the SQL special grantor, "_SYSTEM") with a CASCADE revoke\par
behaviour, so that all Privileges held on the Domain by any other <AuthorizationID> are also revoked.\par
      ## The definition of every Column based on the Domain is changed: the\par
<Domain name> is removed and the Domain's <data type> specification is added.\par
If the <Column definition> has no default value, the Domain's default value is\par
added. If the <Column definition> has no COLLATE clause, the Domain's COLLATE\par
clause is added, provided that the <AuthorizationID> has the USAGE Privilege on the Collation named.\par
      ## The definition of every Table that owns a Column based on the Domain\par
is changed: a <Table Constraint> that is equivalent to every applicable\par
<Domain Constraint> is added, provided that the <AuthorizationID> has all the\par
Privileges needed to add such <Table Constraint>s.\par
      ## All SQL routines, Views and Constraints that depend on the Domain are dropped with a CASCADE drop behaviour.\par
\par
If you want to restrict your code to Core SQL, don't use the DROP DOMAIN statement.\par
\par
Frequently-used numeric Domains\par
\par
Any business needs to store "money" -- usually a signed decimal with two fixed\par
digits after the decimal point; and "interest" -- usually an unsigned decimal\par
with 3 digits after the decimal point. Some SQL DBMSs have special data types\par
for business needs, but Standard SQL doesn't, so this is a good place to use a\par
Domain. For example, these four SQL statements define and utilize two numeric Domains:\par
\par
   CREATE DOMAIN MONEY_ AS DECIMAL(8,2));\par
\par
   CREATE DOMAIN INTEREST_ AS DECIMAL(5,3));\par
\par
   ALTER DOMAIN INTEREST_ ADD CONSTRAINT constraint_1\par
      CHECK (VALUE >= 00.000);\par
\par
   CREATE TABLE Money_Examples (\par
      money_column_1 MONEY_,\par
      interest_column_1 INTEREST_,\par
      money_column_2 MONEY_,\par
      interest_column_2 INTEREST_);\par
\par
In this example, the first two SQL statements create two Domains named MONEY_\par
and INTEREST_. The third SQL statement adds a Constraint to INTEREST_ Domain:\par
it must always have a value greater than or equal to zero. Lastly, the Domains\par
are used in a CREATE TABLE statement -- this saves a bit of typing, but more\par
importantly, using the Domains makes it clear that money and interest fields\par
are being defined -- rather than merely vague, generic decimal fields.\par
\par
SQL provides a predefined unsigned-integer Domain, called CARDINAL_NUMBER,\par
that you could use on the theory that anything predefined is better than a\par
roll-your-own. Since all predefined Objects are belong to INFORMATION_SCHEMA,\par
use a <Schema name> qualifier when making Columns with CARDINAL_NUMBER -- for example:\par
\par
   ALTER TABLE Exact_Examples ADD COLUMN\par
      occurrence_cardinal INFORMATION_SCHEMA.CARDINAL_NUMBER;\par
\par
This definition will cause this SQL statement to fail because CARDINAL_NUMBER\par
allows only unsigned numbers (that is, only numbers that are greater than or equal to zero):\par
\par
   UPDATE Exact_Examples SET\par
      occurrence_cardinal = -1;\par
\par
But this SQL statement will work:\par
\par
   UPDATE Exact_Examples SET\par
      occurrence_cardinal = +1;\par
\par
Note: Numbers in a CARDINAL_NUMBER Domain don't have the same range as C/Delphi "unsigned".\par
\page\par
Chapter 20 -- SQL Constraint and Assertion\par
\par
In this chapter, we'll describe SQL Constraints and SQL Assertions in detail,\par
and show you the syntax to use to create, alter and destroy them.\par
\par
Constraint\par
\par
A Schema may contain zero or more integrity Constraints (an Assertion is just\par
a special type of integrity Constraint: it is not necessarily dependent on a\par
single Base table as simple Constraints are.) An SQL Constraint is a named\par
rule which helps define valid sets of values by putting limits on the results\par
of INSERT, UPDATE or DELETE operations performed on a Base table, an\par
Assertion, by contrast, may define valid sets of values for\par
individual rows of a Base table or for an entire Base table or it may define\par
the set of valid values required to exist among a number of Base tables.\par
Constraints are dependent on some Schema -- the <Constraint name> must be\par
unique within the Schema the Constraint belongs to -- and are created and\par
dropped using standard SQL statements. \par
\par
There are four Constraint variations -- UNIQUE Constraints, PRIMARY KEY\par
Constraints, FOREIGN KEY Constraints and CHECK Constraints.\par
      ## A UNIQUE Constraint defines one or more Columns of a Table as unique\par
Columns: it is satisfied if no two rows in the Table have the same non-null\par
values in the unique Columns. A PRIMARY KEY Constraint is a UNIQUE Constraint\par
that specifies PRIMARY KEY: it is satisfied if (a) no two rows in the Table\par
have the same non-null values in the unique Columns and (b) none of the\par
primary key Columns are NULL. UNIQUE Constraints and PRIMARY KEY Constraints\par
describe a Base table's candidate keys.\par
      ## A FOREIGN KEY Constraint defines one or more Columns of a Table as\par
referencing Columns whose values must match the values of some corresponding\par
referenced Columns in a referenced Base table (the referenced Columns must be\par
UNIQUE Columns for the referenced Table). It is satisfied if, for every row in\par
the referencing Table, the values of the referencing Columns are equal to\par
those of the corresponding referenced Columns in some row of the referenced\par
Table. (If either Table contains NULLs, satisfaction of the FOREIGN KEY\par
Constraint depends on the Constraint's match type.) FOREIGN KEY Constraints\par
describe linkages between Base tables.\par
      ## A CHECK Constraint defines a search condition: it is violated if the\par
result of the condition is FALSE for any row of the Table. An Assertion is a\par
CHECK Constraint that may operate on multiple Tables.\par
\par
Non-deterministic Constraints:\par
A CHECK Constraint may not define a non-deterministic search condition -- that\par
is, any condition whose result may vary from time to time. Here is an example\par
of an invalid CHECK Constraint:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 DATE CHECK (column_1 = CURRENT_DATE);\par
\par
This SQL statement would return an error because the CHECK Constraint's search\par
condition is non-deterministic -- since the value of CURRENT_DATE changes each\par
time the function is called, your DBMS is not able to determine whether the\par
Constraint has been violated or not. For another example, run this query\par
twice, on the same database:\par
\par
   SELECT * \par
   FROM   Table_1 \par
   WHERE  column_time = TIME '13:14:15';\par
\par
You can be sure that the results will be the same both times. Now run this\par
query twice:\par
\par
   SELECT * \par
   FROM   Table_1 \par
   WHERE  column_time = CURRENT_TIME;\par
\par
You can't be sure that the results will be the same both times because the\par
current time is a value from outside your SQL environment, beyond the control\par
of your DBMS. Now run this query twice:\par
\par
   SELECT 'a ' \par
   FROM   Table_1 \par
   UNION \par
   SELECT 'A' \par
   FROM   Table_1;\par
\par
Once again, you can't be sure that the results will be the same both times.\par
With most Collations ("NO PAD" and "case insensitive"), the <literal>s 'a '\par
and 'A' are equivalent -- that is, they're equal to each other. But they're\par
still not the same <literal>.\par
\par
The point is that the only predictable queries are those which depend on SQL-\par
data and defined rules. As soon as you start to use values which are outside\par
SQL, or which result from implementation-dependent answers to areas which the\par
SQL Standards leaves undefined, you have a query which requires a\par
nine-syllable term to describe: "possibly non-deterministic". Specifically,\par
queries are possibly non-deterministic (and therefore not allowed in\par
Constraints) if they depend on:\par
      ## A niladic function (CURRENT_DATE, CURRENT_TIME, CURRENT_TIMESTAMP,\par
LOCALTIME, LOCALTIMESTAMP, USER, CURRENT_USER, SESSION_USER, SYSTEM_USER,\par
CURRENT_PATH, CURRENT_ROLE).\par
      ## An operation which picks from multiple values that may be\par
equivalent-but-not-the-same. Picky operations include: MIN, MAX, UNION (though\par
UNION ALL is okay), INTERSECT, EXCEPT, DISTINCT and grouping columns.\par
Equivalent-but-not-the-same can be true for: character strings and times and\par
timestamps (in the latter cases the external factor that causes\par
non-determinism is the time zone).\par
      ## A routine invocation which is based on a procedure in a host language\par
or on parameters that are set by a host program.\par
\par
No matter what type of Constraint you're defining, the main ideas are always the same.\par
      ## One: You're describing a state which must not be FALSE. This means it\par
can be either TRUE or UNKNOWN. (It can also be "temporarily FALSE" -- your\par
DBMS is supposed to allow bad data until constraint check time. Then, if it\par
descries a FALSE condition, it must wipe the bad data out again, so it's\par
equally correct to say "Constraint violation" and "attempted Constraint\par
violation".) Evaluation of a Constraint is one of the areas where NULLs and\par
three-valued logic play an important role.\par
      ## Two: A Constraint is an Object in a Schema -- it is not a procedure.\par
It is, rather, a revelation to the DBMS about what you want and what you don't\par
want to see in your database.\par
\par
Constraint deferrability:\par
All Constraints are defined with a deferral mode of either DEFERRABLE or NOT\par
DEFERRABLE. A deferral mode of DEFERRABLE allows you to specify when you want\par
your DBMS to check the Constraint for violation (the choices are at statement\par
end or at transaction end). A deferral mode of NOT DEFERRABLE doesn't give you\par
this option: your DBMS will check the Constraint for violation as soon as it\par
finishes executing an SQL statement. Of course, not every SQL statement will\par
cause your DBMS to check Constraints -- the main statements that cause\par
Constraint checking are INSERT, UPDATE and DELETE (there is no Constraint\par
checking for DROP statements). DELETE is slightly less important because\par
whenever you get rid of a row, there is no longer any need to check whether\par
that row violates a Constraint. Consider these SQL statements:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT);\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT constraint_1 \par
      UNIQUE (column_1) NOT DEFERRABLE;\par
\par
   INSERT INTO Table_1 (column_1)\par
   VALUES (1);\par
\par
   INSERT INTO Table_1 (column_1)\par
   VALUES (2);\par
\par
   UPDATE Table_1 SET \par
      column_1 = column_1 + 1;\par
\par
Believe it or not, there are DBMSs alive today which will fail when they\par
encounter this example's UPDATE statement. The reason is that they UPDATE one\par
row at a time and perform the Constraint check immediately after doing each\par
row (this is normally the case whenever a DBMS implements UNIQUE Constraints\par
using a "unique index"). Therefore, as soon as 1+1 = 2 is done for the first\par
row, there's a duplication -- even though, if the DBMS would only proceed to\par
do the next row, the duplication would disappear (it would end up with a 2 in\par
the first row and a 3 in the second row). The fact is, there never is a need\par
for the Constraint to be checked until the end of the UPDATE statement -- nor\par
does the SQL Standard allow for Constraint checking until that time.\par
\par
Every Constraint is also defined with a persistent initial constraint check\par
time that depends on its deferral mode: it is either INITIALLY IMMEDIATE or\par
INITIALLY DEFERRED. A Constraint that is NOT DEFERRABLE always has an initial\par
constraint check time of INITIALLY IMMEDIATE. A Constraint that is DEFERRABLE\par
may have an initial constraint check time of either INITIALLY IMMEDIATE or\par
INITIALLY DEFERRED. During a transaction, each Constraint also has a current\par
constraint check time: its defined initial constraint check time is always the\par
current constraint check time at the beginning of a transaction but you may\par
change the check time for the period of the transaction (from IMMEDIATE to\par
DEFERRED or vice versa) if the Constraint is DEFERRABLE.\par
      ## During a transaction, your DBMS will check every Constraint with a\par
current constraint check time of IMMEDIATE for violation right after it\par
executes an SQL statement -- thus each such Constraint may be checked multiple\par
times during a transaction.\par
      ## During a transaction, your DBMS will wait to check every Constraint\par
with a current constraint check time of DEFERRED until the transaction ends --\par
thus each such Constraint will be checked only once per transaction.\par
For each SQL-session, the current constraint check time of all Constraints is\par
a property of that SQL-session. \par
\par
To create a Constraint, use a <Table Constraint> definition or a <Column\par
Constraint> definition in a CREATE TABLE or an ALTER TABLE statement or use a\par
<Domain Constraint> definition in a  CREATE DOMAIN or an ALTER DOMAIN\par
statement or use the CREATE ASSERTION statement. To destroy a Constraint, use\par
the ALTER TABLE, ALTER DOMAIN or DROP ASSERTION statements. To change an\par
existing Constraint, drop and then redefine it.\par
\par
There is a one-to-many association between Base tables and <Table\par
Constraint>s or <Column Constraint>s: one Base table may be constrained by the\par
rules of many <Table Constraint>s and/or many <Column Constraint>s (each of\par
which may help define only that Table's set of valid values). There is also a\par
many-to-many association between Base tables and <Domain Constraint>s:\par
multiple Base tables may contain one or more Columns that are based on the\par
same Domain -- and that Domain may be constrained by the rules of many <Domain\par
Constraint>s. Finally, there is a many-to-many association between Base tables\par
and Assertions: multiple Base tables may be constrained by the rules of one\par
Assertion, and one Base table may be constrained by the rules of many\par
Assertions.\par
\par
Constraint names:\par
A <Constraint name> identifies a Constraint or an Assertion. The required\par
syntax for a <Constraint name> is: \par
\par
<Constraint name> ::= \par
[ <Schema name>. ] unqualified name \par
\par
A <Constraint name> is a <regular identifier> or a <delimited identifier> that\par
is unique (for all Constraints and Assertions) within the Schema it belongs\par
to. The <Schema name> that qualifies a <Constraint name> names the Schema that\par
the Constraint or Assertion belongs to and can either be explicitly stated, or\par
a default will be supplied by your DBMS as follows:\par
      ## If a <Constraint name> in a CREATE SCHEMA statement isn't qualified,\par
the default qualifier is the name of the Schema you're creating.\par
      ## If the unqualified <Constraint name> is found in any other SQL\par
statement in a Module, the default qualifier is the name of the Schema\par
identified in the SCHEMA clause or AUTHORIZATION clause of the MODULE\par
statement which defines that Module.\par
\par
Here are some examples of <Constraint name>s:\par
\par
   CONSTRAINT_1\par
   -- a <Constraint name>\par
\par
   SCHEMA_1.CONSTRAINT_1\par
   -- a simple qualified <Constraint name>\par
\par
   CATALOG_1.SCHEMA_1.CONSTRAINT_1\par
   -- a fully qualified <Constraint name>\par
\par
<Table Constraint> and <Column Constraint>:\par
A Base table may be constrained by zero or more <Table Constraint>s:\par
Constraints defined on one or more of its Columns in a CREATE TABLE or an\par
ALTER TABLE statement. <Table Constraint>s are dependent on some Base table,\par
and therefore on some Schema -- the <Constraint name> must be unique within\par
the Schema the Constraint belongs to. There are five kinds of <Table\par
Constraint>s: UNIQUE Constraints, PRIMARY KEY Constraints, FOREIGN KEY\par
Constraints, CHECK Constraints and NOT NULL Constraints (which are really just\par
a type of CHECK Constraint).\par
\par
A <Column definition> (and therefore a Base table) may be constrained by zero\par
or more <Column Constraint>s: Constraints defined on a single Column in a\par
CREATE TABLE or an ALTER TABLE statement. A <Column Constraint> logically\par
becomes a <Table Constraint> as soon as it is created. <Column Constraint>s\par
are dependent on some Base table, and therefore on some Schema -- the\par
<Constraint name> must be unique within the Schema the Constraint belongs to.\par
A <Column Constraint> may be any Constraint that can be a <Table Constraint>.\par
\par
<Domain Constraint>:\par
A Domain may be constrained by zero or more <Domain Constraint>s: Constraints\par
defined in a CREATE DOMAIN or an ALTER DOMAIN statement. <Domain Constraint>s\par
are dependent on some Domain, and therefore on some Schema -- the <Constraint\par
name> must be unique within the Schema the Constraint belongs to. All <Domain\par
Constraint>s are CHECK Constraints whose search conditions are applied to all\par
Columns based on the Domain and to all values cast to the Domain. The search\par
condition may not be a recursive search condition (that is, it may not refer,\par
either directly or indirectly, to the Domain that the <Domain Constraint>\par
belongs to) and it must begin with the <value specification> VALUE; that is,\par
the only proper form for a <Domain Constraint>'s rule is:\par
\par
   CHECK (VALUE ...) \par
\par
(This is the only time SQL allows you to use the <value specification> VALUE.)\par
\par
Three things wrong with the World Wide Web are:\par
      ## Pages can be written in different styles and formats, or just be\par
garbage.\par
      ## Pages can be duplicated.\par
      ## Links can be broken (the notorious "URL not found" error).\par
If we could control the World Wide Web, we'd do what we could to stomp out\par
each of those practices, in turn. Specifically, we'd add three basic kinds of\par
Constraints. Well, we don't control the Web. But we do control databases, so\par
we can use Constraints to stop bad data from getting into our Base tables.\par
(There are other lines of defense against bad data -- for example, the\par
requirement that values correspond to a defined <data type>, the WITH CHECK\par
OPTION requirement on a View, the SQL3 TRIGGER feature, and the procedures in\par
your host language programs. We describe these defenses in other chapters.)\par
\par
If it's possible, you should create your Constraints and associate them only\par
with Base tables -- that way, the process is clear to all users. You'll know\par
where to look for information about the Constraints -- they'll be associated\par
with the Tables themselves in the INFORMATION_SCHEMA. And, after reading this\par
chapter, you'll know what the specific, rather rigid, rules are -- which\par
reduces uncertainty, since specific and rigid rules are clear and\par
well-understood rules. In any case, it is logically proper to associate a\par
Constraint with a Table, because a Table is a set of row values and a\par
Constraint is a restriction (or description) of that set of values.\par
\par
Constraint Descriptors\par
\par
A UNIQUE Constraint is defined by a descriptor that contains five pieces of\par
information:\par
      ## The <Constraint name>, qualified by the <Schema name> of the Schema\par
it belongs to.\par
      ## The Constraint's deferral mode: either DEFERRABLE or NOT DEFERRABLE.\par
      ## The Constraint's initial constraint check time: either INITIALLY\par
DEFERRED or INITIALLY IMMEDIATE.\par
      ## The Constraint's rule: the <keyword> UNIQUE, which forces the Table's\par
set of valid values for one or more Columns to be unique.\par
      ## The names and positions of the Columns that are required to contain\par
only unique values. \par
\par
A PRIMARY KEY Constraint is defined by a descriptor that contains five pieces\par
of information:\par
      ## The <Constraint name>, qualified by the <Schema name> of the Schema\par
it belongs to.\par
      ## The Constraint's deferral mode: either DEFERRABLE or NOT DEFERRABLE.\par
      ## The Constraint's initial constraint check time: either INITIALLY\par
DEFERRED or INITIALLY IMMEDIATE.\par
      ## The Constraint's rule: the <keyword> phrase PRIMARY KEY, which forces\par
the Table's set of valid values for one or more Columns to be unique and not\par
NULL.\par
      ## The names and positions of the Columns that are the Table's primary\par
key and thus are required to contain only unique, non-null values. (A Table\par
that has a primary key cannot have a proper supertable.)\par
\par
A FOREIGN KEY Constraint is defined by a descriptor that contains nine pieces\par
of information:\par
      ## The <Constraint name>, qualified by the <Schema name> of the Schema\par
it belongs to.\par
      ## The Constraint's deferral mode: either DEFERRABLE or NOT DEFERRABLE.\par
      ## The Constraint's initial constraint check time: either INITIALLY\par
DEFERRED or INITIALLY IMMEDIATE.\par
      ## The Constraint's rule: the <keyword> phrase FOREIGN KEY, which forces\par
the Table's set of valid values for one or more Columns to match some\par
corresponding Columns.\par
      ## The names and positions of the referencing Column(s) that make up a\par
foreign key for a Table.\par
      ## The name of the Table that contains the referenced Column(s).\par
      ## The names and positions of the references Column(s) in the referenced\par
Table.\par
      ## The Constraint's MATCH type (if any).\par
      ## The Constraint's referential triggered actions (if any). \par
\par
A NOT NULL Constraint is defined by a descriptor that contains four pieces of\par
information:\par
      ## The <Constraint name>, qualified by the <Schema name> of the Schema\par
it belongs to.\par
      ## The Constraint's deferral mode: either DEFERRABLE or NOT DEFERRABLE.\par
      ## The Constraint's initial constraint check time: either INITIALLY\par
DEFERRED or INITIALLY IMMEDIATE.\par
      ## The Constraint's rule: CHECK (<Column name> IS NOT NULL).\par
\par
A CHECK Constraint is defined by a descriptor that contains four pieces of\par
information:\par
      ## The <Constraint name>, qualified by the <Schema name> of the Schema\par
it belongs to.\par
      ## The Constraint's deferral mode: either DEFERRABLE or NOT DEFERRABLE.\par
      ## The Constraint's initial constraint check time: either INITIALLY\par
DEFERRED or INITIALLY IMMEDIATE.\par
      ## The Constraint's rule: the <keyword> CHECK followed by the\par
parenthesized search condition that forces the Table's set of valid values for\par
one or more Columns to be TRUE or UNKNOWN for the condition.\par
\par
An Assertion is defined by a descriptor that contains five pieces of\par
information:\par
      ## The <Constraint name>, qualified by the <Schema name> of the Schema\par
it belongs to.\par
      ## The Constraint's deferral mode: either DEFERRABLE or NOT DEFERRABLE.\par
      ## The Constraint's initial constraint check time: either INITIALLY\par
DEFERRED or INITIALLY IMMEDIATE.\par
      ## The Constraint's rule: the <keyword> CHECK followed by the\par
parenthesized search condition that forces the set of valid values for one or\par
more Base Tables to be TRUE or UNKNOWN for the condition.\par
\par
Constraint Definition\par
\par
A Constraint definition creates a <Table Constraint>, a <Column Constraint> or\par
a <Domain Constraint>. Used in a CREATE TABLE, ALTER TABLE, CREATE DOMAIN or\par
ALTER DOMAIN statement, it names a Constraint and defines the Constraint's\par
type, deferral mode and constraint check time. The required syntax for a\par
Constraint definition is: \par
\par
Constraint definition ::= \par
[ CONSTRAINT <Constraint name> ] \par
Constraint_type \par
[ <constraint attributes> ] \par
\par
   Constraint_type ::=\par
   <Table Constraint> | \par
   <Column Constrain> | \par
   <Domain Constraint>\par
\par
      <Table Constraint> ::=\par
      UNIQUE Constraint | \par
      PRIMARY KEY Constraint | \par
      FOREIGN KEY Constraint | \par
      CHECK Constraint\par
\par
      <Column Constraint> ::=\par
      UNIQUE Constraint | \par
      PRIMARY KEY Constraint | \par
      FOREIGN KEY Constraint | \par
      NOT NULL Constraint | \par
      CHECK Constraint\par
\par
      <Domain Constraint> ::= \par
      CHECK Constraint\par
\par
   <constraint attributes> ::= \par
   <constraint check time> [ [ NOT ] DEFERRABLE ] | \par
   [ NOT ] DEFERRABLE [ <constraint check time> ]\par
\par
      <constraint check time> ::= \par
      INITIALLY DEFERRED | INITIALLY IMMEDIATE\par
\par
A Constraint definition defines a new rule that will constrain a Base table's\par
set of valid values. A <Table Constraint> and a <Column Constraint> are owned\par
by the Table they belong to. A <Domain Constraint> is owned by the Domain it\par
belongs to.\par
\par
<Constraint name>:\par
All Constraints have names. The optional CONSTRAINT clause of a Constraint\par
definition is used to provide an explicit name for a Constraint. If you omit\par
the CONSTRAINT clause from a Constraint definition, your DBMS will provide a\par
default <Constraint name> to identify the Constraint. For example, this SQL\par
statement includes a Constraint definition that includes a CONSTRAINT clause:\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT constraint_1 \par
      PRIMARY KEY(column_1);\par
\par
(The name of the Constraint is CONSTRAINT_1.) This SQL statement includes a\par
Constraint definition that omits the CONSTRAINT clause:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT PRIMARY KEY); \par
\par
(The name of the Constraint is defined by your DBMS and is therefore non-\par
standard, so we recommend that you explicitly name all of your Constraints.)\par
\par
The <Constraint name> identifies the Constraint and the Schema that it belongs\par
to. A <Constraint name> that includes an explicit <Schema name> qualifier\par
belongs to the Schema named. A <Constraint name> that does not include an\par
explicit <Schema name> qualifier belongs to the SQL-session default Schema.\par
(In both cases, that Schema must, of course, own the Table or Domain for which\par
the Constraint is defined.) The <Constraint name> must be unique (for all\par
Constraints and Assertions) within the Schema that owns it. If CREATE TABLE,\par
ALTER TABLE, CREATE DOMAIN or ALTER DOMAIN are part of a CREATE SCHEMA\par
statement, the <Constraint name>, if explicitly qualified, must include the\par
<Schema name> of the Schema being created; that is, it isn't possible to\par
create a Constraint belonging to a different Schema from within CREATE SCHEMA.\par
\par
Types of Constraints:\par
A <Table Constraint> defines a rule that limits the set of values for one or\par
more Columns of a Base table.\par
\par
A <Column Constraint> defines a rule that limits the set of values for one\par
Column of a Base Table. You may define a <Column Constraint> only within a\par
<Column definition>. Once created, a <Column Constraint> logically becomes a\par
<Table Constraint> for the Table that owns the Column that the Constraint is\par
defined for.\par
\par
A <Domain Constraint> defines a rule that limits the set of values for every\par
Column that is based on the Domain that the Constraint is defined for. One or\par
more Columns from one or more Base tables may thus be affected by a <Domain\par
Constraint>. A <Domain Constraint> is a CHECK Constraint that uses the <value\par
specification> VALUE.\par
\par
Deferral mode:\par
A Constraint definition may include a specification of the Constraint's\par
deferral mode: either DEFERRABLE or NOT DEFERRABLE. A deferral mode of NOT\par
DEFERRABLE means that your DBMS will check the Constraint for violation\par
immediately after executing every SQL statement in a transaction. A deferral\par
mode of DEFERRABLE means that your DBMS may defer checking the Constraint for\par
violation until the end of the transaction. If you omit the deferral mode\par
specification from a Constraint definition, the Constraint's deferral mode\par
depends on its initial constraint check time: the deferral mode for an\par
INITIALLY DEFERRED Constraint defaults to DEFERRABLE and the deferral mode for\par
an INITIALLY IMMEDIATE Constraint defaults to NOT DEFERRABLE.\par
\par
Constraint check time:\par
A Constraint definition may also include a specification of the Constraint's\par
initial constraint check time: either INITIALLY DEFERRED or INITIALLY\par
IMMEDIATE. If you omit the constraint check time specification from a\par
Constraint definition, the Constraint will have a constraint check time of\par
INITIALLY IMMEDIATE.\par
\par
If its initial constraint check time is INITIALLY DEFERRED, a Constraint's\par
deferral mode must be DEFERRABLE and its constraint check time will be\par
DEFERRED at the beginning of every transaction. You may use the SET\par
CONSTRAINTS statement to change a DEFERRABLE INITIALLY DEFERRED Constraint's\par
constraint check time for a transaction (this is the current constraint check\par
time) to IMMEDIATE. \par
\par
If its initial constraint check time is INITIALLY IMMEDIATE, a Constraint's\par
deferral mode may be either DEFERRABLE or NOT DEFERRABLE and its constraint\par
check time will be IMMEDIATE at the beginning of every transaction. You may\par
use the SET CONSTRAINTS statement to change a DEFERRABLE INITIALLY IMMEDIATE\par
Constraint's constraint check time for a transaction to DEFERRED but you may\par
not use SET CONSTRAINTS on a NOT DEFERRABLE INITIALLY IMMEDIATE Constraint\par
because such Constraints can't have their constraint check times changed.\par
\par
Immediately after executing any SQL statement, your DBMS checks every\par
Constraint with a current constraint check time of IMMEDIATE for violation,\par
but does not check the Constraints with a current constraint check time of\par
DEFERRED. At the end of a transaction, any Constraints with a current\par
constraint check time of DEFERRED have it changed to IMMEDIATE -- thus, your\par
DBMS checks every Constraint for violation at the end of a transaction. When\par
checked, if any Constraint is violated, the SQL statement that caused it to be\par
checked will fail: your DBMS will return the SQLSTATE error 23000 "integrity\par
constraint violation" unless the SQL statement that fails is a COMMIT\par
statement. If COMMIT fails, your DBMS will return the SQLSTATE error 40002\par
"transaction rollback-integrity constraint violation". In either case, the\par
status of all SQL-data remains as it was prior to the execution of the failed\par
SQL statement.\par
\par
** TRAP: You're taking a huge risk when you use deferred Constraints, since\par
you're not warned of any problems until COMMIT time. Remember that, at this\par
point, instead of returning a message like "sorry the Constraint's been\par
violated" and giving you a chance to fix the problem, your DBMS will say\par
"sorry the Constraint's been violated" and ROLLBACKs the entire transaction!\par
In other words, although you've asked for COMMIT, what you get is ROLLBACK.\par
This is perhaps the only command in any programming language where, if you ask\par
for x, you not only don't get x, you actually get the precise reverse of x! If\par
you must use deferred Constraints, add this SQL statement to your transaction\par
before you COMMIT:\par
\par
   SET CONSTRAINTS ALL IMMEDIATE;\par
\par
The advantage of SET CONSTRAINTS ALL IMMEDIATE is that it won't ROLLBACK, so\par
if you execute it before you COMMIT, you improve your chances of having\par
something to commit.\par
\par
Although it's usually best to check all Constraints for violation right after\par
you've done an operation that might cause your data to be invalid, here's some\par
reasons why you might want to defer Constraint checking:\par
      ## Because some invalid state might be true for a while (such as a\par
transaction that temporarily throws everything out of balance), but you know\par
that the situation will resolve itself by transaction end.\par
      ## Because you want to subvert or ignore Constraints until there is some\par
reason to worry about them. For example, there might be some calculations that\par
you want to perform on a "what if" basis, and the only way to get them\par
straight is by temporarily turning off the Constraint checking mechanism. Such\par
"what if" calculations are normally ended with a ROLLBACK statement.\par
** TRAP: There are some systems -- the notorious example is the requirement\par
for ODBC -- which "auto-commit". This means that as soon as a SQL statement is\par
finished, your helpful DBMS will automatically execute a COMMIT statement for\par
you! As well as being a violation of the SQL Standard and making the ROLLBACK\par
statement useless, this action destroys the basis on which we lay our\par
deferred-Constraint plans.\par
\par
Here is an example of a SQL statement that adds a NOT DEFERRABLE INITIALLY\par
IMMEDIATE Constraint to a Table:\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT constraint_1 \par
      CHECK (column_1 > 500) NOT DEFERRABLE INITIALLY IMMEDIATE;\par
\par
This SQL statement adds a DEFERRABLE INITIALLY IMMEDIATE Constraint to a\par
Table:\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT constraint_1 \par
      CHECK (column_1 > 500) DEFERRABLE INITIALLY IMMEDIATE;\par
\par
This SQL statement adds a DEFERRABLE INITIALLY DEFERRED Constraint to a Table:\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT constraint_1 \par
      CHECK (column_1 > 500) DEFERRABLE INITIALLY DEFERRED;\par
\par
If you want to restrict your code to Core SQL, don't name your Constraints and\par
don't add a <constraint attributes> clause to your Constraint definitions.\par
(This means you'll be defining all Constraints as NOT DEFERRABLE INITIALLY\par
IMMEDIATE.)\par
\par
Constraint_type -- UNIQUE Constraint\par
\par
A UNIQUE Constraint is either a <Table Constraint> or a <Column Constraint>\par
and defines a rule that constrains a unique key to non-duplicate values only.\par
The required syntax for a UNIQUE Constraint is: \par
\par
UNIQUE <Table Constraint> ::= \par
[ CONSTRAINT <Constraint name> ] \par
UNIQUE (<Column name> [ \{,<Column name>\}... ]) | UNIQUE (VALUE) \par
[ <constraint attributes> ] \par
\par
UNIQUE <Column Constraint> ::= \par
[ CONSTRAINT <Constraint name> ] \par
<Column name> UNIQUE \par
[ <constraint attributes> ] \par
\par
A Base table may be constrained by zero or more UNIQUE Constraints, each\par
specifying a rule that a group of one or more Columns (the unique key) may\par
contain only unique values. You can't define a unique key with Columns that\par
have a <data type> of BLOB, CLOB, NCLOB or ARRAY. A unique key is also known\par
as a candidate key of the Table. The main reasons you need candidate keys are\par
(a) to get row-level addressing, (b) so that foreign keys can reference the\par
candidate key and (c) to prevent duplication (keyboard errors, etc).\par
\par
Each UNIQUE Constraint must name a set of Columns that is different from the\par
set of Columns named by any other UNIQUE or PRIMARY KEY Constraint defined for\par
the Table. If you use UNIQUE (VALUE) to define a UNIQUE Constraint, you're\par
constraining the Table that owns the Constraint to have just that one UNIQUE\par
Constraint and -- since a PRIMARY KEY Constraint is a type of UNIQUE\par
Constraint -- you're also constraining that Table not to have any PRIMARY KEY\par
Constraint. UNIQUE (VALUE) constrains the entire row of the Table to be unique\par
from any other row.\par
\par
Here are some examples of UNIQUE Constraint definitions:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      CONSTRAINT constraint_1 UNIQUE(column_1) DEFERRED INITIALLY DEFERRED);\par
   -- defines a UNIQUE <Table Constraint> in CREATE TABLE\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT \par
         CONSTRAINT constraint_1 UNIQUE DEFERRED INITIALLY DEFERRED, \par
      column_2 CHAR(5));\par
   -- defines a UNIQUE <Column Constraint> in CREATE TABLE\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT constraint_2 \par
      UNIQUE(column_1,column_2) DEFERRED INITIALLY DEFERRED;\par
   -- defines a UNIQUE <Table Constraint> in ALTER TABLE\par
\par
Once created, a UNIQUE <Column Constraint> logically becomes a UNIQUE <Table\par
Constraint>. The <Column Constraint> in this SQL statement:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT UNIQUE);\par
\par
is therefore equivalent to the <Table Constraint> in this SQL statement: \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      UNIQUE(column_1)); \par
\par
A UNIQUE Constraint makes it impossible to COMMIT any operation that would\par
cause the unique key to contain any non-null duplicate values. (Multiple null\par
values are allowed, since the null value is never equal to anything, even\par
another null value.) A UNIQUE Constraint is violated if its condition is FALSE\par
for any row of the Table it belongs to. Consider these SQL statements:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(5), \par
      CONSTRAINT constraint_1 \par
         UNIQUE(column_1,column_2) DEFERRABLE INITIALLY DEFERRED);\par
\par
   INSERT INTO Table_1 (column_1, column_2) \par
   VALUES (1, 'hello');\par
\par
For this example, CONSTRAINT_1 would be violated only if you tried to INSERT\par
another \{1, 'hello') row into TABLE_1: a \{1, 'bye') row, a \{2, 'hello') row, a\par
\{null, 'hello') row, a \{1, null) row and a \{null, null) row would all satisfy\par
the Constraint.\par
\par
If you want to restrict your code to Core SQL, don't use the "UNIQUE(VALUE)"\par
form to define a UNIQUE Constraint and don't add a NOT NULL Constraint to any\par
Column that is part of a unique key for a UNIQUE Constraint.\par
\par
Constraint_type -- PRIMARY KEY Constraint\par
\par
A PRIMARY KEY Constraint is either a <Table Constraint> or a <Column\par
Constraint> and defines a rule that constrains a unique key to non-duplicate,\par
non-null values only. The required syntax for a PRIMARY KEY Constraint is:\par
\par
PRIMARY KEY <Table Constraint> ::=\par
[ CONSTRAINT <Constraint name> ]  \par
PRIMARY KEY (<Column name> [ \{,<Column name>\}... ]) \par
[ <constraint attributes> ] \par
\par
PRIMARY KEY <Column Constraint> ::= \par
[ CONSTRAINT <Constraint name> ] \par
<Column name> PRIMARY KEY \par
[ <constraint attributes> ] \par
\par
A Base table may be constrained by no more than one PRIMARY KEY Constraint,\par
which specifies a rule that a group of one or more Columns is the Table's\par
primary key. A primary key is the set of Columns in a Base table that (because\par
they will be used as the main unique identifier for a row) must contain only\par
unique and not null values. You can't define a primary key with Columns that\par
have a <data type> of BLOB, CLOB, NCLOB or ARRAY.\par
\par
A Table's PRIMARY KEY Constraint must name a set of Columns that is different\par
from the set of Columns named by any other UNIQUE Constraint defined for the\par
Table. Which unique key should be the primary key for a Table? The criteria\par
are:\par
      ## Simplicity, i.e.: the key with the fewest Columns and smallest size.\par
      ## Permanence.\par
      ## Mnemonicity, i.e.: the key that people will understand and remember.\par
      ## The key's use in other (e.g.: foreign) Tables.\par
\par
Here are some examples of PRIMARY KEY Constraint definitions:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      CONSTRAINT constraint_1 PRIMARY KEY(column_1) NOT DEFERRABLE;\par
   -- defines a PRIMARY KEY <Table Constraint> in CREATE TABLE\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT CONSTRAINT constraint_1 PRIMARY KEY NOT DEFERRABLE, \par
      column_2 CHAR(5));\par
   -- defines a PRIMARY KEY <Column Constraint> in CREATE TABLE\par
\par
   ALTER TABLE Table_2 ADD CONSTRAINT constraint_2 \par
      PRIMARY KEY(column_1,column_2) NOT DEFERRABLE INITIALLY IMMEDIATE;\par
   -- defines a PRIMARY KEY <Table Constraint> in ALTER TABLE\par
\par
Once created, a PRIMARY KEY <Column Constraint> logically becomes a PRIMARY\par
KEY <Table Constraint>. The <Column Constraint> in this SQL statement:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT PRIMARY KEY);\par
\par
is therefore equivalent to the <Table Constraint> in this SQL statement: \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      PRIMARY KEY(column_1)); \par
\par
A PRIMARY KEY Constraint makes it impossible to COMMIT any operation that\par
would cause the unique key to contain any NULLs or any duplicate values. A\par
PRIMARY KEY Constraint is violated if its condition is FALSE for any row of\par
the Table it belongs to. Consider these SQL statements:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(5), \par
      CONSTRAINT constraint_1 PRIMARY KEY(column_1,column_2) NOT DEFERRABLE );\par
\par
   INSERT INTO Table_1 (column_1, column_2) \par
   VALUES (1, 'hello');\par
\par
For this example, CONSTRAINT_1 would be violated if you tried to INSERT\par
another \{1, 'hello') row into TABLE_1 or if you tried to insert a \{null,\par
'hello') row, a \{1, null) row or a \{null, null) into TABLE_1.\par
\par
The uniqueness of a primary key helps guarantee the integrity of your data.\par
Once you've defined a primary key for a Table, you're protected from simple\par
errors like putting in the same person twice. More importantly, or at least\par
equally importantly, you have the reflection of the "real world" fact that two\par
things aren't alike in every respect -- if they were, they'd form the same\par
record. When you declare a primary key, you are hinting to your DBMS that the\par
data in the key is relatively static. Many attributes of a Table are\par
transient: an employee's salary, age, weight, title, evaluation, etc. But a\par
primary key Column's values tend to be stable -- we don't change people's\par
names or our part numbers very often. A primary key identifier also comes in\par
handy when you're splitting your data into two Tables. For example, consider\par
an "Internet address". You might start off with this Table definition:\par
\par
   CREATE TABLE Table_1 ( \par
      table_id VARCHAR(40), \par
      int_address VARCHAR(50));\par
\par
This is fine as long as whomever is represented in the TABLE_ID Column only\par
has one Internet address. But that person now gives you the Internet address\par
used at work -- and perhaps at several other locations. Should you have a\par
repeating Column (ARRAY) for this data? Well maybe, but the use of non-atomic\par
values is still frowned on and deservedly has a bad rep -- see our chapter on\par
<collection type>s for a discussion of the problem. The classic relational\par
solution is to split your data into two Tables. For example:\par
\par
   CREATE TABLE Table_1 ( \par
      table_id VARCHAR(40), \par
      CONSTRAINT constraint_1 PRIMARY KEY(table_id));\par
\par
   CREATE TABLE Table_2 ( \par
      table_id VARCHAR(40), \par
      int_address VARCHAR(50), \par
      CONSTRAINT constraint_2 FOREIGN KEY(int_address) REFERENCES Table_1);\par
\par
These definitions allow you to store as many Internet addresses for a single\par
person as you want -- a repeating group is possible in SQL, it's just an\par
avoidance of first-normal form if you try to put it into one Table.\par
\par
Constraint_type -- FOREIGN KEY Constraint\par
\par
A FOREIGN KEY Constraint is either a <Table Constraint> or a <Column\par
Constraint> and defines a rule that constrains a foreign key to values that\par
match only those values contained in a referenced unique key. The required\par
syntax for a FOREIGN KEY Constraint is: \par
\par
FOREIGN KEY <Table Constraint> ::=\par
[ CONSTRAINT <Constraint name> ]  \par
FOREIGN KEY (referencing <Column name> [ \{,<Column name>\}... ]) \par
   REFERENCES referenced <Table name> \par
      [ (referenced <Column name> [ \{,<Column name>\}... ]) ] \par
   [ MATCH \{FULL | PARTIAL | SIMPLE\} ] \par
   [ <referential triggered action> ] \par
[ <constraint attributes> ] \par
\par
      <referential triggered action> ::=\par
      ON UPDATE <action> [ ON DELETE <action> ] | \par
      ON DELETE <action> [ ON UPDATE <action> ]\par
\par
         <action> ::=\par
         NO ACTION | \par
         CASCADE | \par
         RESTRICT | \par
         SET NULL | \par
         SET DEFAULT\par
\par
FOREIGN KEY <Column Constraint> ::= \par
[ CONSTRAINT <Constraint name> ] \par
<Column name> REFERENCES referenced <Table name> \par
      [ (referenced <Column name>) ]\par
   [ MATCH \{FULL | PARTIAL | SIMPLE\} ] \par
   [ <referential triggered action> ] \par
[ <constraint attributes> ] \par
\par
A Base table may be constrained by zero or more FOREIGN KEY Constraints, which\par
specify a rule that a group of one or more Columns of the Table may contain\par
only those values found in a similar set of unique Columns belonging to\par
(usually) another Table. You can't define a foreign key with Columns that have \par
a <data type> of BLOB, CLOB, NCLOB or ARRAY. Here are some examples of FOREIGN\par
KEY Constraint definitions:\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT, \par
      CONSTRAINT constraint_1 FOREIGN KEY(column_1) REFERENCES Table_1 \par
         NOT DEFERRABLE); \par
   -- defines a FOREIGN KEY <Table Constraint> in CREATE TABLE\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT CONSTRAINT constraint_1 \par
         FOREIGN KEY REFERENCES Table_1 NOT DEFERRABLE,  \par
      column_2 CHAR(5));\par
   -- defines a FOREIGN KEY <Column Constraint> in CREATE TABLE \par
\par
   ALTER TABLE Table_2 ADD CONSTRAINT constraint_2 \par
      FOREIGN KEY(column_1,column_2) REFERENCES Table_1(column_3,column_5) \par
         DEFERRABLE INITIALLY IMMEDIATE;\par
   -- defines a FOREIGN KEY <Table Constraint> in ALTER TABLE\par
\par
Once created, a FOREIGN KEY <Column Constraint> logically becomes a FOREIGN\par
KEY <Table Constraint>. The <Column Constraint> in this SQL statement:\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT REFERENCES Table_1);\par
\par
is therefore equivalent to the <Table Constraint> in this SQL statement:\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT, \par
      FOREIGN KEY(column_1) REFERENCES Table_1);\par
\par
The rationale for a foreign key is: you can't have an employee in department D\par
if there is no department D, you can't have a branch that produces Widgets if\par
you don't have a product called a Widget, you can't locate an office in state\par
= 'TY' if there is no state named 'Tynnessee'. A FOREIGN KEY Constraint forges\par
a link between the referencing Table and the referenced Table: it makes it\par
impossible to COMMIT any operation that would cause the foreign key to contain\par
any values that are not found in the referenced unique key. (The referencing\par
Table is the Table that the FOREIGN KEY Constraint belongs to; the foreign key\par
itself is made up of one or more Columns of that Table: these are called the\par
referencing Columns. The referenced Table is the Table that contains the\par
unique key that the foreign key must match: the Columns that make up that\par
unique key are called the referenced Columns. SQL allows the referencing Table\par
and the referenced Table to be the same.) In the usual situation, illustrated\par
in the examples above (other actions can be specified), the Constraint makes\par
it impossible to drop TABLE_1 (because TABLE_2 references it), or to delete or\par
change a row in TABLE_1 so that TABLE_2 is left with unmatched referencing\par
values, or to insert a row into  TABLE_2 unless its referencing values are\par
matched somewhere in TABLE_1. A FOREIGN KEY Constraint is violated if its\par
condition is FALSE for any row of the Table it belongs to. The result of the\par
evaluation of the FOREIGN KEY Constraint condition depends on the presence of\par
null values and the degree of matching specified for the Constraint; see the\par
comments on the MATCH clause, later in this section.\par
\par
Referencing Columns:\par
The FOREIGN KEY clause of a FOREIGN KEY <Table Constraint> definition names\par
the referencing Columns: the group of one or more Columns that make up the\par
foreign key (a Column may appear in the list only once). You may specify only\par
unqualified <Column name>s in this clause.\par
\par
Referenced Table and Columns:\par
The REFERENCES clause of a FOREIGN KEY Constraint definition names the\par
referenced Base table: the Base table that contains the referenced unique key.\par
The Table types must match: if the Table that owns the FOREIGN KEY Constraint\par
is a persistent Base table, the referenced Table must also be a persistent\par
Base Table; if the referencing Table is a GLOBAL TEMPORARY Base table, the\par
referenced Table must also be a GLOBAL TEMPORARY Base Table; if the\par
referencing Table is a created LOCAL TEMPORARY Base table, the referenced\par
Table must be either a GLOBAL TEMPORARY Base Table or a created LOCAL\par
TEMPORARY Base table; if the referencing Table is a declared LOCAL TEMPORARY\par
Base table, the referenced Table must be either a GLOBAL TEMPORARY Base Table,\par
a created LOCAL TEMPORARY Base table or a declared LOCAL TEMPORARY Base table;\par
and if the referencing Table is any temporary Base table defined with an ON\par
COMMIT DELETE ROWS clause, the referenced Table must also be a temporary Base\par
Table defined with that clause.\par
\par
The referenced Columns, optionally named in the REFERENCES clause of a FOREIGN\par
KEY Constraint definition, are the group of one or more Columns that make up\par
the referenced unique key (that is, the referenced Columns must be named in a\par
NOT DEFERRABLE UNIQUE or NOT DEFERRABLE PRIMARY KEY Constraint that belongs to\par
the referenced Table and may therefore appear in the list only once). You may\par
specify only unqualified <Column name>s in this clause. The Columns in the\par
foreign key must match the number of, and have a comparable <data type> with,\par
the corresponding Columns in the referenced unique key. If you omit the\par
referenced Columns list from a FOREIGN KEY Constraint definition, the\par
referenced Table must be constrained by a NOT DEFERRABLE PRIMARY KEY\par
Constraint; the primary key is also the referenced unique key.\par
\par
Here are some more examples of FOREIGN KEY Constraint definitions:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(4), \par
      CONSTRAINT constraint_1 \par
         PRIMARY KEY(column_1,column_2) NOT DEFERRABLE); \par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(4), \par
      CONSTRAINT constraint_2 \par
         FOREIGN KEY(column_1,column_2) REFERENCES Table_1); \par
   -- Here the referenced unique key defaults to Table_1's primary key\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(4), \par
      CONSTRAINT constraint_1 \par
         PRIMARY KEY(column_1,column_2) NOT DEFERRABLE); \par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(4), \par
      CONSTRAINT constraint_2 \par
         FOREIGN KEY(column_1,column_2) \par
            REFERENCES Table_1(column_1,column_2));\par
   -- Here the foreign key explicitly matches Table_1's primary key\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(4), \par
      column_3 DATE, \par
      CONSTRAINT constraint_1 \par
         PRIMARY KEY(column_1,column_2) NOT DEFERRABLE, \par
      CONSTRAINT constraint_2 \par
         UNIQUE(column3) NOT DEFERRABLE);\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(4), \par
      column_3 DATE, \par
      CONSTRAINT constraint_3 \par
         FOREIGN KEY(column3) REFERENCES Table_1(column3));\par
   -- Here the foreign key explicitly matches Table_1's unique key; this is\par
mandatory because, if the referenced Column list were omitted, your DBMS would\par
attempt to match the foreign key (COLUMN_3) to Table_1's primary key\par
(COLUMN_1,COLUMN_2) and would fail.\par
\par
Privileges:\par
\par
In order to create a FOREIGN KEY Constraint, the <AuthorizationID> that owns\par
the referencing Table must be the current <AuthorizationID> and must have the\par
REFERENCES Privilege on every referenced Column named.\par
\par
MATCH clause:\par
The optional MATCH clause of a FOREIGN KEY Constraint definition specifies the\par
degree of the required match between the values of the foreign key and the\par
referenced unique key. There are three match options: MATCH SIMPLE, MATCH FULL\par
and MATCH PARTIAL. If you omit the MATCH clause, it defaults to MATCH SIMPLE.\par
For example, these two SQL statements are equivalent:\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT,\par
      CONSTRAINT constraint_1 REFERENCES Table_1);\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT,\par
      CONSTRAINT constraint_1 REFERENCES Table_1 MATCH SIMPLE);\par
\par
The MATCH option specified for a FOREIGN KEY Constraint has an effect only\par
when your foreign key contains null values.\par
\par
For MATCH SIMPLE, a FOREIGN KEY Constraint is satisfied if, for each row of\par
the referencing Table, either (a) at least one of the foreign key Columns is\par
NULL or (b) none of the foreign key Columns is NULL and the value of the\par
entire foreign key equals the value of the entire unique key in at least one\par
row of the referenced Table. For example, given a referenced Table with these\par
two unique key rows:\par
\par
   \{10,'tiny'\} \{20,'huge'\}\par
\par
these foreign key rows are valid for the referencing Table:\par
\par
   \{10,'tiny'\} -- because a matching unique key row exists\par
\par
   \{NULL,'tiny'\} \{10,NULL\} \{NULL,'soso'\} \{30,NULL\} -- because, in each case,\par
one foreign key Column is NULL\par
\par
and this foreign key row is invalid:\par
\par
   \{10,'huge'\} -- because no matching unique key row exists\par
\par
For MATCH FULL, a FOREIGN KEY Constraint is satisfied if, for each row of the\par
referencing Table, either (a) every foreign key Column is NULL or (b) none of\par
the foreign key Columns is NULL and the value of the entire foreign key equals\par
the value of the entire unique key in at least one row of the referenced\par
Table. (If you define a FOREIGN KEY Constraint with MATCH FULL and there is\par
either (a) only one Column in the foreign key or (b) one or more Columns\par
defined as NOT NULL in the foreign key, then the Constraint will have the same\par
effect as if you had defined the Constraint with MATCH SIMPLE.) For example,\par
given a referenced Table with these two unique key rows:\par
\par
   \{10,'tiny'\} \{20,'huge'\}\par
\par
these foreign key rows are valid for the referencing Table:\par
\par
   \{10,'tiny'\} -- because a matching unique key row exists\par
\par
   \{NULL,NULL\} -- because the entire foreign key is NULL\par
\par
and these foreign key rows are invalid:\par
\par
   \{10,'huge'\} -- because no matching unique key row exists\par
\par
   \{NULL,'tiny'\} \{10,NULL\} -- because, in each case, only some of the foreign\par
key is NULL\par
\par
For MATCH PARTIAL, a FOREIGN KEY Constraint is satisfied if, for each row of\par
the referencing Table, at least one foreign key Column is NULL and the values\par
of the rest of the foreign key Columns equal the values of the corresponding\par
unique key Columns in at least one row of the referenced Table. (If you define\par
a FOREIGN KEY Constraint with MATCH PARTIAL and there is either (a) only one\par
Column in the foreign key or (b) one or more Columns defined as NOT NULL in\par
the foreign key, then the Constraint will have the same effect as if you had\par
defined the Constraint with MATCH SIMPLE.) For example, given a referenced\par
Table with these two unique key rows:\par
\par
   \{10,'tiny'\} \{20,'huge'\}\par
\par
these foreign key rows are valid for the referencing Table:\par
\par
   \{10,'tiny'\} -- because a matching unique key row exists\par
\par
   \{NULL,NULL\} -- because the entire foreign key is NULL\par
 \par
   \{NULL,'tiny'\} \{10,NULL\} \{NULL,'huge'\} \{20,NULL\} -- because, in each case,\par
one foreign key Column is NULL but the other matches the corresponding unique\par
Column in some row of the referenced Table\par
\par
and these foreign key rows are invalid:\par
\par
   \{10,'huge'\} -- because no matching unique key row exists\par
\par
   \{NULL,'big'\} \{30,NULL\} -- because, although one foreign key Column is NULL.\par
the other does not match the value of the corresponding unique Column in any\par
row of the referenced Table\par
\par
** TIP: Use MATCH FULL, or define all foreign key Columns with a NOT NULL\par
Constraint.\par
\par
Referential Action:\par
What happens if you UPDATE a primary key? What happens if you DELETE a primary\par
key? Neither should happen often, but if you must, remember that the rule for\par
primary/foreign key relationships is in terms of database states: "no foreign\par
key shall dangle". There are two ways to get rid of a dangling key: prevent it\par
from happening in the first place, or compensate if it does happen. You can do\par
this by defining your FOREIGN KEY Constraints with one ON UPDATE clause and/or\par
one ON DELETE clause, in any order. The optional ON UPDATE clause specifies\par
the action you want your DBMS to take when an UPDATE operation on the\par
referenced Table causes the FOREIGN KEY Constraint to be violated. The\par
optional ON DELETE clause specifies the action you want your DBMS to take when\par
a DELETE operation on the referenced Table causes the FOREIGN KEY Constraint\par
to be violated. If you omit either clause, both default to ON UPDATE NO ACTION\par
and ON DELETE NO ACTION. For example, these two SQL statements are equivalent:\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT,\par
      CONSTRAINT constraint_1 REFERENCES Table_1); \par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT,\par
      CONSTRAINT constraint_1 REFERENCES Table_1 \par
         ON UPDATE NO ACTION ON DELETE NO ACTION);\par
\par
Besides NO ACTION, you may also specify these actions in the ON UPDATE and ON\par
DELETE clauses: RESTRICT, CASCADE, SET NULL and SET DEFAULT. To decide which\par
to use, consider first what you would like to happen. Should you be prevented\par
from leaving a dangling reference -- or should you change the dangling\par
reference too? (A dangling reference is a foreign key that doesn't point to a\par
unique key any more, and it isn't allowed in SQL.) If you do change the\par
dangling reference, should you be changing to (a) the same value as the new\par
unique key, (b) NULL or (c) some other value? Or should the change be a\par
deletion? All these options are available. The action taken by your DBMS in\par
all cases depends on the definition of "matching rows" for the FOREIGN KEY\par
Constraint: this, in turn, depends on the FOREIGN KEY Constraint's MATCH\par
option.\par
\par
For MATCH SIMPLE and MATCH FULL, given a row in the referenced Table, every\par
row in your referencing Table that contains a foreign key whose value equals\par
the value of that unique key, is a matching row. For MATCH PARTIAL, given a\par
row in the referenced Table, every row in your referencing Table that contains\par
a foreign key with at least one non-null Column whose value equals the value\par
of that unique key, is a matching row -- and a matching row that matches only\par
one row of the referenced Table is a unique matching row.\par
      ## If you define a FOREIGN KEY Constraint with MATCH SIMPLE ON DELETE\par
CASCADE or with MATCH FULL ON DELETE CASCADE, every time you DELETE rows from\par
the referenced Table, your DBMS will also DELETE all matching rows from the\par
referencing Table. If you define a FOREIGN KEY Constraint with MATCH PARTIAL\par
ON DELETE CASCADE, every time you DELETE rows from the referenced Table, your\par
DBMS will also DELETE all unique matching rows from the referencing Table.\par
      ## If you define a FOREIGN KEY Constraint with MATCH SIMPLE ON DELETE\par
SET NULL or with MATCH FULL ON DELETE SET NULL, every time you DELETE rows\par
from the referenced Table, your DBMS will also set the entire foreign key in\par
every matching row of the referencing Table to NULL. If you define a FOREIGN\par
KEY Constraint with MATCH PARTIAL ON DELETE SET NULL, every time you DELETE\par
rows from the referenced Table, your DBMS will also set the entire foreign key\par
in every unique matching row of the referencing Table to NULL.\par
      ## If you define a FOREIGN KEY Constraint with MATCH SIMPLE ON DELETE\par
SET DEFAULT or with MATCH FULL ON DELETE SET DEFAULT, every time you DELETE\par
rows from the referenced Table, your DBMS will also set each Column of the\par
foreign key in every matching row of the referencing Table to its default\par
value. If you define a FOREIGN KEY Constraint with MATCH PARTIAL ON DELETE SET\par
DEFAULT, every time you DELETE rows from the referenced Table, your DBMS will\par
also set each Column of the foreign key in every unique matching row of the\par
referencing Table to its default value.\par
      ## If you define a FOREIGN KEY Constraint with MATCH SIMPLE ON DELETE\par
RESTRICT or with MATCH FULL ON DELETE RESTRICT, every time you attempt to\par
DELETE rows from the referenced Table, your DBMS will check for matching rows\par
in the referencing Table. If you define a FOREIGN KEY Constraint with MATCH\par
PARTIAL ON DELETE RESTRICT, every time you attempt to DELETE rows from the\par
referenced Table, your DBMS will check for unique matching rows in the\par
referencing Table. In either case, if any matching (or unique matching, as\par
appropriate) rows exist, the operation will fail: your DBMS will return the\par
SQLSTATE error 23001 "integrity constraint violation-restrict violation". A\par
FOREIGN KEY Constraint defined with ON DELETE NO ACTION acts essentially the\par
same as one defined with ON DELETE RESTRICT.\par
      ## If you define a FOREIGN KEY Constraint with MATCH SIMPLE ON UPDATE\par
CASCADE or with MATCH FULL ON UPDATE CASCADE, every time you UPDATE a\par
referenced Column, your DBMS will also UPDATE the corresponding foreign key\par
Column in all matching rows of the referencing Table to the same value. If you\par
define a FOREIGN KEY Constraint with MATCH PARTIAL ON UPDATE CASCADE, every\par
time you UPDATE a referenced Column, your DBMS will also UPDATE any\par
corresponding non-null foreign key Column in every unique matching row of the\par
referencing Table to the same value -- provided that, for each referencing row\par
changed, all rows of the referenced Table that considered that referencing row\par
to be a matching row also have the same change made. If this isn't the case,\par
the operation will fail: your DBMS will return the SQLSTATE error 27000\par
"triggered data change violation".\par
      ## If you define a FOREIGN KEY Constraint with MATCH SIMPLE ON UPDATE\par
SET NULL, every time you UPDATE a referenced Column, your DBMS will also set\par
the corresponding foreign key Column in all matching rows of the referencing\par
Table to NULL. If you define a FOREIGN KEY Constraint with MATCH FULL ON\par
UPDATE SET NULL, every time you UPDATE a referenced Column, your DBMS will\par
also set the entire foreign key in every matching row of the referencing Table\par
to NULL. If you define a FOREIGN KEY Constraint with MATCH PARTIAL ON UPDATE\par
SET NULL, every time you UPDATE a referenced Column, your DBMS will also set\par
any corresponding non-null foreign key Column in every unique matching row of\par
the referencing Table to NULL.\par
      ## If you define a FOREIGN KEY Constraint with MATCH SIMPLE ON UPDATE\par
SET DEFAULT or with MATCH FULL ON UPDATE SET DEFAULT, every time you UPDATE a\par
referenced Column, your DBMS will also set the corresponding foreign key\par
Column in all matching rows of the referencing Table to its default value. If\par
you define a FOREIGN KEY Constraint with MATCH PARTIAL ON UPDATE SET DEFAULT,\par
every time you UPDATE a referenced Column, your DBMS will also set any\par
corresponding non-null foreign key Column in every unique matching row of the\par
referencing Table to its default value.\par
      ## If you define a FOREIGN KEY Constraint with MATCH SIMPLE ON UPDATE\par
RESTRICT or with MATCH FULL ON UPDATE RESTRICT, every time you attempt to\par
UPDATE a referenced Column, your DBMS will check for matching rows in the\par
referencing Table. If you define a FOREIGN KEY Constraint with MATCH PARTIAL\par
ON UPDATE RESTRICT, every time you attempt to UPDATE a referenced Column, your\par
DBMS will check for unique matching rows in the referencing Table. In either\par
case, if any matching (or unique matching, as appropriate) rows exist, the\par
operation will fail: your DBMS will return the SQLSTATE error 23001 "integrity\par
constraint violation-restrict violation". A FOREIGN KEY Constraint defined\par
with ON UPDATE NO ACTION acts essentially the same as one defined with ON\par
UPDATE RESTRICT.\par
\par
For an example of the NO ACTION/RESTRICT option, consider the following SQL\par
statements:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT DEFAULT 12 \par
         CONSTRAINT constraint_1 PRIMARY KEY(column_1) NOT DEFERRABLE);\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT DEFAULT 15 \par
         CONSTRAINT constraint_2 FOREIGN KEY(column_1) REFERENCES Table_1 \par
            MATCH FULL \par
            ON UPDATE NO ACTION ON DELETE NO ACTION \par
            NOT DEFERRABLE); \par
\par
   INSERT INTO Table_1 VALUES(10); \par
\par
   INSERT INTO Table_1 VALUES(15); \par
\par
   INSERT INTO Table_2 VALUES(10); \par
\par
For TABLE_1 and TABLE_2, the effect of each of these SQL statements:\par
\par
   UPDATE Table_1 SET column_1=11 WHERE column_1=10; \par
\par
   UPDATE Table_2 SET column_1=11 where column_1=10; \par
\par
   INSERT INTO Table_2 VALUES(11); \par
\par
is an error return, because the result in each case would be a value in\par
TABLE_2.COLUMN_1 that does not match some value in TABLE_1.COLUMN_1. (Note:\par
The action specified for the ON UPDATE clause has no effect on UPDATE\par
operations or INSERT operations performed on the referencing Table. Thus, an\par
INSERT operation that attempts to put a row into TABLE_2, or an UPDATE\par
operation that attempts to change a row of TABLE_2, will always fail if the\par
resulting value in TABLE_2.COLUMN_1 does not match some value of\par
TABLE_1.COLUMN_1.) The effect of this SQL statement: \par
\par
   DELETE FROM Table_1 WHERE column_1=10; \par
\par
is also an error return, because deleting the applicable row from\par
TABLE_1 would leave TABLE_2 with a row containing a COLUMN_1 value that does\par
not match any TABLE_1.COLUMN_1 value.\par
\par
To summarize:\par
      ## When an UPDATE operation attempts to update a non-null value in a\par
Column that is referenced in a FOREIGN KEY Constraint defined with ON UPDATE\par
NO ACTION or ON UPDATE RESTRICT, the UPDATE fails, regardless of the MATCH\par
option, if there are matching rows in the referencing Table. \par
      ## When a DELETE operation attempts to delete a row from a Table that is\par
referenced in a FOREIGN KEY Constraint defined with ON DELETE NO ACTION or ON\par
DELETE RESTRICT, the DELETE operation fails, regardless of the MATCH option,\par
if there are matching rows in the referencing Table. \par
\par
For an example of the CASCADE option, consider the following SQL statements:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT DEFAULT 12 \par
         CONSTRAINT constraint_1 PRIMARY KEY(column_1) NOT DEFERRABLE);\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT DEFAULT 15 \par
         CONSTRAINT constraint_2 FOREIGN KEY(column_1) REFERENCES Table_1 \par
            MATCH FULL \par
            ON UPDATE CASCADE ON DELETE CASCADE \par
            NOT DEFERRABLE); \par
\par
   INSERT INTO Table_1 VALUES(10); \par
\par
   INSERT INTO Table_1 VALUES(15); \par
\par
   INSERT INTO Table_2 VALUES(10); \par
\par
For TABLE_1 and TABLE_2, the effect of this SQL statement: \par
\par
   UPDATE Table_1 SET column_1=11 where column_1=10; \par
\par
is that all values of TABLE_1.COLUMN_1 that are equal to 10 are set to 11,\par
with the same effect cascading down; that is, all values in TABLE_2.COLUMN_1\par
that are equal to 10 are also set to 11. And the effect of this SQL statement:\par
\par
   DELETE FROM Table_1 WHERE column_1=10; \par
\par
is that all applicable rows are deleted from TABLE_1, with the same effect\par
cascading down; that is, all matching rows of TABLE_2 are also deleted.\par
\par
To summarize:\par
      ## When an UPDATE operation attempts to update a non-null value in a\par
Column that is referenced in a FOREIGN KEY Constraint defined with MATCH\par
SIMPLE or MATCH FULL and ON UPDATE CASCADE, the referenced Column, and the\par
corresponding referencing Column in all matching rows, are set to the new\par
value. When an UPDATE operation attempts to update a non-null value in a\par
Column that is referenced in a FOREIGN KEY Constraint defined with MATCH FULL\par
and ON UPDATE CASCADE, the referenced Column, and the corresponding\par
referencing Column in all unique matching rows where the referencing Column\par
contains a non-null value, are set to the new value. Unique matching rows with\par
a referencing Column that contains the null value are not updated. \par
      ## When a DELETE operation attempts to delete a row from a Table that is\par
referenced in a FOREIGN KEY Constraint defined with MATCH SIMPLE or MATCH FULL\par
and ON DELETE CASCADE, the applicable row, and all matching rows, are deleted.\par
When a DELETE operation attempts to delete a row from a Table that is\par
referenced in a FOREIGN KEY Constraint defined with MATCH PARTIAL and ON\par
DELETE CASCADE, the applicable row, and all unique matching rows, are deleted.\par
\par
For an example of the SET NULL option, consider the following SQL statements: \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT DEFAULT 12 \par
         CONSTRAINT constraint_1 PRIMARY KEY(column_1) NOT DEFERRABLE);\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT DEFAULT 15 \par
         CONSTRAINT constraint_2 FOREIGN KEY(column_1) REFERENCES Table_1 \par
            MATCH FULL \par
            ON UPDATE SET NULL ON DELETE SET NULL \par
            NOT DEFERRABLE); \par
\par
   INSERT INTO Table_1 VALUES(10); \par
\par
   INSERT INTO Table_1 VALUES(15); \par
\par
   INSERT INTO Table_2 VALUES(10); \par
\par
For TABLE_1 and TABLE_2, the effect of this SQL statement: \par
\par
   UPDATE Table_1 SET column_1=11 where column_1=10; \par
\par
is that all values of TABLE_1.COLUMN_1 that are equal to 10 are set to 11, and\par
that all values in TABLE_2.COLUMN_1 that are equal to 10 are set to the null\par
value. (If TABLE_2.COLUMN_1 did not allow null values, the UPDATE statement\par
would fail.) And the effect of this SQL statement: \par
\par
   DELETE FROM Table_1 WHERE column_1=10; \par
\par
is that all applicable rows are deleted from TABLE_1, and that all values in\par
TABLE_2.COLUMN_1 that are equal to 10 are set to the null value. (If\par
TABLE_2.COLUMN_1 did not allow null values, the DELETE statement would fail.)\par
\par
To summarize:\par
      ## When an UPDATE operation attempts to update a non-null value in a\par
Column that is referenced in a FOREIGN KEY Constraint defined with MATCH\par
SIMPLE and ON UPDATE SET NULL, the referenced Column is set to the new value\par
and the corresponding referencing Column in all matching rows is set to the\par
null value. When an UPDATE operation attempts to update a non-null value in a\par
Column that is referenced in a FOREIGN KEY Constraint defined with MATCH FULL\par
and ON UPDATE SET NULL, the referenced Column is set to the new value and\par
every referencing Column (not just the corresponding Column) in all matching\par
rows is set to the null value. When an UPDATE operation attempts to update a\par
non-null value in a Column that is referenced in a FOREIGN KEY Constraint\par
defined with MATCH PARTIAL and ON UPDATE SET NULL, the referenced Column is\par
set to the new value and the corresponding referencing Column in all unique\par
matching rows is set to the null value. \par
      ## When a DELETE operation attempts to delete a row from a Table that is\par
referenced in a FOREIGN KEY Constraint defined with MATCH SIMPLE or MATCH FULL\par
and ON DELETE SET NULL, the applicable row is deleted and, for all matching\par
rows, each referencing Column is set to the null value. When a DELETE\par
operation attempts to delete a row from a Table that is referenced in a\par
FOREIGN KEY Constraint defined with MATCH PARTIAL and ON DELETE SET NULL, the\par
applicable row is deleted, and, for all unique matching rows, each referencing\par
Column is set to the null value. \par
\par
For an example of the SET DEFAULT option, consider the following SQL\par
statements: \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT DEFAULT 12 \par
         CONSTRAINT constraint_1 PRIMARY KEY(column_1) NOT DEFERRABLE);\par
\par
   CREATE TABLE Table_2 ( \par
      column_1 SMALLINT DEFAULT 15 \par
         CONSTRAINT constraint_2 FOREIGN KEY(column_1) REFERENCES Table_1 \par
            MATCH FULL \par
            ON UPDATE SET DEFAULT ON DELETE SET DEFAULT \par
            NOT DEFERRABLE); \par
\par
   INSERT INTO Table_1 VALUES(10); \par
\par
   INSERT INTO Table_1 VALUES(15); \par
\par
   INSERT INTO Table_2 VALUES(10); \par
\par
For TABLE_1 and TABLE_2, the effect of this SQL statement: \par
\par
   UPDATE Table_1 SET column_1=11 where column_1=10; \par
\par
is that all values of TABLE_1.COLUMN_1 that are equal to 10 are set to 11, and\par
that all values of TABLE_2.COLUMN_1 that are equal to 10 are set to COLUMN_1's\par
default value, 15. (If no row existed where the value of TABLE_1.COLUMN_1 was\par
15, the UPDATE statement would fail.) And the effect of this SQL statement: \par
\par
   DELETE FROM Table_1 WHERE column_1=10; \par
\par
is that all applicable rows are deleted from TABLE_1 and that all values in\par
TABLE_2.COLUMN_1 that are equal to 10 are set to COLUMN_1's default value, 15.\par
(If no row existed where the value of TABLE_1.COLUMN_1 was 15, the DELETE\par
statement would fail.)\par
\par
To summarize:\par
      ## When an UPDATE operation attempts to update a non-null value in a\par
Column that is referenced in a FOREIGN KEY Constraint defined with MATCH\par
SIMPLE or MATCH FULL and ON UPDATE SET DEFAULT, the referenced Column is set\par
to the new value and the corresponding referencing Column in all matching rows\par
is set to its default value. When an UPDATE operation attempts to update a\par
non-null value in a Column that is referenced in a FOREIGN KEY Constraint\par
defined with MATCH PARTIAL and ON UPDATE SET DEFAULT, the referenced Column is\par
set to the new value and the corresponding referencing Column in all unique\par
matching rows is set to its default value. \par
      ## When a DELETE operation attempts to delete a row from a Table that is\par
referenced in a FOREIGN KEY Constraint defined with MATCH SIMPLE or MATCH FULL\par
and ON DELETE SET DEFAULT, the applicable row is deleted, and, for all\par
matching rows, each referencing Column is set to its default value. When a\par
DELETE operation attempts to delete a row from a Table that is referenced in a\par
FOREIGN KEY Constraint defined with MATCH PARTIAL and ON DELETE SET DEFAULT,\par
the applicable row is deleted, and, for all unique matching rows, each\par
referencing Column is set to its default value.\par
\par
Note: It is not possible to update the same Column more than once in a single\par
SQL statement. If such an operation is attempted, the statement will fail:\par
your DBMS will return the SQLSTATE error 27000 "triggered data change\par
violation". \par
\par
Note: All rows that are to be deleted by an SQL statement are effectively\par
deleted at the end of that statement's execution, prior to the checking of any\par
integrity constraints. \par
\par
If you want to restrict your code to Core SQL, don't define your FOREIGN KEY\par
Constraints with a MATCH clause, an ON UPDATE clause or an ON DELETE clause.\par
\par
Constraint_type -- NOT NULL Constraint\par
\par
A NOT NULL Constraint is a <Column Constraint>, defining a rule that\par
constrains a key to non-null values only. The required syntax for a NOT NULL\par
Constraint is: \par
\par
NOT NULL <Column Constraint> ::=\par
[ CONSTRAINT <Constraint name> ]  \par
<Column name> NOT NULL \par
[ <constraint attributes> ] \par
\par
A Column may be constrained by no more than one NOT NULL Constraint, which\par
specifies a rule that the Column may contain only non-null values. Here is an\par
example of a NOT NULL Constraint definition:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT \par
         DEFAULT 15 \par
         CONSTRAINT constraint_1 NOT NULL DEFERRABLE INITIALLY IMMEDIATE); \par
   -- defines a NOT NULL <Column Constraint> in CREATE TABLE\par
\par
Once created, a NOT NULL <Column Constraint> logically becomes a CHECK <Table\par
Constraint>. The <Column Constraint> in this SQL statement: \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT NOT NULL); \par
\par
is therefore equivalent to the <Table Constraint> in this SQL statement: \par
\par
CREATE TABLE Table_1 ( \par
     column_1 SMALLINT, \par
     CHECK (column_1 IS NOT NULL)); \par
\par
A NOT NULL Constraint makes it impossible to COMMIT any operation that would\par
cause the Column to which it belongs to contain any NULLs. A NOT NULL\par
Constraint is violated if it is FALSE for any row of the Table it belongs to.\par
Consider this SQL statement:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT CONSTRAINT constraint_1 NOT NULL, \par
      column_2 VARCHAR(4)); \par
\par
For this example, CONSTRAINT_1 would be violated if you tried to make COLUMN_1\par
contain NULL.\par
\par
Constraint_type -- CHECK Constraint\par
\par
A CHECK Constraint is either a <Table Constraint>, a <Column Constraint> or a\par
<Domain Constraint> and defines a rule that constrains the set of valid values\par
for a Base table. The required syntax for a CHECK Constraint is: \par
\par
CHECK <Table Constraint> ::=\par
[ CONSTRAINT <Constraint name> ]  \par
CHECK (search condition) \par
[ <constraint attributes> ] \par
\par
CHECK <Column Constraint> ::= \par
[ CONSTRAINT <Constraint name> ] \par
<Column name> CHECK (search condition) \par
[ <constraint attributes> ] \par
\par
CHECK <Domain Constraint> ::= \par
[ CONSTRAINT <Constraint name> ] \par
CHECK (VALUE search condition) \par
[ <constraint attributes> ] \par
\par
A Base table may be constrained by zero or more CHECK Constraints, which\par
specify a rule that a group of one or more Columns of a Table may contain only\par
those values that fall into the set defined by the rule -- that is, a CHECK\par
Constraint is satisfied if its search condition evaluates to TRUE or to\par
UNKNOWN for all rows within its scope.\par
\par
Here are some examples of CHECK Constraint definitions:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      CONSTRAINT constraint_1 CHECK(column_1<400) NOT DEFERRABLE);\par
   -- defines a CHECK <Table Constraint> in CREATE TABLE\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT \par
         CONSTRAINT constraint_1 CHECK(column_1<400) NOT DEFERRABLE, \par
      column_2 CHAR(5));\par
   -- defines a CHECK <Column Constraint> in CREATE TABLE\par
\par
   ALTER TABLE Table_2 ADD CONSTRAINT constraint_2 \par
      CHECK(column_1>100 OR column_2='hello') \par
         NOT DEFERRABLE INITIALLY IMMEDIATE;\par
   -- defines a CHECK <Table Constraint> in ALTER TABLE\par
\par
   CREATE DOMAIN domain_1 AS SMALLINT \par
      CONSTRAINT constraint_1 CHECK(VALUE IN 50,100,150) \par
         DEFERRABLE INITIALLY DEFERRABLE;\par
   -- defines a CHECK <Domain Constraint> in CREATE DOMAIN\par
\par
   ALTER DOMAIN domain_1 ADD CONSTRAINT constraint_2 \par
      CHECK(VALUE IS NOT NULL);\par
   -- defines a CHECK <Domain Constraint> in ALTER DOMAIN\par
\par
CHECK <Column Constraint>s may be defined only in a CREATE TABLE statement and\par
must be for a single Column only. CHECK <Table Constraint>s may be defined in\par
a CREATE TABLE or an ALTER TABLE statement and may be for one or more Columns.\par
CHECK <Domain Constraint>s may be defined in a CREATE DOMAIN or an ALTER\par
DOMAIN statement and must contain a search condition that uses the <value\par
specification> VALUE; valid only in a <Domain Constraint> (the <data type> of\par
a given instance of VALUE is the <data type> of the Domain that the <Domain\par
Constraint> belongs to). A <Domain Constraint>'s search condition may not be a\par
recursive search condition (that is, it may not refer, either directly or\par
indirectly, to the Domain that the <Domain Constraint> belongs to).\par
\par
Once created, a CHECK <Column Constraint> logically becomes a CHECK <Table\par
Constraint>. The <Column Constraint> in this SQL statement:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT CHECK(column_1<400));\par
\par
is therefore equivalent to the <Table Constraint> in this SQL statement: \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      CHECK(column_1<400)); \par
\par
A CHECK Constraint's search condition may specify any conditional expression,\par
subject to the following rules:\par
      ## The search condition may not contain (a) a <target specification> or\par
(b) a set function (i.e.: COUNT, AVG, MAX, MIN or SUM) unless the set function\par
is contained in a subquery or (c) any of these functions: CURRENT_PATH,\par
CURRENT_USER, SESSION_USER, SYSTEM_USER, USER, CURRENT_DATE, CURRENT_TIME,\par
CURRENT_TIMESTAMP, LOCALTIME or LOCALTIMESTAMP or (d) any query that is\par
possibly non-deterministic, as defined earlier in this chapter. \par
      ## The search condition may not invoke a non-deterministic routine, or a\par
routine which possibly modifies SQL-data.\par
      ## If a CHECK Constraint belongs to a persistent Base table or to a\par
Domain, its search condition may not refer to any temporary Tables.\par
      ## If a CHECK Constraint belongs to a GLOBAL TEMPORARY Base table, its\par
search condition may refer only to GLOBAL TEMPORARY Base Tables. If a CHECK\par
Constraint belongs to a created LOCAL TEMPORARY Base table, its search\par
condition may refer only to GLOBAL TEMPORARY Base Tables or to created LOCAL\par
TEMPORARY Base tables. If a CHECK Constraint belongs to a declared LOCAL\par
TEMPORARY Base table, its search condition may not refer to any persistent\par
Base Tables.\par
      ## If a CHECK Constraint belongs to a temporary Table defined with ON\par
COMMIT PRESERVE ROWS, its search condition may not contain a subquery that\par
refers to a temporary Table defined with ON COMMIT DELETE ROWS.\par
      ## [Obscure Rule] If a CHECK Constraint's search condition can't be\par
represented in INFORMATION_SCHEMA without truncation, your DBMS will return\par
the SQLSTATE warning 01009 "warning-search condition too long for information\par
schema".\par
\par
Privileges:\par
In order to create a CHECK Constraint, the <AuthorizationID> that owns the\par
Schema to which the Constraint will belong must be the current\par
<AuthorizationID> and must have the REFERENCES Privilege on every Column that\par
is explicitly named in the CHECK Constraint's search condition. If the search\par
condition doesn't explicitly name any Columns, the current <AuthorizationID>\par
must have the REFERENCES Privilege on at least one Column of every Table\par
referred to in the search condition. \par
\par
A CHECK Constraint makes it impossible to COMMIT any operation that would\par
cause the Constraint's search condition to evaluate to FALSE. (This means, of\par
course, that if the condition evaluates to TRUE or to UNKNOWN, the Constraint\par
is satisfied.) Thus, for example, the Constraint defined in this CREATE TABLE\par
statement is violated if any row of TABLE_1 contains a COLUMN_1 value that is\par
greater than 99: \par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(4), \par
      CONSTRAINT constraint_1 CHECK(column_1<100) NOT DEFERRABLE); \par
\par
This SQL statement would therefore violate CONSTRAINT_1:\par
\par
   INSERT INTO Table_1 VALUES (105); \par
\par
because a search condition that evaluates to FALSE violates the Constraint.\par
Both of these SQL statements, however, would satisfy CONSTRAINT_1:\par
\par
   INSERT INTO Table_1 VALUES (-30); \par
   -- a search condition that evaluates to TRUE satisfies the Constraint\par
\par
   INSERT INTO Table_1 VALUES (NULL); \par
   -- NULL is allowed; a search condition that evaluates to UNKNOWN satisfies\par
the Constraint\par
\par
The first use of a CHECK <Table Constraint> is to restrict what range of\par
values is allowed in a Column, for example:\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT constraint_1 \par
      CHECK(column_1 BETWEEN 5 AND 9) NOT DEFERRABLE;\par
\par
You'll often see Column values restrained like this; it's a feature in dialog\par
boxes. The second use of a CHECK <Table Constraint> is to see that two Columns\par
within the same Table agree with each other, for example:\par
\par
   ALTER TABLE Films ADD CONSTRAINT constraint_1 \par
      CHECK(film_type <> 'Action' OR star = 'Stallone') NOT DEFERRABLE;\par
\par
The third use is to find out whether some relation is true between a row in\par
one Table, and a row in another Table or a different row in the same Table,\par
for example:\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT constraint_1 \par
      CHECK (column_1 > (SELECT MAX(column_2) FROM Table_2) NOT DEFERRABLE;\par
\par
This sort of thing was once illegal, but in modern variations of SQL, you'll\par
see inter-table Constraint references on an occasional basis. The fourth use\par
of a CHECK <Table Constraint> is documentary, for example:\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT comment_1 \par
      CHECK ('this is a comment ...' IS NOT NULL) \par
         DEFERRABLE INITIALLY DEFERRED;\par
\par
Most DBMSs allow comments to be added to the metadata some other way, so this\par
final use is rare.\par
\par
For <Domain Constraint>s, the general idea is that object X doesn't belong in\par
type Y or, to put it positively: certain things go in certain classes. These\par
two examples both express the theme "values based on this Domain must not be\par
space":\par
\par
   CREATE DOMAIN domain_1 AS CHAR(1) \par
      CONSTRAINT constraint_1 CHECK (VALUE <> ' ');\par
\par
   CREATE DOMAIN domain_2 AS CHAR(1); \par
\par
   ALTER DOMAIN domain_2 ADD CONSTRAINT constraint_2 \par
      CHECK (VALUE <> ' ');\par
\par
In a <Domain Constraint>'s CHECK condition, the word VALUE is a placeholder:\par
your DBMS replaces it with the appropriate <Column name> when checking the\par
Constraint. The second of these two SQL statements would force a Constraint\par
check:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 domain_1, \par
      column_2 CHAR(10)); \par
   -- makes a Column based on DOMAIN_1\par
\par
   INSERT INTO Table_1 \par
   VALUES (' ', \par
           'bob');\par
   -- fails; CONSTRAINT_1 stops it\par
\par
A <Domain Constraint> applies to every Column that's defined on the Domain,\par
now or in the future. This makes sense since it's rare that a Column is in a\par
Domain all on its own -- and if the name of a manager is subject to some\par
Constraint (must be alphabetic, say), then surely the employees' names and\par
spouses' names should be subject to the same Constraint. There's a case for\par
suggesting that "data type checking" is just a vague form of "<Domain\par
Constraint> checking"; the error messages are different, but the point is the\par
same -- you are restricted as to what you can put in.\par
\par
If you want to restrict your code to Core SQL, don't use a subquery in a CHECK\par
Constraint's search condition. Also, for Core SQL, the REFERENCES Privilege\par
isn't needed to create a CHECK Constraint.\par
\par
CREATE ASSERTION statement \par
\par
The CREATE ASSERTION statement names a new Constraint and defines the\par
Constraint's deferral mode, initial constraint check time and its CHECK search\par
condition. The required syntax for the CREATE ASSERTION statement is: \par
\par
CREATE ASSERTION <Constraint name> \par
CHECK (search condition) \par
[ <constraint attributes> ] \par
\par
CREATE ASSERTION defines a new rule that will constrain the set of valid\par
values for one or more Base tables. An Assertion is owned by the Schema it\par
belongs to.\par
      ## The <Constraint name> identifies the Assertion and the Schema that it\par
belongs to. A <Constraint name> that includes an explicit <Schema name>\par
qualifier belongs to the Schema named. A <Constraint name> that does not\par
include an explicit <Schema name> qualifier belongs to the SQL-session default\par
Schema. (In both cases, that Schema must, of course, own the Tables for which\par
the Assertion is defined.) The <Constraint name> must be unique (for all\par
Constraints and Assertions) within the Schema that owns it.\par
\par
If CREATE ASSERTION is part of a CREATE SCHEMA statement, the <Constraint\par
name>, if explicitly qualified, must include the <Schema name> of the Schema\par
being created; that is, it isn't possible to create an Assertion belonging to\par
a different Schema from within CREATE SCHEMA. For example, this SQL statement\par
will not return an error because the <Constraint name> will default to include\par
the qualifying <Schema name>:\par
\par
   CREATE SCHEMA bob \par
      CREATE TABLE Table_1 (column_1 SMALLINT) \par
      CREATE ASSERTION constraint_1 \par
        CHECK ((SELECT AVG(column_1) FROM Table_1 >40) NOT DEFERRABLE;\par
   -- creates an Assertion called BOB.CONSTRAINT_1 in Schema BOB \par
\par
This SQL statement will not return an error either because the <Constraint\par
name> explicitly includes a qualifying <Schema name> that matches the name of\par
the Schema being created:\par
\par
   CREATE SCHEMA bob \par
      CREATE TABLE bob.Table_1 (column_1 SMALLINT)\par
      CREATE ASSERTION bob.constraint_1 \par
         CHECK ((SELECT AVG(column_1) FROM Table_1 >40) NOT DEFERRABLE;\par
   -- creates an Assertion called BOB.CONSTRAINT_1 in Schema BOB \par
\par
But this SQL statement will return an error because the <Constraint name>\par
explicitly includes a qualifying <Schema name> that is different from the name\par
of the Schema being created:\par
\par
   CREATE SCHEMA bob \par
      CREATE TABLE Table_1 (column_1 SMALLINT) \par
      CREATE ASSERTION sam.constraint_1 \par
        CHECK ((SELECT AVG(column_1) FROM Table_1 >40) NOT DEFERRABLE;\par
   -- tries to create a Constraint belonging to Schema SAM inside Schema BOB;\par
illegal syntax\par
\par
If CREATE ASSERTION is executed as a stand-alone SQL statement, the current\par
<AuthorizationID> must either be the owner of the Schema that this new\par
Constraint belongs to, or the Schema's owner must be a Role that the current\par
<AuthorizationID> may use. That is, only the owner of a Schema can create\par
Constraints for that Schema.\par
\par
An Assertion's CHECK search condition may specify any conditional expression\par
(it will almost inevitably contain the <keyword> EXISTS, the <keyword> UNIQUE\par
or a set function), subject to the following rules (note that these rules are\par
slightly different from the rules given earlier for a CHECK Constraint's\par
search condition):\par
      ## The search condition may not contain a <host parameter name>, an <SQL\par
parameter name>, any of these functions: CURRENT_PATH, CURRENT_USER,\par
SESSION_USER, SYSTEM_USER, USER, CURRENT_DATE, CURRENT_TIME,\par
CURRENT_TIMESTAMP, LOCALTIME or LOCALTIMESTAMP or any query that is possibly\par
non-deterministic, as defined earlier in this chapter.\par
      ## The search condition may not invoke a non-deterministic routine, or a\par
routine which possibly modifies SQL-data.\par
      ## The search condition may not refer to any temporary Tables.\par
      ## [Obscure Rule] If an Assertion's CHECK search condition can't be\par
represented in INFORMATION_SCHEMA without truncation, your DBMS will return\par
the SQLSTATE warning 01009 "warning-search condition too long for information\par
schema".\par
\par
An Assertion makes it impossible to COMMIT any operation that would cause the\par
Constraint's search condition to evaluate to FALSE. (This means, of course,\par
that if the condition evaluates to TRUE or to UNKNOWN, the Constraint is\par
satisfied.) Thus, for example, for these two SQL statements:\par
\par
   CREATE TABLE Table_1 ( \par
      column_1 SMALLINT, \par
      column_2 VARCHAR(4)); \par
\par
   CREATE ASSERTION constraint_1 \par
      CHECK ((SELECT AVG(column_1) FROM Table_1 >40) NOT DEFERRABLE;\par
\par
CONSTRAINT_1 is violated if the average of the TABLE_1.COLUMN_1 values is less\par
than 41. Assume that TABLE_1 contains one row, where COLUMN_1 contains 42.\par
This SQL statement would then violate CONSTRAINT_1:\par
\par
   INSERT INTO Table_1 VALUES (38); \par
\par
because a search condition that evaluates to FALSE violates the Constraint.\par
Both of these SQL statements, however, would satisfy CONSTRAINT_1:\par
\par
   INSERT INTO Table_1 VALUES (100); \par
   -- a search condition that evaluates to TRUE satisfies the Constraint\par
\par
   INSERT INTO Table_1 VALUES (NULL); \par
   -- NULL is allowed; a search condition that evaluates to UNKNOWN satisfies\par
the Constraint\par
\par
The <constraint attributes> clause of CREATE ASSERTION is as defined in\par
"Constraint definition", earlier in this chapter. If you omit the clause, the\par
Constraint defaults to a NOT DEFERRABLE INITIALLY IMMEDIATE Constraint.\par
\par
We've already said that an Assertion constrains Base tables. The reason\par
they're not <Table Constraint>s -- or the reason you'll sometimes want to use\par
Assertions rather than <Table Constraint>s -- lies in the difference between\par
the way an Assertion is checked and the way a <Table Constraint> is checked:\par
an Assertion is checked once, while a <Table Constraint> is checked once for\par
each row in the Table. This difference doesn't affect efficiency: modern DBMSs\par
are capable of figuring out when they really need to check, so we note this\par
only as a guide to what "effectively" happens. But consider what it means to\par
you: Assume a Constraint that, in English, is: "There must be at least one row\par
in Table TABLE_1". If you try to implement this requirement as a <Table\par
Constraint>, for example with this SQL statement:\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT constraint_1 \par
      CHECK (0 <> (SELECT COUNT(*) FROM Table_1));\par
\par
you'll find it won't work: since a <Table Constraint> is checked once "for\par
each row", and there are no rows, the check never happens if you leave the\par
TABLE_1 empty. To make it work, create an Assertion to ensure the condition is\par
checked at least once. For example:\par
\par
   CREATE ASSERTION constraint_1 \par
      CHECK (0 <> (SELECT COUNT(*) FROM Table_1));\par
\par
It's always a good idea to consider creating an Assertion when you see a\par
SELECT condition. Here's another example: consider a Constraint that, in\par
English, is: "We can only hold picnics if there's money." In this case, you\par
could use this <Table Constraint> and it would work:\par
\par
   ALTER TABLE Picnics ADD CONSTRAINT constraint_1 \par
      CHECK (EXISTS (SELECT * FROM Accounts WHERE balance > 0));\par
\par
But CONSTRAINT_1, as defined, is misleading -- the SQL statement suggests that\par
there's a Constraint on the PICNICS Table. There is, of course, but there's a\par
Constraint on the ACCOUNTS Table too and this isn't immediately clear. If you\par
define the same condition with CREATE ASSERTION, you'll be signalling that\par
there's more to it; for example:\par
\par
   CREATE ASSERTION Picnic_Account_Check \par
      CHECK (NOT EXISTS (SELECT * FROM Picnics) OR \par
             EXISTS (SELECT * FROM Accounts WHERE balance > 0));\par
\par
If you want to restrict your code to Core SQL, don't use the CREATE ASSERTION\par
statement.\par
\par
Interlocking references\par
\par
An example of an interlocking reference is:\par
      ## Every Employee must be in a department.\par
      ## Every Department must have at least one employee.\par
This is an "interlock" problem because there must be a reference from the\par
EMPLOYEES Table to the DEPARTMENTS Table, as well as a reference going the\par
other way: from the DEPARTMENTS Table to the EMPLOYEES Table. Here are the\par
Table definitions:\par
\par
   CREATE TABLE Employees ( \par
     emp_id INT,\par
     dept_id INT,\par
     CONSTRAINT emp_constraint_1 \par
      FOREIGN KEY (dept_id) REFERENCES Departments NOT DEFERRABLE);\par
\par
   CREATE TABLE Departments (\par
     dept_id,\par
     CONSTRAINT dept_constraint_1 \par
        PRIMARY KEY (dept_id) NOT DEFERRABLE, \par
     CONSTRAINT dept_constraint_2 \par
       CHECK (dept_id IN (SELECT * FROM Employees) NOT DEFERRABLE);\par
   -- this CHECK clause illustrates the normal way to make a "foreign\par
reference" to a "key" which is not unique or primary\par
\par
In this example, the CREATE TABLE Employees... statement will return an error\par
because it refers to the DEPARTMENTS Table before that Table has been created.\par
Interchanging the statement order wouldn't help, because then the CREATE TABLE\par
Departments... statement will return an error because it refers to the\par
EMPLOYEES Table before that Table has been created. You could put both Table\par
definitions inside a CREATE SCHEMA statement, but that isn't a general\par
solution. To solve the problem, split the CREATE TABLE statements up like\par
this:\par
\par
   CREATE TABLE Employees ( \par
      emp_id INT, \par
      dept_id INT);\par
\par
   CREATE TABLE Departments ( \par
      dept_id INT);\par
\par
   ALTER TABLE Departments ADD CONSTRAINT dept_constraint_1 \par
      PRIMARY KEY (dept_id) NOT DEFERRABLE;\par
\par
   ALTER TABLE Employees ADD CONSTRAINT emps_constraint_1 \par
      FOREIGN KEY (dept_id) REFERENCES Departments NOT DEFERRABLE;\par
\par
   ALTER TABLE Departments ADD CONSTRAINT dept_constraint_2 \par
      CHECK (dept_id IN (SELECT * FROM Employees) NOT DEFERRABLE);\par
\par
Not only does this second attempt resolve the legalities, it also looks\par
better: it's easier to read several short statements, rather than a few long\par
statements. Anyway, with this method, there's no problem defining interlocked\par
Tables. However, there's still a problem with putting data into them. For\par
example, assuming no data exists in either Table, this SQL statement:\par
\par
   INSERT INTO Employees VALUES (1, 1);\par
\par
will cause EMPS_CONSTRAINT_1 to fail because there are no departments. And\par
this SQL statement:\par
\par
   INSERT INTO Departments VALUES (1);\par
\par
will cause DEPT_CONSTRAINT_2 to fail because there are no employees.\par
\par
There are three solutions to this problem.\par
      ## Solution #1. Use SQL3 features. There are, in fact, a few ways to do\par
this with SQL3 -- the clearest would be to join the two Tables and update the\par
join.\par
      ## Solution #2. Take advantage of the fact that NULL matches anything.\par
Begin with the assumption that the DEPARTMENTS Table is not empty, presumably\par
because you used Solution #1 for some other department. Then execute these SQL\par
statements:\par
\par
   INSERT INTO Employees VALUES (1, NULL);\par
\par
   INSERT INTO Departments VALUES (1);\par
\par
   UPDATE Employees SET dept_id = 1 WHERE emp_id = 1;\par
\par
You can sometimes use NULL where you can't use anything else -- so insert a\par
NULL as a temporary placeholder, and replace it when both rows exist.\par
      ## Solution #3. Change the initial setup so that all Constraints are\par
deferred. For example:\par
\par
   CREATE TABLE Employees ( \par
      emp_id INT, \par
      dept_id INT);\par
\par
   CREATE TABLE Departments ( \par
      dept_id INT);\par
\par
   ALTER TABLE Departments ADD CONSTRAINT dept_constraint_1 \par
      PRIMARY KEY (dept_id) DEFERRABLE INITIALLY DEFERRED;\par
\par
   ALTER TABLE Employees ADD CONSTRAINT emps_constraint_1 \par
      FOREIGN KEY (dept_id) REFERENCES Departments \par
         DEFERRABLE INITIALLY DEFERRED;\par
\par
   ALTER TABLE Departments ADD CONSTRAINT dept_constraint_2 \par
      CHECK (dept_id IN (SELECT * FROM Employees)\par
         DEFERRABLE INITIALLY DEFERRED);\par
\par
This method causes the INSERT problem to disappear because no checks will\par
occur at INSERT time. Thus, these INSERT statements would now work without\par
returning an error:\par
\par
   INSERT INTO Employees VALUES (1, 1);\par
\par
   INSERT INTO Departments VALUES (1);\par
\par
   SET CONSTRAINTS ALL IMMEDIATE;\par
   -- recommended once the INSERTs are done\par
\par
We like Solution #3 best because it lacks dependence on SQL3 only features or\par
on tricks.\par
\par
Dropping Constraints\par
\par
Dropping a Constraint is straightforward, providing that you know the\par
<Constraint name> -- that's why we recommend that you explicitly give every\par
Constraint a name when you make it (even a NOT NULL Constraint). <Table\par
Constraint>s and <Column Constraint>s are dropped using the DROP CONSTRAINT\par
<Constraint name> clause of the ALTER TABLE statement, <Domain Constraint>s\par
are dropped using the DROP CONSTRAINT <Constraint name> clause of the ALTER\par
DOMAIN statement and Assertions are dropped with the DROP ASSERTION statement.\par
\par
DROP ASSERTION statement \par
\par
The DROP ASSERTION statement destroys an Assertion. The required syntax for\par
the DROP ASSERTION statement is: \par
\par
DROP ASSERTION <Constraint name> \par
\par
The <Constraint name> must identify an existing Assertion whose owner is\par
either the current <AuthorizationID> or a Role that the current\par
<AuthorizationID> may use. That is, only the <AuthorizationID> that owns the\par
Schema may drop its Assertions. If <Constraint name> does not include an\par
explicit <Schema name> qualifier, the Assertion must belong to the SQL-session\par
default Schema.\par
\par
The effect of DROP ASSERTION <Constraint name>, e.g.:\par
\par
   DROP ASSERTION constraint_1; \par
\par
is that the Assertion named CONSTRAINT_1 will be destroyed, providing that\par
CONSTRAINT_1 is not referred to in any SQL routine or in any Trigger. If the\par
Assertion's CHECK search condition includes a NOT NULL condition that causes\par
one or more Columns to have the "known not nullable" nullability\par
characteristic, then the affected Columns' nullability characteristic becomes\par
"possibly nullable" (unless some other Constraint also constrains them to non-\par
null values).\par
\par
If you want to restrict your code to Core SQL, don't use the DROP ASSERTION\par
statement.\par
\par
Dialects\par
\par
In most DBMSs, it's common that the UNIQUE specification is not supported, but\par
you'll often see a (non-SQL) CREATE UNIQUE INDEX statement that gives you the\par
same functionality instead.\par
\par
Some DBMSs reportedly don't support the FOREIGN KEY <Column Constraint>\par
syntax, but do allow foreign keys to be defined as <Table Constraint>s.\par
\page\par
Chapter 21 -- SQL Character set\par
\par
[Obscure Rule] applies to this entire chapter.\par
\par
In this chapter, we'll describe SQL Character sets in detail, and show you the\par
syntax to use to create, alter and destroy them.\par
\par
Character set\par
\par
A Schema may contain zero or more Character sets. As we explained in our\par
chapter on character strings, an SQL Character set is a combination of a\par
character repertoire (a set of characters) and a Form-of-use (the repertoire's\par
internal encoding scheme). Character sets are dependent on some Schema -- the\par
<Character set name> must be unique within the Schema the Character set\par
belongs to. User-defined Character sets are created and dropped using standard\par
SQL statements.\par
\par
In SQL, a Character set may be a Character set defined by a national or\par
international standard, by your DBMS or by a user of SQL-data.\par
\par
Standard-defined Character sets consist of a set of characters predefined by\par
some standards body and have a default Collation that is the order of the\par
characters in the relevant standard. The default Collation has the PAD SPACE\par
characteristic. The SQL Standard requires a DBMS to support, at a minimum,\par
these standard-defined Character sets: SQL_CHARACTER, GRAPHIC_IRV (also called\par
ASCII_GRAPHIC), LATIN1, ISO8BIT (also called ASCII_FULL) and UNICODE (also\par
called ISO10646).\par
\par
Implementation-defined Character sets consist of a set of characters\par
predefined by your DBMS and have a default Collation that is also defined by\par
your DBMS. The default Collation may have either the PAD SPACE characteristic\par
or the NO PAD characteristic. The SQL Standard requires a DBMS to support, at\par
a minimum, this implementation-defined Character set: SQL_TEXT.\par
\par
[NON-PORTABLE] The complete set of predefined Character sets supported by a\par
DBMS is non-standard because the SQL Standard allows implementors to include\par
support for other Character sets, in addition to the required ones.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
provides support for seven other predefined Character sets, based on commonly\par
available MS-Windows codepages. They are:\par
CODEPAGE_0437 -- MS-DOS West European codepage 437. \par
CODEPAGE_0850 -- MS-DOS International codepage 850. \par
CODEPAGE_1250 -- MS-Windows Latin II codepage 1250.\par
CODEPAGE_1251 -- MS-Windows Cyrillic codepage 1251. \par
CODEPAGE_1253 -- MS-Windows Greek codepage 1253. \par
CODEPAGE_1254 -- MS-Windows Turkish codepage 1254. \par
CODEPAGE_1257 -- MS-Windows Baltic codepage 1257. \par
\par
The pre-defined Character sets provided by your DBMS belong to\par
INFORMATION_SCHEMA (as do Collations defined by standards and Collations,\par
Translations and Form-of-use conversions defined by your DBMS). The SQL\par
special grantee, PUBLIC, always has a USAGE Privilege on every predefined\par
Character set provided by your DBMS. For details on the predefined Character\par
sets, see our chapter on characters.\par
\par
Every Character set has a default Collation: it specifies the rules that\par
determine the results of comparisons between the Character set's characters in\par
the absence of an explicit COLLATE clause.\par
\par
A Character set is defined by a descriptor that contains three pieces of information:\par
      ## The <Character set name>, qualified by the <Schema name> of the Schema it belongs to.\par
      ## A list of the characters that belong to the Character set.\par
      ## The name of the Character set's default Collation. (This may be the Form-of-use encoding scheme for the Character set's repertoire.)\par
\par
User-defined Character sets may belong to any Schema owned by the creator. To\par
create a Character set, use the CREATE CHARACTER SET statement (either as a\par
stand-alone SQL statement or within a CREATE SCHEMA statement). CREATE\par
CHARACTER SET specifies the enclosing Schema, names the Character set and\par
identifies the Character set's repertoire and default Collation. To destroy a\par
Character set, use the DROP CHARACTER SET statement. To change an existing\par
Character set, drop and then redefine it.\par
\par
There is a one-to-many association between Character sets and Collations: one\par
Character set can have many possible Collations defined for it, although only\par
one can be its default Collation.\par
\par
Character set names:\par
A <Character set name> identifies a Character set. The required syntax for a <Character set name> is: \par
\par
<Character set name> ::= \par
[ <Schema name>. ] unqualified name \par
\par
A <Character set name> is a <SQL language identifier> that is unique (for all\par
Character sets) within the Schema it belongs to. The <Schema name> which\par
qualifies a <Character set name> names the Schema that the Character set\par
belongs to and can either be explicitly stated, or it will default to\par
INFORMATION_SCHEMA; that is, an unqualified <Character set name> is always\par
assumed to belong to INFORMATION_SCHEMA -- even if a CREATE CHARACTER SET\par
statement is part of a CREATE SCHEMA statement. (User-defined Character sets\par
may not belong to INFORMATION_SCHEMA. Therefore, when defining, using or\par
dropping a user-defined Character set, always provide an explicit <Schema\par
name> qualifier for the <Character set name>.)\par
\par
Here are some examples of <Character set name>s:\par
\par
   LATIN1\par
   -- a predefined <Character set name>\par
\par
   SCHEMA_1.CHARACTER_SET_1\par
   -- a simple qualified user-defined <Character set name>\par
\par
   CATALOG_1.SCHEMA_1.CHARACTER_SET_1\par
   -- a fully qualified user-defined <Character set name>\par
\par
If you want to restrict your code to Core SQL, don't use any <Character set name>s.\par
\par
CREATE CHARACTER SET statement \par
\par
The CREATE CHARACTER SET statement names a new user-defined Character set and\par
specifies the Character set's repertoire and default Collation. The required\par
syntax for the CREATE CHARACTER SET statement is: \par
\par
CREATE CHARACTER SET user-defined <Character set name> [ AS ] \par
      GET predefined <Character set name> \par
      [ COLLATE <Collation name> ]\par
\par
CREATE CHARACTER SET defines a new user-defined Character set. A Character set is owned by the Schema it belongs to.\par
\par
The user-defined <Character set name> identifies the new Character set and the\par
Schema that it belongs to. A <Character set name> that includes an explicit\par
<Schema name> qualifier belongs to the Schema named. A <Character set name>\par
that does not include an explicit <Schema name> qualifier belongs to\par
INFORMATION_SCHEMA. Since a user-defined Character set can't belong to\par
INFORMATION_SCHEMA, always provide an explicit <Schema name> qualifier when\par
you're creating a Character set.\par
\par
If CREATE CHARACTER SET is part of a CREATE SCHEMA statement, the <Character\par
set name> must include the <Schema name> of the Schema being created; that is,\par
it isn't possible to create a Character set belonging to a different Schema\par
from within CREATE SCHEMA. For example, this SQL statement will not return an\par
error because the <Character set name> explicitly includes a qualifying\par
<Schema name> that matches the name of the Schema being created:\par
\par
   CREATE SCHEMA bob \par
      CREATE CHARACTER SET bob.charset_1 AS GET LATIN1;\par
   -- creates a Character set called BOB.CHARSET_1 in Schema BOB \par
\par
But this SQL statement will return an error because the <Character set name>\par
explicitly includes a qualifying <Schema name> that is different from the name\par
f the Schema being created:\par
\par
   CREATE SCHEMA bob \par
      CREATE CHARACTER SET sam.charset_1 AS GET LATIN1;\par
   -- tries to create a Character set belonging to Schema SAM inside Schema BOB; illegal syntax\par
\par
If CREATE CHARACTER SET is executed as a stand-alone SQL statement, the\par
current <AuthorizationID> must either be the owner of the Schema that this new\par
Character set belongs to, or the Schema's owner must be a Role that the\par
current <AuthorizationID> may use. That is, only the owner of a Schema can\par
create Character sets for that Schema. In addition to creating a Character\par
set, CREATE CHARACTER SET also causes the SQL special grantor, "_SYSTEM", to\par
grant a grantable USAGE Privilege on the new Character set to the Schema owner\par
<AuthorizationID> (that is, the <AuthorizationID creating the Character set). \par
\par
A user-defined Character set must be defined as using the repertoire (and\par
possibly the default Collation) of a predefined Character set provided by the\par
DBMS; that is, you can't create a Character set based on another user-defined\par
Character set. The GET clause of the CREATE CHARACTER SET statement names the\par
predefined Character set that is the source for the new Character set. For\par
example, this SQL statement:\par
\par
   CREATE CHARACTER SET bob.charset_1 AS LATIN1; \par
\par
defines a new user-defined Character set, called BOB.CHARSET_1, in the Schema\par
named BOB. Except for its name, the Character set BOB.CHARSET_1 will be\par
exactly the same as the LATIN1 Character set -- that is, it is not truly\par
possible to "create" new Character sets; merely to rename (and possibly assign\par
new default Collations for) them. The <keyword> AS in the GET clause is noise\par
and can be omitted. For example, these two SQL statements are equivalent:\par
\par
   CREATE CHARACTER SET bob.charset_1 AS GET LATIN1;\par
\par
   CREATE CHARACTER SET bob.charset_1 GET LATIN1; \par
\par
The optional COLLATE clause of the CREATE CHARACTER SET statement allows you\par
to define a default Collation for your user-defined Character set that is\par
different from the default Collation of its source Character set. Your current\par
<AuthorizationID> must have the USAGE Privilege on the Collation named. Here is an example:\par
\par
   CREATE CHARACTER SET bob.charset_1 AS GET LATIN1 COLLATE bob.collation_1; \par
\par
This SQL statement defines a new user-defined Character set, called\par
BOB.CHARSET_1. It contains the same characters as LATIN1 does, but is slightly\par
different because its default Collation won't be LATIN1's default Collation --\par
instead, its default Collation is a Collation named BOB.COLLATION_1.\par
\par
If you want to restrict your code to Core SQL, don't use the CREATE CHARACTER SET statement.\par
\par
DROP CHARACTER SET statement \par
\par
The DROP CHARACTER SET statement destroys a user-defined Character set. The required syntax for the DROP CHARACTER SET statement is: \par
\par
DROP CHARACTER SET <Character set name> \par
\par
The <Character set name> must identify an existing Character set whose owner\par
is either the current <AuthorizationID> or a Role that the current\par
<AuthorizationID> may use. That is, only the <AuthorizationID> that owns the\par
Character set may drop it, and so it isn't possible to drop any of the\par
predefined Character sets provided by your DBMS.\par
\par
The effect of DROP CHARACTER SET <Character set name>, e.g.:\par
\par
   DROP CHARACTER SET bob.charset_1; \par
\par
is that the user-defined Character set named BOB.CHARSET_1 is destroyed,\par
provided that the Character set is not referred to in any View definition,\par
Constraint or Assertion definition, Collation definition, Translation\par
definition or SQL routine. That is, DROP CHARACTER SET ensures that only a\par
Character set with no dependent Objects can be destroyed. If the Character set\par
is used by any other Object, DROP CHARACTER SET will fail.\par
\par
If successful, DROP CHARACTER SET has a two-fold effect.\par
      ## The Character set named is destroyed.\par
      ## The USAGE Privilege held on the Character set by the\par
<AuthorizationID> that owns it is revoked (by the SQL special grantor,\par
"_SYSTEM") with a CASCADE revoke behaviour, so that the USAGE Privilege held\par
on the Character set by any other <AuthorizationID> is also revoked.\par
\par
If you want to restrict your code to Core SQL, don't use the DROP CHARACTER SET statement.\par
\page\par
Chapter 22 -- SQL Collation\par
\par
[Obscure Rule] applies to this entire chapter.\par
\par
In this chapter, we'll describe SQL Collations in detail, and show you the syntax to use to create, alter and destroy them.\par
\par
Collation\par
\par
A Schema may contain zero or more Collations. An SQL Collation is a set of\par
rules that determines the result when characters from a Character set are\par
compared. Collations are dependent on some Schema -- the <Collation name> must\par
be unique within the Schema the Collation belongs to. User-defined Collations\par
are created and dropped using standard SQL statements.\par
\par
In SQL, a Collation may be a Collation defined by a national or international standard, by your DBMS or by a user of SQL-data.\par
\par
Standard-defined Collations are collating sequences predefined for a character\par
repertoire by some standards body. The SQL Standard requires a DBMS to provide\par
a default Collation (based on the character repertoire order) for each of the\par
standard-defined Character sets it supports. In each case, the default\par
Collation has the PAD SPACE characteristic.\par
\par
Implementation-defined Collations are collating sequences predefined for a\par
character repertoire by your DBMS. These Collations may have either the PAD\par
SPACE characteristic or the NO PAD characteristic. The SQL Standard requires a\par
DBMS to provide a default Collation, called SQL_TEXT, for the SQL_TEXT Character set.\par
\par
[NON-PORTABLE] The complete set of predefined Collations provided by a DBMS is\par
non-standard because the SQL Standard allows implementors to include support\par
for other Collations, in addition to the required ones. It also requires\par
implementors (a) to define the names for the standard-defined and (except for\par
SQL_TEXT) the implementation-defined Collations it provides and (b) to define\par
the PAD SPACE characteristic for each implementation-defined Collations it provides.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
provides a SQL_TEXT Collation that follows the order of the Unicode\par
Form-of-use codes. The SQL_TEXT Collation has the PAD SPACE characteristic and\par
is the default Collation for both the SQL_TEXT Character set and the UNICODE\par
Character set. It also provides eleven other predefined Collations, all with\par
the PAD SPACE characteristic. They are:\par
SQL_CHARACTER -- default Collation for Character set SQL_CHARACTER\par
ASCII_GRAPHIC -- default Collation for Character set GRAPHIC_IRV\par
LATIN1 -- default Collation for Character set LATIN1\par
ASCII_FULL -- default Collation for Character set ISO8BIT\par
CODEPAGE_0437 -- default Collation for Character set CODEPAGE_0437\par
Collation CODEPAGE_0850 -- default Collation for Character set CODEPAGE_0850\par
Collation CODEPAGE_1250 -- default Collation for Character set CODEPAGE_1250\par
Collation CODEPAGE_1251 -- default Collation for Character set CODEPAGE_1251\par
Collation CODEPAGE_1253 -- default Collation for Character set CODEPAGE_1253\par
Collation CODEPAGE_1254 -- default Collation for Character set CODEPAGE_1254\par
Collation CODEPAGE_1257 -- default Collation for Character set CODEPAGE_1257\par
\par
The pre-defined Collations provided by your DBMS belong to INFORMATION_SCHEMA.\par
The SQL special grantee, PUBLIC, always has a USAGE Privilege on every predefined Collation provided by your DBMS.\par
\par
A Collation is defined by a descriptor that contains three pieces of information:\par
      ## The <Collation name>, qualified by the <Schema name> of the Schema it belongs to.\par
      ## The name of the Character set on which the Collation operates.\par
      ## Whether the NO PAD or the PAD SPACE characteristic applies to the Collation.\par
\par
User-defined Collations may belong to any Schema owned by the creator. To\par
create a Collation, use the CREATE COLLATION statement (either as a\par
stand-alone SQL statement or within a CREATE SCHEMA statement). CREATE\par
COLLATION specifies the enclosing Schema, names the Collation and defines the\par
Collation's Character set and PAD characteristic. To destroy a Collation, use\par
the DROP COLLATION statement. To change an existing Collation, drop and then redefine it.\par
\par
There is a one-to-many association between Character sets and Collations: one\par
Character set can have many possible Collations defined for it, although only\par
one can be its default Collation.\par
\par
The default Collation for a Character set is the Collation that will be used\par
to compare characters belonging to that Character set in the absence of an\par
explicit specification to the contrary and can either be a Collation defined\par
for the Character set or the Form-of-use encoding scheme for that Character\par
set's repertoire -- that is, the default Collation for a Character set can be\par
defined to be the order of the characters in the character repertoire. (For\par
example, in the 7-bit ASCII character set, the decimal code for the letter A\par
is 65 and the decimal code for the letter B is 66. This is a happy\par
coincidence; it allows your DBMS  to discover that 'A' is less than 'B' by\par
merely executing a CMP: a machine-code numeric comparison. And that's what is\par
meant by "the order of the characters in the repertoire". Note that, since the\par
decimal code for the letter a is 97, it follows that 'A' is less than 'a' --\par
that is, character repertoire order specifies a case-sensitive collating sequence.)\par
\par
Collation names:\par
A <Collation name> identifies a Collation. The required syntax for a <Collation name> is:\par
\par
<Collation name> ::=\par
[ <Schema name>. ] unqualified name\par
\par
A <Collation name> is a <regular identifier> or a <delimited identifier> that\par
is unique (for all Collations) within the Schema it belongs to. The <Schema\par
name> which qualifies a <Collation name> names the Schema that the Collation\par
belongs to and can either be explicitly stated, or it will default to\par
INFORMATION_SCHEMA; that is, an unqualified <Collation name> is always assumed\par
to belong to INFORMATION_SCHEMA -- even if a CREATE COLLATION statement is\par
part of a CREATE SCHEMA statement. (User-defined Collations may not belong to\par
INFORMATION_SCHEMA. Therefore, when defining, using or dropping a user-defined\par
Collation, always provide an explicit <Schema name> qualifier for the <Collation name>.)\par
\par
Here are some examples of possible <Collation name>s:\par
\par
   SQL_TEXT\par
   -- a predefined <Collation name>\par
\par
   SCHEMA_1.COLLATION_1\par
   -- a simple qualified user-defined <Collation name>\par
\par
   CATALOG_1.SCHEMA_1.COLLATION_1\par
   -- a fully qualified user-defined <Collation name>\par
\par
Form-of-use conversion names:\par
A <Form-of-Use conversion name> identifies a character repertoire's encoding\par
scheme -- the one-to-one mapping scheme between each character in the\par
repertoire and a set of internal codes (usually 8-bit values) that define how\par
the repertoire's characters are encoded as numbers. These codes are also used\par
to specify the order of the characters within the repertoire and so can be\par
used to specify the default Collation for a Character set. Supported Forms-of-\par
use are all predefined by your DBMS and thus belong to INFORMATION_SCHEMA. SQL\par
provides no ability to define your own Forms-of-use. The required syntax for a\par
<Form-of-use conversion name> is:\par
\par
<Form-of-use conversion name> ::=\par
[ INFORMATION_SCHEMA. ] unqualified name\par
\par
A <Form-of-use conversion name> is a <regular identifier> or a <delimited\par
identifier> that is unique (for all Forms-of-user) within INFORMATION_SCHEMA.\par
The <Schema name> which qualifies a <Form-of-use conversion name> names the\par
Schema that the Form-of-use belongs to and can either be explicitly stated, or\par
it will default to INFORMATION_SCHEMA: the only Schema that may own a Form-of-use.\par
\par
Here are some examples of possible <Form-of-use conversion name>s:\par
\par
   FORM_1\par
   -- a possible <Form-of-use conversion name>\par
\par
   INFORMATION_SCHEMA.FORM_1\par
   -- a simple qualified possible <Form-of-use conversion name>\par
\par
   CATALOG_1.INFORMATION_SCHEMA.FORM_1\par
   -- a fully qualified possible <Form-of-use conversion name>\par
\par
[NON-PORTABLE] The Forms-of-use available for use is non-standard because the\par
SQL Standard requires implementors to define which (if any) Forms-of-use they\par
will explicitly provide.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book provides no explicit Forms-of use.\par
\par
If you want to restrict your code to Core SQL, don't use any <Collation name>s or <Form-of-use conversion name>s.\par
\par
CREATE COLLATION statement\par
\par
The CREATE COLLATION statement names a new user-defined Collation and\par
specifies the Collation's PAD characteristic and the Character set that the\par
Collation is for. The required syntax for the CREATE COLLATION statement is:\par
\par
CREATE COLLATION user-defined <Collation name>\par
     FOR <Character set name>\par
     FROM existing <Collation name> [ \{NO PAD | PAD SPACE\} ]\par
\par
CREATE COLLATION defines a new user-defined Collation. A Collation is owned by the Schema it belongs to.\par
\par
The user-defined <Collation name> identifies the new Collation and the Schema\par
that it belongs to. A <Collation name> that includes an explicit <Schema name>\par
qualifier belongs to the Schema named. A <Collation name> that does not\par
include an explicit <Schema name> qualifier belongs to INFORMATION_SCHEMA.\par
Since a user-defined Collation can't belong to INFORMATION_SCHEMA, always\par
provide an explicit <Schema name> qualifier when you're creating a Collation.\par
\par
If CREATE COLLATION is part of a CREATE SCHEMA statement, the <Collation name>\par
must include the <Schema name> of the Schema being created; that is, it isn't\par
possible to create a Collation belonging to a different Schema from within\par
CREATE SCHEMA. For example, this SQL statement will not return an error\par
because the <Collation name> explicitly includes a qualifying <Schema name>\par
that matches the name of the Schema being created:\par
\par
   CREATE SCHEMA bob\par
      CREATE COLLATION bob.collation_1 FOR bob.charset_1 FROM SQL_TEXT;\par
   -- creates a Collation called BOB.COLLATION_1 in Schema BOB\par
\par
But this SQL statement will return an error because the <Collation name>\par
explicitly includes a qualifying <Schema name> that is different from the name\par
of the Schema being created:\par
\par
   CREATE SCHEMA bob\par
      CREATE COLLATION sam.collation_1 FOR bob.charset_1 FROM SQL_TEXT;\par
   -- tries to create a Collation belonging to Schema SAM inside Schema BOB; illegal syntax\par
\par
If CREATE COLLATION is executed as a stand-alone SQL statement, the current\par
<AuthorizationID> must either be the owner of the Schema that this new View\par
belongs to, or the Schema's owner must be a Role that the current\par
<AuthorizationID> may use. That is, only the owner of a Schema can create\par
Collations for that Schema. In addition to creating a Collation, CREATE\par
COLLATION also causes the SQL special grantor, "_SYSTEM", to grant the USAGE\par
Privilege on the new Collation to the Schema owner <AuthorizationID> (that is,\par
the <AuthorizationID creating the Collation). The Privilege is grantable if\par
the <AuthorizationID> also has a grantable USAGE Privilege on the Collation\par
named in the FROM clause of the CREATE COLLATION statement.\par
\par
A user-defined Collation must be defined to operate on a Character set. The\par
FOR clause of the CREATE COLLATION statement names that Character set.\par
<Character set name> must be the name of an existing Character set for which\par
the current <AuthorizationID> has the USAGE Privilege.\par
\par
A user-defined Collation must also be defined as using the collating sequence\par
of an existing Collation that is already defined for the Character set named\par
in the FOR clause of the CREATE COLLATION statement. The FROM clause of the\par
CREATE COLLATION statement names this Collation source. The existing\par
<Collation name> must be the name of an existing Collation for which the\par
current <AuthorizationID> has the USAGE Privilege. For example, this SQL statement:\par
\par
   CREATE COLLATION bob.collation_1 FOR bob.charset_1 FROM SQL_TEXT;\par
\par
defines a new user-defined Collation, called BOB.COLLATION_1, in the Schema\par
named BOB. Except for its name, the Collation BOB. COLLATION_1 will be exactly\par
the same as the SQL_TEXT Collation -- that is, it is not truly possible to\par
"create" new Collations, merely to rename (and possibly assign a new PAD\par
characteristic to) them. To define a new Collation, the CREATE COLLATION\par
statement must use some pre-existing Collation as a Collation source -- and,\par
ultimately, all Collations can only be based on some pre-defined Collation\par
provided by your DBMS.\par
\par
The optional PAD characteristic clause of the CREATE COLLATION statement\par
allows you to define a PAD characteristic for your user-defined Collation that\par
is different from the PAD characteristic of its source Collation. If you omit\par
the PAD clause, your new Collation will have the same PAD characteristic as\par
its source Collation does. For example, this SQL statement:\par
\par
   CREATE COLLATION bob.collation_1 FOR bob.charset_1 FROM SQL_TEXT;\par
\par
defines a new user-defined Collation that will have the same PAD\par
characteristic as Collation SQL_TEXT does; that is, except for its name,\par
BOB.COLLATION_1 is exactly like SQL_TEXT. This SQL statement:\par
\par
   CREATE COLLATION bob.collation_1 FOR bob.charset_1 FROM SQL_TEXT PAD SPACE;\par
\par
defines a new user-defined Collation that will have the PAD SPACE characteristic. And this SQL statement:\par
\par
   CREATE COLLATION bob.collation_1 FOR bob.charset_1 FROM SQL_TEXT NO PAD;\par
\par
defines a new user-defined Collation that will have the NO PAD characteristic.\par
\par
A Collation's PAD characteristic affects the result when two strings of\par
unequal size are compared. If the Collation in effect for a comparison has the\par
PAD SPACE characteristic, the shorter string is padded with spaces (on the\par
right) until it's the same length as the larger string; then the comparison is\par
done. If the Collation in effect for a comparison has the NO PAD\par
characteristic, the shorter string is padded with some other character before\par
the comparison is done. In this case, the result is that the shorter comparand\par
will evaluate as less than the longer comparand if they contain the same\par
characters for their common length -- see our chapter on character strings.\par
\par
If you want to restrict your code to Core SQL, don't use the CREATE COLLATION statement.\par
\par
DROP COLLATION statement\par
\par
The DROP COLLATION statement destroys a user-defined Collation. The required syntax for the DROP COLLATION statement is:\par
\par
DROP COLLATION <Collation name> \{RESTRICT | CASCADE\}\par
\par
The <Collation name> must identify an existing Collation whose owner is either\par
the current <AuthorizationID> or a Role that the current <AuthorizationID> may\par
use. That is, only the <AuthorizationID> that owns the Collation may drop it,\par
and so it isn't possible to drop any of the predefined Collations provided by your DBMS.\par
\par
The effect of DROP COLLATION <Collation name> RESTRICT, e.g.:\par
\par
   DROP COLLATION bob.collation_1 RESTRICT;\par
\par
is that the user-defined Collation named BOB.COLLATION_1 is destroyed,\par
provided that the Collation is not referred to in any View definition,\par
Constraint or Assertion definition or SQL routine. That is, DROP COLLATION\par
ensures that only a Collation with no dependent Views, Constraints, Assertions\par
or SQL routines can be destroyed. If the Collation is used by any of these\par
Objects, DROP COLLATION ... RESTRICT will fail.\par
\par
The effect of DROP COLLATION <Collation name> CASCADE, e.g.:\par
\par
   DROP COLLATION bob.collation_1 CASCADE;\par
\par
is that the user-defined Collation named BOB.COLLATION_1 is destroyed.\par
\par
If successful, DROP COLLATION has a six-fold effect.\par
      ## The Collation named is destroyed.\par
      ## The USAGE Privilege held on the Collation by the <AuthorizationID>\par
that owns it is revoked (by the SQL special grantor, "_SYSTEM") with a CASCADE\par
revoke behaviour, so that the USAGE Privilege held on the Collation by any other <AuthorizationID> is also revoked.\par
      ## The definition of any other Collation that named this Collation is\par
amended, so that it no longer refers to it. The effect is that each Collation\par
that was based on the dropped Collation will subsequently use the Form-of-use\par
encoding scheme for the repertoire of its Character set as a collating sequence.\par
      ## The definition of any Character set that named this Collation is\par
amended, so that it no longer refers to it. The effect is that each Character\par
set that used the dropped Collation as its default Collation will subsequently\par
use the Form-of-use encoding scheme for its repertoire as a default Collation.\par
      ## The definition of any Column, Domain, View, Constraint or Assertion\par
that named this Collation is amended, so that it no longer refers to it. The\par
effect is that each Column or Domain that used the dropped Collation as its\par
default Collation will subsequently use the default Collation of its Character set as a default Collation.\par
      ## Every SQL routine that names this Collation is dropped with a CASCADE drop behaviour.\par
\par
If you want to restrict your code to Core SQL, don't use the DROP COLLATION statement.\par
\page\par
Chapter 23 -- SQL Translation\par
\par
[Obscure Rule] applies to this entire chapter.\par
\par
In this chapter, we'll describe SQL Translations in detail, and show you the syntax to use to create, alter and destroy them.\par
\par
Translation\par
\par
A Schema may contain zero or more Translations. An SQL Translation is a set of\par
rules that maps the characters from a source Character set to the characters\par
of a target Character set; effectively translating source strings into target\par
strings. Any pair of Character sets may have zero or more Translations defined\par
to translate strings belonging to one (the source Character set) into strings\par
belonging to the other (the target Character set). Translations are dependent\par
on some Schema -- the <Translation name> must be unique within the Schema the\par
Translation belongs to. User-defined Translations are created and dropped using standard SQL statements.\par
\par
In SQL, a Translation may be a Translation defined by a national or international standard, by your DBMS or by a user of SQL-data.\par
\par
Standard-defined Translations are translations predefined for two character\par
repertoires by some standards body. Implementation-defined Translations are\par
translations predefined for two Character sets by your DBMS. The pre-defined\par
Translations provided by your DBMS belong to INFORMATION_SCHEMA. The SQL\par
special grantee, PUBLIC, always has a USAGE Privilege on every predefined Translation provided by your DBMS.\par
      [NON-PORTABLE] The set of predefined Translations provided by a DBMS is\par
non-standard because the SQL Standard has no required Translations: it\par
requires implementors to define any Translations supported.\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
provides a Translation named OCELOT. It translates SQL_TEXT strings to ASCII_FULL strings.\par
\par
A Translation is defined by a descriptor that contains four pieces of information:\par
      ## The <Translation name>, qualified by the <Schema name> of the Schema it belongs to.\par
      ## The name of the Translation's source Character set: the Character set from which it translates.\par
      ## The name of the Translation's target Character set: the Character set to which it translates.\par
      ## The mapping scheme for the Translation.\par
\par
Two character strings may be compared or assigned to one another only if they\par
both belong to the same Character set. The way to force a comparison or\par
assignment between strings from different Character sets is to use the\par
TRANSLATE function, which uses a Translation defined for the Character sets as an argument.\par
\par
User-defined Translations may belong to any Schema owned by the creator. To\par
create a Translation, use the CREATE TRANSLATION statement (either as a\par
stand-alone SQL statement or within a CREATE SCHEMA statement). CREATE\par
TRANSLATION specifies the enclosing Schema, names the Translation and defines\par
the Translation's source Character set, target Character set and Translation\par
source. To destroy a Translation, use the DROP TRANSLATION statement. To\par
change an existing Translation, drop and then redefine it.\par
\par
There is a one-to-many relationship between Translations and Character sets: a\par
Translation may translate the characters of only one pair of Character sets,\par
but a Character set can be named as either the source or the target for many\par
different Translations.\par
\par
Translation names:\par
A <Translation name> identifies a Translation. The required syntax for a <Translation name> is:\par
\par
<Translation name> ::=\par
[ <Schema name>. ] unqualified name\par
\par
A <Translation name> is a <regular identifier> or a <delimited identifier>\par
that is unique (for all Translations) within the Schema it belongs to. The\par
<Schema name> which qualifies a <Translation name> names the Schema that the\par
Translation belongs to and can either be explicitly stated, or it will default\par
to INFORMATION_SCHEMA; that is, an unqualified <Translation name> is always\par
assumed to belong to INFORMATION_SCHEMA -- even if a CREATE TRANSLATION\par
statement is part of a CREATE SCHEMA statement. (User-defined Translations may\par
not belong to INFORMATION_SCHEMA. Therefore, when defining, using or dropping\par
a user-defined Translation, always provide an explicit <Schema name> qualifier for the <Translation name>.)\par
\par
Here are some examples of possible <Translation name>s:\par
\par
   TRANSLATION_1\par
   -- a <Translation name>\par
\par
   SCHEMA_1.TRANSLATION_1\par
   -- a simple qualified <Translation name>\par
\par
   CATALOG_1.SCHEMA_1.TRANSLATION_1\par
   -- a fully qualified <Translation name>\par
\par
If you want to restrict your code to Core SQL, don't use any <Translation name>s.\par
\par
CREATE TRANSLATION statement\par
\par
The CREATE TRANSLATION statement names a new user-defined Translation and\par
specifies the Translation's source and target Character sets as well as the\par
Translation's source. The required syntax for the CREATE TRANSLATION statement is:\par
\par
CREATE TRANSLATION user-defined <Translation name>\par
   FOR source <Character set name>\par
   TO target <Character set name>\par
   FROM <translation source>\par
\par
   <translation source> ::=\par
   existing <Translation name> |\par
   <specific routine designator>\par
\par
CREATE TRANSLATION defines a new user-defined Translation. A Translation is owned by the Schema it belongs to.\par
\par
The user-defined <Translation name> identifies the new Translation and the\par
Schema that it belongs to. A <Translation name> that includes an explicit\par
<Schema name> qualifier belongs to the Schema named. A <Translation name> that\par
does not include an explicit <Schema name> qualifier belongs to\par
INFORMATION_SCHEMA. Since a user-defined Translation can't belong to\par
INFORMATION_SCHEMA, always provide an explicit <Schema name> qualifier when you're creating a Translation.\par
\par
If CREATE TRANSLATION is part of a CREATE SCHEMA statement, the <Translation\par
name> must include the <Schema name> of the Schema being created; that is, it\par
isn't possible to create a Translation belonging to a different Schema from\par
within CREATE SCHEMA. For example, this SQL statement will not return an error\par
because the <Translation name> explicitly includes a qualifying <Schema name>\par
that matches the name of the Schema being created:\par
\par
   CREATE SCHEMA bob\par
      CREATE TRANSLATION bob.translation_1\par
         FOR SQL_CHARACTER TO LATIN1 FROM function_name;\par
   -- creates a Translation called BOB.TRANSLATION_1 in Schema BOB\par
\par
But this SQL statement will return an error because the <Translation name>\par
explicitly includes a qualifying <Schema name> that is different from the name\par
of the Schema being created:\par
\par
   CREATE SCHEMA bob\par
      CREATE TRANSLATION sam.translation_1\par
         FOR SQL_CHARACTER TO LATIN1 FROM function_name;\par
   -- tries to create a Translation belonging to Schema SAM inside Schema BOB; illegal syntax\par
\par
If CREATE TRANSLATION is executed as a stand-alone SQL statement, the current\par
<AuthorizationID> must either be the owner of the Schema that this new\par
Translation belongs to, or the Schema's owner must be a Role that the current\par
<AuthorizationID> may use. That is, only the owner of a Schema can create\par
Translations for that Schema. In addition to creating a Translation, CREATE\par
TRANSLATION also causes the SQL special grantor, "_SYSTEM", to grant the USAGE\par
Privilege on the new Translation to the Schema owner <AuthorizationID> (that\par
is, the <AuthorizationID creating the Translation). The Privilege is grantable\par
if the <AuthorizationID> also has a grantable USAGE Privilege on both the\par
Translation's source Character set and its target Character set.\par
\par
A user-defined Translation must be defined to operate on a pair of Character\par
sets. The FOR clause of the CREATE TRANSLATION statement names the source\par
Character set; the TO clause names the target Character set. In each case,\par
<Character set name> must be the name of an existing Character set for which\par
the current <AuthorizationID> has the USAGE Privilege.\par
\par
A user-defined Translation must also be defined as using a source mapping\par
scheme: it defines the source and target Character sets' corresponding pairs\par
of characters. The FROM clause of the CREATE TRANSLATION statement names this\par
Translation source. If the FROM clause names some other Translation as the new\par
Translation's source, the existing <Translation name> must be the name of an\par
existing Translation for which the current <AuthorizationID> has the USAGE\par
Privilege and whose source Character set and target Character set are the same\par
as the source and target Character sets you're defining for the new\par
Translation. For example, this SQL statement:\par
\par
   CREATE TRANSLATION bob.translation_2\par
      FOR SQL_CHARACTER TO LATIN1 FROM bob.translation_2;\par
\par
defines a new user-defined Translation, called BOB.TRANSLATION_2, in the\par
Schema named BOB. Except for its name, the Translation BOB.TRANSLATION_2 will\par
be exactly the same as the BOB.TRANSLATION_1 Translation -- that is, it is not\par
truly possible to "create" new Translations with this format, merely to rename\par
them. The other option for specifying a Translation source is to use a\par
<specific routine designator> that names an SQL-invoked function for which the\par
current <AuthorizationID> has the EXECUTE Privilege. The function named must\par
(a) have one character string parameter whose Character set is this\par
Translation's source Character set and (b) return a character  string that\par
belongs to this Translation's target Character set.\par
\par
If you want to restrict your code to Core SQL, don't use the CREATE TRANSLATION statement.\par
\par
DROP TRANSLATION statement\par
\par
The DROP TRANSLATION statement destroys a user-defined Translation. The required syntax for the DROP TRANSLATION statement is:\par
\par
DROP TRANSLATION <Translation name>\par
\par
The <Translation name> must identify an existing Translation whose owner is\par
either the current <AuthorizationID> or a Role that the current\par
<AuthorizationID> may use. That is, only the <AuthorizationID> that owns the\par
Translation may drop it, and so it isn't possible to drop any of the\par
predefined Translations provided by your DBMS.\par
\par
The effect of DROP TRANSLATION <Translation name>, e.g.:\par
\par
   DROP TRANSLATION bob.translation_1;\par
\par
is that the user-defined Translation named BOB.TRANSLATION_1 is destroyed,\par
provided that the Translation is not referred to in any View definition,\par
Constraint or Assertion definition, Collation definition, other Translation\par
definition or SQL routine. That is, DROP TRANSLATION ensures that only a\par
Translation with no dependent Objects can be destroyed. If the Translation is\par
used by any other Object, DROP TRANSLATION will fail.\par
\par
If successful, DROP TRANSLATION has a two-fold effect.\par
      ## The Translation named is destroyed.\par
      ## The USAGE Privilege held on the Translation by the <AuthorizationID>\par
that owns it is revoked (by the SQL special grantor, "_SYSTEM") with a CASCADE\par
revoke behaviour, so that the USAGE Privilege held on the Translation by any\par
other <AuthorizationID> is also revoked.\par
\par
If you want to restrict your code to Core SQL, don't use the DROP TRANSLATION statement.\par
\page\par
Chapter 24 -- SQL Trigger\par
\par
"If you press the SECOND dorsal fin-spine on a trigger fish, an amazing event occurs. The FIRST dorsal fin-spine goes down too."\par
   -- Applied Ichthyology\par
\par
In this chapter, we'll describe SQL Triggers in detail, and show you the syntax to use to create, alter and destroy them.\par
\par
Trigger\par
\par
A Schema may contain zero or more Triggers. An SQL Trigger is a named chain\par
reaction that you set off with an SQL data change statement: it specifies a\par
set of SQL statements that are to be executed (either once for each row or\par
once for the whole triggering INSERT, DELETE or UPDATE statement) either\par
before or after rows are inserted into a Table, rows are deleted from a Table,\par
or one or more Columns are updated in rows of a Table. Triggers are dependent\par
on some Schema -- the <Trigger name> must be unique within the Schema the\par
Trigger belongs to -- and are created, altered and dropped using standard SQL statements.\par
\par
Triggers are similar to Constraints. (In fact, referential Constraints are now\par
defined by the SQL Standard as merely a type of Trigger, although they don't\par
share the same name-space.) What distinguishes a Trigger from a Constraint is\par
flexibility: the Trigger body may contain actual SQL procedure statements,\par
that you define yourself. In effect, when you "create a Trigger on Table\par
TABLE_1", you are saying "whenever (in the future) a specific sort of event\par
occurs which changes Table TABLE_1, execute the following further SQL\par
statements". For example, you could create a Trigger so that, whenever TABLE_1\par
is updated, a counter should be incremented in a summary Table.\par
\par
Triggers are a SQL3 feature, but most DBMS vendors implemented them years ago.\par
People use Triggers to enforce business rules, to maintain logs or to\par
substitute for Constraints (where the rules for Constraints are too restrictive).\par
\par
A Trigger is defined by a descriptor that contains eight pieces of information:\par
      ## The <Trigger name>, qualified by the <Schema name> of the Schema it belongs to.\par
      ## The name of the Table whose data, when changed, will cause the Trigger to be activated. (This is called the Trigger's subject Table.)\par
      ## The Trigger action time, which tells your DBMS when to execute the Trigger body (either BEFORE or AFTER the Trigger event).\par
      ## The Trigger event, which tells your DBMS which data change statement (either INSERT, UPDATE or DELETE), executed on the Trigger's Table, activates the Trigger.\par
      ## The Trigger Column list for the Trigger event, as well as whether the list was explicitly or implicitly defined (for UPDATE Trigger events only).\par
      ## Any old values <Correlation name>, new values <Correlation name>, old values Table alias or new values Table alias defined for the Trigger.\par
      ## The Trigger body: the SQL statements you want your DBMS to execute on the Trigger's Table when the Trigger is activated.\par
      ## The Trigger's timestamp: when it was created.\par
\par
To create a Trigger use the CREATE TRIGGER statement (either as a stand-alone\par
SQL statement or within a CREATE SCHEMA statement). CREATE TRIGGER specifies\par
the enclosing Schema, names the Trigger and defines the Trigger's Table,\par
action time, event and body. To destroy a Trigger, use the DROP TRIGGER\par
statement. To change an existing Trigger, drop and then redefine it.\par
\par
Trigger names:\par
A <Trigger name> identifies a Trigger. The required syntax for a <Trigger name> is:\par
\par
<Trigger name> ::=\par
[ <Schema name>. ] unqualified name\par
\par
A <Trigger name> is a <regular identifier> or a <delimited identifier> that is\par
unique (for all Triggers) within the Schema it belongs to. The <Schema name>\par
that qualifies a <Trigger name> names the Schema that the Trigger belongs to\par
and can either be explicitly stated, or a default will be supplied by your DBMS, as follows:\par
      ## If a <Trigger name> in a CREATE SCHEMA statement isn't qualified, the default qualifier is the name of the Schema you're creating.\par
      ## If the unqualified <Trigger name> is found in any other SQL statement\par
in a Module, the default qualifier is the name of the Schema identified in the\par
SCHEMA clause or AUTHORIZATION clause of the MODULE statement which defines that Module.\par
\par
Here are some examples of <Trigger name>s:\par
\par
   TRIGGER_1\par
   -- a <Trigger name>\par
\par
   SCHEMA_1.TRIGGER_1\par
   -- a simple qualified <Trigger name>\par
\par
  CATALOG_1.SCHEMA_1.TRIGGER_1\par
   -- a fully qualified <Trigger name>\par
\par
CREATE TRIGGER statement\par
\par
The CREATE TRIGGER statement names a new Trigger and defines the Trigger's Table, action time, event and body. The required syntax for the CREATE TRIGGER statement is:\par
\par
CREATE TRIGGER <Trigger name>\par
\{BEFORE | AFTER\} <trigger event> ON <Table name>\par
[ REFERENCING <old or new values alias list> ]\par
<triggered action>\par
\par
   <trigger event> ::=\par
   INSERT |\par
   DELETE |\par
   UPDATE [ OF <trigger Column list> ]\par
\par
      <trigger Column list> ::= <Column name> [ \{,<Column name>\} ... ]\par
\par
   <old or new values alias list> ::=\par
   <old or new values alias>...\par
\par
      <old or new values alias> ::=\par
      OLD [ ROW ] [ AS ] old values <Correlation name> |\par
      NEW [ ROW ] [ AS ] new values <Correlation name> |\par
      OLD TABLE [ AS ] <old values Table alias> |\par
      NEW TABLE [ AS ] <new values Table alias>\par
\par
         <old values Table alias> ::= <identifier>\par
\par
         <new values Table alias> ::= <identifier>\par
\par
   <triggered action> ::=\par
   [ FOR EACH \{ROW | STATEMENT\} ] [ WHEN (search condition) ]\par
      <triggered SQL statement>\par
\par
      <triggered SQL statement> ::=\par
      SQL statement |\par
      BEGIN ATOMIC \{SQL statement;\}... END\par
\par
CREATE TRIGGER defines a new Trigger. A Trigger is owned by the Schema it belongs to.\par
\par
The <Trigger name> identifies the Trigger and the Schema that it belongs to.\par
Typical <Trigger name>s include the Trigger event, e.g.: "Employee_Update" or\par
"After_Delete_From_Employee". A <Trigger name> that includes an explicit\par
<Schema name> qualifier belongs to the Schema named. A <Trigger name> that\par
does not include an explicit <Schema name> qualifier belongs to the\par
SQL-session default Schema. The <Trigger name> must be unique (for all\par
Triggers) within the Schema that owns it.\par
\par
If CREATE TRIGGER is part of a CREATE SCHEMA statement, the <Trigger name>, if\par
explicitly qualified, must include the <Schema name> of the Schema being\par
created; that is, it isn't possible to create a Trigger belonging to a\par
different Schema from within CREATE SCHEMA. For example, this SQL statement\par
will not return an error because the <Trigger name> will default to include the qualifying <Schema name>:\par
\par
   CREATE SCHEMA bob\par
      CREATE TABLE Table_1 (column_1 SMALLINT)\par
      CREATE TRIGGER Trigger_1 AFTER DELETE ON Table_1\par
         INSERT INTO Log_table VALUES ('deleted from Table_1');\par
   -- creates a Trigger called BOB.TRIGGER_1 in Schema BOB\par
\par
This SQL statement will not return an error either because the <Trigger name>\par
explicitly includes a qualifying <Schema name> that matches the name of the Schema being created:\par
\par
   CREATE SCHEMA bob\par
      CREATE TABLE bob.Table_1 (column_1 SMALLINT)\par
      CREATE TRIGGER bob.Trigger_1 AFTER DELETE ON Table_1\par
         INSERT INTO Log_table VALUES ('deleted from Table_1');\par
   -- creates a Trigger called BOB.TRIGGER_1 in Schema BOB\par
\par
But this SQL statement will return an error because the <Trigger name>\par
explicitly includes a qualifying <Schema name> that is different from the name of the Schema being created:\par
\par
   CREATE SCHEMA bob\par
      CREATE TABLE bob.Table_1 (column_1 SMALLINT)\par
      CREATE TRIGGER sam.Trigger_1 AFTER DELETE ON bob.Table_1\par
         INSERT INTO Log_table VALUES ('deleted from Table_1');\par
   -- tries to create a Trigger belonging to Schema SAM inside Schema BOB; illegal syntax\par
\par
If CREATE TRIGGER is executed as a stand-alone SQL statement, the current\par
<AuthorizationID> must either be the owner of the Schema that this new Trigger\par
belongs to, or the Schema's owner must be a Role that the current <AuthorizationID> may use. That is, only the owner of a Schema can create Triggers for that Schema.\par
\par
The CREATE TRIGGER statement's main parts are its Table, its event (the\par
description of the SQL-data change statement that activates the Trigger) and\par
its action (the SQL statements which are to be executed by the Trigger).\par
\par
ON clause:\par
The ON clause of the CREATE TRIGGER statement names the Trigger's Table: the\par
Base table that, when changed, may cause the Trigger to act. The Table must\par
belong to the same Schema that the Trigger will belong to, and the current\par
<AuthorizationID> must have the TRIGGER Privilege on that Table. (You do not\par
need a Privilege to "use" a Trigger. Triggers will be activated whenever you\par
execute the appropriate SQL data-change statement on the Table, whether you want them or not.)\par
\par
Trigger action time:\par
The Trigger action time defines when you want the Trigger's action to be\par
executed: it may be either BEFORE or AFTER. Trigger action time should be\par
BEFORE if you want the Trigger action to occur before the Trigger event. It\par
should be AFTER if you want the Trigger action to occur after the Trigger event.\par
\par
Trigger event:\par
The Trigger event defines the SQL-data change statement whose execution (on\par
the Trigger's Table) will activate the Trigger: it may be either INSERT,\par
DELETE or UPDATE. In the case of UPDATE only, you may add an optional\par
subclause that lists the Trigger Columns: the Columns on which an UPDATE will\par
activate the Trigger (UPDATE on Columns not in the list won't activate the\par
Trigger). The Column list names some or all of the Trigger Table's Columns\par
(each may appear in the list only once). If you omit this optional subclause,\par
the effect is as if you included an OF clause that names every Column of the\par
Trigger's Table. For example, given this Table definition:\par
\par
   CREATE TABLE Table_1 (column_1 SMALLINT, column_2 CHAR(5));\par
\par
these two Trigger definitions are equivalent:\par
\par
   CREATE TRIGGER Trigger_1\par
      AFTER UPDATE ON Table_1\par
         INSERT INTO Log_table VALUES ('updated Table_1');\par
\par
   CREATE TRIGGER Trigger_1\par
      AFTER UPDATE OF column_1,column_2 ON Table_1\par
         INSERT INTO Log_table VALUES ('updated Table_1');\par
\par
Here are two more Trigger definition examples:\par
\par
   CREATE TRIGGER Trigger_1\par
      AFTER INSERT ON Table_1\par
         INSERT INTO Log_table VALUES ('insert into Table_1');\par
\par
   CREATE TRIGGER Trigger_1\par
      AFTER DELETE ON Table_1\par
         INSERT INTO Log_table VALUES ('delete from Table_1');\par
\par
REFERENCING clause:\par
The optional REFERENCING clause of the CREATE TRIGGER statement defines a list\par
of one to four unique <Correlation name>s, or aliases: one name for the old\par
row acted on by the Trigger and/or one name for the new row acted on by the\par
Trigger and/or one name for the old Table acted on by the Trigger and/or one\par
name for the new Table acted on by the Trigger (each may be specified once).\par
The <keyword> AS in each alias option is noise and may be omitted. If neither\par
ROW nor TABLE is specified, the default is ROW -- for example, these four SQL\par
statements are equivalent:\par
\par
   CREATE TRIGGER Trigger_1\par
      AFTER UPDATE ON Table_1 REFERENCING OLD ROW AS old_row_name\par
         FOR EACH ROW INSERT INTO Log_table VALUES ('updated Table_1');\par
\par
   CREATE TRIGGER Trigger_1\par
      AFTER UPDATE ON Table_1 REFERENCING OLD ROW old_row_name\par
         FOR EACH ROW INSERT INTO Log_table VALUES ('updated Table_1');\par
\par
   CREATE TRIGGER Trigger_1\par
      AFTER UPDATE ON Table_1 REFERENCING OLD AS old_row_name\par
         FOR EACH ROW INSERT INTO Log_table VALUES ('updated Table_1');\par
\par
   CREATE TRIGGER Trigger_1\par
      AFTER UPDATE ON Table_1 REFERENCING OLD old_row_name\par
         FOR EACH ROW INSERT INTO Log_table VALUES ('updated Table_1');\par
\par
Your Trigger definition must include a REFERENCING clause if the Trigger\par
action contains references to the Trigger's <Table name> or any of its <Column\par
name>s. The OLD values are the values before the UPDATE/DELETE Trigger event\par
(OLD ROW and OLD TABLE are not allowed if the Trigger event is INSERT) and the\par
NEW values are the values after the UPDATE/INSERT Trigger event (NEW ROW and\par
NEW TABLE are not allowed if the Trigger event is DELETE). If Trigger action\par
time is BEFORE, a REFERENCING clause may not specify OLD TABLE or NEW TABLE.\par
Here are some more REFERENCING clause examples:\par
\par
   ... REFERENCING OLD ROW AS old_row\par
\par
   ... REFERENCING OLD ROW AS old_row, NEW ROW AS new_row\par
\par
   ... REFERENCING OLD Table AS old_table, NEW Table AS new_table\par
\par
(A table alias is either a <regular identifier> or a <delimited identifier>.)\par
\par
Every Trigger event has its own "execution context": it includes the old row\par
values and/or the new row values of the Trigger's Table. If the Trigger event\par
is INSERT, then there are no old row values since no existing rows of a Table\par
are affected by INSERT. If the Trigger event is DELETE, then there are no new\par
row values since DELETE's action is to remove rows from a Table. If the\par
Trigger event is UPDATE, then there are three row versions:\par
      ## [1] The actual row of data in the Trigger's Table.\par
      ## [2] The "old row values" copy of the actual row -- often the same as [1], but if there are two distinct UPDATE events then there might be a difference between [1] and [2]. We'll call this the "old row" from now on.\par
The set of all old rows is the "old Table".\par
      ## [3] The "new row values" copy of the actual row -- it contains what the DBMS proposes to change the actual row to once the UPDATE statement's execution is completed. We'll call this the "new row" from now on.\par
The set of all new rows is the "new  Table".\par
(Note: Even with a BEFORE Trigger, the "new row values" are known to the DBMS.)\par
\par
A Trigger's execution context is important (indeed, it's mandatory) if you are\par
going to refer to the Trigger's Table in the Trigger's action statements. It\par
would usually be wrong to refer to Column COLUMN_1 of Table TABLE_1 with its\par
<Column reference>, TABLE_1.COLUMN_1, since the <Column reference> refers to\par
that Column in the actual Base table copy. What you really need to refer to is\par
either the old row or the new row. The REFERENCING clause of the CREATE\par
TRIGGER statement makes it possible to specify what context names you will use\par
for referring to OLD ROW or NEW ROW in the Trigger action.\par
\par
The execution context is "atomic" in the usual SQL sense of the word: if any\par
action statements fail, then all action statements fail and so does the\par
statement that caused the Trigger activation: your DBMS will return the\par
SQLSTATE error 09000 "triggered action exception". In other words, the old row\par
and the new row are simply destroyed and you're left with the same thing you started with: the actual row.\par
\par
Trigger action:\par
The Trigger action defines the SQL statements you want the Trigger to execute\par
when it is activated and has three parts: the action granularity, the action\par
when condition and the action body.\par
\par
## Action granularity\par
The optional FOR EACH clause of the CREATE TRIGGER statement defines the\par
Trigger action granularity: it may be either FOR EACH STATEMENT (the default)\par
or FOR EACH ROW. The action granularity tells your DBMS how big the field of\par
action is. For example, suppose you create a Trigger for "AFTER UPDATE OF\par
column_1 ON Employees", then do this:\par
\par
   UPDATE Employees SET column_1 = 5;\par
\par
Assume that the EMPLOYEES Table has 1000 rows. If action granularity is FOR\par
EACH STATEMENT, the Trigger action will occur once (just for the statement).\par
If action granularity is FOR EACH ROW, the Trigger action will occur 1000\par
times (once for each row of the Trigger Table). As stated earlier, the default\par
is FOR EACH STATEMENT, but "row" granularity is more common. In fact, if your\par
Trigger definition contains a REFERENCING clause that includes either OLD ROW\par
or NEW ROW, it must also include an action granularity clause of FOR EACH ROW.\par
\par
## Action when condition\par
The optional WHEN clause of the CREATE TRIGGER statement defines the Trigger\par
action when condition: it may be any parenthesized search condition. When the\par
Trigger is activated, if the search condition is TRUE, the Trigger action will\par
occur, if the search condition is FALSE, the Trigger action will not occur and\par
if the search condition is UNKNOWN, then apparently the Trigger action will\par
not occur (the Standard document is unclear about this point: see "satisfies"\par
in the Glossary). If you omit the WHEN clause from a Trigger definition, the\par
Trigger action will occur as soon as the Trigger is activated.\par
\par
Typically, you'd add a WHEN clause to your Trigger definition if the Trigger\par
event definition is too general for your purposes. For example, the Trigger\par
event might be "UPDATE Employees", but the Trigger action should occur only\par
"WHEN salary > 1000.00". Such specificity only makes sense if the action granularity is FOR EACH ROW.\par
\par
## Action body\par
The action body of the CREATE TRIGGER statement defines the Trigger action\par
itself: the SQL statement(s) you want your DBMS to execute when the Trigger is\par
activated. The action body may be either a single SQL statement or it may be a\par
series of SQL statements, delimited by semicolons, with a BEGIN ATOMIC ... END\par
subclause. Here are two examples of Trigger action bodies (the first shows an\par
action body using a single SQL statement and the second shows an action body\par
showing multiple SQL statements):\par
\par
   ... UPDATE Table_1\par
\par
   ... BEGIN ATOMIC\par
         DELETE FROM Table_1;\par
         DELETE FROM Table_2;\par
         DELETE FROM Table_3;\par
      END\par
\par
The Trigger action may not contain a host variable or an SQL parameter\par
reference, nor may it contain a <triggered SQL statement> that is an SQL-\par
transaction statement, an SQL-Connection statement, an SQL-Schema statement or\par
an SQL-session statement (see chapter 1, SQL statement classes). A variety of\par
SQL statements are legal inside the Trigger body, though.\par
      ## If Trigger action time is BEFORE, the Trigger action may include\par
these SQL statements: DECLARE TABLE, DECLARE CURSOR, OPEN, CLOSE, FETCH,\par
SELECT (for a single row only), FREE LOCATOR, HOLD LOCATOR, CALL, RETURN and\par
GET DIAGNOSTICS. It may also name an SQL-invoked routine, as long as that\par
routine isn't one that possibly modifies SQL-data.\par
      ## If Trigger action time is AFTER, the Trigger action may include all\par
of the SQL statements allowed for BEFORE Triggers, plus: INSERT, UPDATE and\par
DELETE. It may also name any SQL-invoked routine.\par
\par
Of the SQL statements available to you for a Trigger action, OPEN, FETCH,\par
CLOSE, single-row SELECT and GET DIAGNOSTICS are not very useful because it is\par
forbidden to include host variables and parameters inside the action body of a\par
Trigger definition. INSERT, UPDATE and DELETE are much more useful; often a\par
Trigger action body consists of just one such SQL-data change statement.\par
(Remember, though, that you can't use them with a BEFORE Trigger.) SQL-invoked\par
routines are useful too. In effect, a procedure in your host language program\par
can be called by a Trigger -- compare the various "callback" situations in the Windows API.\par
\par
If you want to restrict your code to Core SQL, don't use the CREATE TRIGGER statement.\par
\par
Activation of Triggers\par
\par
In our discussion of the CREATE TRIGGER statement, we made this true, but imprecise statement: "When the Trigger event occurs, the Trigger is activated." Let's get more precise about the meaning of "when" and "activated".\par
\par
The meaning of "when" depends on the Trigger action time (BEFORE or AFTER) and\par
on the Trigger's priority relative to other Triggers or Constraints. For\par
example, suppose we associate three Triggers and one Constraint with Table TABLE_1:\par
\par
   CREATE TRIGGER Trigger_1 AFTER UPDATE ON Table_1 ...;\par
\par
   CREATE TRIGGER Trigger_2 BEFORE UPDATE ON Table_1 ...;\par
\par
   CREATE TRIGGER Trigger_3 AFTER UPDATE ON Table_1 ...;\par
\par
   ALTER TABLE Table_1 ADD CONSTRAINT Constraint_1 ...;\par
\par
What is the effect when an UPDATE on TABLE_1 is executed? Since such an UPDATE\par
is a Trigger event for TABLE_1, several things happen -- in a rigid order of events.\par
      ## First, TRIGGER_2 is activated. It's a BEFORE Trigger, so it's first. The DBMS executes TRIGGER_2's action (if TRIGGER_2's definition includes a WHEN clause, this happens only if the search condition is TRUE).\par
      ## Second, the DBMS updates TABLE_1. Trigger events follow BEFORE Trigger actions.\par
      ## Third, CONSTRAINT_1 is checked. Constraint checks occur at end-of-statement.\par
      ## Fourth, TRIGGER_1 is activated. It's an AFTER Trigger, so it occurs after execution of the action statement -- and after any Constraint checking associated with the action statement.\par
      ## Fifth, TRIGGER_3 is activated. It's another AFTER Trigger, and it follows TRIGGER_1 because it was created later (Triggers are timestamped so the DBMS knows the order in which Triggers were created: older Triggers have priority).\par
\par
To sum it up, the order-of-execution for any Triggered SQL-data change\par
statement is: (1) BEFORE Triggers, (2) SQL-data change statement itself, (3)\par
Constraint checks on SQL-data change statement, (4) AFTER Triggers -- and\par
within that, old Triggers before young Triggers.\par
\par
The meaning of "activated" means "the Trigger action happens". Remember that\par
the Trigger action is defined by three separate clauses in the CREATE TRIGGER statement:\par
   [FOR EACH \{ROW|STATEMENT\}]            -- granularity\par
   [WHEN (search condition)]             -- when condition\par
   SQL statement |                       -- body\par
   BEGIN ATOMIC \{SQL statement;\}... END\par
\par
If Trigger action doesn't include "WHEN (search condition)" or if Trigger\par
action does include "WHEN (search condition)" and the condition is TRUE, the\par
DBMS decides that the Trigger action has happened. This specifically means that:\par
      ## If the action body is a SQL statement, the DBMS executes that SQL statement.\par
      ## Otherwise, the action body must be BEGIN ATOMIC ... END, and the DBMS executes all of the SQL statements that occur between the <keyword>s ATOMIC and END, in the order that they are defined.\par
\par
If any part of the Trigger action can't be executed successfully, that SQL\par
statement will fail and so will the entire Trigger action and so will the\par
Trigger event statement that caused the Trigger to activate: your DBMS will\par
return the SQLSTATE error 09000 "triggered action exception". The result is\par
that no change is made to the Trigger's Table or to any other Object that the\par
Trigger might have affected.\par
\par
Trigger Examples\par
\par
The following four scenarios show the use of a Trigger in a real-life situation.\par
\par
Trigger Example -- Logging deletions:\par
Scenario: We want to keep a log file containing data from rows that have been\par
deleted from the BOOKS Table. Here's a Trigger definition that accomplishes this:\par
\par
   CREATE TRIGGER Books_Delete\par
   AFTER DELETE ON Books                 /* See note (a) */\par
      REFERENCING OLD ROW AS Old         /* See note (b) */\par
   FOR EACH ROW                          /* See note (c) */\par
      INSERT INTO Books_Deleted_Log\par
         VALUES (Old.title);             /* See note (d) */\par
\par
This Trigger copies the title of every book deleted from the BOOKS Table into a Table (the log) called BOOKS_DELETED_LOG.\par
\par
      ## Note (a): The Trigger action has to be AFTER, since the Trigger action includes an SQL-data change statement.\par
      ## Note (b): It is conventional to use the alias "Old" or "Old_Row" for the old row.\par
      ## Note (c): No log will occur for a DELETE statement that affects zero rows.\par
      ## Note (d): OLD is an alias for a single old row, so OLD.TITLE is the scalar value derived from the TITLE Column of that old row.\par
\par
Trigger Example -- Inserting default expressions:\par
Scenario: When we add a client, we want the default value for HOME_TELEPHONE\par
to be the same as the WORK_TELEPHONE number. The DEFAULT clause is no good for\par
cases like this, because "DEFAULT <Column name>" is not a legal option. Here's\par
a Trigger definition that accomplishes this:\par
\par
   CREATE TRIGGER Clients_Insert\par
   BEFORE INSERT ON Clients\par
      REFERENCING NEW ROW AS New\par
   FOR EACH ROW\par
      SET New.home_telephone =\par
         COALESCE(New.home_telephone,New.work_telephone);\par
\par
(The SET statement causes the value on the right to be "assigned to" the\par
target on the left; this is part of the "Persistent Stored Modules" feature\par
package -- see our chapter on PSM).\par
\par
With this Trigger in place, this SQL statement:\par
\par
   INSERT INTO Clients (work_telephone)\par
   VALUES ('493-1125');\par
\par
will insert a new row into CLIENTS that has '493-1125' in the HOME_TELEPHONE\par
Column as well as in the WORK_TELEPHONE Column. This Trigger must be activated\par
BEFORE the INSERT, but it is possible to see in advance what values the DBMS\par
has tentatively assigned for the new row.\par
\par
Trigger Example: Constraint substitute:\par
Scenario: The department's budget can't be changed after 5 pm.\par
Here's a Trigger definition that accomplishes this -- but it has some flaws:\par
\par
   CREATE TRIGGER Departments_Update\par
   AFTER UPDATE OF budget ON Departments        /* first flaw */\par
   WHEN (CURRENT_TIME > '17:00:00')             /* second flaw */\par
      SELECT MAX(budget) / 0 FROM Departments;  /* third flaw */\par
\par
Since this CREATE TRIGGER statement contains no action granularity clause, the\par
default applies: FOR EACH STATEMENT. This means that if this SQL statement is executed:\par
\par
   UPDATE Departments SET budget = <value>;\par
\par
the Trigger's SELECT action will be executed -- and it will fail, since it\par
contains a division-by-zero expression. This, in turn, will cause the Trigger\par
event -- the UPDATE statement -- to fail too, since execution context is\par
atomic. (Actually there will be two errors. The main one will be "Triggered\par
action exception" and the secondary one will be "Division by zero".)\par
Therefore, this Trigger prevents anyone from updating DEPARTMENTS.BUDGET after\par
5 pm. Usually it works, but sometimes it doesn't work -- it contains subtle flaws.\par
\par
The first flaw is that a SQL statement like this:\par
\par
   UPDATE Departments SET budget = <value>, name = <value>;\par
\par
might fail to activate the Trigger. In strict Standard SQL, a Trigger's\par
explicit UPDATE Column list -- which in this case is "budget" -- must exactly\par
match the Columns in the UPDATE statement.\par
\par
The second flaw is that the WHEN clause is non-deterministic. In a sense,\par
that's the point of using a Trigger here rather than a Constraint: SQL doesn't\par
allow non-deterministic expressions in a Constraint.\par
\par
The third flaw is that this SQL statement:\par
\par
   UPDATE Departments SET budget = NULL;\par
\par
will pass -- it won't activate the Trigger because dividing a NULL value by\par
zero is legal SQL syntax -- and so the Trigger doesn't accomplish its purpose\par
100% of the time.\par
\par
We're not saying that it's bad to use Triggers as Constraint substitutes. This\par
example only shows that you should think hard about the possible consequences\par
before using "tricks".\par
\par
Trigger Example -- Cascading update:\par
Scenario: The first time we elect Bob, we all get a 1% tax cut. On the other\par
hand, every change in taxes will affect the national debt, and cause Bob's\par
popularity to drop. Here are two Trigger definitions that map this situation:\par
\par
   CREATE TRIGGER Prime_Minister_Update\par
   AFTER UPDATE ON Prime_Ministers\par
      REFERENCING OLD ROW AS Old, NEW ROW AS New FOR EACH ROW\par
   WHEN (New.name = 'Bob' AND New.name <> Old.name)\par
      UPDATE Taxpayers SET tax_payable = tax_payable * 0.99;\par
\par
   CREATE TRIGGER Taxpayer_Update\par
   AFTER UPDATE ON Taxpayers\par
      REFERENCING OLD ROW AS Old, NEW ROW AS New FOR EACH ROW\par
   BEGIN ATOMIC\par
      UPDATE National_Debt SET\par
         amount = amount + (New.payable - Old.payable);\par
      UPDATE Prime_Ministers SET\par
        approval_rating = approval_rating - 0.01;\par
   END;\par
\par
In this example, some updates of the PRIME_MINISTERS Table will cause an\par
update of the TAXPAYERS Table, and updates of TAXPAYERS will cause both an\par
update of the NATIONAL_DEBT Table and of PRIME_MINISTERS. Shown as a diagram,\par
with --> as a symbol for "causes possible UPDATE of", we have:\par
\par
Prime_Ministers --> Taxpayers --> National_Debt\par
     ^                 |\par
     |                 |\par
     |                 |\par
     -------------------\par
\par
There is an apparent cycle here, but the second UPDATE to PRIME_MINISTERS is\par
for a different Column than the first, so the effects don't cascade forever.\par
If we said "a change in the national debt will Trigger Bob's overthrow", then\par
we would have a true cycle -- that would be bad. Your DBMS is supposed to\par
detect it if the same Column changes value twice in a cycle, and cause the\par
Trigger action (and the SQL data-change statement that activated the Trigger)\par
to fail: it will return the SQLSTATE error 27000 "triggered data change violation".\par
\par
Triggers versus Constraints\par
\par
The essential idea of a Trigger is that if you change a Table, you cause a\par
given set of SQL statements to be executed. This idea is good: it allows you\par
to associate "rules" with Tables. And it can be efficient in a client-server\par
environment, because Trigger actions are pre-parsed and stored on the server.\par
However, Triggers are not the only way to implement this idea. There are\par
other ways to accomplish the same effect.\par
\par
As one alternative, you could incorporate SQL statements in "method"\par
procedures. This requires somewhat advanced procedures; see our chapter on UDTs.\par
\par
As another alternative, you could use a Constraint to declare what the most\par
important rules are. As we said earlier though, the advantage of using a\par
Trigger, instead of a Constraint, is flexibility. You can use a wide variety\par
of SQL statements in a Trigger, while the only things you can do with\par
Constraints are integrity checks and foreign key options. But is flexibility a\par
good thing? There are reasons why you should prefer the "rigidity" that Constraints imply:\par
      ## Your DBMS can recognize exactly what you're trying to accomplish, and optimize accordingly.\par
      ## You know what the consequences are because people thought them through when they devised the rigid syntax -- so there's less chance of bugs.\par
      ## Constraints have been part of standard SQL for a long time, while Triggers have not been.\par
      ## Constraints are deferrable; Triggers aren't.\par
Most experts appear to agree that you should use Constraints instead of\par
Triggers, if you can. Triggers are tricky.\par
\par
DROP TRIGGER statement\par
\par
The DROP TRIGGER statement destroys a Trigger. The required syntax for the DROP TRIGGER statement is:\par
\par
DROP TRIGGER <Trigger name>\par
\par
DROP TRIGGER destroys a Trigger. The <Trigger name> must identify an existing\par
Trigger whose owner is either the current <AuthorizationID> or a Role that the\par
current <AuthorizationID> may use. That is, only the <AuthorizationID> that\par
owns the Trigger may drop it.\par
\par
The effect of DROP TRIGGER <Table name>, e.g.:\par
\par
   DROP TRIGGER Trigger_1;\par
\par
is that the Trigger named is destroyed: it will have no further effect on SQL-data. No other Objects are affected by DROP TRIGGER, since no Objects are dependent on Triggers.\par
\par
If you want to restrict your code to Core SQL, don't use the DROP TRIGGER statement.\par
\par
Dialects\par
\par
Triggers are not part of SQL-92 or the SQL3 Core SQL specifications, but many\par
DBMSs have had them for years -- particularly "client-server" DBMSs. Since\par
these DBMSs supported Triggers before SQL3 came out, they naturally differ\par
from SQL3 and from each other. Here are some deviations we have noticed:\par
      ## There is no TRIGGER Privilege; only Table owners can create Triggers.\par
      ## A given Table can have only one BEFORE Trigger and one AFTER Trigger, or can have only a limited number of Triggers (e.g. 12) in total.\par
      ## Trigger events are conglomerable, e.g.: "BEFORE INSERT OR UPDATE OF ...".\par
      ## It is illegal to access the subject Table during the Trigger action, except through "new" and "old" row references. Such references must always be preceded by a colon (as if they're host variables).\par
      ## The WHEN clause is not supported.\par
      ## Assignments do not include the keyword SET, and are legal only for Triggers.\par
\page\par
Chapter 25 -- SQL-invoked Routine\par
\par
In this chapter, we'll describe SQL-invoked routines in detail, and show you the syntax to use to create, alter and destroy them.\par
\par
Routine\par
\par
A Schema may contain zero or more SQL-invoked routines. An SQL-invoked routine\par
(or SQL routine), is the generic name for either a procedure (SQL-invoked\par
procedure) or a function (SQL-invoked function). SQL routines are dependent on\par
some Schema (they're also called Schema-level routines) and are created,\par
altered and dropped using standard SQL statements.\par
\par
The concepts of "procedure" and "function" are the same in SQL as in other\par
languages, so the ideas in this chapter will be old hat to any programmer.\par
However, the syntax is all new: there was no standardized way to make SQL\par
routines until SQL3. Actually there still isn't -- it will take time before\par
all vendors fall in line -- but it's certainly time that everybody knows what routines are, according to the SQL Standard.\par
\par
In SQL, a routine consists of at least three items: a <Routine name>, a set of\par
parameter declarations and a routine body. An SQL procedure is a routine that\par
is invoked with a CALL statement; it may have input parameters, output\par
parameters and parameters that are both input parameters and output\par
parameters. An SQL function is a routine that returns a value when invoked by\par
a <routine invocation>; it has only input parameters, one of which may be\par
defined as the result parameter (if you do this, the function is called a\par
type-preserving function because the <data type> of the result is a subtype of\par
the <data type> of the result parameter). A function can also be defined as an\par
SQL-invoked method; it is invoked by a <method invocation> and its first parameter (called the subject parameter) must be a UDT.\par
\par
The case for routines can be summarized by noting these advantages:\par
      ## Flexibility: You can do even more with routines than you can with Constraints or Triggers, and you can do them in a wider variety of scenarios.\par
      ## Efficiency: Quite often, it's possible to replace slow generic SQL statements with painstakingly-optimized routines, especially "external routines" (i.e.: routines written in languages other than SQL).\par
      ## Cleanliness: Routines let you avoid writing the same SQL code in two places.\par
      ## Globalization: Is your SQL code enforcing the rules of the whole business? Then it should be associated with the entire database. Procedures are particularly useful for specialized Privilege checking.\par
      ## Sharing: Routines are (usually) cached on the server, and are (sometimes) accessible to all programmers. You needn't re-transmit and re-prepare every frequently-used code piece.\par
\par
An SQL-invoked routine is defined by a descriptor that contains 18 pieces of information:\par
      ## The not necessarily unique <Routine name> of the routine, qualified by the <Schema name> of the Schema it belongs to (or by MODULE).\par
      ## The unique <specific name> of the routine, qualified by the <Schema name> of the Schema it belongs to.\par
      ## The <external routine name> of the routine (for external routines).\par
      ## The routine's <AuthorizationID>.\par
      ## The routine's SQL-path.\par
      ## The language the routine is written in.\par
      ## A descriptor for every parameter in the routine. The parameter descriptor contains the <SQL parameter name> (if any), the parameter's <data type>, the ordinal position of the parameter in the routine body and\par
whether the parameter is an input parameter, an output parameter or both.\par
      ## Whether the routine is an SQL-invoked function or an SQL-invoked procedure and, in the first case, whether it is also an SQL-invoked method.\par
      ## The maximum number of dynamic result sets (for procedures).\par
      ## Whether the routine is deterministic or possibly non-deterministic.\par
      ## Whether the routine possibly modifies SQL-data, possibly reads SQL-data, possibly contains SQL or does not possibly contain SQL.\par
      ## The <returns data type> of the routine, and whether the return value is a locator (for functions).\par
      ## Whether the routine is a type-preserving function or a mutator function.\par
      ## The routine's result parameter (for type-preserving functions).\par
      ## Whether the routine is a null-call routine (for functions).\par
      ## The routine's creation timestamp: when it was created.\par
      ## The routine's last-altered timestamp: when it was last changed.\par
      ## The routine body of the routine: the SQL procedure statement that is executed when the routine is run (for SQL routines) or the host language statements that are executed when the routine is run (for external routines).\par
\par
An SQL-invoked routine can be an SQL routine (a routine written in SQL) or an\par
external routine (a routine written in a standard host language). Routines\par
can, of course, also be externally-invoked routines, but in this chapter, we\par
are concerned strictly with "Schema routines" -- SQL-invoked routines that are\par
stored in the database, just like other Schema Objects (Tables, Domains,\par
etc.). Our aim is to describe how routines are created and how they are "invoked" (i.e.: called). The first part is the hard part.\par
\par
To create an SQL-invoked routine use the CREATE FUNCTION or CREATE PROCEDURE\par
statements (either as stand-alone SQL statements or within a CREATE SCHEMA\par
statement). CREATE FUNCTION and CREATE PROCEDURE specify the enclosing Schema,\par
name the SQL-invoked routine and define the routine's body and routine\par
characteristics. To destroy an SQL-invoked routine, use the DROP ROUTINE, DROP\par
FUNCTION or DROP PROCEDURE statements. To change an existing routine, drop and then redefine it.\par
\par
SQL-invoked routine names:\par
An SQL-invoked routine name is either a <Routine name> or a <specific name>: both identify an SQL-invoked routine. The required syntax for an SQL-invoked routine name is:\par
\par
<Routine name> ::=\par
[ <Schema name>. ] unqualified name |\par
[ MODULE. ] unqualified name\par
\par
<specific name> ::=\par
[ <Schema name>. ] unqualified name\par
\par
A <Routine name> and a <specific name> are both a <regular identifier> or a\par
<delimited identifier>. The <Schema name> that qualifies a <Routine name> or a\par
<specific name> names the Schema that the SQL-invoked routine belongs to and\par
can either be explicitly stated, or a default will be supplied by your DBMS, as follows:\par
      ## If a <Routine name> or a <specific name> in a CREATE SCHEMA statement isn't qualified, the default qualifier is the name of the Schema you're creating.\par
      ## If the unqualified <Routine name> or <specific name> is found in any\par
other SQL statement in a Module, the default qualifier is the name of the\par
Schema identified in the SCHEMA clause or AUTHORIZATION clause of the MODULE statement which defines that Module.\par
\par
More than one SQL-invoked routine in a Schema may have the same <Routine name>s. Your DBMS will determine which routine is being invoked as follows:\par
      ## Since procedures and functions are created with separate SQL statements, your DBMS can uniquely identify the type of multiple routines identified by the same <Routine name>.\par
      ## Two procedures in a Schema may have the same <Routine name> only if\par
they don't also have the same number of parameters. Thus, your DBMS can\par
uniquely identify one procedure from another by checking the parameters of\par
each procedure with the same <Routine name>.\par
      ## Two functions in a Schema must have unique <specific name>s. Thus, your DBMS can uniquely identify one function from another by checking the <specific name> of each function with the same <Routine name>.\par
\par
Here are some examples of <Routine name>s:\par
\par
   ROUTINE_1\par
   -- a <Routine name>\par
\par
   SCHEMA_1.ROUTINE_1\par
  -- a simple qualified <Routine name>\par
\par
   CATALOG_1.SCHEMA_1.ROUTINE_1\par
  -- a fully qualified <Routine name>\par
\par
   MODULE.ROUTINE_1\par
  -- a local <Routine name>\par
\par
Here are some examples of <specific name>s:\par
\par
   SPECIFIC_ROUTINE_1\par
   -- a <specific name>\par
\par
   SCHEMA_1.SPECIFIC_ROUTINE_1\par
  -- a simple qualified <specific name>\par
\par
   CATALOG_1.SCHEMA_1.SPECIFIC_ROUTINE_1\par
   -- a fully qualified <specific name>\par
\par
SQL parameter names:\par
An <SQL parameter name> identifies an SQL parameter. The required syntax for an <SQL parameter name> is:\par
\par
<SQL parameter name> ::= <identifier>\par
\par
An <SQL parameter name> is a <regular identifier> or a <delimited identifier> that is unique (for all parameters) in the routine it belongs to. Here are some examples of <SQL parameter name>s:\par
\par
   PARAMETER_1\par
   -- a <regular identifier>\par
\par
   "PARAMETER_1's helper"\par
   -- a <delimited identifier>\par
\par
CREATE PROCEDURE/FUNCTION statement\par
\par
The CREATE PROCEDURE/FUNCTION statement names a new SQL-invoked procedure or\par
function and defines the routine's SQL parameters, characteristics and routine\par
body. The required syntax for the CREATE PROCEDURE/FUNCTION statement is:\par
\par
CREATE PROCEDURE <Routine name>\par
<SQL parameter declaration list>\par
<routine characteristics>\par
<routine body>\par
\par
CREATE \{<function specification> | <method specification>\}\par
<routine body>\par
\par
   <function specification> ::=\par
   FUNCTION <Routine name>\par
   <SQL parameter declaration list>\par
   <returns clause>\par
   <routine characteristics>\par
   STATIC DISPATCH\par
\par
   <method specification> ::=\par
   <partial method signature> FOR <UDT name>\par
   [ SPECIFIC <specific name> ]\par
\par
   <SQL parameter declaration list> ::=\par
   ([ <parameter declaration> [ \{,<parameter declaration>\}... ] ])\par
\par
      <parameter declaration> ::=\par
      [ \{IN | OUT | INOUT\} ]\par
      [ <SQL parameter name> ]\par
      <data type> [ AS LOCATOR ]\par
      [ RESULT ]\par
\par
   <routine characteristics> ::=\par
   [ <routine characteristic>... ]\par
\par
      <routine characteristic> ::=\par
      LANGUAGE \{ADA | C | COBOL | FORTRAN | MUMPS | PASCAL | PLI | SQL\} |\par
      PARAMETER STYLE \{SQL | GENERAL\} |\par
      SPECIFIC <specific name> |\par
      \{DETERMINISTIC | NOT DETERMINISTIC\} |\par
      <SQL-data access indication> |\par
      \{RETURN NULL ON NULL INPUT | CALL ON NULL INPUT) |\par
      DYNAMIC RESULT SETS unsigned integer\par
\par
         <SQL-data access indication> ::=\par
         NO SQL |\par
         CONTAINS SQL |\par
         READS SQL DATA |\par
         MODIFIES SQL DATA\par
\par
      <returns clause> ::=\par
      RETURNS <data type> [ AS LOCATOR ]\par
      [ CAST FROM <data type> [ AS LOCATOR ] ]\par
\par
   <routine body> ::=\par
   <SQL routine body> |\par
   <external body reference>\par
\par
      <SQL routine body> ::= SQL procedure statement\par
\par
      <external body reference> ::=\par
      EXTERNAL [ NAME <external routine name> ]\par
      [ PARAMETER STYLE \{SQL | GENERAL\} ]\par
      [ TRANSFORM GROUP <group name> ]\par
      [ WITH \{HOLD | RELEASE\} ]\par
\par
The CREATE PROCEDURE/CREATE FUNCTION statement lets you define an SQL-invoked routine. Here's a simpler version of the required syntax:\par
\par
\{CREATE PROCEDURE | CREATE FUNCTION\}\par
<Routine name>                         /* name of procedure or function */\par
( [parameter [\{,parameter\}...])        /* parameter declaration list */\par
[RETURNS <data type> <result cast>]    /* for function only */\par
                                       /* <routine characteristics> start */\par
[LANGUAGE \{ADA|C|COBOL|FORTRAN|MUMPS|PASCAL|PLI|SQL\}]  /*language clause*/\par
[PARAMETER STYLE \{SQL|GENERAL\}]                        /* parameter style */\par
[SPECIFIC <specific name>]\par
[DETERMINISTIC|NOT DETERMINISTIC]           /* deterministic characteristic */\par
[NO SQL|CONTAINS SQL|READS SQL DATA|MODIFIES SQL DATA] /* access indication */\par
[RETURN NULL ON NULL INPUT|CALL ON NULL INPUT]         /* null-call clause */\par
[DYNAMIC RESULT SETS unsigned integer                 /* for procedure only */\par
                                       /* <routine characteristics> end */\par
[STATIC DISPATCH]                                     /* for function only */\par
<routine body>\par
\par
As you can see, our "simpler" version isn't much simpler -- there's lots of\par
options! So what we'll do with this SQL statement is first give you a quick\par
one-paragraph description of each clause, then we'll start with some examples\par
of simple SQL routines and work our way up -- piece by piece -- to fairly complicated matters.\par
\par
CREATE ... <Routine name> clause:\par
First of all, to create an SQL-invoked routine, the <keyword> phrase CREATE\par
PROCEDURE or CREATE FUNCTION is the basic choice. Either way, you are creating\par
a "routine". But there are two kinds of routines: "procedures" (which don't\par
return values) and "functions" (which do return values). Your choice at this\par
stage will determine how the routine is called later. CREATE PROCEDURE defines\par
a new SQL-invoked procedure. CREATE FUNCTION defines a new SQL-invoked\par
function. A routine is owned by the Schema it belongs to.\par
\par
The <Routine name> identifies the routine and the Schema that it belongs to --\par
this is the name of the routine as it appears to SQL. The description of the\par
routine is stored (as a Schema Object) in INFORMATION_SCHEMA, so <Routine\par
name> has to follow the same rules as any other Schema Object name. A <Routine\par
name> that includes an explicit <Schema name> qualifier belongs to the Schema\par
named. A <Routine name> that does not include an explicit <Schema name>\par
qualifier belongs to the SQL-session default Schema. However -- an unusual\par
point -- <Routine name> does not have to be unique within its Schema; that is,\par
two different routines in the same Schema may have the same <Routine name>\par
because your DBMS will have other ways of uniquely identifying a routine (this\par
easement of the usual rule is not allowed in Core SQL.)\par
\par
If CREATE PROCEDURE/CREATE FUNCTION is part of a CREATE SCHEMA statement, the\par
<Routine name>, if explicitly qualified, must include the <Schema name> of the\par
Schema being created; that is, it isn't possible to create a routine belonging\par
to a different Schema from within CREATE SCHEMA. The owner of a Schema always\par
has the EXECUTE Privilege on every routine that belongs to that Schema. This\par
Privilege is a grantable Privilege only if (a) the routine is an SQL routine\par
and the Schema owner has a grantable Privilege for every part of the routine\par
body or (b) the routine is an external routine.\par
\par
Parameter declaration list:\par
A routine's parameter declaration list is a parenthesized, comma-delimited\par
sequence of declarations taking the form "[IN | OUT | INOUT] [<parameter\par
name>] <data type> ..." and so on. The purpose of a parameter declaration is\par
to describe what values or addresses are being passed to the routine. The\par
optional <parameter name> identifies a parameter and must be unique (for all\par
parameters) in the routine it belongs to. We'll discuss the details later,\par
when we've given you some examples. The parameter declaration list is\par
mandatory, but it may be blank -- for example: "()".\par
\par
RETURNS clause:\par
The RETURNS clause -- RETURNS <data type> <result cast> -- is a mandatory\par
clause if your SQL statement is CREATE FUNCTION. Usually this clause describes\par
the <data type> of what the function returns, for example: RETURNS SMALLINT.\par
Sometimes it is necessary to cast the result, for example: RETURNS CHAR(10) CAST FROM DATE.\par
\par
Having described the initial mandatory parts of the routine specification, we can now give you a rough analogy for the C function declaration:\par
\par
   long function1 (param1 short);\par
\par
In SQL, this is:\par
\par
   CREATE FUNCTION function1\par
      (IN param1 SMALLINT) RETURNS INTEGER ...\par
\par
At this point, we need to emphasize that this example is a rough analogy. The SQL statement is executable (it is not a mere function declaration), and it is far from finished yet.\par
\par
Routine characteristics clause:\par
The routine characteristics clause defines certain characteristics of your\par
routine. It may include zero or one specification of any (or all) of the eight\par
optional characteristic specification subclauses, in any order.\par
\par
## LANGUAGE subclause\par
The LANGUAGE subclause names the language the routine is written in. The\par
official expectation is that the routine is written in one of the ISO\par
"standard" languages: Ada, C, COBOL, FORTRAN, MUMPS, Pascal, PLI (note the\par
spelling) or SQL. In practice, your DBMS probably won't support all of the\par
standard languages (for example, MUMPS is often excluded); but it may support\par
others (for example, BASIC or Java). If you omit the LANGUAGE subclause, the\par
default is LANGUAGE SQL and your routine is an SQL routine. A routine written\par
in any language other than SQL, is an external routine to SQL.\par
\par
## PARAMETER STYLE subclause\par
The PARAMETER STYLE subclause is only necessary for external routines and can\par
be specified only once in a routine definition -- you can only put it in\par
either one of the <routine characteristics> clause or the <external body\par
reference> clause. If you omit the PARAMETER STYLE subclause, the default is\par
PARAMETER STYLE SQL. Again, we'll discuss parameter details when we have some examples to show you.\par
\par
## SPECIFIC subclause\par
The SPECIFIC <specific name> subclause uniquely identifies the routine. Since\par
your routine definition will already contain a <Routine name>, what would you\par
need a <specific name> for? Well, it mostly relates to UDTs and we'll defer\par
discussing routines for UDTs to our chapter on UDTs.\par
\par
## deterministic characteristic subclause\par
The DETERMINISTIC | NOT DETERMINISTIC subclause is important if you intend to\par
include the routine in a Constraint, since Constraint routines must be\par
deterministic. If you omit the deterministic characteristic subclause, the\par
default is NOT DETERMINISTIC (which actually means "possibly\par
non-deterministic"; see our chapter on Constraints and Assertions). A\par
DETERMINISTIC function always returns the same value for a given list of SQL\par
arguments. A DETERMINISTIC procedure always returns the same values in its SQL\par
parameters for a given list of SQL arguments. A possibly NOT DETERMINISTIC\par
routine might, at different times, return different results even though the\par
SQL-data is the same. You may not specify DETERMINISTIC if the routine could\par
return different results at different times.\par
\par
## SQL data access indication subclause\par
The NO SQL | CONTAINS SQL | READS SQL DATA | MODIFIES SQL DATA subclause\par
specifies what sort of SQL statements are in the routine (if any). If your\par
routine LANGUAGE subclause is LANGUAGE SQL, then the routine will certainly\par
"contain" SQL statements, but even an external LANGUAGE PASCAL routine can\par
contain SQL/CLI functions or embedded SQL statements, so LANGUAGE PASCAL ...\par
CONTAINS SQL is a valid specification. If a routine contains any SQL-data\par
change statements (INSERT, UPDATE and/or DELETE), its SQL data access\par
subclause must state MODIFIES SQL DATA; otherwise if the routine contains any\par
other SQL-data statements (e.g.: SELECT or FETCH), the SQL data access\par
subclause must state READS SQL DATA; otherwise if the routine contains any\par
other SQL statements, the SQL data access subclause must state CONTAINS SQL;\par
otherwise if the routine contains no SQL statements at all, the SQL data\par
access subclause must state NO SQL. If you omit the SQL data access indication\par
subclause, the default is CONTAINS SQL.\par
\par
## null-call subclause\par
The RETURN NULL ON NULL INPUT | CALL ON NULL INPUT subclause is for functions\par
written in a host language, since a host language cannot handle NULLs. When\par
the null-call subclause is RETURN NULL ON NULL INPUT, the routine is a\par
"null-call" routine. If you call a null-call routine with any parameter set to\par
the null value, the return is immediate: the function returns NULL. When the\par
null-call subclause is CALL ON NULL INPUT and you call the routine with any\par
parameter set to the null value, execution of the routine follows standard\par
rules for operations with null values (e.g.: comparisons of nulls to other\par
values return UNKNOWN, and so on). If you omit the null-call subclause, the\par
default is CALL ON NULL INPUT.\par
\par
## DYNAMIC RESULT SETS subclause\par
The DYNAMIC RESULT SETS subclause is legal only within a CREATE PROCEDURE\par
statement. The "result sets" in question are query results, and the concept\par
here is that, within the routine, a certain number of Cursors (the unsigned\par
integer) can be opened for the results. In other words, you can CALL a\par
procedure which STATIC DISPATCH clause contains up to "n" OPEN (Cursor)\par
statements, and those Cursors will be visible after you return from the\par
procedure. If you omit the DYNAMIC RESULT SETS subclause, the default is DYNAMIC RESULT SETS 0.\par
\par
Remember that the "routine characteristics" subclauses may be defined in any\par
order in a routine definition. The final two clauses must appear at the end of the SQL statement.\par
\par
STATIC DISPATCH clause:\par
The optional STATIC DISPATCH clause is legal only within a CREATE FUNCTION\par
statement. It must be specified for functions that are not also SQL-invoked\par
methods, and that contain parameters whose <data type> is either a <reference\par
type>, a UDT or an ARRAY whose element <data type> is either a <reference type> or a UDT.\par
\par
<routine body>:\par
The <routine body> is a mandatory part of a routine definition. For a LANGUAGE\par
SQL routine, you'd put a SQL procedure statement here (it may be any SQL\par
statement other than an SQL-Schema statement, an SQL-Connection statement or\par
an SQL-transaction statement). For an external routine, you'd put an external\par
interface description here. Clearly, the body of the routine is what really matters.\par
\par
Routine Parameters\par
\par
A routine's SQL parameter declaration list is a parenthesized, comma-delimited\par
list of definitions for the routine's parameters. Here's the required syntax\par
for a parameter definition in a CREATE PROCEDURE/CREATE FUNCTION statement again:\par
\par
<parameter declaration> ::=\par
[ \{IN | OUT | INOUT\} ]                       /* parameter mode */\par
[ <SQL parameter name> ]\par
<data type> [ AS LOCATOR ]\par
[ RESULT ]\par
\par
parameter mode:\par
The optional [IN | OUT | INOUT] parameter mode specification is legal only\par
within CREATE PROCEDURE statements. IN defines an input SQL parameter, OUT\par
defines an output SQL parameter and INOUT defines both an input SQL parameter\par
and an output SQL parameter. (In SQL routines, the SQL parameters may not be\par
named in a host variable or parameter specification in the routine body.) This\par
is a directional specification. If you omit the parameter mode subclause, the default is IN.\par
\par
<SQL parameter name>:\par
The optional <SQL parameter name> is simply that: a name that you'll use if\par
you refer to the parameter within the routine. If you're defining an SQL\par
routine, this subclause is not optional: you must include an <SQL parameter\par
name> for each of the routine's parameters. If you're defining an external\par
routine, an <SQL parameter name> for each of its parameters is not mandatory\par
because in an external routine you can use any name you like; the ordinal\par
position of the parameter within the routine is what matters.\par
\par
<data type>:\par
The <data type> of a parameter is always an SQL <data type> and must be\par
defined for every parameter. The value of an SQL parameter with a character\par
string <data type> has IMPLICIT coercibility. At this time, we include the\par
optional [ AS LOCATOR ] indicator here only for completeness: it's valid only\par
when you're defining an external routine with a parameter whose <data type> is\par
either BLOB, CLOB, NCLOB, ARRAY or a UDT.\par
\par
RESULT:\par
The optional <keyword> RESULT is applicable only for UDTs, and is noted here only for completeness at this time.\par
\par
Here's an example of a parameter declaration list for a CREATE PROCEDURE statement:\par
\par
   CREATE PROCEDURE procedure_1 (\par
      IN Apple CHAR(6), OUT Orange CHAR(6))\par
      ...\par
\par
The list is legal only within a CREATE PROCEDURE statement because it contains\par
IN and OUT declarations (within a CREATE FUNCTION statement, all parameters\par
are assumed to be IN). The parameter named APPLE is a 6-character input\par
parameter; the parameter named ORANGE is a 6-character output parameter.\par
Here's an example of a parameter declaration list for a CREATE FUNCTION statement:\par
\par
   CREATE FUNCTION function_1 (Apple CHAR(6))\par
      ...\par
\par
Invoking routines\par
\par
Creating a routine is complex. Invoking a routine can be easy. The secret is: don't use the same <Routine name> twice in the same Schema.\par
\par
CALL statement\par
\par
The CALL statement invokes a procedure. The required syntax for the CALL statement is:\par
\par
CALL <Routine name> <SQL argument list>\par
\par
   <SQL argument list> ::=\par
   ([ <SQL argument> [ \{,<SQL argument>\}... ] ])\par
\par
      <SQL argument> ::=\par
      scalar_expression_argument |\par
      <host parameter name> [ [ INDICATOR ] <host parameter name> ] |\par
\par
The <Routine name> must identify an SQL-invoked procedure and the <SQL\par
argument list> must correspond to that procedure's parameter declarations in\par
both number and comparable <data type>. (A "scalar_expression_argument" is any\par
expression which evaluates to a single value.) For example, for this procedure:\par
\par
   CREATE PROCEDURE procedure_1 (\par
      IN in_param SMALLINT, OUT out_param SMALLINT\par
      ...\par
\par
use this CALL statement to invoke it:\par
\par
   CALL procedure_1(5,5);\par
\par
The SQL argument for an IN SQL parameter or an INOUT SQL parameter must be a\par
scalar_expression_argument. The SQL argument for an OUT SQL parameter may be a host language variable.\par
\par
Your current <AuthorizationID> must have the EXECUTE Privilege on a procedure to CALL it.\par
\par
<routine invocation>\par
\par
A <routine invocation> invokes a function. The required syntax for a <routine invocation> is:\par
\par
<Routine name> <SQL argument list>\par
\par
   <SQL argument list> ::=\par
   ([ <SQL argument> [ \{,<SQL argument>\}... ] ])\par
\par
      <SQL argument> ::=\par
      scalar_expression_argument |\par
      scalar_expression_argument AS <UDT name>\par
\par
The <Routine name> must identify an SQL-invoked function and the <SQL argument\par
list> must correspond to that function's parameter declarations in both number\par
and comparable <data type>. (A "scalar_expression_argument" is any expression\par
which evaluates to a single value.) For example, for this function:\par
\par
   CREATE FUNCTION function_1 (in_param SMALLINT) ...;\par
\par
use this <routine invocation> to invoke it wherever it's legal to use a value expression:\par
\par
   function_1(5)\par
\par
Here's an example:\par
\par
   INSERT INTO Table_1 VALUES (function_1(5));\par
\par
Your current <AuthorizationID> must have the EXECUTE Privilege on a function to invoke it.\par
\par
Routine examples\par
\par
Here are four examples of SQL-invoked routines that might be used in real-life situations.\par
\par
Routine example -- Reset procedure:\par
Objective: Define and invoke a procedure which sets Column COLUMN_1, in Table\par
TABLE_1, to zero for all rows. Here's a procedure definition to accomplish this:\par
\par
   CREATE PROCEDURE\par
      Reset_table_1                             /* Routine name */\par
      ()                                        /* An empty parameter list */\par
      MODIFIES SQL DATA                         /* Data access clause */\par
      UPDATE Table_1 SET column_1 = 0;          /* The routine body */\par
\par
To invoke RESET_TABLE_1, use this SQL statement:\par
\par
   CALL Reset_table_1();\par
\par
When you invoke a routine, you're telling your DBMS to execute the routine body. For this example, this SQL statement:\par
\par
  CALL Reset_table_1();\par
\par
has the same effect as this SQL statement:\par
\par
   UPDATE Table_1 SET column_1 = 0;\par
\par
Details worth noting:\par
      ## It's fairly common for a <Routine name> to consist of a verb and an Object, as in this case. The style of routine definitions is still evolving.\par
      ## Even though there are no parameters, the parentheses which enclose the parameter declaration list are necessary, both during creation and during invocation.\par
      ## The SQL-data access clause -- MODIFIES SQL DATA -- is necessary in this case because the procedure contains the SQL-data change statement INSERT. It's a good habit to specify the data access clause even when it is not necessary.\par
\par
Routine example -- Constant function:\par
Objective: Define and invoke a function which returns the constant pi, as a\par
DECIMAL value. Here's a function definition to accomplish this:\par
\par
   CREATE FUNCTION\par
      Pi                            /* Routine name */\par
      ()                            /* An empty parameter list */\par
      RETURNS DECIMAL(3,2)          /* What the function returns */\par
      CONTAINS SQL                 /* Data access clause */\par
      RETURN 3.14;                 /* The routine body */\par
\par
To invoke PI, use the <routine invocation> "Pi()" in an SQL statement, for example:\par
\par
   INSERT INTO Table_1 (decimal_column) VALUES (Pi());\par
\par
In this example, the routine body contains a RETURN statement, which is legal\par
only within SQL functions. RETURN must specify some value (you can put any\par
expression which evaluates to a single value here) with a <data type> that is\par
assignable to the <data type> defined in the function definition's RETURNS\par
clause. In this case, the function invocation in this SQL statement:\par
\par
   INSERT INTO Table_1 (decimal_column) VALUES (Pi());\par
\par
has the same effect as this SQL statement:\par
\par
   INSERT INTO Table_1 (decimal_column) VALUES (3.14);\par
\par
** Tip: You can't define constants in SQL, but you can define constant functions. They help ensure that values like \'e3 (pi) are defined only once, and are referenced by a name rather than a <literal>.\par
\par
Routine example -- Subquery function:\par
Objective is: Define and invoke a replacement for a frequently-used subquery. Here's a function definition to accomplish this:\par
\par
   CREATE FUNCTION\par
      Max_                          /* Routine name */\par
      ()                            /* An empty parameter list */\par
      RETURNS DATE                  /* What the function returns */\par
      CONTAINS SQL                  /* Data access clause */\par
      RETURN (                      /* The routine body */\par
         SELECT MAX(date_column)\par
         FROM   Table_1\par
         WHERE  smallint_column > 5);\par
\par
To invoke MAX_, use the <routine invocation> "Max_()" in an SQL statement, for example:\par
\par
  SELECT * FROM Table_2 WHERE Column_1 < Max_();\par
\par
The potential advantage with this example is that "Max_()" is easier to type\par
than "SELECT MAX(date_column) FROM Table_1 WHERE smallint_column > 5);". It's\par
also safer -- if a subquery is long and complex and used frequently, you'll\par
reduce the chances of error by putting the subquery into a function.\par
\par
A far less likely advantage is that the MAX_ routine is parsed and done only\par
once. Although that sort of optimization is theoretically possible, there are\par
some hidden dynamic variables that could change each time MAX_ is invoked (for\par
example, the Schema that contains TABLE_1). One does not call functions like\par
this for "efficiency" reasons.\par
\par
Routine example -- Withdrawal procedure:\par
Objective: Perform a logged balanced withdrawal, like real banks do. Here's a procedure definition to accomplish this:\par
\par
   CREATE PROCEDURE\par
      Withdraw                             /* Routine name */\par
      (parameter_amount DECIMAL(6,2),     /* Parameter list */\par
      parameter_teller_id INTEGER,\par
      parameter_customer_id INTEGER)\par
      MODIFIES SQL DATA                   /* Data access clause */\par
      BEGIN ATOMIC                        /* Routine body */\par
        UPDATE Customers\par
           SET balance = balance - parameter_amount\par
           WHERE customer_id = parameter_customer_id;\par
        UPDATE Tellers\par
           SET cash_on_hand = cash_on_hand + parameter_amount\par
           WHERE teller_id = parameter_teller_id;\par
        INSERT INTO Transactions VALUES (\par
           parameter_customer_id,\par
           parameter_teller_id,\par
           parameter_amount);\par
      END;\par
\par
To invoke WITHDRAW, use a CALL statement that names the procedure and provides a value for each of its parameters, for example:\par
\par
   CALL Withdraw (15.33,44,90182);\par
\par
Typical bank transactions always involve changes to multiple accounts (for the\par
general ledger, the customer and the teller), and are always logged.\par
Therefore, in the real world, withdrawals are done via procedures. This\par
example is translated from a procedure written in a host language (not SQL);\par
however, the routine is really used in a real bank. Details worth noting:\par
      ## The parameters (all of which are IN SQL parameters) are simply referenced by name within the routine body.\par
      ## The routine body contains a compound SQL procedure statement (a sequence of SQL statements within a "BEGIN ATOMIC ... END" block). Correctly, compound SQL statements are only legal in Triggers,\par
or as part of the "Persistent Stored Modules" SQL package (see our chapter on PSM) -- so this example shows the use of an extension to Standard Core SQL.\par
\par
Routines are particularly applicable to Roles. For example, a bank teller\par
might not have the Privilege to access a Table, but would have the Privilege\par
to EXECUTE the WITHDRAW Procedure. Typically, one finds that when groups of\par
employees are involved, the applicable Privilege is not an "access Privilege\par
on a Table" but an "EXECUTE Privilege on a routine".\par
\par
RETURN statement\par
\par
The RETURN statement returns a value from an SQL-invoked function. The required syntax for the RETURN statement is:\par
\par
RETURN <value expression> | NULL\par
\par
The RETURN statement ends the execution of an SQL-invoked function, returning\par
the function's result. The return can either be a <value expression> or, if\par
the function's result is a null value, the <keyword> NULL.\par
\par
External Routines\par
\par
"Host calls DBMS: no story. DBMS calls host: story!"\par
   -- Journalist's man-bites-dog rule, slightly adapted\par
\par
Since most applications involve two languages -- SQL and the host -- there are four possible routine interface situations:\par
      ## Host invokes SQL -- this is a common situation, discussed in our chapters on SQL/CLI and embedded SQL.\par
      ## Host invokes host -- this is also common, but none of our business: this is an SQL book.\par
      ## SQL invokes SQL -- this is the situation we've shown you in the example so far; they've all been SQL routines.\par
      ## SQL invokes host -- this is not a common situation, but external routines" are conceivably quite useful.\par
\par
You can write Standard SQL routines in Ada, C, COBOL, Fortran, MUMPS, Pascal\par
or PL/1. If you do, the routine definition must include a LANGUAGE clause that\par
names the host language you're using and its routine body would have to be a\par
reference to an external routine, instead of an SQL procedure statement. Here,\par
once again, is the required syntax for an <external body reference> in a\par
CREATE PROCEDURE/CREATE FUNCTION statement:\par
\par
EXTERNAL\par
[ NAME <external routine name> ]\par
[ PARAMETER STYLE \{SQL | GENERAL\} ]\par
[ TRANSFORM GROUP <group name> ]\par
[ WITH \{HOLD | RELEASE\} ]\par
\par
The <keyword> EXTERNAL tells your DBMS you're defining an external routine.\par
\par
NAME clause:\par
The optional NAME clause specifies the routine's external name. If you omit\par
the NAME clause, it will default to the routine's unqualified <Routine name>.\par
\par
PARAMETER STYLE clause:\par
The optional PARAMETER STYLE clause determines whether some additional\par
parameters will be passed automatically and has two options: SQL or GENERAL.\par
If the specification is PARAMETER STYLE SQL, then automatic parameters (such\par
as indicators) will be passed as well. If the specification is PARAMETER STYLE\par
GENERAL, then there is no automatic parameter passing. If you omit the clause,\par
the default is PARAMETER STYLE SQL. Remember not to use a parameter style\par
clause here if there is already a parameter style clause in the main definition.\par
\par
TRANSFORM GROUP clause:\par
The optional TRANSFORM GROUP <group name> clause is necessary only if the\par
function is for transforming UDT values to host values, or vice versa. If you\par
omit the clause, the default is TRANSFORM GROUP DEFAULT.\par
\par
WITH clause:\par
The optional WITH \{HOLD | RELEASE\} clause is a future consideration; the presumption is that it has to do with holdable Cursors.\par
\par
Here's an example of an external routine that is an SQL-invoked procedure:\par
\par
   CREATE PROCEDURE\par
      Routine_1                      /* Routine name */\par
      ()                             /* empty parameter list */\par
      LANGUAGE C                     /* language clause */\par
      NO SQL                         /* C routine has no SQL calls */\par
      EXTERNAL                       /* routine body */\par
         NAME "wHoldPrivilegeTest";  /* actual name of the routine*/\par
\par
Unfortunately, this information is not quite sufficient. In Windows, for\par
example, we would also need to know the name of the DLL. So there has to be\par
some non-standard extra stuff added to this routine, which will be done at the\par
implementation level.\par
\par
External routines are necessary, or at least very useful, for these things:\par
      ## Accessing the operating system. For example, you can't call the\par
Windows API from SQL, but you can create an external routine which does so.\par
The ability to access the operating system is particularly useful for\par
Privilege checks.\par
      ## Translating data. The traditional usage here is\par
encryption/decryption. We'd also note that, if your DBMS produces error\par
messages in English and you want them in Italian, this is a good place to\par
intercept them.\par
      ## Optimizing. Since SQL is not famous for low-level efficiency, it's\par
usually faster to write some routines in a compiled language, or better yet in\par
assembler (shameless plug: see our book OPTIMIZING C WITH ASSEMBLY CODE).\par
Hashing and pattern matching would make good examples here.\par
\par
External routines are not so wonderful if you're trying to write purely\par
portable SQL applications. Also, their existence can confuse the DBMS's\par
optimizer, and even confuse application programmers. We suggest that you keep\par
it simple: don't write external routines that call SQL.\par
\par
If you want to restrict your code to Core SQL, don't use LOCATOR indicators,\par
DYNAMIC RESULT SETS clauses, TRANSFORM GROUP clauses or duplicate <Routine\par
name>s when defining an SQL-invoked routine and don't define any SQL-invoked methods.\par
\par
DROP ROUTINE/PROCEDURE/FUNCTION statement\par
\par
The DROP ROUTINE/PROCEDURE/FUNCTION statement destroys an SQL-invoked procedure or function. The required syntax for the DROP ROUTINE/PROCEDURE/FUNCTION statement is:\par
\par
DROP <specific routine designator> \{RESTRICT | CASCADE\}\par
\par
   <specific routine designator> ::=\par
   \{ROUTINE | FUNCTION | PROCEDURE\} <Routine name>\par
      [ ([ <data type> [ \{,<data type>\}... ] ]) ]\par
\par
DROP ROUTINE/PROCEDURE/FUNCTION destroys an SQL-invoked routine. The <Routine\par
name> must identify an existing SQL-invoked routine whose owner is either the\par
current <AuthorizationID> or a Role that the current <AuthorizationID> may\par
use. That is, only the <AuthorizationID> that owns the routine may drop it. If\par
<Routine name> is not unique within the routine's Schema, then you must\par
include a <data type> list that provides the <data type> of each of the\par
routine's parameters -- your DBMS will match this list to the parameter\par
declaration lists of every routine called "<Routine name>" to find the one you\par
want to drop. If you remember to always give unique <Routine name>s to your\par
routines, you'll avoid a great deal of potential difficulty.\par
\par
DROP ROUTINE drops either an SQL-invoked function or an SQL-invoked procedure,\par
so it's best to be more specific. DROP FUNCTION drops an SQL-invoked function,\par
so <Routine name> must identify a function. DROP PROCEDURE drops an SQL-\par
invoked procedure, so <Routine name> must identify a procedure. In no case may\par
<Routine name> identify a routine that was created as part of a UDT\par
definition.\par
\par
The effect of DROP routine type <Routine name> RESTRICT, e.g.:\par
\par
   DROP ROUTINE routine_1 RESTRICT;\par
\par
   DROP FUNCTION function_1 RESTRICT;\par
\par
   DROP PROCEDURE procedure_1 RESTRICT;\par
\par
is that the routine named is destroyed, provided that the routine is not\par
invoked or used by any other routine or in a View definition, Constraint\par
definition, Assertion definition, Trigger definition, Column definition or\par
Domain definition and provided that the routine is not a from-sql function or\par
a to-sql function associated with an external routine. That is, RESTRICT\par
ensures that only a routine with no dependent Objects can be destroyed. If the\par
routine is used by any other Object, DROP ROUTINE/FUNCTION/PROCEDURE ... RESTRICT will fail.\par
\par
The effect of DROP routine type <Routine name> CASCADE, e.g.:\par
\par
   DROP ROUTINE routine_1 CASCADE;\par
\par
   DROP FUNCTION function_1 CASCADE;\par
\par
   DROP PROCEDURE procedure_1 CASCADE;\par
\par
is that the routine named is destroyed.\par
\par
Successfully destroying a routine has a three-fold effect:\par
      ## The routine named is destroyed.\par
      ## The EXECUTE Privilege held on the routine by the <AuthorizationID>\par
that owns it is revoked (by the SQL special grantor, "_SYSTEM") with a CASCADE\par
revoke behaviour, so that all EXECUTE Privileges held on the routine by any\par
other <AuthorizationID> are also revoked.\par
      ## All SQL routines, Views, Constraints, Assertions, Triggers, Columns\par
and Domains that depend on the routine are dropped with a CASCADE drop behaviour.\par
\par
If you want to restrict your code to Core SQL, don't use the CASCADE drop behaviour for your DROP ROUTINE/FUNCTION/PROCEDURE statements.\par
\par
Dialects\par
\par
One way or another, DBMSs have been calling routines for several years. The\par
oldest example we can think of is ibm DB2's EDITPROC and VALIDPROC functions,\par
which were used to massage or verify input data, and had to be written in\par
360/Assembler.\par
\par
At the moment, a minority of DBMSs include support for "procedures" (not\par
functions). The syntax for creation and invocation is essentially the same as\par
what we've described in this chapter, but in all cases the details differ. For\par
example, the ODBC document has a definition for procedures, an escape\par
mechanism for calling them and a specification of some CLI functions that\par
depend on them (such a the SQLProcedures function). However, ODBC makes no\par
attempt to specify the grammar for a CREATE PROCEDURE statement.\par
\page\par
Chapter 26 -- PSM: Not just Persistent Stored Modules\par
\par
The initials "PSM" refer to the specifications of a document labelled "ISO/IEC\par
9075-4 Information Technology - Database Languages - SQL: Part 4: Persistent\par
Stored Modules (SQL/PSM)". Part 4 is one of the standard SQL documents, but it\par
is not essential -- that is, it describes SQL features that are optional. A\par
DBMS that complies with part 4 can claim "enhanced SQL conformance" (provided,\par
of course, that it also fully supports Core SQL). We will use the phrase\par
"essential SQL" to mean "SQL without PSM, as defined in Parts 1 and 2 of the SQL Standard".\par
\par
In essential SQL, the concept of Modules -- that is, SQL-client Modules -- is\par
defined and used frequently (in effect, every type of SQL binding style\par
conceptually uses Modules, at least implicitly). However, nobody implements\par
them and nobody cares. What vendors have implemented, and what programmers\par
have used throughout SQL's history, is some variant of: (a) embedded SQL, (b)\par
SQL/CLI or (c) both. There has been no popular implementation of a complete\par
SQL language which can do all the things that other programming languages offer.\par
\par
For example, in essential SQL, there is no easy way to do these things:\par
      ## Declare variables.\par
      ## Assign to variables.\par
      ## Control flow of execution with loops or if/then statements.\par
      ## Write complete program modules.\par
\par
With PSM, there is a way to overcome those deficiencies -- if they are\par
deficiencies. Essentially, PSM is a package of extensions to the essential SQL\par
specification. Since one important extension is the ability to create and\par
destroy program modules, the package name is "Persistent Stored Modules".\par
However, the other extensions -- variable handling and program control -- can\par
be implemented independently. For example, some DBMSs allow "assignment"\par
statements to be used within Triggers, even though they have no support for persistent stored modules.\par
\par
Persistent Stored Modules\par
\par
In SQL, the word "persistent" is applied to Schema Objects that survive over\par
SQL-sessions (as "persistent Base tables" do). And the sort of Modules we're\par
talking about are indeed Schema Objects -- they're stored in Schemas, just as\par
Tables and Domains and other Schema Objects are. (The actual storage is on the\par
server and these Objects are sometimes called "SQL-server Modules", but their\par
physical location is not important.)\par
\par
It is, then, reasonable to think of a Persistent Stored Module as a [program]\par
Module which is stored permanently within a Schema of an SQL "database". As\par
with other Schema Objects, there are CREATE, ALTER and DROP statements for\par
creating, altering and dropping Modules. In this chapter, we'll briefly\par
describe these Modules, and show you the syntax to use to create, alter and destroy them.\par
\par
A Schema may contain zero or more Modules. An SQL Module is a named group of\par
SQL statements. Modules are dependent on some Schema -- the <Module name> must\par
be unique within the Schema the Module belongs to -- and are created, altered\par
and dropped using standard SQL statements. All Modules consist of various\par
identifying elements (e.g.: the Module name, the Module <AuthorizationID> and\par
an associated <Schema name> and <Character set name>) as well as the temporary\par
Table declarations necessary to use the Module. In addition, a Module must\par
contain one or more SQL procedures.\par
\par
An SQL procedure is a named program procedure that will execute an SQL\par
statement when it is called. It contains the list of parameter declarations\par
necessary to execute the procedure and exactly one SQL statement. Procedures\par
are called from Modules with a call statement that provides the procedure name\par
and the necessary values for the parameters that are declared in the\par
procedure. SQL procedures must reference parameters to pass values between the\par
program and SQL-data. Since parameters must map to host language variables,\par
they are not nullable unless they are coupled with an indicator parameter.\par
\par
SQL provides a status parameter -- SQLSTATE -- whose value indicates whether\par
or not an SQL statement was successfully executed. All procedures must contain an SQLSTATE declaration.\par
\par
A Module is defined by a descriptor that contains six pieces of information:\par
      ## The <Module name>, qualified by the <Schema name> of the Schema it belongs to.\par
      ## The name of the Character set that is used to express the names of all Schema Objects mentioned in the Module's definition.\par
      ## The Module's <AuthorizationID> -- this is the <AuthorizationID> that owns the Module's Schema.\par
      ## The list of <Schema name>s contained in the Module's path specification.\par
      ## A descriptor for every declared local temporary Table defined in the Module.\par
      ## A descriptor for every SQL-invoked routine contained in the Module.\par
\par
To create a Module, use the CREATE MODULE statement (either as a stand-alone\par
SQL statement or within a CREATE SCHEMA statement). CREATE MODULE specifies\par
the enclosing Schema, names the Module and identifies the Module's Character\par
set, declared Tables and routines. To change an existing Module, use the ALTER\par
MODULE statement. To destroy a Module, use the DROP MODULE statement.\par
\par
There is a one-to-many association between Schemas and Modules: one Schema can own multiple Modules.\par
\par
Module names:\par
A <Module name> identifies a Module. The required syntax for a <Module name> is:\par
\par
<Module name> ::=\par
[ <Schema name>. ] unqualified name\par
\par
A <Module name> is a <regular identifier> or a <delimited identifier> that is\par
unique (for all Modules) within the Schema it belongs to. The <Schema name>\par
which qualifies a <Module name> names the Schema that the Module belongs to\par
and can either be explicitly stated, or a default will be supplied by your DBMS as follows:\par
      ## If a <Module name> in a CREATE SCHEMA statement isn't qualified, the default qualifier is the name of the Schema you're creating.\par
      ## If the unqualified <Module name> is found in any other SQL statement,\par
the default qualifier is the name of the Schema identified in the SCHEMA\par
clause or AUTHORIZATION clause of the CREATE MODULE statement that defines that Module.\par
\par
Here are some examples of <Module name>s:\par
\par
   MODULE_1\par
   -- a <Module name>\par
\par
   SCHEMA_1.MODULE_1\par
   -- a simple qualified <Module name>\par
\par
   CATALOG_1.SCHEMA_1.MODULE_1\par
   -- a fully qualified <Module name>\par
\par
CREATE MODULE statement\par
\par
The CREATE MODULE statement creates an SQL-server Module: a Module that belongs to a Schema. The required syntax for the CREATE MODULE statement is:\par
\par
CREATE MODULE <Module name>\par
   [ NAMES ARE <Character set name> ]\par
   [ SCHEMA default <Schema name>]\par
   [ PATH <Schema name> [ \{,<Schema name>\}... ] ]\par
   [ DECLARE TABLE statement(s) ]\par
   <SQL-invoked routine>; ...\par
   END MODULE\par
\par
CREATE MODULE defines a new SQL-server Module -- don't get this mixed up with\par
the simple MODULE statement that is part of essential SQL, it defines an SQL-\par
client Module and, although the two are similar, PSM statements won;t work on\par
anything but a PSM Module. An SQL-server Module is owned by the Schema it\par
belongs to.\par
\par
The <Module name> identifies the Module and the Schema that it belongs to. A\par
<Module name> that includes an explicit <Schema name> qualifier belongs to the\par
Schema named. A <Module name> that does not include an explicit <Schema name>\par
qualifier belongs to the SQL-session default Schema. The <Module name> must be\par
unique within the Schema that owns it.\par
\par
If CREATE Module is part of a CREATE SCHEMA statement, the <Module name>, if\par
explicitly qualified, must include the <Schema name> of the Schema being\par
created; that is, it isn't possible to create a Module belonging to a\par
different Schema from within CREATE SCHEMA.\par
\par
The optional NAMES ARE clause provides the name of the Character set that is\par
used to express the names of all Schema Objects mentioned in the Module's\par
definition. If you omit the clause, the Module's Character set is the default\par
Character set of the Schema it belongs to.\par
\par
The optional SCHEMA clause names the default Schema for the Module -- that is,\par
the name of the Schema that owns the Schema Objects referred to in the Module.\par
If you omit the clause, the default <Schema name> is the name of the Schema\par
that owns the Module.\par
\par
The optional PATH clause names the Module's default path: the path used to\par
qualify unqualified <Routine name>s that identify <routine invocation>s that\par
are part of this CREATE MODULE statement. You must include the name of the\par
Schema being created in the PATH clause and, if you include multiple names,\par
all of the Schemas named must belong to the same Catalog. If you omit the\par
clause, your DBMS will give the Module a default path that includes the name\par
of the Schema that the Module belongs to.\par
\par
The Module can contain zero or more DECLARE TABLE statements, each declaring a local temporary Table that will only be visible to this Module.\par
\par
The Module can contain one or more SQL-invoked routines -- these do the Module's work. Here's a simple example:\par
\par
CREATE MODULE Employees_Module         /* This begins and names the Module */\par
  DECLARE PROCEDURE Delete_Employees() /* This is an SQL routine */\par
      MODIFIES SQL DATA\par
      DELETE FROM Employees;\par
  DECLARE PROCEDURE Update_Employees() /* This is an SQL routine */\par
      MODIFIES SQL DATA\par
      UPDATE Employees SET col=NULL;\par
  DECLARE PROCEDURE Insert_Employees() /* This is an SQL routine */\par
      MODIFIES SQL DATA\par
      INSERT INTO Employees VALUES (5);\par
  END MODULE\par
\par
If your memory stretches back to our chapter on SQL routines, you'll recognize\par
the PROCEDURE statements here -- procedures and functions are part of\par
essential SQL. What the CREATE MODULE statement allows you to do is construct\par
a "package" of procedures, in the same way that a C implementation allows the\par
construction of a library. Our example is a rather crude attempt to "package"\par
the main SQL-data change statements that can happen with the EMPLOYEES Table.\par
Note: The DECLARE <keyword> before "PROCEDURE" is optional.\par
\par
ALTER MODULE statement\par
\par
The ALTER MODULE statement lets you change a Module's definition. The required syntax for the ALTER MODULE statement is:\par
\par
ALTER MODULE <Module name>\par
   \{ADD | DROP\} <Module contents> ...\par
\par
ALTER MODULE changes an existing Module. <Module contents> can be a function,\par
a procedure or any of the other things that might be part of a Module\par
(exceptions, handlers, variables, Cursors, declared Tables and so on).\par
\par
Here's an example of an ALTER MODULE statement:\par
\par
   ALTER Module Employees_Module\par
     DROP PROCEDURE Insert_Employees;\par
\par
After the execution of this ALTER MODULE statement, the EMPLOYEES_MODULE Module will have only two procedures left: Delete_Employees and Update_Employees.\par
\par
DROP MODULE statement\par
\par
The DROP MODULE statement destroys an SQL-server Module. The required syntax for the DROP MODULE statement is:\par
\par
DROP MODULE <Module name> \{RESTRICT | CASCADE\}\par
\par
The <Module name> must identify an existing Module whose owner is either the\par
current <AuthorizationID> or a Role that the current <AuthorizationID> may\par
use. That is, only the <AuthorizationID> that owns the Module may drop it.\par
\par
The effect of DROP MODULE <Module name> RESTRICT, e.g.:\par
\par
   DROP MODULE module_1 RESTRICT;\par
\par
is that the Module named is destroyed, provided that the Module doesn't\par
contain the definition of an SQL-invoked routine that is invoked outside of\par
the Module -- i.e.: in an SQL routine that isn't defined in this Module or in\par
any View definition, Trigger definition, Constraint or Assertion definition.\par
That is, RESTRICT ensures that only a Module with no dependent Objects can be\par
destroyed. If the Module is used by any other Object, DROP MODULE ... RESTRICT will fail.\par
\par
The effect of DROP MODULE <Module name> CASCADE, e.g.:\par
\par
   DROP MODULE module_1 CASCADE;\par
\par
is that the Module named is destroyed.\par
\par
Successfully dropping a Module has a six-fold effect:\par
      ## The Module named is destroyed.\par
      ## All Privileges held on the Module by the <AuthorizationID> that owns\par
it are revoked (by the SQL special grantor, "_SYSTEM") with a CASCADE revoke\par
behaviour, so that all Privileges held on the Module by any other\par
<AuthorizationID> are also revoked.\par
      ## All SQL routines, Triggers, Views and Constraints that depend on the Module are dropped with a CASCADE drop behaviour.\par
\par
BEGIN ... END: compound statement\par
\par
Advance warning: BEGIN ... END has several optional clauses. We are going to\par
start with the simplest form, and examine the options in following sections.\par
\par
In its simplest form, BEGIN ... END in SQL serves the same purpose as\par
"begin...end" in Pascal or "\{...\}" in C. BEGIN ... END encloses a sequence of\par
statements which are part of the same syntactical unit: a compound statement.\par
The simplest required syntax is:\par
\par
BEGIN\par
   [ <SQL statement>; ... ]\par
END\par
\par
Here's a simple example:\par
   BEGIN\par
       INSERT INTO Table_1 VALUES (5);\par
       INSERT INTO Table_2 VALUES (6);\par
   END\par
\par
ATOMIC statements:\par
A slightly more complicated form of a compound statement has one extra optional clause: [NOT] ATOMIC. The required syntax is:\par
\par
BEGIN [ [ NOT ] ATOMIC ]    /* whether compound statement is atomic */\par
  [ <SQL statement>; ... ]\par
END\par
\par
If ATOMIC is specified, the compound statement may not contain COMMIT or\par
ROLLBACK. If you omit the clause, it defaults to NOT ATOMIC: the compound\par
statement may contain COMMIT or ROLLBACK. Here's an example:\par
\par
   BEGIN ATOMIC\par
      INSERT INTO Table_1 VALUES (5);\par
      INSERT INTO Table_2 VALUES (6);\par
   END\par
\par
We've already discussed the idea that transactions are atomic, and individual\par
SQL statements are atomic. Compound SQL statements can be atomic too, provided\par
that they are explicitly designated by the <keyword> ATOMIC. Thus, in the\par
above example, if the first INSERT statement succeeds but the second INSERT\par
statement fails, then the effects of the first INSERT is cancelled. It's as if\par
there was a savepoint at the beginning of the compound statement and a\par
ROLLBACK TO SAVEPOINT was executed when the second INSERT failed.\par
\par
Variables:\par
A slightly more complicated form of a compound statement has one more optional\par
clause: a variable declaration list. The required syntax is:\par
\par
BEGIN [ [ NOT ] ATOMIC ]\par
  [ <variable declaration>; ... ]     /* variable-declaration list */\par
  [ <SQL statement>; ... ]\par
END\par
\par
   <variable declaration> ::=\par
   DECLARE <SQL variable name> <data type> [ DEFAULT default value ]\par
\par
Here's an example:\par
\par
   BEGIN ATOMIC\par
     DECLARE v1 CHAR(5);                          /* variable declaration */\par
     DECLARE v2,v3,v4 SMALLINT;                   /* variable declaration */\par
     DECLARE v5 DATE DEFAULT DATE '1993-01-01';   /* variable declaration */\par
     SELECT * INTO v1,v2,v3,v4 FROM Table_1;      /* statement */\par
     INSERT INTO Table_2 VALUES (v1,v2,v3,v4,v5); /* statement */\par
   END\par
\par
** TRAP: Don't get confused by the similarity to a <Column definition>. A\par
variable definition can contain ONLY a <data type> and (optionally) a DEFAULT\par
clause. It cannot contain a <Domain name>, a <Constraint> or a COLLATE clause.\par
\par
In our example we defined five variables: v1, v2, v3, v4, v5. BEGIN ... END\par
defines a "local scope", which means that (a) these variable names have no\par
meaning outside the compound statement, (b) the values in these variables are\par
not saved when the compound statement ends and (c) the values in these\par
variables are not reset by execution of a ROLLBACK statement, because\par
variables are not part of the database.\par
\par
The example uses the first four variables as targets in a singleton SELECT\par
statement. It also uses all five variables as sources in an INSERT statement.\par
Variables can be used in all sorts of <value expression>s. Variables are\par
extremely useful for temporary storage, and it's a wonder that most SQL\par
implementations get along without them. The designers of SQL don't give us the\par
option of using variables for persistent storage: we're supposed to use Base\par
tables for that.\par
\par
Assignment statements:\par
Assignment statements begin with the <keyword> SET -- but don't call them "SET\par
statements", to avoid confusion with non-PSM statements that also begin with\par
SET. Assignment statements are syntactically similar to the SET clauses used\par
in UPDATE statements. Here is the required syntax:\par
\par
SET\par
   <target>     /* where the value goes to; usually a variable */\par
   =\par
   <source>     /* where the value comes from; an expression */\par
\par
In theory the <target> doesn't have to be a variable -- it could be a\par
parameter or a "host variable" -- but normal programs will take the form\par
"<variable> = <expression>". Here are some examples:\par
\par
   SET v1 = 5\par
\par
   SET v1 = (v2+7)/5\par
\par
   SET v1 = NULL\par
\par
   SET v1 = column_1\par
\par
Cursors:\par
A slightly more complicated form of a compound statement has one more optional\par
clause: a Cursor declaration list. The required syntax is:\par
\par
BEGIN [ [ NOT ] ATOMIC ]\par
  [ <variable declaration>; ... ]\par
  [ DECLARE CURSOR statement; ... ]      /* Cursor-declaration list */\par
  [ <SQL statement>; ... ]\par
END\par
\par
The mechanics of Cursors are the same for PSM as they are for embedded SQL and for SQL/CLI. Here's an example:\par
\par
   BEGIN\par
     DECLARE v1 SMALLINT;             /* variable-declaration */\par
     DECLARE cc CURSOR FOR\par
        SELECT column_1 FROM Table_1; /* Cursor-declaration */\par
     OPEN cc;                         /* statement */\par
     FETCH cc INTO v1;                /* statement */\par
     CLOSE cc;                        /* statement */\par
     INSERT INTO Table_2 VALUES (v1); /* statement */\par
   END\par
\par
Objects that you declare in a compound statement have "local scope", so the\par
<Cursor name> in this example -- cc -- can only be  used by SQL statements\par
within the BEGIN ... END. The example could be replaced with this SQL statement:\par
\par
    INSERT INTO Table_2 SELECT column1 FROM Table_1;\par
\par
if there is only one row in TABLE_1.\par
\par
Conditions:\par
A slightly more complicated form of a compound statement changes the optional\par
variable declaration clause: instead of a variable declaration list, BEGIN ...\par
END actually allows a variable or condition declaration list, so that you can\par
declare conditions as well as variables. The required syntax is:\par
\par
BEGIN [ [ NOT ] ATOMIC ]\par
  [ <variable | condition declaration>; ... ] /* variable-or-condition\par
declaration list */\par
  [ DECLARE CURSOR statement; ... ]\par
  [ <SQL statement>; ... ]\par
END\par
\par
   <condition declaration> ::=\par
      DECLARE <condition name> CONDITION [ FOR <sqlstate value> ]\par
\par
Quick review: An SQLSTATE value is a 5-character status code string. Upon\par
completion of any SQL statement, there will be a status code in SQLSTATE,\par
which is the main diagnostic field. Typical values are '01006'\par
(warning-privilege not revoked), '22012' (data exception-division by zero),\par
'42000' (syntax error or access violation). You'll find a complete list of\par
SQLSTATE values in our chapter on SQL/CLI diagnostics.\par
\par
Here's an example of the latest form of BEGIN ... END:\par
\par
   BEGIN ATOMIC\par
     DECLARE v1 SMALLINT;                          /* variable-declaration */\par
     DECLARE warning_revoke CONDITION FOR '01006'; /* condition declaration */\par
     DECLARE divide_by_zero CONDITION FOR '22012'; /* condition declaration */\par
     DECLARE syntax_error CONDITION FOR '42000';   /* condition declaration */\par
     DECLARE cc CURSOR FOR\par
        SELECT column_1 FROM Table_1;              /* Cursor-declaration */\par
     OPEN cc;                                      /* statement */\par
     FETCH cc INTO v1;                             /* statement */\par
     CLOSE cc;                                     /* statement */\par
     INSERT INTO Table_2 VALUES (v1);              /* statement */\par
     INSERT INTO Table_1 VALUES (0);               /* statement */\par
     INSERT INTO Table_2 VALUES (1);               /* statement */\par
   END\par
\par
In this example, we have simply given condition names to three of the possible SQLSTATE values.\par
\par
Handlers:\par
A slightly more complicated form of a compound statement adds another optional\par
clause: a handler declaration list. The required syntax is:\par
\par
BEGIN [ [ NOT ] ATOMIC ]\par
  [ <variable | condition declaration>; ... ]\par
  [ DECLARE CURSOR statement; ... ]\par
  [ <handler declaration>; ...]               /* handler-declaration list */\par
  [ <SQL statement>; ... ]\par
END\par
\par
  <handler declaration> ::=\par
  DECLARE <handler type> HANDLER FOR <condition value list> <handler action>\par
\par
     <handler type> ::= \{CONTINUE | EXIT | UNDO \}\par
\par
     <handler action> ::= <SQL statement>\par
\par
     <condition value list> ::= <condition value> [ \{,<condition value>\}... ]\par
\par
     <condition value> ::=\par
     <sqlstate value>| <condition name>| SQLEXCEPTION | SQLWARNING | NOT FOUND\par
\par
The following example contains three handlers. The first is for an SQLSTATE\par
value, the second is for a condition name and the third is for any warning\par
(i.e.: any SQLSTATE in class '01').\par
\par
  BEGIN\par
    DECLARE constraint_error CONDITION FOR '23000';/* condition declaration */\par
    DECLARE v1 CHAR(5) DEFAULT 'Okay!';            /* variable declaration */\par
    DECLARE CONTINUE HANDLER FOR '22003'           /* handler declaration */\par
       SET v1 = 'Ovflw';\par
    DECLARE CONTINUE HANDLER FOR constraint_error  /* handler declaration */\par
       SET v1 = 'c-err';\par
    DECLARE CONTINUE HANDLER FOR SQLWARNING        /* handler declaration */\par
       SET v1 = '?????';\par
    INSERT INTO Table_1 VALUES (99999);            /* statement */\par
    INSERT INTO Table_2 VALUES (v1);               /* statement */\par
  END\par
\par
To see the effect of these handlers, consider what will happen with the SQL statement:\par
\par
   INSERT INTO Table_1 VALUES (99999);\par
\par
If this SQL statement fails due to overflow, then variable v1 gets 'Ovflw'; if\par
it fails due to an integrity Constraint violation, then variable v1 gets\par
'c-err'; if it succeeds but there is some warning, then variable v1 gets\par
'?????'. But, regardless, play continues because all the handlers are CONTINUE\par
handlers. So the second INSERT statement will put in one of the values\par
'Ovflw', 'c-err', '?????' or 'Okay!' ('Okay!' is the default value for v1 so\par
this is what goes in if the result of the first INSERT is success with no warnings).\par
\par
What if exception '42000' happens? That would be an "unhandled exception"\par
since we did not define a handler for exception '42000'. The result would be\par
that the second INSERT is not attempted -- the whole compound statement fails.\par
\par
The following chart compares the exception-handling features of embedded SQL, the CLI and the PSM.\par
\par
                                EMBEDDED SQL       CLI   PSM\par
method of declaration           EXEC SQL WHENEVER  none  handler-declaration\par
what happens                    GOTO               N/A   any SQL statement\par
handles SQLNOTFOUND?            yes                N/A   yes\par
handles SQLERROR?               yes                N/A   yes\par
handles SQLWARNING?             yes                N/A   yes\par
handles specific status codes?  no                 N/A   yes\par
\par
Among the SQL statements that a handler can execute are two new special ones: the SIGNAL statement and the RESIGNAL statement. These SQL statements affect the diagnostics area.\par
\par
Labels:\par
We're still not done with the BEGIN ... END statement. The final form of a\par
compound statement adds two more optional clauses: a beginning label and an\par
end label. The required syntax for a compound statement is:\par
\par
[ <beginning_label>: ]\par
BEGIN [ [ NOT ] ATOMIC ]\par
  [ <variable | condition declaration>; ... ]\par
  [ DECLARE CURSOR statement; ... ]\par
  [ <handler declaration>; ...]\par
  [ <SQL statement>; ... ]\par
END [ <end_label> ]\par
\par
  <beginning_label> ::= <identifier>\par
\par
  <end_label> ::= <identifier>\par
\par
If you add labels to your compound statement, they should be equivalent (if\par
both are specified). Labels are useful as referents for various control\par
statements, which we will discuss later. Here's an example:\par
\par
  full_blown_example:                      /* beginning_label */\par
  BEGIN ATOMIC                             /* compound statement is atomic */\par
    DECLARE v1 INTEGER DEFAULT 0;          /* variable declaration */\par
    DECLARE c1 CONDITION FOR '01000';      /* condition declaration */\par
    DECLARE CONTINUE HANDLER FOR SQLERROR  /* handler declaration */\par
      SET v1 = 1;                          /* assignment statement */\par
    INSERT INTO Table_1 VALUES (0);        /* statement */\par
    INSERT INTO Table_2 VALUES (v1);       /* statement */\par
  END full_blown_example                   /* end_label */\par
\par
This is our final version of BEGIN .. END. It looks quite imposing. That's\par
because MOST SYNTACTIC ITEMS ARE LOCAL TO THE COMPOUND STATEMENT. Therefore\par
everything is within the compound statement and, by contrast, the Module definition is trivial.\par
\par
SIGNAL statement\par
\par
The SIGNAL statement is used to clear the diagnostics area. The required syntax for the SIGNAL statement is:\par
\par
SIGNAL <condition name or sqlstate value>\par
   SET <signal information item list>\par
\par
   <signal information item list> ::=\par
   <signal information item> [ \{,<signal information item>\}... ]\par
\par
      <signal information item> ::=\par
      <condition information item name> = <simple value specification>\par
\par
The SIGNAL statement clears every record in the diagnostics area. The end\par
result is a record containing the passed condition name or sqlstate value. If\par
you include the optional SET clause, your DBMS effectively executes:\par
\par
   RESIGNAL <signal information item list>;\par
\par
Note: You'll find the list of <condition information item name>s in our chapter on embedded SQL -- see the GET DIAGNOSTICS statement.\par
\par
RESIGNAL statement\par
\par
The RESIGNAL statement is used to pass conditions on to another handler. The required syntax for the RESIGNAL statement is:\par
\par
RESIGNAL [ <condition name or sqlstate value> ]\par
   SET <signal information item list>\par
\par
The RESIGNAL statement passes the given exception "up the line" to the next\par
appropriate handler (since compound statements may be embedded in compound\par
statements, this next appropriate handler will usually be in some outside\par
context). The current diagnostics area remains unchanged, but -- if the\par
optional [<condition name or sqlstate value>] clause is specified -- there\par
will be one more diagnostics record, containing this new value. If you include\par
the optional SET clause, the <condition information item name> field in the\par
first condition area in the diagnostics area is changed to the value indicated.\par
\par
Program Control\par
\par
Essential SQL has almost nothing that can control the program flow (except for\par
the CALL and RETURN statements which are associated with SQL routines). By\par
contrast, a DBMS with PSM support will allow eight control statements. Of\par
these, seven are similar to statements which appear in other languages. The\par
eighth, FOR, depends on Objects which are unique to the SQL environment.\par
Here's a list of these statements:\par
      ## CASE -- Switch depending on condition.\par
      ## IF -- If (condition) do.\par
      ## ITERATE -- Restart loop.\par
      ## LOOP -- Do statement(s) repeatedly.\par
      ## LEAVE -- Break out of a loop or block.\par
      ## WHILE -- Repeat statement(s) as long as condition is true.\par
      ## REPEAT -- Repeat statement(s) until condition is true.\par
      ## FOR -- Cursor-based FETCH loop.\par
\par
CASE statement\par
\par
The CASE statement is useful for switching between possible execution paths.\par
There are two forms -- one contains search conditions, the other contains\par
value expressions. The required syntax for the CASE statement is:\par
\par
searched CASE statement ::=\par
CASE\par
  WHEN <search condition> THEN <statement>(s)\par
  [ WHEN <search condition> THEN <statement>(s) ... ]\par
  [ ELSE <statement>(s) ]\par
END CASE\par
\par
simple CASE statement ::=\par
CASE <case value>\par
   WHEN <when value> THEN <statement>(s)\par
   [ WHEN <when value> THEN <statement>(s) ... ]\par
   [ ELSE <statement>(s) ]\par
END CASE\par
\par
A "simple CASE statement" is merely a shorthand, and may be replaced by a\par
"searched CASE statement" which has the form: "CASE WHEN <when value> = <case\par
value> ...". Thus, the following examples, showing a searched CASE statement\par
on the left and a simple CASE statement on the right, are exactly equivalent:\par
\par
   CASE                                CASE parameter_value\par
     WHEN parameter_value = 15           WHEN 15\par
      THEN INSERT INTO t VALUES (15);     THEN INSERT INTO t VALUES (15);\par
     WHEN parameter_value = 17           WHEN 17\par
      THEN INSERT INTO t VALUES (17);     THEN INSERT INTO t VALUES (17);\par
     ELSE INSERT INTO t VALUES (0);      ELSE INSERT INTO t VALUES (0);\par
   END CASE                            END CASE\par
\par
When executing a CASE statement, the DBMS goes through the WHEN clauses from\par
top to bottom, looking for a TRUE condition. If it finds one, it executes the\par
statement(s) after THEN, and the CASE terminates. If it finds none, it\par
executes the statements(s) after ELSE -- or, if there is no ELSE, returns this\par
SQLSTATE error: 20000 "case not found for case statement". For the above\par
example, then, if the value of parameter_value is 5, then the DBMS will\par
execute this SQL statement:\par
\par
   INSERT INTO t VALUES (0);\par
\par
** TRAP: The syntax for the CASE statement is somewhat different from the\par
syntax for the SQL CASE expression (see our chapter on simple search\par
conditions). In particular, the CASE statement has no equivalent for the ELSE\par
NULL clause, and the terminator is END CASE rather than END.\par
\par
IF statement\par
\par
The IF statement is useful for simple "if (x) then (do this)" situations. The required syntax for the IF statement is:\par
\par
IF <search condition> THEN <SQL statement>(s)\par
   ELSEIF <search condition> THEN <SQL statement>(s)\par
   ELSE <SQL statement>(s)\par
END IF\par
\par
Here's an example:\par
\par
  IF\par
   5=5 THEN UPDATE Table_1 SET column_1 = column_1 + 1;\par
  END IF\par
\par
In this example, the search condition is TRUE, so the UPDATE statement will be\par
executed. If the search condition had been FALSE or UNKNOWN, then the UPDATE statement would not have been executed.\par
\par
LOOP statement\par
\par
The LOOP statement is useful for repeated execution of SQL statements. The required syntax for the LOOP statement is:\par
\par
[ <beginning_label>: ]\par
LOOP\par
   <SQL statement>(s)\par
END LOOP [ <end_label> ]\par
\par
The SQL statements between LOOP and END LOOP are repeated until the loop\par
finishes. The <beginning_label> and the <end_label> must be equivalent, if you\par
use them both. Here's an example:\par
\par
   LOOP\par
      SET x = x + 1;\par
   END LOOP\par
\par
This example shows an infinite loop. The usual way to exit from a loop is with the LEAVE statement.\par
\par
LEAVE statement\par
\par
The LEAVE statement is useful for exiting a block or for exiting a loop. The required syntax for the LEAVE statement is:\par
\par
LEAVE <statement_label>\par
\par
Here's an example:\par
\par
   beginning_label:\par
   LOOP\par
     SET x = x + 1;\par
     IF x > 1000 THEN LEAVE beginning_label; END IF;\par
   END LOOP beginning_label\par
\par
In this example, the loop will be exited once the value of x passes 1000.\par
\par
WHILE statement\par
\par
The WHILE statement is useful for repeated execution of SQL statements, with a\par
built-in equivalent to the LEAVE statement. The required syntax for the WHILE statement is:\par
\par
[ <beginning_label>: ]\par
WHILE <search condition> DO\par
   <SQL statement>(s)\par
END WHILE [ <end_label> ]\par
\par
As long as the <search condition> is TRUE, the SQL statements between WHILE\par
and END WHILE are repeatedly executed. The <beginning_label> and the\par
<end_label> must be equivalent, if you use them both. Here's an example:\par
\par
   WHILE x <= 1000 DO\par
      SET x = x + 1;\par
   END WHILE\par
\par
This example will loop, incrementing x, until "x <= 1000" is either FALSE or\par
UNKNOWN. If the <search condition> is FALSE or UNKNOWN when the loop begins, then nothing happens.\par
\par
REPEAT statement\par
\par
The REPEAT statement is much like the WHILE statement, except that the\par
condition is tested after the execution of the SQL statement(s). The required syntax for the REPEAT statement is:\par
\par
[ <beginning_label>: ]\par
REPEAT\par
   <SQL statement>(s) UNTIL <search condition>\par
END REPEAT [ <end_label> ]\par
\par
As long as the <search condition> is FALSE or UNKNOWN, the SQL statements\par
between REPEAT and END REPEAT are repeatedly executed. The <beginning_label>\par
and the <end_label> must be equivalent, if you use them both. Here's an example:\par
\par
   REPEAT\par
      DELETE FROM Table_1 WHERE column_1 = x;\par
      SET x = x + 1;\par
      UNTIL x > 5\par
   END REPEAT\par
\par
In this example, the UPDATE statement will be repeated until x is greater than 5 -- that is, the loop will repeat until after the condition is TRUE.\par
\par
** TRAP: The example is an infinite loop if the initial value of x is NULL.\par
\par
FOR statement\par
\par
The FOR statement is useful for simplified FETCH loops. Execution takes place\par
for each row of a result set. The required syntax for the FOR statement is:\par
\par
[ <beginning_label>: ]\par
FOR <loop variable name> AS [ <Cursor name>\par
   [ \{ASENSITIVE | INSENSITIVE | SENSITIVE\} ] CURSOR FOR ]\par
   <query expression> [ ORDER BY clause ] [ updatability clause ]\par
DO\par
   <SQL statement>(s)\par
END FOR [ <end_label> ]\par
\par
Here's an example:\par
\par
   FOR x AS Cursor_1 CURSOR FOR\par
      SELECT name, address_1, address_2 FROM Addresses\par
   DO\par
      UPDATE Addresses SET address_1 = '' WHERE CURRENT OF Cursor_1;\par
   END FOR\par
\par
Effectively, a Cursor is opened when the loop begins, fetched for each row of\par
the result set, and closed when the loop ends. In this example, the UPDATE\par
statement is executed for each fetched row before the next iteration. SQL's\par
FOR loop is different, in style and meaning, from FOR loops in other\par
languages.\par
\par
ITERATE statement\par
\par
The ITERATE statement is useful for "re-starting": going back to the beginning\par
of the list of statements inside a loop, and proceeding with the next\par
iteration of the loop. The required syntax for the ITERATE statement is:\par
\par
ITERATE <statement_label>\par
\par
The ITERATE statement can appear only within an "iterated SQL statement" --\par
that is, within LOOP, WHILE, REPEAT or FOR). The <statement_label> must be the\par
<beginning_label> of the iterated SQL statement. If the iteration condition\par
for the iterated SQL statement is TRUE, or if the statement doesn't have an\par
iteration condition, ITERATE causes the next iteration of the loop to start.\par
If the iteration condition is FALSE or UNKNOWN, ITERATE causes the loop to\par
end. Here's an example:\par
\par
   beginning_of_while:\par
   WHILE (color_of_moon_in_june = 'blue') DO\par
      ...\par
      SET spot_remover = 'active';\par
      IF (birthday_test() IS UNKNOWN)\par
        THEN ITERATE beginning_of_while;\par
      END IF\par
      SET checkout_status = 0;\par
   END WHILE\par
\par
Should everything be in SQL?\par
\par
PSM is an extension package which makes SQL3 a reasonably complete language.\par
There are still some things you can't do (such as disk or screen I/O), but\par
anybody could write external-routine libraries which would plug the remaining gaps.\par
\par
So what?\par
\par
For several years, programmers have written applications in "host languages"\par
and invoked SQL statements either via embedded SQL or via the CLI. By now\par
there is an awful lot of legacy code in those host languages. It has to be\par
expected, too, that there are good host-language optimizers out there -- don't\par
bother pitting C and SQL head-to-head with a "Sieve of Eratosthenes" benchmark. The SQL code would lose.\par
\par
On the other hand, we could say that:\par
      ## Yes, SQL optimizers are inferior for low-level benchmarks, but\par
they're better at the high level -- and you'd be helping SQL optimizers if you\par
could pass them groups of SQL statements, rather than individual SQL statements.\par
      ## A lot of programming effort is spent solving the "impedance mismatch"\par
problem -- the fact that host languages don't store data the SQL way, or\par
process sets the SQL way, or have the same ideas of access control. With\par
Modules inside the SQL environment, DBMSs can act in a consistent way across platforms.\par
      ## Remote Data Access is feasible with SQL, but not with a host language.\par
\par
In the end, the world's SQL developers will decide which arguments are the\par
most convincing. At the moment, PSM is not (yet) the popular way to go.\par
\par
Dialects\par
\par
PSM's features are vaguely similar to Oracle's PL/SQL, which also has: BEGIN\par
... END, LOOP, WHILE, and (using different keywords) assignment statements and\par
handlers. Informix SQL has a FOREACH statement, which does the same thing as\par
the standard FOR statement.\par
\par
Even if a vendor does not support any form of PSM, you may find that some of\par
the above-described features have been added individually into essential SQL.\par
For example, a DBMS which fully supports SQL routines will probably allow\par
compound statements too, in at least a limited way.\par
\page\par
Chapter 27 -- User-defined Types\par
\par
[Obscure Rule] applies for this entire chapter.\par
\par
SQL began life as a procedurally oriented language, or -- properly speaking --\par
as a language with procedures that worked on sets. Nowadays the rage is for\par
object oriented languages -- like C++ and Java. The popularity of object\par
orientation ("OO" for short) has been so great, that some have attempted to\par
supersede SQL with pure "OO DBMSs" (POET is an example). On the other hand, a\par
great deal of time and trouble has been invested getting SQL to where it is\par
today, so most users and experts have looked to a more moderate solution.\par
Namely: extending SQL so that it can handle databases the OO way, but without\par
abandoning the current language. We'll call this hybrid object/relational, or O/R for short.\par
\par
The inspirations have come from languages like C++ and Object Pascal, which\par
are extensions of C and Pascal. Those extended languages have been successful.\par
It appears that there will be an equivalent success for the Object Oriented\par
SQL extensions, once DBMS vendors implement them and users get acquainted with them.\par
\par
We're not at that stage yet. What you're going to read about in this chapter\par
is the very latest stuff, just accepted as part of the SQL Standard, and still\par
quite wet around the edges. Since that's so, we will depart from the usual\par
chapter organization. The first parts of this chapter are merely a tutorial\par
which (we hope) you'll find is fairly light reading, peppered with liberating\par
slogans like "a type is a class" or "a row is an object". The middle parts of\par
this chapter are more of a syntactical slog as we get into the details of\par
CREATE TYPE and the various SQL statements associated with it; however, we\par
have omitted some details which we think will not be part of real DBMS implementations for some years.\par
\par
If you've ever used an object oriented language, you'll find the concepts are\par
familiar (which they're supposed to be -- that's the point). However, you must\par
start with a good recollection of the earlier chapters on <data type>s, procedures and SQL syntax.\par
\par
UDTs\par
\par
Until now, all the SQL <data type>s we've described have predefined <data\par
type>s, sometimes called "built-in" or "primitive" <data type>s -- although\par
some portions of them are definable by users (for example, the length of a\par
CHAR <data type>), most of their inherent structure is already set. The O/R\par
part of SQL, though, uses user-defined data types, or UDTs. UDTs are just as\par
easy to use as predefined data types; however, they are a lot harder to set up.\par
\par
Just consider some of the things which are already handled for you (programmed\par
in the DBMS) if you use a predefined data type:\par
      ## There's a way of storing the data physically in a Table (this is the concept of instantiation, which we'll have some trouble with later).\par
      ## There are comparison operations for the <data type>s, so you can tell whether two values are the same, or one is greater than the other (this is the concept of ordering).\par
      ## There are built-in operators for the <data type>s, for example "+" is used to add to numbers together and produce another number (this is the concept of methods that change values of certain data types).\par
      ## There are cast operations so that values in one <data type> can be converted to another, or interchanged with host language variables (this is the concept of cast methods and transforms).\par
With UDTs, you're on your own in all these cases. When you make a UDT, you're going to have to remember that all those things won't be there, unless you put them there yourself.\par
\par
However, when you do it, you'll end up with a <data type> that's just as good\par
as the predefined types. You'll be able to use your new UDT wherever you could use a predefined type before.\par
\par
A Schema may contain zero or more UDTs. An SQL UDT is a named, user-defined\par
set of valid values. UDTs are dependent on some Schema -- the <UDT name> must\par
be unique within the Schema the UDT belongs to (it may not be the same as any\par
<Domain name> in its Schema either) -- and are created, altered and dropped\par
using standard SQL statements. The Objects that may belong to a UDT are known as Attributes; they depend on some UDT.\par
\par
A UDT can be either a distinct type -- a UDT that is based on a single\par
predefined <data type> -- or a structured type -- a UDT that is based on a list of Attribute definitions.\par
\par
A UDT is defined by a descriptor that contains twelve pieces of information:\par
      ## The <UDT name>, qualified by the <Schema name> of the Schema it belongs to.\par
      ## Whether the UDT is ordered.\par
      ## The UDT's ordering form: either EQUALS, FULL or NONE.\par
      ## The UDT's ordering category: either RELATIVE, HASH or STATE.\par
      ## The <specific routine designator> that identifies the UDT's ordering function.\par
      ## If the UDT is a direct subtype of one or more other UDTs, then the names of those UDTs.\par
      ## If the UDT is a distinct type, then the descriptor of the <data type> it's based on; otherwise an Attribute descriptor for each of the UDT's Attributes.\par
      ## The UDT's degree: the number of its Attributes.\par
      ## Whether the UDT is instantiable or not instantiable.\par
      ## Whether the UDT is final or not final.\par
      ## The UDT's Transform descriptor.\par
      ## If the UDT's definition includes a method signature list, a descriptor for each method signature named.\par
\par
To create a UDT, use the CREATE TYPE statement (either as a stand-alone SQL\par
statement or within a CREATE SCHEMA statement). CREATE TYPE specifies the\par
enclosing Schema, names the UDT and identifies the UDT's set of valid values.\par
To destroy a UDT, use the DROP TYPE statement. None of SQL3's UDT syntax is\par
Core SQL, so if you want to restrict your code to Core SQL, don't use UDTs.\par
\par
UDT names:\par
A <UDT name> identifies a UDT. The required syntax for a <UDT name> is:\par
\par
<UDT name> ::=\par
[ <Schema name>. ] unqualified name\par
\par
A <UDT name> is a <regular identifier> or a <delimited identifier> that is\par
unique (for all Domains and UDTs) within the Schema it belongs to. The <Schema\par
name> which qualifies a <UDT name> names the Schema that the UDT belongs to\par
and can either be explicitly stated, or a default will be supplied by your DBMS as follows:\par
      ## If a <UDT name> in a CREATE SCHEMA statement isn't qualified, the default qualifier is the name of the Schema you're creating.\par
      ## If the unqualified <UDT name> is found in any other SQL statement in\par
a Module, the default qualifier is the name of the Schema identified in the\par
SCHEMA clause or AUTHORIZATION clause of the MODULE statement that defines that Module.\par
\par
UDT example\par
\par
Here's an example of a UDT definition:\par
\par
CREATE TYPE book_udt AS                -- the UDT name will be book_udt\par
title CHAR(40),                        -- title is the first attribute\par
buying_price DECIMAL(9,2),             -- buying_price is the second attribute\par
selling_price DECIMAL(9,2)             -- selling_price is the third attribute\par
NOT FINAL                              -- this is a mandatory Finality Clause\par
METHOD profit( ) RETURNS DECIMAL(9,2); -- profit is a method, defined later\par
\par
This CREATE TYPE statement results in a UDT named BOOK_UDT. The components of\par
the UDT are three attributes (named TITLE, BUYING_PRICE and SELLING_PRICE) and\par
one method (named PROFIT).\par
      ## The three name-and-data-type pairs "title CHAR(40)" and "buying_price\par
DECIMAL(9,2)" and "selling_price DECIMAL(9,2)" are the UDT's Attribute definitions.\par
      ## The words NOT FINAL matter only for subtyping, which we'll get to\par
later. Briefly, though, if a UDT definition doesn't include an UNDER clause,\par
the finality clause must specify NOT FINAL.\par
      ## The clause "METHOD profit () RETURNS DECIMAL (9,2)" is a teaser. Like\par
an Attribute, a "method" is a component of a UDT. However, this method --\par
PROFIT -- is actually a declaration that a function named PROFIT exists. This\par
function isn't defined further in the UDT definition -- there is a separate\par
SQL statement for defining functions: CREATE METHOD. All we can see at this\par
stage is that PROFIT has a name and a (predefined) data type>, just as regular\par
Attributes do. Some people would call PROFIT a "derived Attribute".\par
\par
Columns based on UDTs\par
\par
Let us begin by making a Table, one of whose Columns is a UDT:\par
\par
CREATE TABLE T (\par
   book_column book_udt,\par
   serial_number INTEGER);\par
\par
You can use a UDT wherever the syntax requires <data type>. So far so good.\par
Now let's INSERT a new row into the Table. This won't be so simple.\par
\par
   BEGIN                                  /* compound statement: start */\par
     DECLARE u book_udt;                  /* temporary variable declaration */\par
     SET u = book_udt();                  /* constructor function */\par
     SET u = u.title('The Compleat SQL'); /* mutator function */\par
     SET u = u.buying_price(10.00);       /* mutator function */\par
     SET u = u.selling_price(20.00);      /* mutator function */\par
     INSERT INTO T VALUES (u,1);          /* ordinary-looking SQL statement */\par
   END;                                   /* compound statement: end */\par
\par
To understand the above compound statement, you'll need to look closely at the\par
declaration and the four function calls that precede the INSERT statement.\par
They are simple things, but the terminology is fancy.\par
\par
First: "DECLARE u book_udt;" is a declaration of a temporary variable named u.\par
Nothing new about that (if you remember your PSM chapter), but it shows that\par
variables too can be based on UDTs instead of predefined <data type>s.\par
\par
Second: "u = book_udt();" is a constructor function. The function we're\par
calling is named BOOK_UDT, the same as the UDT. That's not a coincidence. The\par
DBMS's job is to create a constructor function automatically. When the "CREATE\par
TYPE book_udt1" was executed, this SQL statement happened implicitly:\par
\par
   CREATE FUNCTION book_udt1 ()\par
   RETURNS book_udt1\par
   ...\par
   RETURN V\par
\par
In this CREATE FUNCTION statement, the RETURN, V, is a value of type\par
BOOK_UDT1, with all Attribute instance values equal to their default! What\par
does that mean? It means that when we call the BOOK_UDT1 function, the return\par
is a "default value" of the BOOK_UDT1 type. That's useful, so it's good to\par
know that the DBMS makes a constructor function for every UDT.\par
\par
Third: "u.title('The Compleat SQL');" is a mutator function. The function\par
we're calling is named TITLE, the same as the first Attribute in the UDT. Once\par
again, this is not a coincidence. The DBMS's job is to create a mutator\par
function automatically. When the "CREATE TYPE book_udt1" was executed, this\par
SQL statement also happened implicitly:\par
\par
   CREATE METHOD title\par
      (attribute CHAR(40))\par
         RETURNS book_udt\par
         SELF AS RESULT\par
         LANGUAGE SQL\par
         DETERMINISTIC\par
         CONTAINS SQL\par
         RETURN NULL ON NULL INPUT\par
\par
This statement defines a "method" (or "method function") because it is a\par
component of a UDT. To invoke the method, we just have to say "<udt\par
instance>.<method name> ( <new value> )" and the new value is a CHAR(40)\par
string, which is compatible with the Attribute's definition. The reason that\par
this method is called a mutator function is that it changes the value in the\par
object instance. So now the title in u is 'The Compleat SQL'.\par
\par
You might wonder: why all the fuss? If the whole point is to set U.TITLE to a\par
value, why not just:\par
\par
   SET u.title = 'The Compleat SQL';      /* not a good idea! */\par
\par
Using a SET statement like this would violate an object-oriented principle\par
called "encapsulation", according to which: the only access to Attributes is\par
via their functions (methods) -- so SET is not legal. If you're used to\par
Windows programming, you'll see the benefits of encapsulation: nothing can\par
access the storage except pre-approved routines which change if the storage\par
method changes.\par
\par
Fourth and fifth: "u.buying_price(10.00;" and "u.selling_price(20.00);" are\par
two more mutator functions. When the UDT was created, the DBMS made methods\par
for BUYING_PRICE and FOR SELLING_PRICE too, just as it must do for every\par
Attribute in a UDT.\par
\par
The bottom line is: constructor functions are the ordinary way to make new\par
instances of UDTs; mutator functions are the ordinary way to change Attributes\par
in UDT instances. Using the constructor and the mutators, we have been able to\par
set up a fully-initialized UDT instance -- u -- with the contents we want.\par
\par
Sixth: "INSERT INTO T VALUES (u,1);" is d\'8anouement. Clearly, it puts a value\par
into Table T. What the value looks like, we have no idea: it's encapsulated.\par
We do know, though, that what we put in was \{'The Compleat SQL', 10.00,\par
20.00\}. Insertion phase complete.\par
\par
Let us now get something back out of the UDT. You've probably guessed already that we aren't going to just say:\par
\par
   SELECT book_column, serial_number\par
   FROM   T;\par
\par
To retrieve from a UDT, we need yet another function -- the opposite of a\par
mutator -- to get the Attribute values out of BOOK_COLUMN into a\par
representation that we can read. Such a function is called an observer\par
function and, once again, the DBMS makes observer functions implicitly at the\par
time that a UDT is created -- one for each Attribute, like this:\par
\par
   CREATE METHOD title ()\par
      RETURNS CHAR(40)\par
      LANGUAGE SQL\par
      DETERMINISTIC\par
      CONTAINS SQL\par
      RETURN NULL ON NULL INPUT;\par
\par
Since the observer method exists to help us get values out, we can use them in\par
SELECT statements. To get all the values, we can use this SQL statement:\par
\par
   SELECT book_column.title(),\par
          book_column.buying_price(),\par
          book_column.selling_price()\par
   FROM   T\par
   WHERE  serial_number > 0;\par
\par
In summary, these are the functions associated with our example UDT BOOK_UDT:\par
      ## One constructor function, named BOOK_UDT.\par
      ## Three mutator functions, named TITLE, BUYING_PRICE and SELLING_PRICE.\par
      ## Three observer functions, also named TITLE, BUYING_PRICE and SELLING_PRICE.\par
(Actually the above is only for the "default case", we'll worry about options\par
later.) As the examples indicated, constructors and mutators and observers are\par
all we need for simple storage and retrieval operations.\par
\par
Routine Names and Signatures:\par
One of the strengths of the Object/Relational system is that all the functions\par
have the same name as the Attribute they're associated with, which makes them\par
easy to remember. But at first there's a little confusion too! How do we tell\par
them apart? If you look closely at these three references, you'll see the differences:\par
      ## title -- the name of an Attribute.\par
      ## title( -- the name of an observer method.\par
      ## title('The Compleat SQL') -- the name of a mutator method.\par
\par
The DBMS distinguishes between names the same way that you do. The first\par
distinction is easy: if it's got parentheses after it, then it must be a\par
routine name. The next distinction is that title() has no arguments, while\par
title('The Compleat SQL') has one argument. That's the difference between an\par
observer and a mutator. Let's express this latter distinction as a general set of rules.\par
      ## Rule 1: It is legal for two routines to be "in the same name class" -- that is, two routines with the same name may be in the same Schema.\par
      ## Rule 2: Routines are distinguishable by their category. The four categories are "procedures", "functions" and two types of "method".\par
      ## Rule 3: Routines in the same category are distinguishable by the count of parameters, and the declared type of those parameters, in their parameter list.\par
\par
Since the name alone isn't enough, we have to come up with a different term to\par
describe "what it is that distinguishes routines". The term that is in common\par
use is "signature". The signature of a routine is the routine name plus the\par
routine category plus the parameter-data-type list, and it's what the DBMS\par
uses when it needs to figure out what routine you're really trying to call.\par
\par
Defining a Typed Table based on a UDT\par
\par
It's one thing to base Columns on UDTs. It's quite another thing to base\par
Tables on UDTs. Tables based on UDTs are called "typed Tables" (or\par
"referenceable Tables"). They are also called "the two sided coin" -- because\par
from one angle, typed Tables look like relations but from another angle they\par
look like "instantiated classes" (to borrow a term from OO).\par
\par
To make a typed Table, use the REF syntax: "CREATE TABLE <Table name> OF <UDT name> ... REF IS <column name>". For example:\par
\par
   CREATE TABLE Book\par
      OF book_udt REF IS self_referencing_column;\par
\par
To execute this SQL statement, you must have the Privilege to create a Table\par
-- that is, you must be the Schema owner, and you must have a USAGE privilege\par
on the UDT. There are several options and there are some side effects, but let\par
us concentrate now on the OO significance: this instantiates the class.\par
\par
As we said, "instantiated classes" are OO terminology. The OO equivalent for\par
"user-defined type" is "class". In pure OO languages, creating a class (with\par
its Attributes and methods) takes care of everything, since classes are by\par
default "instantiable" ("instantiable" is a short way to say "there can be\par
instances of the class, namely objects based on the class definition").\par
\par
This form of CREATE TABLE takes the Attribute definitions from a UDT and\par
transfers them to <Column definition>s in a Table. Since BOOK_UDT has three\par
Attributes -- TITLE, BUYING_PRICE, SELLING_PRICE -- the BOOK Table will have\par
four Columns -- <self-referencing column>, TITLE, BUYING_PRICE, SELLING_PRICE.\par
Of these, only the first Column, <self-referencing column>, needs a bit of explanation.\par
\par
A self-referencing Column is the equivalent of what in object-oriented\par
terminology would be an "object identifier". All typed Tables have a\par
self-referencing Column; that's why typed Tables are sometimes called\par
"referenceable Tables". The point about this self-referencing Column is that\par
it uniquely identifies a single row. Now, the row in the BOOK Table is going\par
to be an instance of the "class" BOOK_UDT -- which means a row is an object.\par
So we'll be able to reference this object later, by referring to the value in\par
its self-referencing Column. The name of the self-referencing Column is\par
whatever we specify in the REF IS clause -- in this case, SELF_REFERENCING_COLUMN.\par
\par
There are several options for generation of self-referencing Column values.\par
Theoretically the best option is to derive the values from the Table's primary\par
key. But in this phase of the discussion we'll just use the default option:\par
VALUES ARE SYSTEM GENERATED. In effect, with the default option, a self-referencing column is an arbitrary row identifier.\par
\par
Treating a typed Table as a Table:\par
This is the heads side of our two-sided coin. Table BOOK is just a Table. Therefore, all these operations are legal:\par
\par
  INSERT INTO Book (title, buying_price, selling_price)\par
  VALUES ('The compleat SQL',10.00,20.00);\par
\par
  UPDATE Book SET\par
    title = 'The Incompleat SQL';\par
\par
  SELECT selling_price - buying_price\par
  FROM   Book\par
  WHERE  title LIKE '%SQL%';\par
\par
Notice that in the INSERT statement example, we did not trouble to specify a new value for SELF-REFERENCING COLUMN. That is because the value is system-generated.\par
\par
Now here is another operation: let us make a new Table which "references" the BOOK Table:\par
\par
  CREATE TABLE Book_chapter (\par
    book_ref_column REF(book),        /* a referencing Column */\par
    other_column CHAR(1024));         /* an ordinary Column */\par
\par
  INSERT INTO Book_chapter\par
    SELECT self_referencing_column, 'text for other_column'\par
    FROM   Book\par
    WHERE  title = 'The Incompleat SQL';\par
\par
We described the REF <data type> in our chapter on <reference type>s, and you\par
can look up the details there for how REF is defined. Here, at last, is an\par
actual use for the REF <data type>. The new row in BOOK_CHAPTER will contain a\par
"reference" to a single row in BOOK. This is awfully similar to referencing a\par
primary key row from a foreign key, and in fact the BOOK_CHAPTER's BOOK_REF\par
COLUMN can be made to have the paraphernalia of a foreign key, including ON DELETE or CASCADE options.\par
\par
Treating a typed Table as an instantiable class:\par
This is the flip side of our two-sided coin. It is possible to refer to the UDT's Attributes as they are stored (instanced) in the typed Table, using references. For example:\par
\par
   book_udt_reference_value -> profit()\par
\par
will invoke the PROFIT method on the underlying value in BOOK_UDT.\par
\par
Further: if we have a "REF (book)" value to steer by, we can perform "navigational" tricks. For example, this expression is legal:\par
\par
   book_ref_column -> title\par
\par
The result is the value in the TITLE Column of BOOK, for the row whose self-referencing Column is the value in the BOOK_REF_COLUMN of BOOK_CHAPTER.\par
\par
Now, getting deeply into the object-oriented business, we arrive at the\par
concepts of "subclasses" and "superclasses" -- or, since we're using UDTs,\par
"subtypes" and "supertypes". The concept is fairly easy to grasp if we remind\par
ourselves that we are merely modelling the real world, and in the real world\par
these statements are manifestly true:\par
      ## The BOOK_UDT type can be subdivided by topic -- say, SCIENCE or HISTORY.\par
      ## The HISTORY type can be further subdivided into ANCIENT and MODERN, while the SCIENCE type can be further subdivided into PHYSICS and (following Lord Kelvin's famous dictum that\par
"all science is either physics or stamp collecting") STAMP COLLECTING.\par
\par
In other words, we can think of a "family of types", of which the proud single\par
patriarch is BOOK_UDT (but we avoid the word patriarch and say "maximal\par
supertype" instead). HISTORY and SCIENCE are subtypes of BOOK_UDT; therefore,\par
by definition, BOOK_UDT is the supertype of HISTORY and SCIENCE. HISTORY, in\par
turn, is the supertype of ANCIENT and MODERN, ... and so on.\par
\par
The point of all this is: BOOK_UDT is a data type, so -- like any data type --\par
its specification includes a description of its representation and of the\par
operations that can be performed on it. That description is applicable as well\par
for HISTORY and for STAMP COLLECTING, unless we explicitly say otherwise: the\par
subtype inherits the Attributes and methods of the supertype.\par
\par
We could, of course, reflect some subtyping concept using purely relational\par
operations (by joining a BOOK Table to a PHYSICS Table, for example). But the\par
advantage of object orientation is that such operations are implicit in the\par
definition. By declaring that a is a subtype of b, you are saying that a is\par
automatically linked to b, so the linking process is practically invisible.\par
\par
To make the above discussion concrete, here are some SQL statements that make\par
subtypes. In these examples, the <keyword> UNDER means "as a subtype of".\par
\par
   CREATE TYPE history UNDER book_udt           NOT FINAL;\par
\par
   CREATE TYPE science UNDER book_udt           NOT FINAL;\par
\par
   CREATE TYPE modern UNDER history             NOT FINAL;\par
\par
   CREATE TYPE ancient UNDER history            NOT FINAL;\par
\par
   CREATE TYPE physics UNDER science            NOT FINAL;\par
\par
   CREATE TYPE stamp_collecting UNDER science   NOT FINAL;\par
\par
Admittedly, these new types lack personality. We've kept it that way so that\par
you can imagine for yourself what additional Attributes or methods you would\par
want to add to the subtypes, on top of the "inheritance" that they receive from the supertypes.\par
\par
Finally, we can flip the coin over again and say: if a type can have subtypes,\par
surely the instantiation of a type can have instantiations of subtypes. In other words, Tables can have subtables:\par
\par
   CREATE TABLE History UNDER Book;\par
\par
   CREATE TABLE Science UNDER Book;\par
\par
   CREATE TABLE Ancient UNDER History;\par
\par
   CREATE TABLE Moderns UNDER History;\par
\par
   CREATE TABLE Physics UNDER Science;\par
\par
   CREATE TABLE Stamp_collecting UNDER Science;\par
\par
Notice that the "subtables" and "supertables" defined are a family whose\par
relationships match the relationships of the "subtypes" and "supertypes" they are based on. In fact, that is a requirement.\par
\par
Here endeth the tutorial.\par
\par
CREATE TYPE statement\par
\par
The CREATE TYPE statement defines a UDT. The required syntax for the CREATE TYPE statement is:\par
\par
CREATE TYPE <UDT name>\par
[ UNDER <supertype UDT name> ]\par
[ AS \{<predefined type> | <Attribute definition list>\} ]\par
[ \{INSTANTIABLE | NOT INSTANTIABLE\} ]\par
\{FINAL | NOT FINAL\}\par
[ <reference type specification> ]\par
[ <cast option> ]\par
[ <method signature> [ \{,<method signature> \}... ] ]\par
\par
   <Attribute definition list> ::=\par
   (<Attribute definition> [ \{,<Attribute definition>\}... ])\par
\par
      <Attribute definition> ::=\par
      <Attribute name> \{ <data type> | <Domain name> \}\par
      [ REFERENCES ARE [ NOT ] CHECKED [ ON DELETE\par
          \{NO ACTION | CASCADE | RESTRICT | SET NULL | SET DEFAULT\} ] ]\par
      [ DEFAULT default value ]\par
      [ COLLATE <Collation name> ]\par
\par
   <reference type specification> ::=\par
   REF USING <predefined type> [ <ref cast option> ] |\par
   REF <Attribute name> [ \{,<Attribute name>\} ... ] |\par
   REF IS SYSTEM GENERATED\par
\par
      <ref cast option> ::=\par
      [ CAST (SOURCE AS REF) WITH <cast-to-ref identifier> ]\par
      [ CAST (REF AS SOURCE) WITH <cast-to-type identifier> ]\par
\par
   <cast option> ::=\par
   [ CAST (SOURCE AS DISTINCT)WITH <cast to distinct identifier> ]\par
   [ CAST (DISTINCT AS SOURCE) WITH <cast to source identifier> ]\par
\par
   <method signature> ::=\par
   <original method signature> |\par
   OVERRIDING [ INSTANCE | STATIC ] <partial method signature>\par
\par
      <original method signature> ::=\par
      [ INSTANCE | STATIC ] <partial method signature>\par
      [ SELF AS RESULT ] [ SELF AS LOCATOR ]\par
      [ LANGUAGE \{ADA | C | COBOL | FORTRAN | MUMPS | PASCAL | PLI | SQL\} ]\par
      [ PARAMETER STYLE \{SQL | GENERAL\} ]\par
      [ [ NOT ] DETERMINISTIC ]\par
      [ \{NO SQL | CONTAINS SQL | READS SQL DATA | MODIFIES SQL DATA\} ]\par
      [ \{RETURN NULL ON NULL INPUT | CALL ON NULL INPUT\} ]\par
\par
      <partial method signature> ::=\par
      METHOD <routine name>\par
      (SQL parameter declaration list)\par
      RETURNS <data type>\par
\par
CREATE TYPE defines a new UDT: a named set of valid data values. A UDT is owned by the Schema it belongs to.\par
      ## The <UDT name> identifies the UDT and the Schema that it belongs to.\par
A <UDT name> that includes an explicit <Schema name> qualifier belongs to the\par
Schema named. A <UDT name> that does not include an explicit <Schema name>\par
qualifier belongs to the SQL-session default Schema. The <UDT name> must be\par
unique (for all Domains and UDTs) within the Schema that owns it. If CREATE\par
TYPE is part of a CREATE SCHEMA statement, the <UDT name>, if explicitly\par
qualified, must include the <Schema name> of the Schema being created; that\par
is, it isn't possible to create a UDT belonging to a different Schema from\par
within CREATE SCHEMA.\par
\par
There are actually three variants of CREATE TYPE, used in distinct ways:\par
\par
Making structured types    Making structured types Making distinct types\par
(garden variety UDTs)      (subtype UDTs)          (not really truly UDTs)\par
CREATE TYPE <name>         CREATE TYPE <name>      CREATE TYPE <name>\par
AS <Attribute definitions> UNDER <name>            AS <predefined type>\par
...                        ...                     ...\par
NOT FINAL                  [NOT] FINAL             FINAL\par
\par
If the representation clause is "AS <predefined data type>" -- for example:\par
\par
   CREATE TYPE UDT_1 AS CHAR(15) FINAL\par
\par
then this UDT is a distinct type. Usually when we talk about UDTs we mean the\par
other kind of UDT -- the structured type -- because there's not much that one\par
can do with a distinct type.\par
\par
If you use a subtype clause -- for example:\par
\par
   CREATE TYPE a UNDER b ...\par
\par
you are making a new subtype under an existing supertype. The supertype must\par
exist, it must be a structured type UDT that was defined as NOT FINAL and you\par
must have the UNDER Privilege on it. Notice that there can be only one\par
supertype; this means that SQL, like Java, has a "single inheritance" rule.\par
Notice too that you can have both a subtype clause and an Attribute definition\par
list in the same CREATE TYPE statement; this means that the subtype can have\par
both inherited Attributes (Attributes taken from the supertype) and original\par
Attributes (Attributes taken from the new definition, which follow the inherited Attributes).\par
\par
If the representation is "... AS <Attribute list> ...", then each Attribute\par
definition must look very much like a <Column definition> looks in a CREATE TABLE statement -- for example:\par
\par
   attribute_1 CHAR(1000) CHARACTER SET ISO8BIT,\par
   attribute_2 TIME WITH TIME ZONE DEFAULT '12:00:00'\par
\par
Constraints (such as NOT NULL) are illegal, though. An <Attribute name> is an\par
<identifier>; all <Attribute name>s must be unique within their UDT. The\par
Attribute's <data type> may be a UDT, but cyclic references are illegal.\par
\par
The Standard is contradictory about the instantiable clause. It's safe to\par
assume that "instantiable", as in all OO languages, means "can be\par
instantiated" (a "non-instantiable" or "abstract" UDT would have no instances\par
but could have instantiable subtypes). Use of typed Tables is only possible if\par
the type is intantiable.\par
\par
The Standard is also contradictory about the finality clause. It probably\par
means (as in Java) that the new UDT may have no proper subtypes. That is, no\par
further UDT may be created UNDER it. (There is a belief that the clause is for\par
distinguishing distinct types from structured types. We don't believe that. We\par
repeat that a distinct type s a UDT defined with "AS <predefined type>", all\par
other UDTs are structured types.) If the CREATE TYPE statement contains any\par
Attribute definitions, then NOT FINAL is mandatory. Otherwise either FINAL or\par
NOT FINAL is mandatory.\par
\par
The reference specification is either "user-generated" (REF USING), "derived"\par
(REF <Attribute list>) or "system-generated" (REF IS SYSTEM GENERATED). With\par
the default -- REF IS SYSTEM GENERATED -- there is no further specification\par
because values are implementation-dependent. With the main option -- REF USING\par
-- there is a further specification: the <Attribute name> list. Because (as in\par
pure relational systems) a row's uniqueness   should depend on Column values,\par
the <Attribute name>s here would be an indirect list of a "key value".\par
\par
The cast option is legal only for distinct types. The cast's source and target\par
<data type>s are the <predefined type> specified earlier in the CREATE TYPE\par
statement and the name of the UDT, respectively.\par
\par
A UDT's methods are defined in pretty well the same way as functions; indeed a\par
method is a function, albeit a function which cannot live without its UDT and\par
which is called in a slightly different way than a regular function. The\par
default method characteristics are LANGUAGE SQL, PARAMETER STYLE SQL, NOT\par
DETERMINISTIC, CONTAINS SQL, NOT NULL CALL. (Note: Although the Standard says\par
that NOT DETERMINISTIC is the default, it's hard to believe that this is the\par
true intent.) The difference between an "overriding" and an "original" method\par
is that an overriding method "overrides" an already-existing method with the\par
same name, in some supertype. Method signatures must be distinct. Remember\par
that, as noted in the tutorial section of this chapter, structured UDTs have\par
implicitly-created methods: one constructor method for the UDT as a whole, n\par
mutator methods (one for each Attribute), and n observer methods (one for each\par
Attribute). As for distinct types: apparently no implicitly-created methods\par
exist for them, but there may be a "transform" function for casting to/from host languages.\par
\par
Distinct types:\par
The simplest way to make a UDT is with:\par
\par
   CREATE TYPE <UDT name> AS <predefined data type> FINAL;\par
\par
which -- since it has no Attribute list -- is not a specification of a\par
"structured type" with all the OO trimmings. Instead, UDTs made this way are\par
called "distinct types". The main idea behind distinct types is that they\par
constitute enforceable domains. For example, suppose we define two currency data types:\par
\par
   CREATE TYPE euro AS DECIMAL(8,2) FINAL;\par
\par
   CREATE TYPE mark AS DECIMAL(8,2) FINAL;\par
\par
If we now attempt to pass a "euro" value to a "mark" target, we will fail --\par
the distinct type provides us with a simple form of type checking that we\par
cannot achieve using an SQL Domain.\par
\par
Distinct types have methods, just like structured types. However, they are\par
limited in various ways. Usually, when we make generalized comments about\par
object-orientation analogies -- such as "UDTs are classes" -- we have structured types in mind, not distinct types.\par
\par
CREATE TABLE statement\par
\par
We've already shown you the CREATE TABLE statement in our chapter on Tables.\par
However, there are two options to add to that description now, for Object/Relational Tables.\par
\par
The first option has to do with the creation of typed Tables. Here's the syntax:\par
\par
CREATE TABLE <Table name>\par
OF <UDT name>\par
...\par
[ REF IS <self-referencing Column name>\par
   \{SYSTEM GENERATED | USER GENERATED | DERIVED\} ]\par
\par
In addition to the usual rules for Table creation, here are other rules to\par
follow when you use this syntax:\par
      ## You must have the USAGE Privilege on <UDT name>.\par
      ## <UDT name> must specify a structured UDT.\par
      ## The optional REF clause may appear within the Table element list\par
(that is, inside the parentheses along with the Column and Constraint\par
definitions). The <self-referencing Column name> must be a valid and distinct\par
<identifier>. The three options associated with "REF IS ..." are (like CREATE\par
TYPE's REF clause) either "user-generated", "derived" or "system-generated".\par
With the default -- SYSTEM GENERATED -- the Column values are\par
implementation-dependent. With the main option -- DERIVED -- Column values\par
come from the Table's primary key. A typed Table always has one\par
self-referencing Column, and its position within the Table is fixed: it is\par
always the first Column in the Table. The "REF IS ..." clause only specifies a\par
few details about the self-referencing Column. Note: typed Tables are known\par
(sometimes) as "referenceable Tables" and (rarely) as "object UDTs".\par
\par
The second option has to do with the creation of subtables. Here's the syntax:\par
\par
CREATE TABLE <subtable name>\par
...\par
UNDER <supertable name>\par
...\par
\par
In addition to the usual rules for Table creation, here are other rules to\par
follow when you use this syntax:\par
      ## You must have UNDER privileges on <supertable name>.\par
      ## Both the subtable and the supertable must be typed Tables.\par
      ## The subtable/supertable relationship must mirror the\par
subtype/supertype relationship. For example: if ty1 is a subtype of ty2, and\par
ta1 is a typed Table based on ty1, and ta2 is a typed Table based on ty2, then\par
it is legal to create ta1 UNDER ta2 -- but it is not legal to create ta2 UNDER ta1.\par
\par
CREATE CAST statement\par
\par
With uDTS, you'll need some way of assigning UDT values to predefined <data\par
type> targets, or vice versa. Further, if you have two distinct UDTs -- say\par
UDT1 and UDT2 -- then you'll also need some way to assign values based on UDT1\par
to UDT2 targets, or vice versa. This might all be complicated by the fact that\par
subtypes contain their supertypes' Attributes, which should imply a degree of\par
mutual assignability. In sum, you need the ability to "cast" a UDT to or from\par
another data type. The solution is to create a user-defined cast for the\par
chosen <data type>s, with the CREATE CAST statement. The required syntax for\par
the CREATE CAST statement is:\par
\par
CREATE CAST (<source type> AS <target type>)\par
WITH <specific routine designator>\par
[ AS ASSIGNMENT ]\par
\par
A UDT value is assignable to a UDT target only if the source value is a\par
subtype of the target UDT. There can be only one user-defined cast for any\par
given combination of source and target types. Either <source type> or <target\par
type> must be either UDT or REF, but the other operand can be any <data type>.\par
To execute CREATE CAST, you must be the owner of both the cast function\par
identified by <specific routine designator>) and the <target type> (if it is a UDT).\par
\par
The <specific routine designator> is usually a signature -- for example,\par
"FUNCTION f (SMALLINT)" can be a <specific routine designator>. It is also\par
possible to identify a routine using a specific name, which is a unique,\par
possibly mangled, name that is usually assigned by the DBMS. The cast function\par
identified by the <specific routine designator> must have the general form:\par
\par
   FUNCTION <name> (<source type>) RETURNS <target type>\par
   ... DETERMINISTIC\par
   ... \{ NO SQL | CONTAINS SQL \}\par
   ...\par
\par
AS ASSIGNMENT (which is not the default) means that the cast is "implicitly\par
invocable" during assignment operations. That is, if x is UDT_1, and there is\par
an implicitly-invocable cast, then this is a legal assignment:\par
\par
   x = 'F'\par
\par
Otherwise, this is a legal assignment:\par
\par
   x = CAST ('F' AS UDT_1)\par
\par
[Obscure Rule] An assignment might involve a choice between several possible\par
"implicitly invocable" cast functions. The DBMS picks the one that fits these\par
criteria:\par
      ## It's an implicitly-invocable cast function -- i.e.: it was mentioned with AS ASSIGNABLE.\par
      ## The cast function's result <data type> is the target's declared type.\par
      ## The cast function has one parameter, and that parameter has a "declared type", and that declared type is in the "type precedence list" of the declared type of the source value.\par
If there are two cast functions which meet all these requirements, the DBMS picks the one whose declared type is highest in the "type precedence list".\par
\par
** TIP: If you decide to make a user-defined cast for "a to b", be reciprocal:\par
make a user-defined cast for "b to a" as well. Users expect all casts to be two-way.\par
\par
** TIP: For hierarchy's sake: if A1 is a supertype of A2, and B1 is a supertype of B2, then make casts from A1 to B1 and from A2 to B2 -- not A1 to B2 nor A2 to B1. That is, cast from super to super and from sub to sub.\par
\par
Here is a user-defined cast for the BOOK_UDT type which we used in earlier\par
examples. The UDT has three Attributes (title CHAR(40), buying_price\par
DECIMAL(9,2), selling_price DECIMAL(9,2)). Since each Attribute's type is\par
either CHAR or castable to CHAR, we'll make a function which simply\par
concatenates each Attribute into one big character string. Here's how:\par
\par
  CREATE FUNCTION f (book_udt) RETURNS CHAR(80)\par
     DETERMINISTIC CONTAINS SQL\par
     BEGIN\par
        DECLARE c CHAR(60);\par
        SET c = book_udt.title()\par
                ||\par
                CAST(book_udt.buying_price() AS char(20))\par
                ||\par
                CAST(book_udt.selling_price() AS char(20));\par
        RETURN (u);\par
     END;\par
\par
Now that we have a function, we can make a cast for the function:\par
\par
   CREATE CAST (book_udt AS CHAR(60))\par
   WITH FUNCTION f (book_udt);\par
\par
Now that we have a cast, we can use BOOK_UDT in a CAST expression:\par
\par
  SELECT CAST(book_udt AS CHAR(60))\par
  FROM   Books;\par
\par
Thus, we can design our own external representation of a UDT, without worrying about its internal representation.\par
\par
For distinct type UDTs only, the DBMS automatically creates two casts. For example, if you make this UDT:\par
\par
   CREATE TYPE longitude AS REAL FINAL;\par
\par
the DBMS will make these two casts for it:\par
\par
   CREATE CAST (longitude AS REAL) ... AS ASSIGNMENT;\par
\par
   CREATE CAST (REAL AS longitude) ... AS ASSIGNMENT;\par
\par
Now, suppose you have a variable "lo" of type LONGITUDE. Because of the automatic cast, it's legal to cast a <literal> to LONGITUDE, for example:\par
\par
    SET lo = CAST (33.59 AS longitude);\par
\par
Not only that, though! The casts are AS ASSIGNMENT casts, so this SQL statement is also legal:\par
\par
   SET lo = 33.59;\par
\par
The AS ASSIGNMENT feature, which got into the SQL Standard at a very late\par
stage, is bound to confuse some people: they'll think that "distinct types"\par
are just a way to rename predefined <data type>s. That would be a delusion.\par
The reason that "SET lo = 33.59;" is legal is that there is an implicit cast\par
(the DBMS makes it silently) which happens to be an implicitly invoked cast\par
(it contains an AS ASSIGNMENT clause).\par
\par
** TIP: Implicitly invocable casts are convenient but error-prone. If you\par
don't want to allow loosely-typed phrases like "money_column = 5.00", you\par
should DROP the cast that the DBMS created and then explicitly make it again -\par
- but without specifying "AS ASSIGNMENT" in the definition.\par
\par
CREATE ORDERING statement\par
\par
For UDT values, you'll need some way of knowing that "udt-value-1 is greater\par
than udt-value-2" -- or less, or equal. Otherwise you'll be unable to use UDTs\par
in search conditions, or in ORDER BY clauses, or in GROUP BY clauses, or after\par
the word DISTINCT. The solution is to create an ordering for the UDT with the\par
CREATE ORDERING statement. The required syntax for the CREATE ORDERING statement is:\par
\par
CREATE ORDERING FOR <UDT name>\par
\{EQUALS ONLY BY | ORDER FULL BY\}\par
<ordering category>\par
\par
   <ordering category ::=\par
   RELATIVE WITH <specific routine designator> |\par
   HASH WITH <specific routine designator> |\par
   STATE [ <specific name> ]\par
\par
A UDT value is comparable to another UDT value only if both UDTs are in the\par
same subtype family. There can be only one ordering for a UDT. To execute\par
CREATE ORDERING, you must be the owner of both the UDT and routine named in\par
the <ordering category>. Since UDTs in the same type family are related, all\par
orderings for UDTs within the same type family must all be defined either with\par
EQUALS ONLY BY or with ORDER FULL BY.\par
\par
A <specific routine designator> is usually a signature. For example, "FUNCTION\par
f (SMALLINT)" can be a <specific routine designator>. It is also possible to\par
identify a routine using a <specific name>: an additional routine name, used\par
to uniquely identify a routine. A routine's <specific name> is usually\par
assigned by the DBMS. The ordering routine must be DETERMINISTIC and must not\par
possibly modify SQL-data.\par
\par
The <ordering category> "RELATIVE WITH <specific routine designator>" is legal\par
only for maximal supertypes (i.e.: types that have no proper supertypes of\par
their own). RELATIVE WITH functions have two parameters (both are UDT types)\par
and return an INTEGER.\par
\par
The <ordering category> "HASH WITH <specific routine designator>" is legal for\par
subtypes, but only if their supertypes are also defined with HASH WITH\par
orderings. Typically, the <specific routine designator> named will identify an\par
observer method for one of the UDT's Attributes. HASH WITH functions have one\par
parameter (its type is UDT) and return a predefined <data type>.\par
\par
The <ordering category> "STATE" is legal only for maximal supertypes. If you\par
specify STATE, the DBMS implicitly creates a function named EQUALS. It is the\par
duty of the EQUALS function to return TRUE if all Attribute values are equal.\par
\par
Because the ordering routine is user-defined, it's impossible to say exactly\par
what the various ordering categories imply. The following is a generalization:\par
      ## An EQUALS function returns TRUE if all values are equal; otherwise it returns FALSE. It never returns UNKNOWN.\par
      ## A RELATIVE function returns an integer value less than zero for less than values, returns zero for equal values and returns an integer greater than zero for greater than values.\par
      ## A HASH function returns an absolute ordering within the predefined <data type>.\par
\par
Here's an example of CREATE ORDERING:\par
\par
   CREATE ORDERING FOR book_udt\par
   ORDER FULL BY HASH WITH\par
      FUNCTION title (book_udt);   /* observer function for title Attribute */\par
\par
There is no need to create an ordering for a distinct type. As with casts, the DBMS implicitly does the following when CREATE TYPE is executed:\par
\par
   CREATE ORDERING FOR <UDT name>\par
   ORDER FULL BY HASH WITH\par
      FUNCTION <Schema name>.<cast-to-source identifier> (<UDT name>);\par
\par
Comparisons of distinct types work exactly the same way as comparisons of the predefined <data type>s they are based on.\par
\par
** TIP: When you create a maximal supertype, make sure to execute a CREATE\par
ORDERING statement for that type. When you create a subtype, the matter is\par
less urgent because subtypes inherit from their supertypes.\par
\par
Other processes for Object/Relational Users\par
\par
There are several other SQL statements and expression which are useful, but\par
not vital, when working with Object/Relational SQL. All of these statements\par
are simply analogs of statements we have already seen; only the type of Schema\par
Object is different. We therefore limit ourselves to noting their existence\par
here, in the hope that you'll find the details to be intuitive.\par
\par
ALTER TYPE statement\par
\par
The ALTER TYPE statement lets you change the definition of a UDT. The required syntax for the ALTER TYPE statement is:\par
\par
ALTER TYPE <UDT name> <alter type action>\par
\par
   <alter type action> ::=\par
   ADD ATTRIBUTE <Attribute definition> |\par
   DROP ATTRIBUTE <Attribute name>\par
\par
CREATE METHOD statement\par
\par
The CREATE METHOD statement lets you make a new method -- it's actually a special form of the CREATE FUNCTION statement. The required syntax for the CREATE METHOD statement is:\par
\par
CREATE [ INSTANCE | STATIC ] METHOD <routine name>\par
(SQL parameter declaration list)\par
RETURNS <data type>\par
FOR <UDT name>\par
[ SPECIFIC <specific name> ]\par
<routine body>\par
\par
(See our chapter on procedures for a definition of <routine body>.)\par
\par
A method is a function which is associated with a UDT. Methods and functions\par
can look quite different, even when they're the same thing. Consider these two examples:\par
\par
CREATE FUNCTION f                    CREATE METHOD f\par
(book_udt)                           ()\par
RETURNS FLOAT                        RETURNS FLOAT\par
                                     FOR book_udt\par
\par
These examples -- shorn of unnecessary detail -- illustrate a confusing fact:\par
the function and the method are the same thing! When you want to list a\par
method's parameters, you should "augment" the parameter list by adding one\par
parameter, called the "self" parameter, in ordinal position 1.\par
\par
CREATE TRANSFORM statement\par
\par
The CREATE TRANSFORM statement lets you make a method that will be used in\par
casting for host languages. The required syntax for the CREATE TRANSFORM statement is:\par
\par
CREATE \{TRANSFORM | TRANSFORMS\} FOR <UDT name>\par
<group name>\par
(<transform element> [ \{,<transform element>\} ... ])\par
\par
   <transform element> ::=\par
   TO SQL WITH <specific routine designator> |\par
   FROM SQL WITH <specific routine designator>\par
\par
A TRANSFORM is an SQL-invoked function that is automatically invoked when you\par
transfer UDT values to and from a host language program. It identifies one or\par
two functions -- each identified by a <group name> (the name is either an <identifier> of the <keyword> DEFAULT).\par
\par
The TRANSFORM's TO SQL function casts a predefined <data type> value to a UDT\par
value and gets invoked whenever a UDT value is passed to the DBMS by a host\par
language program or external routine. The TRANSFORM's FROM SQL function casts\par
a UDT value to a predefined <data type> value and gets invoked whenever a UDT\par
value is passed from the DBMS to a host language program or external routine.\par
\par
DROP CAST statement\par
\par
The DROP CAST statement lets you destroy a user-defined cast. The required syntax for the DROP CAST statement is:\par
\par
DROP CAST (<source type> AS <target type> \{CASCADE | RESTRICT\}\par
\par
DROP ORDERING statement\par
\par
The DROP ORDERING statement lets you destroy an ordering for a UDT. The required syntax for the DROP ORDERING statement is:\par
\par
DROP ORDERING FOR <UDT name> \{CASCADE | RESTRICT\}\par
\par
DROP TRANSFORM statement\par
\par
The DROP TRANSFORM statement lets you destroy a transform. The required syntax for the DROP TRANSFORM statement is:\par
\par
DROP TRANSFORM \{ALL | <group name>\} FOR <UDT name> \{CASCADE | RESTRICT\}\par
\par
DROP TYPE statement\par
\par
The DROP TYPE statement lets you destroy a UDT. The required syntax for the DROP TYPE statement is:\par
\par
DROP TYPE <UDT name> \{CASCADE | RESTRICT\}\par
\par
NEW statement\par
\par
The NEW statement lets you invoke a method on a newly-constructed value of a structured type. The required syntax for the NEW statement is:\par
\par
NEW <method invocation>\par
\par
TREAT statement\par
\par
The TREAT statement lets you modify the declared type of a structured type\par
expression to a type of one of its supertypes. The required syntax for the\par
TREAT statement is:\par
\par
TREAT (<subtype expression> AS <target UDT>)\par
\par
DEREF function\par
\par
The DEREF function lets you obtain the data value referenced by a <reference type>. The required syntax is:\par
\par
<deref function> ::=\par
DEREF (<reference type> expression>)\par
\par
Is Object/Relational really Object Oriented?\par
\par
Is O/R really OO? Lets go through the features that are considered to be\par
standard parts of an object-oriented specification and see whether SQL3\par
delivers them. (In this list, "UDT" means "UDTs which are structured types".)\par
      ## Classes. UDTs are classes. SQL3 vocabulary may include words like\par
"type family" where most languages' vocabulary would have "class family", but\par
the essential functionality is the same.\par
      ## Encapsulation. SQL3 keeps data representation separate from data\par
access, but does not allow for PRIVATE and PUBLIC Attribute definitions --\par
those are matters for GRANT and REVOKE to handle.\par
      ## Extensibility. It is possible to put together packages consisting of\par
new type families, methods and representations. Such packages exist today,\par
although to a large extent -- for efficiency reasons -- the methods are\par
external functions written in some other language.\par
      ## Inheritance. A UDT may be defined under another UDT. Subtypes inherit\par
the methods and Attributes of their supertypes. Inheritance is single, as in\par
most pure object-oriented languages.\par
      ## Instantiation. SQL3's UDTs may be used in place of predefined <data\par
type>s in SQL-data statements. Rows in typed Tables may be treated as objects,\par
complete with object identifiers.\par
      ## Introspection. SQL already has a clean way to find out what a\par
database's structural components are: INFORMATION_SCHEMA. It should be no big\par
deal to put wrappers around SQL statements that SELECT from\par
INFORMATION_SCHEMA. Unfortunately, it is more likely that wrappers will\par
instead be put around the unwieldy CLI Catalog functions (see our chapter on\par
CLI Catalog functions).\par
      ## Polymorphism. Multiple methods in a type family may have the same\par
name. The DBMS will choose the specific method based on the signature. This is Java-like.\par
\par
It should be admitted that, like any hybrid, SQL3 will look bad to purists on\par
both sides. The relational theorists will note that SQL3's new features --\par
especially self-referencing columns -- allow for "pointer-chasing" demons\par
which we thought were buried along with pre-SQL DBMSs. The object oriented\par
aficionados may decry the ease with which encapsulation can be broken, at\par
least in appearance, by recourse to SQL-92 manipulation methods. From both\par
directions, SQL3 will get flak as a chimera -- a monster with a lion's head on\par
a goat's body with a serpent's tail -- which certainly betrays its origins as an animal designed by a committee.\par
\par
All such criticisms are beside the point, though. SQL3 was put together to\par
meet certain needs which are urgent in the current market environment:\par
      ## To meld with object-oriented host languages, especially Java.\par
      ## To allow for multi-media extensions.\par
      ## To pre-empt the chaos which would result from non-standard vendor definitions, or competition from pure OO DBMSs.\par
\par
Given these goals, Object/Relational SQL3 is a reasonable development. We now wait to see whether users will find that it truly meets these urgent needs.\par
\par
Dialects\par
\par
Some SQL vendors have already introduced Object/Relational features. We give especial note to:\par
\par
UniSQL: A smaller group, which gained note in 1992 for being the first to\par
introduce an Object/Relational SQL (though some O/R features can be traced all\par
the way back to 1980s versions of DB2 and Ingres).\par
\par
IBM: Offers "relational extenders", which are packages containing UDTs,\par
user-defined functions, triggers and constraints. At the moment, IBM's\par
"universal database" is probably the implementation which is closest to the\par
SQL3 Object/Relational spec.\par
\par
Informix: Bought Illustra (one of the Object/Relational pioneers) and since\par
then has won some praise for its "DataBlades" (tm) plug-ins, which are\par
described as data-type extensions -- that is, Informix emphasizes the utility\par
of defining your own data types, rather than the purported benefits of OO.\par
\par
Oracle: Oracle8's "cartridges" are another name for what we might call "class\par
libraries" in pure OO contexts. So far, most cartridges have been multimedia\par
packages, for example "Video cartridges" and "Spatial cartridges". For\par
performance reasons, Oracle's Object/Relational features have not been popular\par
among its users, till recently.\par
\par
And finally, watch Sun. The world is waiting to see the impact of JavaBlend,\par
which purportedly will merge Java with SQL3's Object/Relational extensions.\par
\page\par
Chapter 28 -- Introduction to SQL-data operations\par
\par
In this chapter, we'll describe some common SQL constructs. We'll be using\par
these constructs in the following chapters, to describe how operations on SQL-\par
data work. [Obscure Rule] applies to everything we talk about here, but the\par
definitions are a necessary evil for understanding some of what lies ahead.\par
\par
<value specification>\par
\par
A <value specification> is a scalar expression that specifies either a\par
<literal>, a host language variable parameter or an SQL parameter as a source\par
for a data value. The required syntax for a <value specification> is:\par
\par
<value specification> ::=\par
<literal> |\par
<general value specification>\par
\par
   <general value specification> ::=\par
   <host parameter name> [ [ INDICATOR ] <host parameter name> ] |\par
   <SQL parameter reference> |\par
   <element reference> |\par
   CURRENT_PATH |\par
   CURRENT_ROLE |\par
   CURRENT_USER |\par
   SESSION_USER |\par
   SYSTEM_USER |\par
   USER |\par
   VALUE\par
\par
   <simple value specification> ::=\par
   <literal> | \par
   <host parameter name> | \par
   <SQL parameter reference>\par
\par
A <value specification> specifies a value that is not selected from a Table --\par
that is, a <value specification> is either the value represented by a\par
<literal>, the value represented by a host language variable or the value\par
represented by an SQL parameter. A simple <value specification> is either a\par
<literal>, the value of a host language variable or the value of an SQL\par
parameter: it may not be the null value. If a <simple value specification>\par
does evaluate to NULL, the SQL statement that contains it will fail: your DBMS\par
will return the SQLSTATE error 22004 "data exception-null value not allowed".\par
\par
A host parameter specification identifies a host parameter (or a host\par
parameter and its indicator) in an SQL-client Module. If the indicator for a\par
host parameter is set to a negative number, that means the value represented\par
by the host parameter is NULL. If the indicator is set to any other number,\par
that means the value represented by the host parameter is the current value of\par
that host parameter. The required syntax for a <host parameter name> is:\par
\par
<host parameter name> ::=\par
:<identifier>\par
\par
A <host parameter name> is a <regular identifier> or a <delimited identifier>\par
preceded by a colon (for example, :param_name) -- it identifies a host\par
language parameter, so the name you choose must also, of course, be a valid\par
parameter name in that host language. Each <host parameter name> must be\par
defined in the SQL-client Module that you use it in. The indicator for a host\par
parameter has to be an integer type. We'll talk more about host parameters and\par
variables in our chapters on binding styles.\par
\par
An <SQL parameter reference> identifies a parameter of an SQL-invoked routine,\par
so it can be the name of a function that returns only one value (for example,\par
CURRENT_ROLE) or an <SQL parameter name>. (For the syntax of an <SQL parameter\par
name>, see our chapter on SQL-invoked routines.) The value represented by an\par
<SQL parameter reference> is the current value of that SQL parameter.\par
\par
An <element reference> identifies an element of an array; see out chapter on\par
<collection type>s. The value represented by an <element reference> is the\par
current value of that element in that particular array.\par
\par
CURRENT_ROLE, CURRENT_USER, SESSION_USER, SYSTEM_USER and USER all identify an\par
<AuthorizationID>; see our chapter on that SQL Object. The value represented\par
by any of these functions is the current value returned by that function: each\par
returns an SQL_TEXT character string whose value represents an <AuthorizationID>.\par
\par
CURRENT_PATH identifies a <Schema name> list that helps your DBMS track\par
routines. In the list, both the <Schema name>s and their qualifying <Catalog\par
name>s are <delimited identifier>s and multiple <Schema name>s are separated by commas.\par
      ## [NON-PORTABLE] The result of CURRENT_PATH is non-standard because the\par
SQL Standard requires implementors to define whether the result string is\par
fixed length or variable length and the result string's fixed length or\par
maximum length (as applicable).\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
has CURRENT_PATH return a variable length SQL_TEXT string. The result has a maximum length of 128 octets.\par
\par
VALUE identifies an instance of a data value and can only be used in a Domain definition; see our chapter on Domains.\par
\par
[Obscure Rule] If the <data type> of a <value specification> is character string, the character string it represents has a coercibility attribute of COERCIBLE.\par
\par
If you want to restrict your code to Core SQL, don't use an <element reference> or CURRENT_PATH to specify a value.\par
\par
<value expression>\par
\par
A <value expression> is a scalar expression that specifies a data value. In\par
this book, we most often use the term "scalar_expression" to show you where a\par
<value expression> is allowed in SQL syntax. The required syntax for a <value expression> is:\par
\par
<value expression> ::=\par
<numeric value expression> |\par
<string value expression> |\par
<datetime value expression> |\par
<interval value expression> |\par
<boolean value expression>\par
<UDT value expression> |\par
<row value expression> |\par
<reference value expression> |\par
<collection value expression> |\par
\par
A <value expression> specifies a value that may or may not be selected from a\par
Table -- that is, it may be a <value specification> or it may be the result of\par
an expression on SQL-data that returns a single number, character string, bit\par
string, BLOB, date, time, timestamp, interval, Boolean value, UDT value, row\par
of data, REF value or array. The <data type> of a <value expression> is\par
determined by the <data type> of the value it evaluates to.\par
\par
The following SQL constructs all qualify as <value expression>s; each can\par
optionally include a Collation specification (i.e.: COLLATE <Collation name>)\par
to force a collating sequence for the value represented by the <value\par
expression>, provided that value's <data type> is character string:\par
      ## A <Column reference>: represents the value of that Column.\par
      ## A set function specification: represents the value returned by that function.\par
      ## A scalar subquery: represents the value returned by that subquery.\par
      ## A CASE expression: represents the value returned by that expression.\par
      ## A CAST specification: represents the value as CAST to the target <data type>.\par
      ## A <subtype treatment>: represents the value as modified.\par
      ## A <dereference operation>: represents the value returned by that function.\par
      ## An <array value expression>: represents the value of that array.\par
      ## A <routine invocation>: represents the value returned by that routine.\par
      ## A <Field reference>: represents the value of that Field of a particular row.\par
      ## A <method invocation> and a <method reference>: represents the value returned by that method.\par
\par
If you want to restrict your code to Core SQL, don't use a <value expression>\par
that evaluates to a Boolean value, an array, an interval or a REF value, don't\par
use a <subtype treatment> to specify a value and don't use the COLLATE clause\par
to force a collating sequence for any value.\par
\par
<row value constructor>\par
\par
A <row value constructor> defines an ordered set of values that make up one row of data. The required syntax for a <row value constructor> is:\par
\par
<row value constructor> ::=\par
<value expression> |\par
(<value expression> [ \{,<value expression>\} ... ]) |\par
<row subquery> \}\par
\par
A <row value constructor> constructs a row of data values in one of three possible ways:\par
      ## By evaluating a single <value expression>, for example, the\par
<character string literal> 'GOODBYE'. In this case, the <value expression> may\par
not be enclosed in parentheses. This rule is explicitly stated in the SQL\par
Standard to resolve a syntactic ambiguity: in certain circumstances, the syntax: (<value expression>) is permitted.\par
      ## By evaluating two or more comma-delimited <value expression>s enclosed in parentheses, for example: ('GOODBYE',10).\par
      ## By evaluating a <row subquery>, for example:\par
\par
   ... (SELECT column_2, column_5 FROM Table_2)\par
\par
The <data type>s of the Column(s) of a <row value constructor> are the <data\par
type>s of the <value expression>(s) or the Column(s) of the <row subquery>\par
that make up the <row value constructor>. If a <row value constructor> is\par
derived from a <row subquery>, then the degree (i.e.: the number of Columns)\par
of the <row value constructor> is the degree of the Table that results from\par
the evaluation of the <row subquery>; otherwise, the degree of the <row value\par
constructor> is the number of <value expression>s that make up the <row value constructor>.\par
\par
In this case, if the number of rows returned by the <row subquery> is zero,\par
the result is a single row containing null values for every Column of the <row\par
subquery>. If the number of rows returned  by the subquery is one, the result\par
is that single row. (Note: a <row subquery> may not return more than one row.)\par
\par
<target specification>\par
\par
A <target specification> is a scalar expression that specifies a host language\par
variable parameter, an SQL parameter or a Column as the target for a data\par
value. The required syntax for a <target specification> is:\par
\par
<target specification> ::=\par
<host parameter name> [ [ INDICATOR ] <host parameter name> ] |\par
<SQL parameter name> |\par
<Column reference>\par
\par
A <target specification> specifies a place to put a value. Most often, this\par
will be a <Column reference> (as in an INSERT statement), but you can also\par
assign values to an output SQL parameter (see our chapter on SQL-invoked\par
routines) or to a variable in a host language program (see our chapters on\par
binding styles). A <simple target specification> is either a host language\par
variable, an output SQL parameter or a "known not nullable" Column: it may not be the null value.\par
\page\par
Chapter 29 -- Simple Search Conditions\par
\par
We've come at last to the point where we can begin showing you the most important aspect of SQL -- how to query your "database". In this chapter, we'll begin by describing simple search conditions.\par
\par
Truth Values\par
\par
In our chapter on the Boolean <data type>, we noted what SQL's truth values are: TRUE, FALSE and UNKNOWN. But what are truth values for? There are four possible answers to that question:\par
      ## To support conditional branches and loops, as in traditional programming languages. There are optional SQL3 constructs like "IF (condition is TRUE) THEN (perform this operation)". However, that's advanced stuff.\par
We'll discuss program control operations in a later chapter.\par
      ## To store in the database. For that, we have the BOOLEAN <data type>.\par
      ## To support the CASE expression.\par
      ## To support relational restriction.\par
\par
It is answer #4 -- "to support relational restriction" -- that most people\par
think of first. Commonly, they would use simple terms for the process -- like\par
"finding" or "searching" -- since the essence of the affair is indeed simple:\par
they just want to pick certain rows from a Table; say, the ones where the NAME\par
Column contains Smith, or the ones where the value in the SPENDING Column is\par
greater than the value in the BUDGET Column. These are such simple questions\par
that they seem trite, but they already illustrate some distinguishing features of SQL searching.\par
\par
First of all, they show that rows are picked by content, not by address.\par
Although most SQL packages have some option for selecting rows according to\par
their position or ordinal location, the makers of relational theory did not intend that to be an important part of the search process.\par
\par
Secondarily, they show that Column values must meet certain conditions (such\par
as being equal or being greater). We can easily contrive exceptions to this\par
statement; for example some searches do not involve Column values. But\par
certainly the idea that "conditions must be met" is universal. For successful\par
searching, you have to know how to conceive and specify these conditions.\par
\par
As we said at the beginning, in this chapter we will concern ourselves only\par
with the simpler conditional expressions which are necessary for searching.\par
Before we do that, though, we'll briefly discuss the SQL statement that you\par
will use with search conditions most often: the SELECT statement.\par
\par
SELECT statement\par
\par
The SELECT statement retrieves data from one or more Tables. Here is the required syntax for a simple SELECT statement (or, as the SQL Standard calls it, a <query specification>):\par
\par
SELECT [ DISTINCT | ALL ]\par
\{Column expression [ AS name ]\} [ ,... ] | *\par
FROM <Table reference> [ \{,<Table reference>\} ... ]\par
[ WHERE search condition ]\par
[ GROUP BY Columns [ HAVING condition ] ]\par
\par
The SELECT statement queries your SQL-data: it returns a results Table derived\par
from the Tables referred to in the FROM clause. The derivation of the result\par
Table can be described as a sequence of operations in which the result of each\par
operation is input for the next. The sequence of the operations is FROM, then\par
WHERE, then GROUP BY, then HAVING, then the select list (that is, the list of\par
Column expressions) and the descriptions of the clauses that follow appear in this order.\par
\par
FROM clause:\par
The FROM clause supplies a list of <Table references> for the query. A <Table\par
reference> is any expression which results in a Table but is usually just a\par
<Table name> or a <Correlation name> that identifies a Table that contains\par
SQL-data you want to query. <Column name>s throughout the SELECT statement\par
must be unambiguous; that is, they must be qualified with a <Correlation name>\par
if one was defined for the Table that owns them, and with their <Table name>\par
if SELECT is retrieving data from multiple Tables which have Columns with\par
identical names. The required syntax for the FROM clause is:\par
\par
FROM <Table reference> [ \{,<Table reference>\} ... ]\par
\par
## Table reference\par
Several times throughout this book, we make the comment that the result of an\par
SQL query is a Table. To understand the entire syntax that you may use to\par
formulate a query then, you'll have to start with what a Table is -- and we've\par
already shown you that a Table is a set of Columns and row. Up until now,\par
though, whenever we've talked about Tables, we've referred to them only with a\par
<Table name>. Since the result of a query is a Table derived by evaluating\par
that query, not all SQL Tables have an explicit <Table name> -- so SQL allows\par
you to refer to any Table using a <Table reference>. The required syntax for a <Table reference> is:\par
\par
<Table reference> ::=\par
[ ONLY ]\{<Table name> | <query name>\} [ [ AS ] <Correlation name> [ (<derived Column list>) ] ] |\par
<Table subquery> [ AS ] <Correlation name> [ (<derived Column list>) ] |\par
<joined Table> |\par
LATERAL (<query expression>) [ AS ] <Correlation name> [ (<derived Column list>) ]\par
\par
   <derived Column list> ::=\par
   <Column name> [ \{,<Column name> \}... ]\par
\par
A <Table reference> is simply a reference to some Table: this may be a\par
reference to a named Table (that is, a <Table name> that identifies a Base\par
table or a View) or a reference to a Table returned by a query. Thus there are\par
five possible options for a <Table reference>:\par
      ## It can refer to a Base table or a View using a <Table name>. The\par
optional <keyword> ONLY in front of such a reference can only be used if the\par
reference is to a typed Table. In that case, the <Table reference> refers to\par
every row of the Table (or result Table), except for any rows that have a\par
subrow in a proper subtable of that Table.\par
      ## It can refer to a result Table using a <query name>.\par
      ## It can refer to the result of a Table subquery.\par
      ## It can refer the result of a join of multiple Tables.\par
      ## It can refer to a lateral Table: the result of a parenthesized <query expression> preceded by the <keyword> LATERAL.\par
\par
In each case, you can optionally provide a <Correlation name> for the Table\par
being referred to, as well as explicit names for each of the Columns belonging\par
to the Table being referred to (the names specified must, of course, be unique for that reference).\par
\par
If you want to restrict your code to Core SQL, don't use a <query name> to\par
make up a <Table reference> and don't use the <keyword> ONLY to make up a\par
<Table reference> that refers to a typed Table.\par
\par
WHERE clause:\par
The optional WHERE clause is used to set the retrieval conditions for rows.\par
Any rows that don't fall into the guidelines specified are eliminated from the\par
results Table. The search conditions specified may include the arithmetic and\par
Boolean operators, the SQL predicates (e.g.: comparison, BETWEEN, LIKE) and\par
the SQL scalar functions, as well as parentheses to set the desired evaluation\par
order. The required syntax for the WHERE clause is:\par
\par
WHERE <search condition>\par
\par
GROUP BY clause:\par
The optional GROUP BY clause logically rearranges the interim result returned\par
by the WHERE clause into groups. The result is a set of rows where each common\par
datum is gathered into one group. That is, within a group, all values of a\par
grouping Column are the same value. For grouping, all NULLs are considered\par
equal: they form one group. Because every row that contains a group contains\par
the same value for that group, the name of a grouping Column can be used in a\par
condition for the HAVING clause or to identify a result Column in the select\par
list. We'll show you the required syntax for the GROUP BY clause in our\par
chapter on grouping.\par
\par
HAVING clause:\par
The optional HAVING clause is used to set the retrieval conditions for groups.\par
Any groups that don't fall into the guidelines specified are eliminated from\par
the results Table. The search conditions specified may include the arithmetic\par
and Boolean operators, the SQL predicates (e.g.: comparison, BETWEEN, LIKE)\par
and the SQL scalar functions, as well as parentheses to set the desired\par
evaluation order. HAVING is normally applied to the interim result returned by\par
the GROUP BY clause. If a SELECT statement doesn't include a GROUP BY clause,\par
then HAVING treats all rows of the interim result as a single group. We'll\par
show you the required syntax for the HAVING clause in our chapter on grouping.\par
\par
SELECT LIST clause:\par
The select list produces a final results Table by selecting only those Columns\par
(or Column expressions) specified. The select list may include <Column name>s,\par
<Column reference>s, Column expressions (that is, any expression which\par
evaluates to a single Column, such as a scalar subquery) or an asterisk, as\par
well as one of the <keyword>s DISTINCT or ALL. (The asterisk is a shorthand\par
for a list of all the Columns of the Tables named in the FROM clause. The\par
DISTINCT option ensures that duplicate rows are eliminated from the result.\par
The ALL option, which is the default, ensures that duplicate rows are included\par
in the result.) A Column expression can be a <literal>, a scalar function or\par
some other expression derived from the Columns whose values you want to\par
retrieve but may not include any expression that will evaluate to a Column\par
with a BLOB, CLOB or NCLOB <data type> if DISTINCT is specified. You can use\par
the optional AS name clause to specify a name for a Column expression; it will\par
be used to identify that result for the entire SELECT statement. The required\par
syntax for a select list is:\par
\par
SELECT [ ALL | DISTINCT ] Column list\par
\par
   Column list ::=\par
   expression [ [ AS ] <Column name> ] [ , ... ] |\par
   *\par
\par
Let's try some SELECT examples on a small group of Tables. They look like this\par
(a question mark in a Column represents a null value):\par
\par
DEPARTMENT\par
DEPT  MANAGER     FUNCTION       CODE\par
A     SMITH A     ACCOUNTING     1\par
B     JONES B     INF SYSTEMS    2\par
C     BROWN C     CUST REL       3\par
D     BLACK D     OPERATIONS     4\par
E     GREEN E     SALES          5\par
\par
EMPLOYEE\par
EMPNUM      DEPT  SURNAME     GNAME    ADDRESS\par
 1          A     KOO         SARA     234 WEST\par
 2          B     MARSH       JOHN     456 EAST\par
 3          C     JONES       MABEL    567 NORTH\par
 4          D     MORGAN      CHUCK    963 SOUTH\par
10          A     SMITH       ALICE    234 WEST\par
11          B     JONES       BOB      325 RIVER\par
20          E     FRANCIS     CHRIS    861 BERLIN\par
28          B     TURNER      LINDA    114 ROBIN\par
35          E     OLSEN       CAROL    555 RIVER\par
40          B     WARREN      NANCY    ?\par
\par
PAYROLL\par
EMPNUM      RATE        LOCATION          PAID              APPT\par
 1           6.00       10TH FLOOR        1989-10-31        10:15:00\par
 2           5.00       16TH FLOOR        1989-09-30        10:20:00\par
 3           5.00       WAREHOUSE         1989-09-30        10:30:00\par
 4           8.00       BASEMENT          1989-10-15        12:00:10\par
10          16.00       16TH FLOOR        1989-09-30        12:30:00\par
11          16.00       16TH FLOOR        1989-10-15        13:15:10\par
20           9.00       WAREHOUSE         1989-10-15        14:00:00\par
28          ?           16TH FLOOR        1989-09-15        14:10:00\par
35           9.00       10TH FLOOR        1989-10-31        14:20:00\par
40          16.00       10TH FLOOR        1989-10-31        14:35:07\par
\par
Simple retrieval:\par
To find all departments with employees (retrieve a single Column from a\par
Table), the following SQL statements are equivalent:\par
\par
   SELECT dept FROM Employee;\par
\par
   SELECT ALL dept FROM Employee;\par
\par
   SELECT Employee.dept FROM Employee;\par
\par
   SELECT ALL Employee.dept FROM Employee;\par
\par
The first two examples use unqualified <Column name>s in the select list,\par
while the last three use <Column reference>s (that is, <Column name>s\par
qualified with their <Table name>s). Unless the lack of a qualifier makes a\par
<Column name> ambiguous, the qualifier is unnecessary. The result in all cases\par
is:\par
\par
DEPT\par
A\par
B\par
C\par
D\par
A\par
B\par
E\par
B\par
E\par
B\par
\par
Departments are duplicated in the result because SELECT doesn't eliminate them unless the DISTINCT option is used, as in these equivalent SQL statements:\par
\par
   SELECT DISTINCT dept FROM Employee;\par
\par
   SELECT DISTINCT Employee.dept FROM Employee;\par
\par
The result in both cases is:\par
\par
DEPT\par
A\par
B\par
C\par
D\par
E\par
\par
To find the name of each department's manager (retrieve multiple Columns from one Table):\par
\par
   SELECT dept,manager FROM Department;\par
\par
The result is:\par
\par
DEPT  MANAGER\par
A     SMITH A\par
B     JONES B\par
C     BROWN C\par
D     BLACK D\par
E     GREEN E\par
\par
To retrieve all Columns of one Table, these three SQL statements are equivalent:\par
\par
   SELECT empnum,rate,location,paid FROM Payroll;\par
\par
   SELECT * FROM Payroll;\par
\par
   SELECT Payroll.* FROM Payroll;\par
\par
The result in all three cases is the entire PAYROLL Table. (An asterisk can be used as shorthand for "all Columns" and can be qualified just as a <Column name> can be.)\par
\par
Qualified retrieval:\par
To find all employees working in department A (retrieve one Column which fulfills one search condition):\par
\par
   SELECT surname FROM Employee WHERE dept='A';\par
\par
The result is:\par
\par
SURNAME\par
KOO\par
SMITH\par
\par
Remember that <character string literal>s must always be enclosed in single quotes.\par
\par
To find department A employees with an employee number smaller than 10 (retrieve one Column fulfilling multiple search conditions):\par
\par
   SELECT surname FROM Employee\par
   WHERE  dept='A' AND empnum<10;\par
\par
The result is:\par
\par
SURNAME\par
KOO\par
\par
To find the full name of the department A employee whose employee number is 10 (retrieve multiple Columns fulfilling multiple conditions from a Table):\par
\par
   SELECT gname,surname FROM Employee\par
   WHERE  dept='A' AND empnum=10;\par
\par
The result is:\par
\par
GNAME   SURNAME\par
ALICE   SMITH\par
\par
Retrieval with a <literal>:\par
To include a <literal> in a result:\par
\par
   SELECT empnum,\par
          'Hourly Rate=' AS hourly_rate,\par
          rate\par
   FROM   Payroll\par
   WHERE  empnum=1 OR empnum=10;\par
\par
The result is:\par
\par
EMPNUM      HOURLY_RATE       RATE\par
 1          Hourly Rate=       6.00\par
10          Hourly Rate=      16.00\par
\par
The second Column of the result is derived from the <character string literal> expression in the select list.\par
\par
Retrieval with an arithmetic expression:\par
To calculate an employee's daily pay from the hourly rate earned (retrieve multiple Columns from a Table with an arithmetic expression):\par
\par
   SELECT empnum,\par
          'Daily Rate=' AS comment,\par
          rate*8 AS daily_rate\par
   FROM   Payroll\par
   WHERE  empnum=1 OR empnum=10;\par
\par
The result is:\par
\par
EMPNUM      COMMENT           DAILY_RATE\par
 1          Daily Rate=        48.00\par
10          Daily Rate=       128.00\par
\par
The third Column of the result is derived from the arithmetic expression in the select list.\par
\par
Retrieval with LIKE:\par
To find all employees with surnames beginning with "M" (retrieve all values matching a simple string pattern):\par
\par
   SELECT empnum,surname FROM Employee\par
   WHERE  surname LIKE 'M%' AND empnum<3;\par
\par
The result is:\par
\par
EMPNUM      SURNAME\par
 2          MARSH\par
\par
To find the departments whose manager's surname has the letter "R" as the second character:\par
\par
   SELECT dept,manager FROM Department\par
   WHERE  surname LIKE '_R%';\par
\par
The result is:\par
\par
DEPT  MANAGER\par
C     BROWN C\par
E     GREEN E\par
\par
To find all employees whose given name does not include the letter "A" (retrieve values which do not match a simple string pattern):\par
\par
   SELECT empnum,gname FROM Employee\par
   WHERE  gname NOT LIKE '%A%';\par
\par
The result is:\par
\par
EMPNUM      GNAME\par
 2          JOHN\par
 4          CHUCK\par
11          BOB\par
\par
(We discussed the LIKE predicate in our chapter on character strings.)\par
\par
Retrieval with SIMILAR:\par
To find all employees whose location starts with 2 digits (retrieve all values matching a complicated string pattern):\par
\par
   SELECT empnum,location FROM Payroll\par
   WHERE  location SIMILAR TO '[:DIGIT:][:DIGIT:]%';\par
\par
The result is:\par
\par
EMPNUM    LOCATION\par
 1        10TH FLOOR\par
 2        16TH FLOOR\par
10        16TH FLOOR\par
11        16TH FLOOR\par
28        16TH FLOOR\par
35        10TH FLOOR\par
40        10TH FLOOR\par
\par
To find all employees whose location doesn't start with 2 digits (retrieve all values that don't match a complicated string pattern):\par
\par
   SELECT empnum,location FROM Payroll\par
   WHERE  location NOT SIMILAR TO '[:DIGIT:][:DIGIT:]%';\par
\par
The result is:\par
\par
EMPNUM      LOCATION\par
 3          WAREHOUSE\par
 4          BASEMENT\par
20          WAREHOUSE\par
\par
(We discussed the SIMILAR predicate in our chapter on character strings.)\par
\par
Retrieval with IS NULL:\par
To find all employees with unknown addresses on file (retrieve all rows containing a null value):\par
\par
   SELECT empnum,surname,gname\par
   FROM   Employee\par
   WHERE  address IS NULL;\par
\par
The result is:\par
\par
EMPNUM  SURNAME  GNAME\par
40      WARREN   NANCY\par
\par
To find the departments with known managers (retrieve all rows that don't contain null values):\par
\par
   SELECT manager FROM Department\par
   WHERE  manager IS NOT NULL;\par
\par
The result is:\par
\par
MANAGER\par
SMITH A\par
JONES B\par
BROWN C\par
BLACK D\par
GREEN E\par
\par
(We discussed the IS NULL predicate in our chapter on NULLs.)\par
\par
Retrieval with a scalar function:\par
To concatenate an employee's first initial and surname:\par
\par
   SELECT empnum,\par
          SUBSTRING(gname FROM 1 FOR 1) || '. ' || surname AS fullname\par
   FROM   Employee\par
   WHERE  empnum=10;\par
\par
The result is:\par
\par
EMPNUM   FULLNAME\par
10        A. SMITH\par
\par
To concatenate the values retrieved from a Column with a <literal>:\par
\par
   SELECT 'HELLO ' || gname AS greeting\par
   FROM   Employee\par
   WHERE  empnum=4;\par
\par
The result is:\par
\par
GREETING\par
HELLO CHUCK\par
\par
To find the length of a Column value and a <literal>:\par
\par
   SELECT surname,\par
          CHAR_LENGTH(surname) AS surname_length,\par
          CHAR_LENGTH('MARY') AS literal_length\par
   FROM   Employee\par
   WHERE  dept='A';\par
\par
The result is:\par
\par
SURNAME  SURNAME_LENGTH  LITERAL_LENGTH\par
KOO      3               4\par
SMITH    5               4\par
\par
(The CHAR_LENGTH function returns a character string's length inclusive of blanks and trailing zeros. This example assumes that SURNAME is a variable length Column.)\par
\par
Retrieval using date arithmetic:\par
To find the number of days since the last pay date (assume the current date is November 10, 1989):\par
\par
   SELECT paid,\par
          (DATE '1989-11-10' - paid) INTERVAL DAY AS last_paid\par
   FROM   PAYROLL\par
   WHERE  empnum=1;\par
\par
The result is:\par
\par
PAID          LAST_PAID\par
1989-10-31    10\par
\par
To add three months and two days to the last pay date:\par
\par
   SELECT empnum,\par
          paid,\par
          ((paid + INTERVAL '3' MONTH) + INTERVAL '2' DAY) AS new_date\par
   FROM   PAYROLL\par
   WHERE  empnum=1;\par
\par
The result is:\par
\par
EMPNUM  PAID        NEW_DATE\par
1       1989-10-31  1990-02-02\par
\par
Joins:\par
The ability to join a Table to others is one of the most powerful features of SQL. A join is an operation in which data is retrieved from multiple Tables. Here are some examples.\par
\par
To find all information available on all employees (retrieve a join of all Columns) the following SQL statements are equivalent:\par
\par
   SELECT Employee.*,Payroll.*\par
   FROM   Employee,Payroll\par
   WHERE  Employee.empnum=Payroll.empnum;\par
\par
   SELECT *\par
   FROM   Employee,Payroll\par
   WHERE  Employee.empnum=Payroll.empnum;\par
\par
The result is the entire EMPLOYEE Table joined with the entire PAYROLL Table\par
over their matching employee numbers; ten rows and ten columns in all. Note\par
the <Column reference>s for the EMPNUM Column, necessary to avoid ambiguity.\par
To eliminate duplicate Columns from the result, specific <Column reference>s\par
(rather than *) must also be listed in the select list, as in this SQL statement:\par
\par
   SELECT Employee.empnum,dept,surname,rate,location\par
   FROM   Employee,Payroll\par
   WHERE  Employee.empnum=1 AND Employee.empnum=Payroll.empnum;\par
\par
The result is:\par
\par
EMPNUM      DEPT  SURNAME     RATE  LOCATION\par
1           A     KOO         6.00  10TH FLOOR\par
\par
To find an employee's manager (retrieve one Column from multiple Tables):\par
\par
   SELECT surname,manager\par
   FROM   Employee,Department\par
   WHERE  empnum=28 AND Employee.dept=Department.dept;\par
\par
The result is:\par
\par
SURNAME     MANAGER\par
TURNER      JONES B\par
\par
To find the pay rates and locations of all department A employees (join values fulfilling multiple conditions from multiple Tables):\par
\par
   SELECT Employee.*,Payroll.*\par
   FROM   Employee,Payroll\par
   WHERE  dept='A' AND Employee.empnum=Payroll.empnum;\par
\par
The result is the EMPLOYEE Table joined with the PAYROLL Table, for all rows where the DEPT column contains 'A'.\par
\par
To find the department and payroll data for employee 35:\par
\par
   SELECT Employee.empnum,surname,Employee.dept,manager,rate\par
   FROM   Employee,Department,Payroll\par
   WHERE  Employee.empnum=35 AND\par
          Employee.empnum=Payroll.empnum AND\par
          Employee.dept=Department.dept;\par
\par
The result is:\par
\par
EMPNUM      SURNAME     DEPT  MANAGER     RATE\par
35          OLSEN       E     GREEN E     9.00\par
\par
To find the manager and locations of department C's employees:\par
\par
   SELECT Department.dept,manager,location\par
   FROM   Department,Payroll,Employee\par
   WHERE  Department.dept='C' AND\par
          Department.dept=Employee.dept AND\par
          Employee.empnum=Payroll.empnum;\par
\par
The result is:\par
\par
DEPT  MANAGER     LOCATION\par
C     BROWN C     WAREHOUSE\par
\par
Predicates\par
\par
You'll have noticed by now that the fundamental SQL condition is the\par
predicate. It states a condition whose result is either TRUE, FALSE or\par
UNKNOWN. An example of a predicate is the familiar expression:\par
\par
   Example #1: x = 5\par
\par
Specifically, Example#1 is an example of a "<comparison predicate>". Note that the predicate contains a single condition. This is not a predicate:\par
\par
   Example #2: x = 5 AND y = 6\par
\par
because AND is a Boolean operator that combines two predicates. However, both\par
Example #1 and Example #2 are examples of "search conditions", and we will get\par
back to Boolean operators later on.\par
\par
The one thing we can say about predicates in general is that they describe\par
operations which take non-truth-value arguments and return truth-value\par
results. The truth value might be TRUE or FALSE; for most predicates (but not\par
all) the truth value might also be UNKNOWN.\par
\par
Listed below are the fourteen SQL3 predicates, of which ten are SQL-92\par
predicates and seven are acceptable in Core SQL, and of which all but five may\par
return any of TRUE, FALSE or UNKNOWN.\par
\par
STANDARD  NAME                  KEYWORDS OR SYMBOLS         SQL-92? CORE? TFU\par
<comparison predicate>          = > >= < <= <>              YES     YES   TFU\par
<quantified\par
    comparison predicate>       = > >= < <= <> ALL|ANY|SOME YES     YES   TFU\par
<between predicate>             [NOT] BETWEEN               YES     YES   TFU\par
<in predicate>                  [NOT] IN                    YES     YES   TFU\par
<like predicate>                [NOT] LIKE                  YES     YES   TFU\par
<null predicate>                IS [NOT] NULL               YES     YES   TF\par
<exists predicate>              [NOT] EXISTS                YES     YES   TF\par
<unique predicate>              [NOT] UNIQUE                YES           TF\par
<match predicate>               [NOT] MATCH                 YES           TF\par
<overlaps predicate>            [NOT] OVERLAPS              YES           TFU\par
<similar predicate>             [NOT] SIMILAR TO                          TFU\par
<quantified predicate>          FOR ALL|ANY|SOME                          TFU\par
<distinct predicate>            IS DISTINCT FROM                          TF\par
<type predicate>                IS [NOT] OF (type-list)                   TFU\par
\par
<comparison predicate>:\par
The required syntax for a <comparison predicate> is:\par
\par
<comparison predicate> ::=\par
expression_1 comparison operator expression_2\par
\par
A <comparison predicate> compares two values and returns either TRUE, FALSE or\par
UNKNOWN. (If either argument is NULL, the <comparison predicate> returns\par
UNKNOWN.) There are six comparison operators. Listed below are their symbols,\par
their official names, their converses (i.e.: what the operator would be if the\par
predicate was negated) and two examples of predicates which contain the symbol and are TRUE.\par
\par
Symbol  Name           Examples of TRUE predicates    Negation\par
=       equals         1=1                            <>\par
                       X'1'=B'0001'\par
>       greater than   1>0                            <=\par
                       DATE '2100-01-01'>CURRENT_DATE\par
>=      greater than   1>=0                           <\par
        or equals      CURRENT_TIME>=CURRENT_TIME\par
<       less than      1<2                            >=\par
                       TIME '01:01:01'<TIME '01:01:02'\par
<=      less than      1<=2                           >\par
        or equals      B'000000'<=B'000000'\par
<>      not equals     1<>2                           =\par
                       'A'<>'B'\par
\par
There is nothing about the SQL comparison operators which would surprise the\par
experienced programmer, although the use of the symbol <> for "not equals" is\par
worth noting. There are some old DBMSs which accept != instead, but only <> is\par
acceptable in standard SQL. Most commonly, the first comparand is a <Column\par
name> and the second is a <literal>, e.g.:\par
\par
    city = 'PARIS'\par
       -- a Column/<literal> comparison\par
\par
Some general rules:\par
      ## The two expression arguments must be "comparable". Generally, this is\par
the case if they have comparable <data type>s; for example, if both are\par
numeric. If the comparands are rows, each corresponding pair of Fields must\par
have comparable <data type>s. We discussed what is meant by a comparable <data\par
type> in our chapters on each of the SQL predefined <data type>s; refer to\par
those discussions for complete details on how comparisons work on a specific <data type>.\par
      ## For BLOBs, CLOBs, NCLOBs, REFs and ARRAYs, the only legal comparison operators are = and <>. There may also be some restrictions for UDTs.\par
\par
It's remarkable to think that, in primitive DBMSs, the Column/<literal> comparison was pretty well all that there was. But today we can get much fancier:\par
\par
   UPPER(city) = 'PARIS'\par
      -- an expression/<literal> comparison\par
\par
   spending >= budget\par
      -- a Column/Column comparison\par
\par
   'PARIS' = city\par
      -- a <literal>/Column comparison (not recommended)\par
\par
   column_1+5=column_2+7\par
      -- an expression/expression comparison\par
\par
Finally, we could use row values instead of scalar values in our comparisons:\par
\par
   (column_1,column_2) = ('ADAMS',77)\par
      -- a row-value/row-value comparison\par
\par
Use row-value comparisons sparingly, because some DBMSs won't support them.\par
\par
<between predicate>:\par
The required syntax for a <between predicate> is:\par
\par
<between predicate> ::=\par
expression_1 [ NOT ] BETWEEN [ ASYMMETRIC | SYMMETRIC ]\par
expression_2 AND expression_3\par
\par
A <between predicate> compares a value to a range of values and returns either\par
TRUE, FALSE or UNKNOWN. (If any argument is NULL, the <between predicate>\par
returns UNKNOWN.) BETWEEN searches for data in a specific range. NOT BETWEEN\par
searches for data that do not fall into the range given.\par
\par
Some general rules:\par
      ## The three expressions must be comparable. If the comparands are rows,\par
they must be of the same degree and each corresponding pair of Fields must\par
have comparable <data type>s.\par
      ## The <between predicate> can't be used with BLOBs, CLOBs, NCLOBs, REFs and ARRAYs.\par
\par
The ASYMMETRIC <between predicate> is TRUE if the value of expression_1 is\par
greater than or equals the value of expression_2 and the value of expression_1\par
is less than or equals the value of expression_3. For example, these <between predicate>s are all TRUE:\par
\par
   1 BETWEEN 0 AND 2\par
\par
   'B' BETWEEN 'A' AND 'B'\par
\par
   CURRENT_TIME BETWEEN TIME '00:00:00.000000' AND TIME '23:59:59.999999'\par
\par
NOT BETWEEN is simply the negation of BETWEEN so this predicate is also TRUE:\par
\par
   3 NOT BETWEEN 0 AND 2\par
\par
ASYMMETRIC is the predicate's default condition.\par
\par
The SYMMETRIC <between predicate> is TRUE either (a) if the value of\par
expression_1 is greater than or equals the value of expression_2 and the value\par
of expression_1 is less than or equals the value of expression_3 or (b) if the\par
value of expression_1 is greater than or equals the value of expression_3 and\par
the value of expression_1 is less than or equals the value of expression_2.\par
For example, these <between predicate>s are both TRUE:\par
\par
   1 BETWEEN SYMMETRIC 2 AND 0\par
\par
   3 NOT BETWEEN SYMMETRIC 2 AND 0\par
\par
The SYMMETRIC option is new to SQL with SQL3.\par
\par
In short, BETWEEN is just a shorthand for a combination of >= and <= comparisons, so the same rules that apply for comparisons of specific <data type>s apply to BETWEEN as well.\par
\par
## Retrieval with BETWEEN\par
Here are two <between predicate> retrieval examples from the sample Tables\par
shown at the beginning of this chapter. First, to find the names of the\par
manager of departments A, B and C (retrieve values that match any in a specified range):\par
\par
   SELECT dept,manager FROM Department\par
   WHERE  dept BETWEEN 'A' AND 'C';\par
\par
The result is:\par
\par
DEPT  MANAGER\par
A     SMITH A\par
B     JONES B\par
C     BROWN C\par
\par
To find the employee numbers of all employees whose pay rate is either less\par
than 8.00 or greater than 16.00 (retrieve values not falling into a specified range):\par
\par
   SELECT empnum,rate FROM Payroll\par
   WHERE  rate NOT BETWEEN 8 AND 16;\par
\par
The result is:\par
\par
EMPNUM      RATE\par
1           6.00\par
2           5.00\par
3           5.00\par
\par
<distinct predicate>:\par
The required syntax for a <distinct predicate> is:\par
\par
<distinct predicate> ::=\par
expression_1 IS DISTINCT FROM expression_2\par
\par
A <distinct predicate> tests two values to see whether they are distinct and returns either TRUE or FALSE. The <distinct predicate> is new to SQL with SQL3.\par
\par
Some general rules:\par
      ## The two expressions must be comparable. If the comparands are rows,\par
they must be of the same degree and each corresponding pair of Fields must have comparable <data type>s.\par
      ## The <distinct predicate> can't be used with BLOBs, CLOBs or NCLOBs.\par
\par
The <distinct predicate> is TRUE if the value of expression_1 is not equal to\par
the value of expression_2 -- that is, IS DISTINCT FROM is the same as the <>\par
<comparison predicate> in every way -- except one. If expression_1 is NULL and\par
expression_2 is NULL, this predicate returns UNKNOWN:\par
\par
   expression_1 <> expression_2\par
\par
(all comparisons return UNKNOWN if either argument is NULL). On the other hand, this predicate will return FALSE:\par
\par
   expression_1 IS DISTINCT FROM expression_2\par
\par
That is, two NULL values are not distinct from one other. And if expression_1 is NULL and expression_2 is non-null, this predicate returns UNKNOWN:\par
\par
   expression_1 <> expression_2\par
\par
On the other hand, this predicate will return TRUE:\par
\par
   expression_1 IS DISTINCT FROM expression_2\par
\par
That is, a NULL value is distinct from every non-null value. (For arrays, IS\par
DISTINCT FROM tests each corresponding pair of array elements. If the arrays\par
are empty, or if any element of the first array contains the same value as its\par
corresponding element in the second array, or if both elements are NULL, IS\par
DISTINCT FROM returns FALSE.) Except for the difference when NULLs are\par
involved, IS DISTINCT FROM is just a shorthand for the <> comparison, so the\par
same rules that apply for comparisons of specific <data type>s apply to IS DISTINCT FROM as well.\par
\par
## Retrieval with IS DISTINCT FROM\par
Here is a <distinct predicate> retrieval example from the sample Tables shown\par
at the beginning of this chapter. To find the names of employees who don't\par
live at 234 West (retrieve values that are distinct from a specified value):\par
\par
   SELECT gname,surname FROM Employee\par
   WHERE  address IS DISTINCT FROM '234 West';\par
\par
The result is:\par
\par
GNAME       SURNAME\par
JOHN        MARSH\par
MABEL       JONES\par
CHUCK       MORGAN\par
BOB         JONES\par
CHRIS       FRANCIS\par
LINDA       TURNER\par
CAROL       OLSEN\par
NANCY       WARREN\par
\par
Note that the final row is included in the result despite the fact that Nancy's Warren address is unknown; that is, there is a null value in the ADDRESS Column for that employee.\par
\par
If you want to restrict your code to Core SQL, don't use the <distinct predicate>.\par
\par
Search Conditions\par
\par
A search condition consists of one or more Boolean value expressions. A\par
Boolean value is either TRUE or FALSE or UNKNOWN. In SQL-92, only a predicate\par
can return TRUE, FALSE or UNKNOWN and therefore all search conditions are\par
predicates (or multiple predicates) with Boolean operators. In SQL3, the\par
definition is broader because there is another source for Boolean values,\par
namely <literal>s or Column values of <data type> BOOLEAN, therefore search\par
conditions might also contain values of <data type> BOOLEAN.\par
\par
Here are six examples of search conditions. The first two consist of a simple predicate and a simple Boolean, respectively. The other four are more complex: they contain Boolean operators.\par
\par
   x = 1\par
\par
   NOT x = 1\par
\par
   x = 1 AND y = 3\par
\par
   x = 1 OR y = 3\par
\par
   (boolean_column_1 OR boolean_column_2) IS FALSE\par
\par
We discussed the Boolean operators in our chapter on the BOOLEAN <data type>. Here's a quick recap.\par
      ## The IS [NOT] \{TRUE | FALSE | UNKNOWN\} Boolean operator is rarely\par
seen. Its effect is to change a Boolean value (which is TRUE or FALSE or\par
UNKNOWN) to either TRUE or FALSE. For example, given a search condition "(x =\par
5) IS UNKNOWN", if x is NULL then the predicate "x = 5" returns UNKNOWN,\par
therefore the search condition as a whole is TRUE.\par
      ## The NOT Boolean operator reverses TRUEs and FALSEs, but leaves\par
UNKNOWNs alone. There is a trap here: the search condition "NOT (x = 1)"\par
differs slightly from "(x = 1) IS FALSE" (you can see why if you assume again\par
that the value of x is NULL). In any case, "NOT (x = 1)" is a bad style choice\par
because people have trouble reading Boolean operators. The better choice is "(x <> 1)".\par
      ## The AND Boolean operator combines two Boolean values: if both are\par
TRUE, the result is TRUE. For example, this search condition is true: "5 > 0\par
AND 0 = 0 AND 0 <= 5". However, this search condition is false: "5 > 0 AND 0 = 0 AND 0 >0 5".\par
      ## The OR Boolean operator combines two Boolean values: if either one is TRUE, the result is TRUE.\par
\par
Search Conditions in Clauses:\par
Since an SQL3 search condition returns a Boolean value, it can be used in situations which would appear exotic/erroneous in SQL-92, for example:\par
\par
   SELECT (numeric_column=5)\par
   FROM   Table_1\par
   WHERE  boolean_column=(char_column LIKE 'A%');\par
\par
But our immediate interest is not exotica. We want to look at some plain\par
everyday clauses which contain search conditions as a matter of course. The\par
interesting thing about these clauses is that they contain implicit Boolean\par
operators. Here are the clauses and the implicit Boolean operators.\par
\par
Clause                             Implicit Boolean Operator\par
CHECK (in Constraint definition)   IS NOT FALSE\par
WHERE                              IS TRUE\par
WHEN (in a CASE expression)        IS TRUE\par
ON (for joining)                   IS TRUE\par
WHEN (in a Trigger definition)     "satisfies")\par
HAVING                             IS TRUE\par
\par
Notice that the implicit Boolean looks for TRUE in every case but one -- we\par
talked about the CHECK clause in our chapter on Constraints and Assertions and\par
noted that a condition that evaluates to UNKNOWN also satisfies a Constraint.\par
Everywhere else though, although SQL has lots of rules for generating and\par
manipulating UNKNOWN values, it normally throws them away in the final step of\par
a search. So, if you want to see results which are either TRUE or UNKNOWN, you\par
must force them through with this expression:\par
\par
   "... WHERE (search condition) IS NOT FALSE"\par
\par
Since IS NOT FALSE is evaluated before WHERE, all UNKNOWNs are converted to\par
TRUEs before the WHERE's implicit IS TRUE Boolean operator takes effect.\par
(Actually, most people don't want to see results which are UNKNOWN, but\par
forcing them through is handy if you want to simulate the effect of a CHECK Constraint search condition.)\par
\par
There is also an implicit Boolean AND operator between clauses. For example, this SQL statement:\par
\par
   SELECT Table_1.*,\par
          Table_2.*\par
   FROM   Table_1 INNER JOIN Table_2 ON Table_1.column_1 = Table_2.column_1\par
   WHERE  Table_1.column_2 = 5;\par
\par
is effectively the same as this SQL statement:\par
\par
   SELECT Table_1.*, \par
          Table_2.*\par
   FROM   Table_1, Table_2\par
   WHERE  Table_1.column_1 = Table_2.column_1 AND\par
          Table_1.column2 = 5;\par
\par
However, such a transformation ignores evaluation order. We'll get back to joins in a later chapter.\par
\par
## Some example searches\par
The main use of search conditions is to search. Let's try some examples on a small Table. This Table, which we'll call TEAMS, contains this data:\par
\par
TEAMS\par
CITY      TEAM_NAME   STADIUM_CAPACITY   STANDING   REVENUE\par
Calgary   Stampeders             45000          5   15000000.00\par
Edmonton  Eskimos                60000          4   20000000.00\par
Hamilton  Tiger Cats             22000          1   25000000.00\par
Montreal  Alouettes              18000          3   30000000.00\par
Regina    Roughriders            31000          6   35000000.00\par
Toronto   Argonauts              80000          2   40000000.00\par
Vancouver Lions                      ?          7   45000000.00\par
Winnipeg  Blue Bombers           31000          8   50000000.00\par
\par
Question: What city is represented by the Blue Bombers?\par
\par
   SQL query: SELECT city\par
              FROM   Teams\par
              WHERE team_name = 'Blue Bombers';\par
\par
   Answer: Winnipeg.\par
\par
Question: What teams, other than the Edmonton Eskimos, have stadia with a capacity of over 40000?\par
\par
   SQL query: SELECT team_name\par
              FROM   Teams\par
              WHERE  (city<>'Edmonton' OR team_name<>'Eskimos') AND\par
                     stadium_capacity > 40000;\par
\par
   Answer: Calgary, Toronto.\par
\par
Question: What teams, other than the Edmonton Eskimos, might have stadia with a capacity of over 40000?\par
\par
   SQL query: SELECT team_name\par
              FROM   Teams\par
              WHERE  (city<>'Edmonton' OR team_name<>'Eskimos') AND\par
                     (stadium_capacity > 40000 ) IS NOT FALSE;\par
\par
   Answer: Calgary, Toronto, Vancouver.\par
\par
Question: Show teams whose revenue per seat is more than $1000, as well as teams which are in the top half of the standings.\par
\par
   SQL query: SELECT team_name\par
              FROM   Teams\par
              WHERE  revenue/stadium_capacity > 1000 OR standing > 4;\par
\par
   Answer: Hamilton, Montreal, Regina, Winnipeg, Toronto, Edmonton.\par
\par
Question: Show all teams.\par
\par
   SQL query: SELECT *\par
              FROM   Teams\par
              WHERE  TRUE;\par
\par
   Answer: Calgary, Edmonton, Hamilton, Montreal, Regina, Toronto, Vancouver, Winnipeg.\par
\par
This SQL statement is the same as "SELECT * FROM Teams" and it shows an\par
interesting SQL3 development. Whereas in SQL-92 it was necessary to express\par
"always true" and "always false" with explicit literal expressions like "1 =\par
1" and "1 <> 2", it's now possible to use a simple <Boolean literal>.\par
\par
Here's a few more examples, this time from the sample Tables shown at the\par
beginning of this chapter. First, to find the employees who are located in the\par
basement or whose pay rate is between 5.00 and 6.00:\par
\par
   SELECT empnum,rate,location FROM Payroll\par
   WHERE  location='BASEMENT' OR rate BETWEEN 5 AND 6;\par
\par
The result is:\par
\par
EMPNUM      RATE        LOCATION\par
1           6.00        10TH FLOOR\par
2           5.00        16TH FLOOR\par
3           5.00        WAREHOUSE\par
4           8.00        BASEMENT\par
\par
To find the names of employees with employee numbers less than 10 who also work in Department B:\par
\par
   SELECT gname,surname FROM Employee\par
   WHERE  dept='B' AND empnum<10;\par
\par
The result is:\par
\par
GNAME    SURNAME\par
JOHN     MARSH\par
\par
SQL's <case expression>\par
\par
The CASE expression is not a filtering operation, but it fits in this context\par
because CASE specifies a conditional value: it takes a search condition as\par
input and returns a scalar value. The required syntax for the <case expression> is:\par
\par
<case expression> ::= <case abbreviation> | <case specification>\par
\par
   <case abbreviation> ::=\par
   NULLIF(<value expression> ,<value expression>) |\par
   COALESCE(<value expression> \{,<value expression>\}... )\par
\par
   <case specification> ::= <simple case> | <searched case>\par
\par
      <simple case> ::=\par
      CASE\par
         <value expression>\par
         \{WHEN <value expression> THEN <result>\}...\par
         [ ELSE <result> ]\par
      END\par
\par
      <searched case> ::=\par
      CASE\par
         \{WHEN <search condition> THEN <result>\}...\par
         [ ELSE <result> ]\par
      END\par
\par
         <result> ::= <value expression> | NULL\par
\par
The <case abbreviation>s NULLIF and COALESCE are both shorthands for a simple CASE expression. For example, this expression:\par
\par
   NULLIF(value_1,value_2)\par
\par
is equivalent to this expression:\par
\par
   CASE WHEN value_1=value_2 THEN NULL\par
      ELSE value_1\par
   END\par
\par
Use NULLIF when you have some special value instead of NULL, for example the displayable '?' to represent a null value.\par
\par
This expression:\par
\par
   COALESCE(value_1,value_2)\par
\par
is equivalent to this expression:\par
\par
   CASE WHEN value_1 IS NOT NULL THEN value_1\par
      ELSE value_2\par
   END\par
\par
And an expression containing more than two COALESCE values is equivalent to a series of COALESCE expressions, which are in turn equivalent to a series of CASE conditions. For example, this expression:\par
\par
   COALESCE(value_1,value_2,value_3)\par
\par
is equivalent to this expression:\par
\par
   CASE WHEN value_1 IS NOT NULL THEN value_1\par
      ELSE COALESCE(value_2,value_3)\par
   END\par
\par
A simple CASE expression operates on a <value expression>: any expression that\par
returns a scalar value, except for a routine that is possibly\par
non-deterministic or that might modify SQL-data. The <data type> of this CASE\par
operand must be comparable with the <data type> of the WHEN clause's <value\par
expression>(since the simple CASE expression compares the two to see if they\par
are equal) and with the ELSE clause's <result>. (If you omit the ELSE clause,\par
it defaults to ELSE NULL.)\par
\par
A searched CASE expression also operates on a <value expression> that must be\par
comparable with the <data type> of the WHEN clause's operands and the <data\par
type> of the ELSE clause's <result>. You may specify any appropriate search\par
condition in a searched CASE expression's WHEN clause. Once again, the CASE\par
operand may be any expression that returns a scalar value, except for a\par
routine that is possibly non-deterministic or that might modify SQL-data, and\par
the default ELSE clause is ELSE NULL.\par
\par
Here are two equivalent examples of CASE expressions (the first example is a searched CASE, the second is a simple CASE)\par
\par
   CASE\par
      WHEN column_1 = 1 THEN 'one!'\par
      WHEN column_1 = 2 THEN 'two!'\par
      ELSE 'many'\par
   END\par
\par
   CASE column_1\par
      WHEN 1 THEN 'one!'\par
      WHEN 2 THEN 'two!'\par
      ELSE 'many'\par
    END\par
\par
The searched CASE expression works as follows:\par
      ## Find the first WHEN clause whose search condition is TRUE. Return the value given in that WHEN clause's THEN sub-clause.\par
      ## If no WHEN search condition is TRUE, return the value given in the ELSE clause.\par
      ## All returnable values (in THEN clauses and in the ELSE clause) must have <data type>s that are comparable with the CASE operand.\par
      ## At least one of the THEN values must be non-null. For example, this expression is not legal:\par
\par
   CASE column_1\par
     WHEN 1 THEN NULL\par
      ELSE NULL\par
   END\par
\par
The simple CASE expression works the same way -- simple CASE is merely a\par
shorthand form of searched CASE, where each WHEN clause is taken to mean "WHEN\par
case operand = when expression".\par
\par
We prefer to use searched CASE expressions on stylistic grounds, but many\par
people prefer simple CASE expressions because they're similar to Pascal's\par
case, or C's switch. (Notice, however, that the parallels are inexact, because\par
SQL's CASE is an expression, while Pascal's case and C's switch are statements.)\par
\par
We will now repeat one of the questions that we asked in the previous section, about the TEAMS Table.\par
\par
Question: What city is represented by the Blue Bombers?\par
\par
   SQL query: SELECT CASE\par
                        WHEN team_name = 'Blue Bombers' THEN city\par
                        ELSE '*********'\par
                     END AS city\par
              FROM Teams;\par
   Answer:\par
\par
   CITY\par
   *********\par
   *********\par
   *********\par
   *********\par
   *********\par
   *********\par
   *********\par
   Winnipeg\par
\par
The answer is the same, but with a lot of dross. It's possible to use CASE\par
expressions this way as retrieval substitutes, but the more common\par
applications are (a) to make up for SQL's lack of an enumerated <data type>,\par
(b) to perform complicated if/then calculations, (c) for translation and (d)\par
to avoid exceptions. We find CASE expressions to be indispensable, and it\par
amazes us that in pre-SQL-92 DBMSs they didn't exist.\par
\par
Rules of Aggregation:\par
The THEN values in a CASE expression, as well as the results of set operations\par
or arrays, are considered to be aggregations; that is, they have a <data type>\par
that is determined by evaluating the <data type>s of each value in a set. The\par
aggregation rules determine which <data type>s are compatible, and what the\par
<data type> of the result is. Stated in a very general way, the aggregation\par
rules are that "what's compatible for assignment is compatible for\par
aggregation", "varying trumps fixed" and "long trumps short". More specifically:\par
      ## All numeric -- INT, SMALLINT, NUMERIC, DECIMAL, FLOAT, REAL, DOUBLE\par
PRECISION -- values are compatible. If any aggregated value is approximate\par
numeric, the result is approximate numeric; otherwise the result is exact\par
numeric and the result's scale is the biggest scale of any of the aggregated\par
values. For example, this expression:\par
\par
   CASE ...\par
      THEN CAST(x AS DECIMAL(9)) ...\par
      THEN CAST (y AS DECIMAL(5,3))\par
      ELSE NULL\par
   END\par
\par
should return a result with a <data type> of DECIMAL(9,3). (We say should\par
because some of the decisions here are implementation-defined -- the only\par
guaranteed facts are that the scale will be 3 and the <data type> will be some\par
sort of exact numeric.)\par
      ## All BIT or BIT VARYING values are compatible. If any aggregated value\par
is a BIT VARYING then the result is a BIT VARYING; otherwise the result is a\par
BIT. The result's length is the length of the longest aggregated value. For\par
example, if a Table was defined with "... column_1 BIT(5),column_2 BIT VARYING(4) ...", this expression:\par
\par
   CASE ... THEN column_1 ... ELSE column_2 END\par
\par
will return a result with a <data type> of BIT VARYING(5).\par
      ## All BLOB values are compatible.\par
      ## All CHAR, NCHAR, VARCHAR, NCHAR VARYING, CLOB and NCLOB values are\par
compatible, provided the Character set is the same. If any aggregated value is\par
a CLOB then the result is a CLOB; otherwise if any value is a VARCHAR then the\par
result is a VARCHAR; otherwise the result is a CHAR. The result's length is\par
the length of the longest aggregated value. The result's Collation will depend\par
on coercibility; see the appropriate tables in our chapter on character\par
strings. For example, this expression:\par
\par
   CASE ... THEN 'a' ... THEN 'abcd' ... ELSE 'abc' END\par
\par
will return a result with a <data type> of CHAR(4), because <character string\par
literal>s are fixed-length character strings and the size of the largest\par
aggregated <literal> is 4 characters.\par
      ## All DATE values are compatible.\par
      ## All TIME and TIME WITH TIME ZONE values are compatible. If any\par
aggregated value is TIME WITH TIME ZONE, the result is TIME WITH TIME ZONE;\par
otherwise the result is TIME. The fractional precision of the result is the\par
largest fractional precision of any of the aggregated values.\par
      ## All TIMESTAMP and TIMESTAMP WITH TIME ZONE values are compatible. If\par
any aggregated value is TIMESTAMP WITH TIME ZONE, the result is TIMESTAMP WITH\par
TIME ZONE; otherwise the result is TIMESTAMP. The fractional precision of the\par
result is the largest fractional precision of any of the aggregated values.\par
      ## All year-month INTERVAL values are compatible. The datetime fields of\par
the result are from the earliest to the latest fields in any aggregated value.\par
For example, this expression:\par
\par
   CASE ... THEN INTERVAL '1' YEAR ... THEN INTERVAL '1' MONTH END\par
\par
will return a result with a <data type> of INTERVAL YEAR TO MONTH.\par
      ## All day-time INTERVAL values are compatible. The datetime fields of the result are from the earliest to the latest fields in any aggregated value.\par
      ## All BOOLEAN values are compatible.\par
      ## All REF values of the same referenced type (UDT) are compatible.\par
      ## ALL UDT values whose most specific types have some common supertype are compatible.\par
\par
If you want to restrict your code to Core SQL, don't use BLOBS, CLOBs or NCLOBs in a CASE expression.\par
\par
Dialects\par
\par
The truth is, most vendors are just starting to get used to the SQL-92 search\par
conditions, so don't depend heavily on these SQL3 features:\par
      ## BOOLEAN <data type>\par
      ## <distinct predicate>\par
      ## SYMMETRIC <between predicate>\par
\par
You'll find even stricter limitations if you don't use a fairly powerful DBMS\par
-- there are some that don't support row-value comparisons, IS [NOT]\par
\{TRUE|FALSE|UNKNOWN\} and the more difficult predicates (e.g.: MATCH and OVERLAPS).\par
\page\par
Chapter 30 -- Searching with Joins\par
\par
It's France in the 1600s. Rene Descartes is playing cards with Madame du\par
Barry. The game is War. Each player has a deck. Rene plays a card from the top\par
of his deck. Madame du Barry plays a card from the top of her deck. If Rene's\par
card has a higher value then Madame's, he wins the trick. If his card has a\par
lower value, Madame wins the trick. In the case of a tie, each player throws\par
down another card. They repeat this until one player has all the tricks, or\par
until Rene and Madame think of something more interesting to do (it's France in the 1600s).\par
\par
In set theory, each trick is an ordered two-element pair. There are (52*52)\par
possible first-round combinations. To honor Mr Descartes, we call the set of\par
all possible tricks the Cartesian product of the two original (deck) sets. Two valuable insights arise from playing the game:\par
      ## Insight: What matters is the values on the cards. There are no\par
threads connecting the queens in Rene's deck to the queens in Madame's deck.\par
There are no notes on each card saying "I match the nth card from the top in\par
the other deck". There are, in other words, no pointers -- in the real world, we match based on values.\par
      ## Insight: Slow, tedious meaninglessness. We recognize that there is\par
always conceptually a Cartesian product, but we would like as quickly as\par
possible to filter out the only interesting cases -- the ties (the 52*4 cases\par
where the cards' face values are equal).\par
\par
The first insight is the basis of relational-database theory. The second is a warning that we want to minimize the undesirable consequences of joined Tables.\par
\par
Joined Tables\par
\par
The SQL definition for a joined Table is: a Table derived from a Cartesian\par
product, an inner join, an outer join or a union join. The required syntax for a joined Table is:\par
\par
<joined Table> ::=\par
<Table reference> CROSS JOIN <Table reference> |\par
<Table reference> [ NATURAL ] [ <join type> ] JOIN <Table reference>\par
   [ <join specification> ] |\par
( <joined Table> )\par
\par
   <join type> ::=\par
   INNER |\par
   \{LEFT | RIGHT | FULL\} [ OUTER ] |\par
   UNION\par
\par
   <join specification> ::=\par
   ON <search condition> |\par
   USING (join <Column name> [ \{,join <Column name>\} ... ])\par
\par
Basically, a joined Table is the result of some expression that represents an\par
explicit join of two Tables, each of which is identified by a <Table\par
reference> (the <Table reference> could itself be a joined Table, but is\par
usually just a <Table name> or a Table identified by a <Correlation name>, and\par
we'll use only that form for now). We'll use a library database with these\par
Tables in all the examples of joins that follow. Here's our data:\par
\par
BORROWERS\par
NAME      BORROWER_ID   PARENT\par
Paige     1             Barbara\par
Hayley    2             Barbara\par
Jaclyn    3             Christa\par
Christa   4             Edith\par
Barbara   5             Edith\par
Edith     6             NULL\par
\par
CHECKOUTS\par
BORROWER_ID   BOOK_ID\par
1            1\par
2            2\par
2            3\par
\par
BOOKS\par
CHECKOUT_DATE     BOOK_ID     TITLE\par
1999-04-27        1           The Borrowers\par
1999-04-28        2           The Unexpected Mrs. Pollifax\par
1999-04-29        3           The Hobbit\par
NULL              4           Friday\par
\par
Our example database illustrates a very common Humans --> Transactions -->\par
Objects framework, which appears in many businesses -- (Customers --> Sales\par
--> Products), (Clients --> Deposits_Withdrawals --> Accounts), (Workers -->\par
Shifts --> Tasks) -- so think of your own analogies for each example of a join situation that follows.\par
\par
Cartesian-filter Join:\par
"List titles for all Books checked out on April 27"\par
\par
Our answer to this question -- the first of several answers -- will use the traditional syntax, which is legal in all versions of SQL:\par
\par
   SELECT title\par
   FROM   Books, Checkouts\par
   WHERE  checkout_date = DATE '1999-04-27' AND\par
          Books.book_id = Checkouts.book_id;\par
\par
In this SELECT statement, the words "FROM Books, Checkouts" tell the DBMS we\par
want a Cartesian join of BOOKS and CHECKOUTS. That gives us four\par
BOOKS/CHECKOUTS pairs. But the WHERE conditions filter out the unwanted pairs\par
and leave us with only one.\par
\par
When we think of both the WHERE clause conditions as "filters" that winnow the\par
results from an imagined Cartesian BOOKS+CHECKOUTS Table, the two conditions\par
both appear to be doing similar tasks. It appears natural that both conditions\par
should be in the WHERE clause. Now, here is a niggle: it's not real. You are\par
supposed to conceptualize that a Cartesian product is formed and then\par
filtered, but -- since the number of rows in a Cartesian product is always the\par
number of rows in each individual Table multiplied by each other -- its size\par
rises geometrically as database size rises, so the DBMS will avoid it and\par
quietly use a navigational trick instead ("first find a CHECKOUTS row where\par
CHECKOUT_DATE = April 27, then take the BOOK_ID of that checkout and find\par
BOOK_ID within BOOKS ...").\par
\par
Efficiency of evaluation isn't the subject of this chapter, though. Right now\par
we're only concerned with the fact that Cartesian products are a simplifying\par
myth. Unfortunately, to programmers aware of the myth, it is obvious that the\par
two conditions in the WHERE clause are not really the same sort of thing. One\par
is a typical filter, but the other is a glue directive to the DBMS. It's not\par
really a WHERE sort of condition at all.\par
\par
Cartesian-filter Join II: CROSS JOIN:\par
As shown in our syntax diagram earlier, we could use the <keyword>s "CROSS\par
JOIN" instead of a comma in the FROM clause to get the same result:\par
\par
   SELECT title\par
   FROM   Books CROSS JOIN Checkouts\par
   WHERE  checkout_date = DATE '1999-04-27' AND\par
          Books.book_id = Checkouts.book_id;\par
\par
This is synonymous with the "... FROM Books, Checkouts ..." query (CROSS JOIN\par
just means "Cartesian product"), and it's too bad we didn't use English words\par
instead of commas in the first place, but CROSS JOIN is relatively new (a\par
SQL-92 introduction).\par
\par
JOIN ... USING:\par
We're still asking: "List titles for all Books checked out on April 27". This time we will use the modern syntax:\par
\par
   SELECT title\par
   FROM   Books INNER JOIN Checkouts USING (book_id)\par
   WHERE  checkout_date = DATE '1999-04-27';\par
\par
For some years to come, the conventional syntax for joins (our first example)\par
will still be the most popular. However, modern syntax (of which JOIN ...\par
USING is the best example) is now seen frequently in tutorials and magazine\par
articles, especially when Microsoft Access is the subject. In modern syntax,\par
we acknowledge that joining conditions might look better in a clause of their\par
own. The clause "USING (book_id)" replaces the traditional "WHERE ...\par
Books.book_id = Checkouts.book_id". Thus, BOOK_ID is a reference to both\par
BOOK_ID Columns -- the one in the BOOKS Table and the one in the CHECKOUTS\par
Table. It's not a piece of luck, you know, that we used the same <Column name>\par
in both Tables -- you should always use the same <Column name> when you\par
anticipate joining over a pair of Columns.\par
\par
NATURAL JOIN:\par
The ultimate simplification of JOIN ... USING is to throw out the <Column\par
name>s entirely, and specify "wherever <Column name>s are the same in both\par
Tables, join on them". Here's how:\par
\par
   SELECT title\par
   FROM   Books NATURAL JOIN Checkouts\par
   WHERE  checkout_date = DATE '1999-04-27';\par
\par
A natural join is a join over matching Columns (Columns which have the same\par
name in the Tables being joined). This is the ultimate step. It hides the join\par
process from the user who gets the result. Perhaps, one could even change the\par
join <Column name>s, or add new Columns, without having to change all SELECT\par
statements which refer to the joined Tables. On the other hand, users of\par
NATURAL JOIN have to be careful that all joinable Columns really do have the\par
same name, and that all non-joinable Columns don't. The casual-looking "Books\par
NATURAL JOIN Checkouts" is only possible when database naming conventions are formal and enforced.\par
\par
In some places, the custom is to use NATURAL JOIN for only one class of\par
situations: where one is joining a Table with a FOREIGN KEY Constraint to the\par
Table that the foreign key REFERENCES. Such a join is, due to the way that\par
primary/foreign keys work, always a "one-to-many" join (that is: there will\par
always be only one row in TABLE_1 which is joined with between zero and infinity rows in TABLE_2).\par
\par
JOIN ... ON:\par
There is one more way to "List titles for books checked out on April 27":\par
\par
   SELECT title\par
   FROM   Books INNER JOIN Checkouts ON (Books.book_id = Checkouts.book_id)\par
   WHERE  checkout_date = DATE '1999-04-27';\par
\par
With this syntax, the ON clause introduces a conditional expression for a\par
join: it contains a conditional expression just like a WHERE clause does.\par
Legally, you could take all the conditions out of the WHERE clause and put\par
them in the ON clause, but that would flout the principle of the exercise,\par
which is: "ON clauses should have joining conditions, WHERE clauses should\par
have filtering conditions". Earlier we discussed why this syntax just looks\par
better, to some people, than the conventional syntax. Later we'll discuss one\par
situation where you must use ON rather than WHERE, but the current example is\par
not one of those situations. The more immediate question is: why would we ever\par
want to use ON rather than USING? The immediate reply is: well, USING is only\par
possible when you're joining over two Columns with the same name and when the\par
relator is implicitly equality ("="). Joins can, of course, also be related\par
using the other SQL comparison operators too.\par
\par
Self-Joins:\par
Here's a new question: "List parents with their children".\par
\par
Among our library's borrowers are several children. Their parents also have\par
cards (it's one of the conditions of membership for child borrowers). That is,\par
there is a relationship between different rows of the same Table. When we have\par
a query that bases itself on an intra-Table relationship, we must join the\par
Table with itself -- this is called a self-join and is one of the rare cases\par
where SQL provides no alternative means of answering the query. Here's an example:\par
\par
   SELECT Parents.name,\par
          Children.name\par
   FROM   Borrowers AS Parents,\par
          Borrowers AS Children\par
   WHERE  Parents.name = Children.parent;\par
\par
The result is:\par
\par
NAME      NAME\par
Barbara   Paige\par
Barbara   Hayley\par
Christa   Jaclyn\par
\par
In a self-join, by definition, all the Columns in the first Table have the\par
same names as the Columns in the second Table. So we can't "SELECT name ..."\par
or even "SELECT Borrowers.name ..." -- such expressions are ambiguous. This is\par
a case where we absolutely must use a <Correlation name> to explicitly\par
identify each Table, and each Column of a particular Table. Here, we've given\par
one copy of the BORROWERS Table the <Correlation name> PARENTS, and the other\par
the <Correlation name> CHILDREN, so as to be able to distinguish between them.\par
\par
Theta-Joins:\par
A theta-join is any Cartesian product that's filtered by a condition which compares values from both Tables. That is, the general theta-join form is:\par
\par
   <Table_1.Column> relator <Table_2.Column>\par
\par
where the relator is almost always "=", as in this example:\par
\par
   Sellers.seller_name = Sales.seller_name\par
\par
This special case of theta-join -- where the relation is equality -- is called an equijoin. Although all relators are legal, the other kinds of theta-join are, in fact, rare.\par
\par
In a typical programming life, you'll never encounter a lone theta-join (or if\par
you do, you're looking at some sort of an error). The common cases are always\par
double theta-joins. Here is an example:\par
\par
## double theta: > combined with equijoin\par
"List identification numbers of borrowers who took out books on two different days"\par
\par
To answer this request, we need to use a greater than operator, so this is an\par
example of a general theta-join -- but it's also an equijoin. Here are two\par
ways of doing it (the first example uses the WHERE clause to set the\par
conditions and the second example uses the ON clause for the same purpose):\par
\par
      -- <with WHERE>\par
   SELECT DISTINCT Firsts.borrower_id\par
   FROM   Checkouts Firsts, Checkouts Seconds\par
   WHERE  Firsts.date > Seconds.date AND\par
          Firsts.borrower_id = Seconds.borrower_id;\par
\par
   --  <with ON>\par
   SELECT DISTINCT Firsts.borrower_id\par
   FROM Checkouts Firsts, Checkouts Seconds\par
   ON   (Firsts.borrower_id = Seconds.borrower_id) AND\par
        (Firsts.date > Seconds.date);\par
\par
(Remember that the <keyword> AS is optional when you're defining a <Correlation name>.) The result is:\par
\par
BORROWER_ID\par
2\par
\par
*** TIP: For queries containing the word "different", consider whether a ">" will do. Queries with > are often a bit faster than queries with <>.\par
\par
The double theta-join is, in practice, often associated with a self-join. Sometimes the relators are <= and >= (for instance, when we join over a floating-point number).\par
\par
Bad Joins:\par
"List all the borrowers whose names appear in a book title, and the book titles"\par
\par
   SELECT Borrowers.name, Books.title\par
   FROM   Borrowers INNER JOIN Titles\par
   ON     (POSITION(TRIM(Borrowers.name) IN Books.title) > 0)\par
\par
The result is no rows found.\par
\par
It might please 'Paige' to find her name on a book: 'The book of Paige ...'. The syntax is technically legal. The reasons that we use this as a bad join example are:\par
      ## The Domain of BORROWERS.NAME is not the same as the Domain of\par
BOOKS.TITLE, and there are no Columns common to BORROWERS and BOOKS which\par
would qualify for a NATURAL JOIN. Together, these two observations are always\par
signs that a query is frivolous, if not downright erroneous.\par
      ## The joining expression contains a scalar, and has both Columns on the same side of the relator. Together, these two characteristics will choke every DBMS currently in existence.\par
\par
Allow the query, of course. But, for critical and common situations, use only simple expressions, on related Tables, over similar Columns. Odd syntax is bad syntax.\par
\par
Joins with multiple Tables:\par
"List titles and borrowers for books taken out on April 27"\par
\par
The answer is straightforward -- once you know two-Table joins you can also do three-Table joins:\par
\par
   SELECT DISTINCT Borrowers.name, Books.title\par
   FROM   Borrowers, Checkouts, Books\par
   WHERE  Borrowers.borrower_id = Checkouts.borrower_id AND\par
          Books.book_id = Checkouts.book_id AND\par
          Checkouts.checkout_date = DATE '1999-04-27';\par
\par
The result is:\par
\par
NAME    TITLE\par
Paige   The Borrowers\par
\par
It should be possible in a 3-way join to follow a chain of links as a reading\par
exercise. In this case, if we start with the first Table (BORROWERS), we can\par
see that it's possible to go from there to CHECKOUTS (using the BORROWER_ID\par
Column), and from CHECKOUTS to BOOKS (using the BOOK_ID Column). If there is\par
no chain, think hard: maybe the query "goes Cartesian" during some intermediate stage.\par
\par
*** TRAP: The next query looks like it does the same thing. In fact, though, it is an example of the most common mistake that can happen with multi-Table joins:\par
\par
   SELECT DISTINCT Borrowers.name, Books.title\par
   FROM   Borrowers, Books\par
   WHERE  Borrowers.borrower_id IN\par
      (SELECT borrower_id\par
       FROM   Checkouts\par
       WHERE  checkout_date = DATE '1999-04-27') AND\par
              Books.book_id IN\par
                (SELECT book_id\par
                 FROM   Checkouts\par
                 WHERE checkout_date = DATE '1999-04-27');\par
\par
The error is in the assumption that "if A is linked to B and C is linked to B,\par
then C is linked to A". That sounds like fundamental arithmetic (the Law Of\par
Transitivity) -- but it's wrong in this case because B is not a value -- it is\par
a set of values -- and the IN predicate means "... linked to any one of (B)\par
...". When writing a multi-Table join, an intermediate link should be true\par
"for all", not just "for any".\par
\par
What about 4-Table, 5-Table, 6-Table joins? Yes, as long as you remember that\par
adding a new Table adds time to your query geometrically. Eventually you will\par
run into a fixed limit for every DBMS. To conform with the US government's\par
requirements (FIPS 127-2), an "intermediate level" SQL DBMS must be able to\par
join at least 10 Tables. If you find yourself needing more than that, you\par
might want to consider either (a) splitting up your query using temporary\par
Tables or (b) combining two Tables into one ("denormalizing").\par
\par
Avoiding duplicates:\par
"List names of borrowers who have taken out books"\par
\par
To get the result, you can use any join syntax you like, provided you include DISTINCT in your select list. Here's an example:\par
\par
   SELECT DISTINCT name\par
   FROM   Borrowers, Checkouts\par
   WHERE  Borrowers.borrower_id = Checkouts.borrower_id;\par
\par
The result is:\par
\par
NAME\par
Paige\par
Hayley\par
\par
Without DISTINCT, we would see 'Hayley' twice in the result, because Hayley\par
took out two books. Any join can cause duplication unless both sides of the\par
join are unique keys. So we are tempted to say: "always use DISTINCT when you\par
join" ... but that would be a false tip. True, you want to eliminate\par
duplicates caused in this case by the join, but what if there are two Hayleys?\par
That is, do you want to eliminate duplicates which were not caused by the\par
join? Some people would answer "yes I do", and would add "duplicate\par
information isn't real information anyway". We'll contrive an example, then:\par
(a) we want to hand out name cards to borrowers who took books out, so this\par
list is going to a printer and (b) assume that there are two different\par
'Hayley's, one of whom took out two books. If we form a query using DISTINCT,\par
we'll get too few 'Hayley' cards -- but if we don't use DISTINCT we'll get too\par
many 'Hayley' cards. For such situations, the real tip is: use a subquery, like this:\par
\par
   SELECT name\par
   FROM   Borrowers\par
   WHERE  borrower_id IN (SELECT borrower_id FROM Checkouts);\par
\par
This query neither generates nor eliminates duplicates, so would be better. We'll talk more about subqueries in a later chapter.\par
\par
Amusing story: There once was a vendor who secretly converted all subqueries\par
into joins (the transform is fairly easy), and that vendor's DBMS produced\par
spurious duplicate rows when subqueries were used. Instead of admitting this,\par
that vendor's employees wrote an "SQL textbook" informing the public that\par
false duplicates were a necessary evil of Standard SQL! The vendor is still around and sells thousands of copies a month.\par
\par
OUTER JOIN:\par
"List all books, along with the dates they were checked out and who borrowed them (if they're out)".\par
\par
This query will give us the NATURAL JOIN of the BOOKS and CHECKOUTS Tables:\par
\par
   SELECT DISTINCT Books.title,\par
                   Books.checkout_date,\par
                   Checkouts.borrower_id\par
   FROM   Books NATURAL JOIN Checkouts;\par
\par
The result is:\par
\par
TITLE                           CHECKOUT_DATE       BORROWER_ID\par
The Borrowers                   1999-04-27        1\par
The Unexpected Mrs. Pollifax    1999-04-28        2\par
The Hobbit                      1999-04-29        2\par
\par
There is one book missing from the list. At this point, most people will say\par
"What about 'Friday'? I realize it's not in the CHECKOUTS Table, but that very\par
fact is important to me. It seems your join will always lose information\par
unless both Tables have the same set of matching keys."\par
\par
True -- but there is a way around this. Let's give 'Friday' a checkout:\par
\par
   INSERT INTO Checkouts VALUES (NULL,4);\par
\par
Now, when we do the NATURAL JOIN again, we get this result:\par
\par
TITLE                           CHECKOUT_DATE       BORROWER_ID\par
The Borrowers                   1999-04-27        1\par
The Unexpected Mrs. Pollifax    1999-04-28        2\par
The Hobbit                      1999-04-29        2\par
Friday                          NULL              NULL\par
\par
... and that's your answer. (Incidentally we inserted NULL in the BORROWER_ID Column because the book wasn't really checked out, so no one's ID could apply.)\par
\par
"So, to band-aid your broken join you invent an ad-hoc CHECKOUTS row that matches. I can imagine what your idea of a general solution would be."\par
\par
Exactly. The general solution would be imaginary rows. In fact, we don't really have to insert them all, we can just pretend they're there -- and call what we're doing an OUTER JOIN.\par
\par
"Okay."\par
\par
But is it really okay? It's true that the OUTER JOIN has answered the example\par
question: an OUTER JOIN will answer any question of the form "give me the join\par
of Table A and Table B without losing information from Table A." So, sure it's\par
okay, as long as we keep in mind that there's a band-aid involved. In\par
particular -- what is this NULL? Certainly it does not mean UNKNOWN. Remember,\par
we're not uncertain what the BORROWER_ID is; on the contrary, we know\par
perfectly well that there is no BORROWER_ID for 'Friday'.\par
\par
SQL actually provides us with "official" syntax to express an OUTER JOIN request:\par
\par
   SELECT Books.title, Books.checkout_date, Checkouts.borrower_id\par
   FROM   Checkouts RIGHT OUTER JOIN Books USING (book_id);\par
\par
Our example is a "right" outer join because, although we have everything in\par
the right (second) Table (which is BOOKS), there are implied NULLs in the left\par
(first) Table (which is CHECKOUTS). In such cases, the <keyword> RIGHT is\par
mandatory (although the <keyword> OUTER is optional). You must always use\par
RIGHT [OUTER] JOIN in conjunction with a USING clause or an ON clause --\par
though a query can certainly also include a WHERE clause, it should not\par
contain the joining conditions.\par
\par
Since there are RIGHT [OUTER] JOINs, there ought to be LEFT [OUTER] JOINs too,\par
and indeed there are. For instance, we could have made our query this way:\par
\par
   SELECT Books.title, Books.checkout_date, Checkouts.borrower_id\par
   FROM   Books LEFT OUTER JOIN Checkouts USING (book_id);\par
\par
There is also a FULL [OUTER] JOIN, for situations when there might be missing information from both joined Tables. This is rarely used.\par
\par
To summarize: the basic idea behind an OUTER JOIN is that, where an INNER JOIN\par
would lose rows because there is no row in one of the joined Tables that\par
matches a row in the other Table, an OUTER JOIN includes such rows -- with a\par
NULL in the Column positions that would show values from some matching row, if\par
a matching row existed. An INNER JOIN loses non-matching rows; an OUTER JOIN\par
preserves them. For two Tables, a LEFT OUTER JOIN preserves non-matching rows\par
from the first Table, a RIGHT OUTER JOIN preserves non-matching rows from the\par
second Table and a FULL OUTER JOIN preserves non-matching rows from both Tables.\par
\par
Consider using OUTER JOIN if you worry that INNER JOIN would lose information\par
that is really valuable. But if you use them a lot, that's too often. There\par
are severe consequences to using outer joins unnecessarily:\par
      ## Outer-Join-Downside #1: Performance. Inner joins are always faster.\par
      ## Outer-Join-Downside #2: Syntax. Although all the major vendors are now able to handle the SQL-92 Standard syntax for outer joins, there is a bewildering variety of "outer join" syntaxes still in existence.\par
      ## Outer-Join-Downside #3: Three-way-join confusion. Let's face it,\par
we're not bright enough to figure out what "Table_1 LEFT JOIN Table_2 RIGHT\par
JOIN Table_3" means. And it appears that not all vendors are bright either.\par
Trying multiple outer joins with different DBMSs will give different results.\par
      ## Outer-Join-Downside #4: Nullability. You can't think "Column X was defined as NOT NULL so it will never be NULL" -- any Column can be NULL if it's in an OUTER JOIN.\par
      ## Outer-Join-Downside #5: confused NULL. We can't tell whether a NULL is due to an OUTER JOIN or was always there.\par
\par
UNION JOIN:\par
A UNION JOIN constructs a result Table that includes every Column of both\par
Tables and every row of both Tables. Every Column position that has no value\par
because it wasn't part of one or the other Table you're joining, gets a null\par
value. Here's an example:\par
\par
   SELECT Checkouts UNION JOIN Books;\par
\par
The result is:\par
\par
BORROWER_ID BOOK_ID     CHECKOUT_DATE  BOOK_ID    TITLE\par
1             1         NULL           NULL       NULL\par
2             2         NULL           NULL       NULL\par
2             3         NULL           NULL       NULL\par
NULL          NULL      1999-04-27     1          The Borrowers\par
NULL          NULL      1999-04-28     2          The Unexpected Mrs. Pollifax\par
NULL          NULL      1999-04-29     3          The Hobbit\par
NULL          NULL      NULL           4          Friday\par
\par
Joined Tables aren't updatable in SQL-92. Usually, this means that a View\par
which is based on a query that joins multiple Tables can't be the object of a\par
DELETE, INSERT or UPDATE statement.\par
\par
But such Views might be updatable in SQL3. For example, a UNION JOIN is useful\par
in SQL3 because it allows you to change the joined data. Consider a situation\par
where you want to INSERT a row into a UNION JOIN of two Tables, where the\par
first Table has five Columns and the second Table has six Columns (so the\par
UNION JOIN has 11 Columns). There are three possible situations:\par
      ## If the first 5 Columns of the new row are all NULL and any of the\par
last six Columns are a non-null value, then the INSERT operation strips off\par
the first 5 NULLs and puts the remaining new row into the second Table.\par
      ## If any of the first 5 Columns of the new row are a non-null value and\par
all of the last six Columns are NULL, then the INSERT operation strips off the\par
last six NULLs and puts the remaining new row into the first Table.\par
      ## If any of the first 5 Columns of the new row are a non-null value and\par
any of the last six Columns are also a non-null value, then the INSERT\par
operation will fail: your DBMS will return the SQLSTATE error 22014 "data\par
exception-invalid update value".\par
\par
Now consider a situation where you want to DELETE a row from the same UNION JOIN. This time, there are two possible situations:\par
      ## If the row you want to DELETE was derived from the first Table (that\par
is, the row contains only NULLs for every Column derived from the second\par
Table), then the DELETE operation will remove that row from the first Table.\par
      ## If the row you want to DELETE was derived from the second Table, then the DELETE operation will remove that row from the second Table.\par
\par
Finally, consider a situation where you want to UPDATE a row from the same\par
UNION JOIN. Once again, there are three possible situations:\par
      ## If the row you want to UPDATE was derived from the first Table (and so the last six Columns of the row are NULL), then the UPDATE operation will change that row in the first Table.\par
      ## If the row you want to UPDATE was derived from the second Table (and\par
so the first five Columns of the row are NULL), then the UPDATE operation will\par
change that row in the second Table.\par
      ## If any of the first 5 Columns of the row you want to change are a\par
non-null value and any of the last six Columns are also a non-null value, then\par
the UPDATE operation will fail: your DBMS will return the SQLSTATE error 22014\par
"data exception-invalid update value".\par
\par
Syntax rules\par
\par
Now that we've shown you an example of each type of join, here's a list of the\par
formal syntax rules you'll have to follow when forming a join expression.\par
First, we'll repeat the join syntax itself:\par
\par
<joined Table> ::=\par
<Table reference> CROSS JOIN <Table reference> |\par
<Table reference> [ NATURAL ] [ <join type> ] JOIN <Table reference>\par
   [ <join specification> ] |\par
( <joined Table> )\par
\par
   <join type> ::=\par
   INNER |\par
   \{LEFT | RIGHT | FULL\} [ OUTER ] |\par
   UNION\par
\par
   <join specification> ::=\par
   ON <search condition> |\par
   USING (join <Column name> [ \{,join <Column name>\} ... ])\par
\par
You can't join over BLOBs, CLOBs, NCLOBs or ARRAYs, so don't name any Column\par
with one of these <data type>s in a USING clause and don't expect a NATURAL\par
JOIN to join over such Columns either.\par
\par
If your join expression specifies NATURAL, it may not include either an ON\par
clause or a USING clause: your DBMS will just search out the Columns with the\par
same name and equal values in each Table. The common Columns must have mutually comparable <data type>s.\par
\par
If your join expression specifies UNION, it may not also specify NATURAL, nor\par
may it include an ON clause or a USING clause: your DBMS will merely join\par
every Column in each Table together, for all rows in both Tables.\par
\par
If your join expression doesn't specify either NATURAL or UNION, then it must\par
include either an ON clause or a USING clause, to tell your DBMS what the join conditions are.\par
\par
If your join expression is "Table_1 NATURAL JOIN Table_2", the effect is the same as if you specified "Table_1 NATURAL INNER JOIN Table_2" -- so non-matching rows won't be part of the result Table.\par
\par
If you want to restrict your code to Core SQL, don't use CROSS JOIN, don't use UNION JOIN, don't use NATURAL for any type of join and don't use FULL [OUTER] JOIN.\par
\par
Retrieval using joins:\par
The ability to join a Table to others is one of the most powerful features of\par
SQL. Here's some more examples of joins, using the sample database we defined\par
in our chapter on simple search conditions. Remember that, to join Tables, the\par
select list must contain the unambiguous names of the desired Columns, and the\par
ON, USING or WHERE clause must specify the conditions which define the\par
relationship between them. (The relationship is usually equality, but it need\par
not be.) Also, of course, the Columns that specify the required join\par
relationship must have comparable <data-type>s; that is, they must either both\par
be numeric or both be character strings or both be dates, and so on. They do\par
not always have to have the same name, but it is helpful in reading the query if they do.\par
\par
To find all information available on all employees (retrieve a join of all Columns) the following SQL statement are equivalent:\par
\par
   SELECT Employee.*,Payroll.*\par
   FROM   Employee,Payroll\par
   WHERE  Employee.empnum=Payroll.empnum;\par
\par
   SELECT *\par
   FROM   Employee,Payroll\par
   WHERE  Employee.empnum=Payroll.empnum;\par
\par
   SELECT *\par
   FROM   Employee NATURAL JOIN Payroll;\par
\par
   SELECT *\par
   FROM   Employee JOIN Payroll ON(empnum);\par
\par
   SELECT *\par
   FROM   Employee JOIN Payroll USING(Employee.empnum=Payroll.empnum);\par
\par
The result is the entire EMPLOYEE Table joined with the entire PAYROLL Table\par
over their matching employee numbers; ten rows and ten columns in all. Note\par
the <Column reference>s for the EMPNUM Column, to avoid ambiguity. To\par
eliminate duplicate Columns from the result, specific <Column reference>s\par
(rather than "*") must be put in the select list, as in these two equivalent SQL statements:\par
\par
   SELECT Employee.empnum,dept,surname,rate,location\par
   FROM   Employee,Payroll\par
   WHERE  Employee.empnum=1 and Employee.empnum=Payroll.empnum;\par
\par
   SELECT Employee.empnum,dept,surname,rate,location\par
   FROM   Employee NATURAL JOIN Payroll\par
   WHERE  Employee.empnum=1;\par
\par
The result is:\par
\par
EMPNUM DEPT SURNAME RATE  LOCATION\par
1      A    KOO     6.00  10TH FLOOR\par
\par
To find an employee's manager (retrieve one equivalent Column from multiple Tables):\par
\par
   SELECT surname,manager\par
   FROM   Employee NATURAL JOIN Department\par
   WHERE  empnum=28;\par
\par
The result is:\par
\par
SURNAME     MANAGER\par
TURNER      JONES B\par
\par
To find the pay rates and locations of all department A employees (join values fulfilling multiple conditions from multiple Tables):\par
\par
   SELECT Employee.*,Payroll.*\par
   FROM   Employee NATURAL JOIN Payroll ON dept='A';\par
\par
The result is the EMPLOYEE Table joined with the PAYROLL Table, for all rows where the DEPT Column contains an "A" in both Tables.\par
\par
To find the department and payroll data for employee 35, here are two equivalent SQL statements:\par
\par
   SELECT Employee.empnum,surname,Employee.dept,manager,rate\par
   FROM   Employee,Department,Payroll\par
   WHERE  Employee.empnum=35 AND\par
          Employee.empnum=Payroll.empnum AND\par
          Employee.dept=Department.dept;\par
\par
   SELECT empnum,surname,dept,manager,rate\par
   FROM   Department NATURAL JOIN Employee NATURAL JOIN Payroll\par
   WHERE  empnum=35;\par
\par
The result is:\par
\par
EMPNUM  SURNAME  DEPT  MANAGER  RATE\par
35      OLSEN    E     GREEN E  9.00\par
\par
Outer join results Tables are produced exactly the same way as inner join results are -- with the exception that, in an outer join, rows are retrieved even when data in one of the Tables has no match in the other.\par
\par
If a row in the first Table named has no match in the second Table, and the\par
outer join type is either a LEFT JOIN or a FULL JOIN, then a dummy row appears\par
for the second Table. If a row in the second Table named has no match in the\par
first Table, and the outer join type is either a RIGHT JOIN or a FULL JOIN,\par
then a dummy row appears for the first Table. In both cases, the Columns in a\par
dummy row are all equal to their DEFAULT values.\par
\par
For example, suppose TABLE_1 has one Column and four rows, containing the values \{1,2,3,5\} and TABLE_2 has one Column and four rows, containing the values \{2,4,5,7\}. An inner join query on the Tables would be:\par
\par
   SELECT Table_1.column_1 AS T1_column,\par
          Table_2.column_1 AS T2.column\par
   FROM   Table_1 NATURAL JOIN Table_2;\par
\par
The result is:\par
\par
T1_COLUMN    T2_COLUMN\par
2            2\par
5            5\par
\par
The values in either Table that have no match are not retrieved.\par
\par
A left outer join query on the Tables would be:\par
\par
   SELECT Table_1.column_1 AS T1_column,\par
          Table_2.column_1 AS T2_column\par
   FROM   Table_1 LEFT JOIN Table_2 USING (column_1);\par
\par
The result is:\par
\par
T1_COLUMN    T2_COLUMN\par
1            NULL\par
2            2\par
3            NULL\par
5            5\par
\par
The values in the first (left) Table that have no match are matched with a NULL (or default) value.\par
\par
A right outer join query on the Tables would be:\par
\par
   SELECT Table_1.column_1 AS T1_column,\par
          Table_2.column_1 AS T2_column\par
   FROM   Table_1 RIGHT JOIN Table_2 USING (column_1);\par
\par
The result is:\par
\par
T1_COLUMN    T2_COLUMN\par
2            2\par
NULL         4\par
5            5\par
NULL         7\par
\par
The values in the second (right) Table that have no match are matched with a NULL (or default) value.\par
\par
A full outer join query on the Tables would be:\par
\par
   SELECT Table_1.column_1 AS T1_column,\par
          Table_2.column_1 AS T2_column\par
   FROM   Table_1 FULL JOIN Table_2 USING (column_1);\par
\par
The result is:\par
\par
T1_COLUMN    T2_COLUMN\par
1            NULL\par
2            2\par
3            NULL\par
NULL         4\par
5            5\par
NULL         7\par
\par
The values in either Table that have no match are matched with a NULL (or default) value.\par
\par
Dialects\par
\par
Since "modern" syntax is relatively new to SQL, various products support different syntax for the types of joins we've illustrated here. For example:\par
      ## Oracle uses "WHERE Table_1.column (+) = Table_2.column" for a LEFT OUTER JOIN.\par
      ## For Microsoft SQL Server, the search condition for an OUTER JOIN must be an equals condition.\par
\page\par
Chapter 31 -- Searching with Subqueries \par
\par
A subquery is a parenthesized query enclosed within some outer SQL statement. Most queries are SELECTs, so this means that a subquery usually takes the form "(SELECT ...)", nested somewhere inside an expression. Queries return result sets, or Tables, and the values in such Tables can be used when the syntax of the outer expression calls for a value of the appropriate . Subqueries make an SQL statement look structured, and indeed it was the presence of subqueries that gave the original SQL its distinctive look (the letters SQL used to stand for "Structured Query Language"). Nowadays subqueries are less essential because there other ways (particularly joins and UNION/EXCEPT/INTERSECT operators) to reach the same ends. Nevertheless, they are important because they provide these benefits: ## SQL statements with subqueries are readable. Most people, especially if they are familiar with the role of subordinate clauses in English, can figure that a subquery-containing SQL statement can be read "from the inside out" -- that is, they can focus on the subquery's workings first, and then on the separate analysis of the outer statement. Statements with joins, by contrast, must be read all at once. ## Certain types of problems can be stated more concisely, and more efficiently, with subqueries. Subquery syntax A subquery is used to specify either a value (the scalar subquery, which returns one value), a row (the row subquery, which returns one row), or a Table (the Table subquery, which returns a result Table). The required syntax for a subquery is: ::= ( ) That is, a subquery is a parenthesized -- and the is usually a SELECT statement. Here's an example: SELECT /* outer statement begins */ Table_1.column_1, Table_1.column_2 FROM Table_1 WHERE Table_1.column_1 = (SELECT * /* subquery begins */ FROM Table_2 WHERE Table_2.column_1 = 5); There are some restrictions regarding where subqueries can be used and what they may contain. In early SQL days, the restrictions were quite strict. For instance, the subquery had to be on the right side of a comparison operator within a WHERE clause, as in the above example. Nowadays, the restrictions for an SQL subquery, in a fully-conformant DBMS environment, are mild: ## There can be no ORDER BY clause inside the subquery. ## The subquery's select list may not include any reference to a value that evaluates to a BLOB, CLOB, NCLOB or ARRAY. ## A subquery may not be immediately enclosed within a set function, for example: ... AVG((SELECT column_1 FROM Table_1)) ... is not legal syntax. It is legal to nest subqueries within subqueries. The maximum level of nesting depends on your implementation, since the Standard doesn't specify the number of levels of nesting that must be supported. We said earlier that there are three types of subquery. They are distinguished from each other, not by their form -- the general form of a subquery is always just "()" -- but by the shape of their result: how many Columns and rows do they return? ## If a subquery can return exactly one Column and one row, it is a scalar subquery. The subquery: ... (SELECT MAX(Table_1.column_1) FROM Table_1) ... would fit the bill, but usually it's not so easy to simply glance at a query and realize that it will return only one Column and one row. ## If a subquery can return more than one Column, but still exactly one row, it is a row subquery. A row subquery is just a generalized derivation of a scalar subquery, used in some comparisons. Row subqueries are the least-frequently-seen type of subquery. ## If a subquery can return more than one Column and more than one row, it is a Table subquery. A Table subquery is another type of \par
, and can be used in an SQL statement wherever a \par
can be used -- which isn't very often! However, there are some special search operators which are specifically designed to work with Table subqueries. Discussion of those search operators is an important part of this chapter. Thus, the distinction between subquery types depends on the size of the select list, and the number of rows returned. The three types of subquery are not utterly separate: a scalar subquery's definition is subsumed by a row subquery's definition, which is subsumed by a Table subquery's definition. (In fact, a one-Column Table subquery is such a common thing that some people regard it as a separate type, which they call a "Column subquery".) Nevertheless, the potential distinction should be kept in mind. It's easy to get confused by assuming that everything which applies for one type, applies for the others as well. We will discuss scalar subqueries, row subqueries and Table subqueries separately. Scalar Subqueries In general terms, a scalar subquery resembles a scalar function. Remember that a scalar function returns a single value, given an argument which is some sort of expression -- well, a scalar subquery returns a single value, given an argument which is a . Since that value must be a scalar value, a few aspects of scalar subqueries are simply logical consequences of their definitions: ## The , Collation, length and all other significant attributes of the value are inherited from the attributes of the selected Column. For example, the result of the subquery: ... (SELECT 'abc' FROM Table_1) ... has a of CHAR(3). ## It is an error if, at runtime, the DBMS discovers that a scalar subquery returns more than one row. If this is the case, the entire SQL statement will fail: your DBMS will return the SQLSTATE error 21000 "cardinality violation". One thing that does not follow from the definition, and in fact surprises some analysts, is the value returned when a scalar subquery returns zero rows. In this case, the result is NULL. For example, consider this SQL statement: UPDATE Table_1 SET column_1 = (SELECT column_1 FROM Table_2 WHERE 1 = 2); Since 1 is never equal to 2, the search condition in this subquery example will always be FALSE -- so the subquery result is an empty set. In this case, the UPDATE operation assigns a null value to COLUMN_1 in TABLE_1. This is a case where NULL obviously does not mean "unknown" or "not applicable" -- it means "not there" -- but no great harm results. Here are some examples of scalar subqueries. You can tell that these must be scalar subqueries -- not row subqueries or Table subqueries -- because they are being used in places where only scalar values are legal. -- scalar subquery in a select list SELECT 'value is: ', (SELECT column_1 FROM Table_1) FROM Table_2; -- scalar subquery in an UPDATE ... SET clause UPDATE Table_1 SET column_1 = (SELECT AVG(column_1) FROM Table_2); -- scalar subquery in a comparison SELECT column_3,column_1 FROM Table_1 WHERE (SELECT MAX(column_1) FROM Table_1) = (SELECT MIN(column_1) FROM Table_2); -- scalar subquery with arithmetic INSERT INTO Table_1 VALUES (1 + (SELECT column_1 FROM Table_2)); Our third example of a scalar subquery shows its use in a WHERE clause. This is a traditional and common usage, as it used to be the only place a subquery could appear. These general observations apply if you're including a scalar subquery in a comparison: ## The "comparison" operator is not limited to the traditional operators: it can be pretty well any predicate, including LIKE or BETWEEN. ## The subquery can be on either side of the comparison operator. There can even be subqueries on both sides of the comparison operator. ## The subquery can be in an expression, along with arithmetic or scalar function operators. ## The subquery result will depend on the number of rows returned: one row is normal and gives a known result, two or more rows results in a "cardinality violation" error and zero rows results in the comparison predicate returning UNKNOWN, because the subquery result value is NULL. We've repeated these general observations here because we want to emphasize that such observations apply only to scalar subqueries. None of them will apply when we discuss comparisons that involve Table subqueries. Row Subqueries Row subqueries are similar to scalar subqueries in the one fundamental respect: they may not return more than one row. If a row subquery returns two or more rows, the entire SQL statement will fail: your DBMS will return the SQLSTATE error 21000 "cardinality violation". Row subqueries offer a slight convenience for comparison operations. For example, we can say: SELECT * FROM Table_1 WHERE (column_1,'X') = (SELECT column_1,column_2 FROM Table_2); That is, we can compare two Column values using a single equals operator. This is more concise, and probably more efficient, than comparing twice with scalar subqueries, as in this equivalent example: SELECT * FROM Table_1 WHERE Table_1.column_1 = (SELECT Table_2.column_1 FROM Table_2) AND 'X' = (SELECT Table_2.column_2 FROM Table_2); A row subquery, then, is a form of row value expression -- an expression that evaluates to one row. This construct can be used with every SQL predicate, not just basic comparison. Table Subqueries We now switch from talking about "one-row" subqueries, to talking about "multi-row" subqueries, or Table subqueries. This means, almost exclusively, subqueries that are used in comparison operations. Quite often, a Table subquery looks like a scalar subquery, because -- almost always -- a single Column makes up the subquery's select list. You can distinguish a Table subquery from context, though: it will always be preceded by a special for-Table-subqueries-only operator, either " ALL", " ANY" (or its synonym, " SOME"), "IN", "EXISTS", or "UNIQUE". Correlated Subqueries: A correlated subquery is a subquery that contains references to the values in Tables that are referred to in the outer statement (that is, the SQL statement that the subquery is nested in). These references are, in standard terminology, "outer references". One tends to find outer references in Table subqueries, although in theory there is nothing to restrict them to that role. Here's an example (for now, concentrate only on the syntax we're showing): SELECT * FROM Table_1 WHERE column_1 = ANY (SELECT column_1 FROM Table_2 WHERE column_2 = Table_1.column_2); There are two things to note in this example: ## First: the subquery's WHERE clause refers to "Table_1.column_2", but TABLE_1 is not mentioned in the subquery's FROM clause. Instead, TABLE_1 is named in the outer query's FROM clause -- this is the outer reference. ## Second: besides "Table_1.column_2", the subquery's WHERE clause has another Column named COLUMN_2. This reference is to the COLUMN_2 that belongs to TABLE_2. We could have used the TABLE_2.COLUMN_2 for clarity, but this isn't necessary. By default, a applies to the Table(s) in the nearest FROM clause -- there is a scoping rule that says: look in the local subquery first for resolution of s, then look outward, progressing if necessary through several levels of nesting, till the outermost query is reached. Occasionally, the \par
s are the same in the subquery and in the outer statement. When this happens, it's the subquery analog of the self-join and so you'll need to define s for the Tables. Here's an example: SELECT * FROM Table_1 AS T_one_a WHERE column_1 = ANY (SELECT column_1 FROM Table_1 AS T_one_b WHERE T_one_b.column_2 = T_one_a.column_2); Whenever a subquery contains an outer reference, it is correlated with the outer statement. That means your DBMS can't evaluate the subquery without feeding it values from outside the subquery. Correlation can be messy, and some DBMSs handle it poorly. But sometimes there's no alternative. Quantified Comparisons In our chapters on the various s, we showed you which of them could be used in an expression that compared a value of that with the collection of values returned by a Table subquery. Here's a more detailed explanation of quantified comparisons using the quantifiers ALL, SOME, ANY. ALL: The required syntax for an ALL quantified comparison is: scalar_expression comparison_operator ALL \par
Here, "scalar_expression" may be any expression that evaluates to a single value and "comparison_operator" may be any one of: = or > or < or >= or <= or <>. ALL returns TRUE if the Table subquery returns zero rows or if the comparison operator returns TRUE for every row returned by the Table subquery. ALL returns FALSE if the comparison operator returns FALSE for at least one row returned by the Table subquery. Suppose that TABLE_1 has one Column, defined as DECIMAL(6,2). Here's what will happen, for different values in the rows of TABLE_1, for this expression: ... WHERE 1000.00 > ALL (SELECT column_1 FROM Table_1) ... ## If TABLE_1 contains the values \{100.00, 200.00, 300.00\}, the expression is TRUE: all of TABLE_1's values are less than 1000.00. ## If TABLE_1 contains the values \{100.00, 2000.00, 300.00\}, the expression is FALSE: one of TABLE_1's values is greater than 1000.00. ## If TABLE_1 contains the values \{1000.00, 200.00, 300.00\}, the expression is FALSE too: one of TABLE_1's values is equal to 1000.00. ## If TABLE_1 contains no values, the expression is TRUE: when the set is empty, ALL is TRUE. ## If TABLE_1 contains the values \{100.00, NULL, 300.00\}, the expression is UNKNOWN: when NULLs are involved, ALL is UNKNOWN. ANY or SOME: The required syntax for an ANY or SOME quantified comparison is: scalar_expression comparison_operator ANY \par
| scalar_expression comparison_operator SOME \par
Once again, "scalar_expression" may be any expression that evaluates to a single value and "comparison_operator" may be any one of: = > < >= <= <>. SOME and ANY are synonyms. They return TRUE if the comparison operator returns TRUE for at least one row returned by the Table subquery. They return FALSE if the Table subquery returns zero rows or if the comparison operator returns FALSE for every row returned by the Table subquery. Suppose, once again, that TABLE_1 has one Column, defined as DECIMAL(6,2). Here's what will happen, for different values in the rows of TABLE_1, for this expression: ... WHERE 1000.00 > ANY (SELECT column_1 FROM Table_1) ... ## If TABLE_1 contains the values \{100.00, 200.00, 300.00\}, the expression is TRUE: all of TABLE_1's values are less than 1000.00. ## If TABLE_1 contains the values \{100.00, 2000.00, 300.00\}, the expression is TRUE too: at least some of TABLE_1's values are less than 1000.00. ## If TABLE_1 contains no values, the expression is FALSE: when the set is empty, ANY is FALSE. ## If TABLE_1 contains the values \{1000.00, 2000.00, 3000.00\}, the expression is FALSE too: all of TABLE_1's values are greater than or equal to 1000.00. ## If TABLE_1 contains the values \{100.00, NULL, 300.00\}, the expression is UNKNOWN: when NULLs are involved, ANY is UNKNOWN. There is a small trap when one considers the expression "... 1000.00 <> ANY () ...". Such an expression could be carelessly read as "... 1000 is not equal to any subquery result ..." -- that is, 1000 is not equal to every row returned by the subquery. That is not the correct way to read such expressions because it leads to the English-language ambiguity that "any" can mean "every". There are three ways to avoid such ambiguities: ## Don't use the ANY . Use its synonym, SOME, instead. ## When negatives are involved, replace ANY with ALL. Logic tells us that these transformations are possible: expression <> ANY subquery --> expression = ALL subquery NOT (expression = ANY subquery) --> expression <> ALL subquery as long as the subquery does not return an empty set. ## Use a completely different syntax, for example, the EXISTS predicate, which we'll discuss later in this chapter. Quantified retrieval: Here's some examples of comparisons with subqueries, using the sample database we defined in our chapter on simple search conditions. To find the records for the employees reporting to a manager named D. Black: SELECT * FROM Employee WHERE dept = (SELECT dept FROM Department WHERE manager='BLACK D'); The result is: EMPNUM DEPT SURNAME GNAME ADDRESS 4 D MORGAN CHUCK 963 SOUTH Because there is only one possible row in the DEPARTMENT Table with a manager named "BLACK D", the equals operator can be used in this subquery without a quantifier. If more than one value is possible, either ALL, ANY or SOME is needed to quantify the comparison operator, as in this example: SELECT manager FROM Department WHERE dept = ANY (SELECT dept FROM Employee WHERE empnum, the , the and the . Each will return a boolean value: either TRUE, FALSE or UNKNOWN. : The required syntax for an is: ::= row_expression [ NOT ] IN ::= \par
| (scalar_expression [ \{,scalar_expression\}... ]) An compares a value to a collection of values and returns either TRUE, FALSE or UNKNOWN. (If any argument is NULL, the returns UNKNOWN.) IN searches for data that matches any one of a specified collection of values. NOT IN searches for data that doesn't match any of the values in the collection. Note the words we've used in this explanation: IN can be used to replace the quantified comparison "= ANY" -- that is, these two expressions are equivalent: ... WHERE 'A' IN (SELECT column_1 FROM Table_1) ... ... WHERE 'A' = ANY (SELECT column_1 FROM Table_1) ... This example shows one of the two variants of IN. The other variant is: IN () This syntax has nothing to do with subqueries, but while we're on the subject, these two expressions are also equivalent: ... WHERE column_1 IN ('A','B','C') ... ... WHERE column_1 = 'A' OR column_1 = 'B' OR column_1 = 'C' ... Some general rules: ## All the expressions must be comparable. You can use [NOT] IN to compare one or more values to a collection: "row_expression" may be any expression which evaluates either to a single value, or to a row of values. In the first case, if you're comparing to a Table subquery, it must evaluate to a one-Column Table whose is comparable to the result of "row_expression" -- and if you're comparing to a list of values, the list may contain only one value with a that is comparable to the result of "row_expression" ("scalar_expression" may be any expression which evaluates to a single value). In the second case, if you're comparing to a Table subquery, it must evaluate to a Table with the same number of Columns as the result of "row_expression" has, and each corresponding pair of values must have mutually comparable s -- and if you're comparing to a list of values, the list must contain the same number of values as the result of "row_expression" has, and each corresponding pair of values must have mutually comparable s. ## The can't be used with BLOBs, CLOBs, NCLOBs, REFs and ARRAYs. The is TRUE if the value of "row_expression" is found within the . For example, these s are both TRUE: 1 IN (1,2,3) 1 IN (SELECT column_1 FROM Table_1 where column_1 = 1) NOT IN is simply the negation of IN so these predicates are also TRUE: 1 NOT IN (5,6,7) 1 NOT IN (SELECT column_1 FROM Table_1 where column_1 = 15) In other words, the has two variants, both of which are merely shorthands for some other comparison syntax, so the same rules that apply for comparisons of specific s apply to IN as well. In both cases, IN appears to be more popular than the wordings it replaces. If you want to restrict your code to Core SQL, make sure that all "scalar_expressions" in an are either s, references to a host variables or SQL parameters, s, or CURRENT_PATH, CURRENT_ROLE, CURRENT_USER, SESSION_USER, SYSTEM_USER, USER. ## Retrieval with IN Here's some examples of the , using the sample database we defined in our chapter on simple search conditions. To find the addresses of the employees working in either department C or department D (retrieve values which match any of a list of specified values): SELECT dept,empnum,address FROM Employee WHERE dept IN ('C','D'); The result is: DEPT EMPNUM ADDRESS C 3 567 NORTH D 4 963 SOUTH To find the employee numbers of the employees whose pay rate is not 5.00, 9.00, or 16.00 (retrieve values which do not match any of a specified list): SELECT empnum FROM Payroll WHERE rate NOT IN (5,9,16); The result is: EMPNUM 1 4 To find the names of employees earning a rate of 8.00 (retrieve values which match any returned by a subquery): SELECT surname FROM Employee WHERE empnum IN (SELECT empnum FROM Payroll WHERE rate=8); The result is: SURNAME MORGAN In this example, the subquery is first evaluated to find the payroll records with a rate of 8.00. The employee numbers of the result are then compared to the employee numbers of the EMPLOYEE Table to retrieve the surnames for the final result. To find the employees located in the warehouse: SELECT surname FROM Employee WHERE empnum IN (SELECT empnum FROM Payroll WHERE location='WAREHOUSE'); The result is: SURNAME JONES FRANCIS To find the names of the employees who report to A Smith : SELECT gname,surname FROM Employees WHERE dept IN (SELECT dept FROM Department WHERE manager='SMITH A'); The result is: GNAME SURNAME SARA KOO ALICE SMITH IN expressions can be nested. To find the manager of employees working in the warehouse: SELECT manager FROM Department WHERE dept IN (SELECT dept FROM Employee WHERE empnum IN (SELECT empnum FROM Payroll WHERE location='WAREHOUSE')); The result is: MANAGER BROWN C GREEN E To find the names of employees who don't work on the 10th floor (retrieve values which don't match any returned by a subquery): SELECT gname,surname FROM Employees WHERE empnum IN (SELECT empnum FROM Payroll WHERE location<>'10TH FLOOR'); The result is: GNAME SURNAME JOHN MARSH MABEL JONES CHUCK MORGAN ALICE SMITH BOB JONES CHRIS FRANCIS LINDA TURNER : The required syntax for an is: ::= [ NOT ] EXISTS \par
An is a test for a non-empty set and returns either TRUE or FALSE. EXISTS is TRUE if the Table subquery returns at least one row; otherwise it is FALSE. NOT EXISTS is TRUE if the Table subquery returns zero rows; otherwise it is FALSE. By tradition, the \par
following an begins with "SELECT *". In this case, the asterisk is not a shorthand for a list of Columns, it merely stands for "some Column". Unless you're using Core SQL, it doesn't actually matter what you put here -- but in Core SQL, the Table subquery's select list must either be just an asterisk, or it must evaluate to a single derived Column. Whatever you use, the result is the same: if the subquery returns any rows, EXISTS is TRUE -- regardless of the number of Columns that the subquery result contains. Here's an example: SELECT column_1 FROM Table_1 WHERE EXISTS (SELECT * FROM Table_2); If there are any rows at all in TABLE_2, then the search condition is TRUE and all values of TABLE_1.COLUMN_1 will be selected. This is a rare example of a rather static subquery. Much more often, the Table subquery will be a correlated subquery. If you use EXISTS, followed by a correlated subquery with a single outer reference, you are accomplishing the same thing as you would accomplish with a quantified ANY comparison. For example, here are two equivalent SQL statements: -- query using "> ANY" and a simple subquery SELECT * FROM Table_1 WHERE column_1 > ANY (SELECT column_1 FROM Table_2 WHERE Table_2.column_2 = 5); -- the same query, using EXISTS and a correlated subquery SELECT * FROM Table_1 WHERE EXISTS (SELECT * FROM Table_2 WHERE Table_2.column_2 = 5 AND Table_1.column_1 > Table_2.column_1); The EXISTS version of the request is more cumbersome, but it's a better choice if there are several items to compare between the outer statement and the subquery. NOT EXISTS is merely the negation of EXISTS, but it deserves attention as a separate operator. The interesting case is a double-nested NOT EXISTS predicate, which can solve questions of the general form: find all the As which are related to all of the Bs. Logicians call these FORALL questions. An example of a FORALL question is "list the students who are in a class for every course that the school offers". Expressed with a double-nested NOT EXISTS predicate, this question is answered with: SELECT student_name FROM Students WHERE NOT EXISTS (SELECT * FROM Courses WHERE NOT EXISTS (SELECT * FROM Classes WHERE Classes.course_id = Courses.course_id AND Classes.student_id = Students.student_id)); In other words: "look for the case where there exists no student where there exists no course where there exists a class for the course containing the student". We can't say that quickly three times, but it doesn't matter: you can use this example as a template for FORALL questions. ## Retrieval with EXISTS Here's some examples of the , using the sample database we defined in our chapter on simple search conditions. To find the names of employees earning a rate of 8.00 (retrieve a value only if some condition exists): SELECT surname FROM Employee WHERE EXISTS (SELECT * FROM Payroll WHERE rate=8 AND empnum=Employee.Empnum); The result is: SURNAME MORGAN To find the employees located in the warehouse: SELECT surname FROM Employee WHERE EXISTS (SELECT * FROM Payroll WHERE location='WAREHOUSE' AND empnum=Employee.empnum); The result is: SURNAME JONES FRANCIS EXISTS expressions can be nested. To find the managers of employees working in the warehouse: SELECT MANAGER FROM Department WHERE EXISTS (SELECT * FROM employee WHERE dept=Department.dept AND EXISTS (SELECT * FROM Payroll WHERE location='WAREHOUSE' AND empnum=Employee.empnum)); The result is: MANAGER BROWN C GREEN E : The required syntax for a is: ::= [ NOT ] UNIQUE \par
A is a test for duplicate rows and returns either TRUE or FALSE. UNIQUE returns TRUE if the Table subquery returns zero rows or one row, or if every row returned by the Table subquery is unique (that is, every row contains a different set of non-null values than every other row); otherwise it returns FALSE. NOT UNIQUE returns TRUE if any row returned by the Table subquery is an exact duplicate of another row; otherwise it returns FALSE. The can't be used if the Table subquery returns Columns with a of BLOB, CLOB, NCLOB or ARRAY. For an example of how UNIQUE works, suppose that TABLE_1 has one Column, defined as DECIMAL(6,2). Here's what will happen, for different values in the rows of TABLE_1, for this expression: ... WHERE UNIQUE (SELECT column_1 FROM Table_1) ... ## If TABLE_1 contains the values \{100.00, 200.00, 300.00\}, the expression is TRUE: all of TABLE_1's rows are different. ## If TABLE_1 contains only \{100.00\}, the expression is TRUE too: all of TABLE_1's rows are different, since there is only one. ## If TABLE_1 contains no values, the expression is also TRUE: when the set is empty, UNIQUE is TRUE. ## If TABLE_1 contains the values \{100.00, 2000.00, 100.00\}, the expression is FALSE: at least two of TABLE_1's rows are the same. ## If TABLE_1 contains the values \{100.00, NULL, 300.00\}, the expression is TRUE: when NULLs are involved, UNIQUE ignores them and looks at the remaining values. In this case, all of TABLE_1's remaining rows are different. ## If TABLE_1 contains the values \{100.00, NULL, 100.00\}, the expression is FALSE: after eliminating NULLs, at least two of TABLE_1's remaining rows are the same. The was introduced to SQL with SQL-92 but is still not much used in application programs. Its main purpose is to expose the operation which the DBMS uses to handle UNIQUE Constraints. For example, in this pair of SQL statements, the first is a UNIQUE Constraint definition and the second is a statement that the DBMS implicitly uses to enforce the Constraint: -- UNIQUE Constraint definition ALTER TABLE Table_1 ADD CONSTRAINT unique_constraint UNIQUE(column_1); -- implicitly-used enforcement statement SELECT * FROM Table_1 WHERE UNIQUE (SELECT column_1 FROM Table_1); If you want to restrict your code to Core SQL, don't use the . : The required syntax for a is: ::= row_expression MATCH [ UNIQUE ] [ SIMPLE | PARTIAL | FULL ] \par
A is a test for matching rows and returns either TRUE or FALSE. The "row_expression" can be any expression which evaluates to one row of values; this row must be comparable to the rows returned by the Table subquery -- that is, "row_expression" and Table subquery must return rows with the same number of values, and each pair of corresponding values must have comparable s. The can't be used if either "row_expression" or the Table subquery returns values with a of BLOB, CLOB, NCLOB or ARRAY. The has eight possible forms: ## row_expression MATCH Table subquery ## row_expression MATCH SIMPLE Table subquery ## row_expression MATCH UNIQUE Table subquery ## row_expression MATCH UNIQUE SIMPLE Table subquery ## row_expression MATCH PARTIAL Table subquery ## row_expression MATCH UNIQUE PARTIAL Table subquery ## row_expression MATCH FULL Table subquery ## row_expression MATCH UNIQUE FULL Table subquery The first forms are equivalent, as are the third and fourth forms: if none of \{SIMPLE | PARTIAL | UNIQUE\} is specified, the default is SIMPLE. The expression "row_expression MATCH SIMPLE Table subquery" is TRUE only in two cases: ## It is TRUE if the result of "row_expression" contains at least one NULL -- e.g.: if "row_expression" evaluates to \{100, NULL, 300\}. ## It is TRUE if the result of "row_expression" contains no NULLs and the Table subquery returns at least one row that is equal to "row_expression". (Remember that if a row returned by the Table subquery contains any NULLs, the result of the comparison to "row_expression" would be UNKNOWN, so such rows would make the predicate return FALSE). The expression "row_expression MATCH UNIQUE SIMPLE Table subquery" is TRUE only in two cases: ## It is TRUE if the result of "row_expression" contains at least one NULL. ## It is TRUE if the result of "row_expression" contains no NULLs and the Table subquery returns exactly one row that is equal to "row_expression". The expression "row_expression MATCH PARTIAL Table subquery" is TRUE only in two cases: ## It is TRUE if the result of "row_expression" contains only NULLs -- e.g.: if "row_expression" evaluates to \{NULL, NULL, NULL\}. ## It is TRUE if the Table subquery returns at least one row whose values equal their corresponding non-null values in "row_expression" -- e.g.: if "row_expression" evaluates to \{100, NULL, 300\}, at least one row returned by the subquery must be \{100, , 300\}. The expression "row_expression MATCH UNIQUE PARTIAL Table subquery" is TRUE only in two cases: ## It is TRUE if the result of "row_expression" contains only NULLs. ## It is TRUE if the Table subquery returns exactly one row whose values equal their corresponding non-null values in "row_expression". The expression "row_expression MATCH FULL Table subquery" is TRUE only in two cases: ## It is TRUE if the result of "row_expression" contains only NULLs. ## It is TRUE if the result of "row_expression" contains no NULLs and the Table subquery returns at least one row that is equal to "row_expression". The expression "row_expression MATCH UNIQUE FULL Table subquery" is TRUE only in two cases: ## It is TRUE if the result of "row_expression" contains only NULLs. ## It is TRUE if the result of "row_expression" contains no NULLs and the Table subquery returns exactly one row that is equal to "row_expression". Assume a Table called TABLE_1, defined with three Columns and containing this data: TABLE_1 COLUMN_1 COLUMN_2 COLUMN_3 10 10 10 10 10 10 10 NULL 10 10 10 20 Using TABLE_1, here are some examples of expressions, all of which are TRUE: ... WHERE ROW(10,NULL,10) MATCH SIMPLE (SELECT * FROM Table_1) ... ... WHERE ROW(10,10,10) MATCH SIMPLE (SELECT * FROM Table_1) ... ... WHERE ROW(10,NULL,10) MATCH UNIQUE SIMPLE (SELECT * FROM Table_1) ... ... WHERE ROW(NULL,NULL,NULL) MATCH PARTIAL (SELECT * FROM Table_1) ... ... WHERE ROW(10,NULL,10) MATCH PARTIAL (SELECT * FROM Table_1) ... ... WHERE ROW(NULL,NULL,NULL) MATCH UNIQUE PARTIAL (SELECT * FROM Table_1) ... ... WHERE ROW(NULL,NULL,NULL) MATCH FULL (SELECT * FROM Table_1) ... ... WHERE ROW(10,10,10) MATCH FULL (SELECT * FROM Table_1) ... Still using TABLE_1, here are some examples of expressions, all of which are FALSE: ... WHERE ROW(10,10,10) MATCH UNIQUE SIMPLE (SELECT * FROM Table_1) ... ... WHERE ROW(10,NULL,10) MATCH UNIQUE PARTIAL (SELECT * FROM Table_1) ... ... WHERE ROW(10,NULL,10) MATCH FULL (SELECT * FROM Table_1) ... ... WHERE ROW(10,10,10) MATCH UNIQUE FULL (SELECT * FROM Table_1) ... If you want to restrict your code to Core SQL, don't use the . : The required syntax for a is: ::= FOR ALL \par
list () | FOR ANY \par
list () | FOR SOME \par
list () \par
list ::= \par
[ \{,\par
\} ... ] A is a three-valued comparison test: it takes the Cartesian product of "\par
list", compares the resulting rows to the search condition specified and returns either TRUE, FALSE or UNKNOWN. The \par
list may contain one or more \par
s or expressions that evaluate to Tables. The s work the same way that the regular quantifiers do -- that is: ## FOR ALL returns TRUE if the search condition is TRUE for every row of the result of "\par
list", returns TRUE if the result of "\par
list" is zero rows, returns FALSE if the search condition is FALSE for at least one row of the result of "\par
list", and otherwise returns UNKNOWN. ## FOR ANY returns TRUE if the search condition is TRUE for at least one row of the result of "\par
list", returns FALSE if the search condition is FALSE for every row of the result of "\par
list", returns FALSE if the result of "\par
list" is zero rows, and otherwise returns UNKNOWN. (As usual, FOR SOME is a synonym for FOR ANY.) Subqueries are good for answering many complex analytical questions, but they can be hard to understand. As a good example, consider the "double NOT EXISTS" method, which handles FORALL questions in an ugly manner. The SQL3 Standard tries to resolve this by introducing FOR ALL and FOR ANY -- two new predicates, which work only with Tables. Syntactically, the quantified predicates don't have to involve subqueries. But there are times when they could be replacements for subqueries (particularly the confusing NOT EXISTS syntax). Here are some simple examples: ... FOR ALL (SELECT * FROM Employee AS Emps) (Emps.empnum>50) evaluates to FALSE if there are no employees with employee numbers greater than 50. ... FOR ANY (SELECT * FROM Payroll AS Pay) (Pay.location='BASEMENT') evaluates to TRUE if at least one employee works in the basement. If you want to restrict your code to Core SQL, don't use the . Joins versus Subqueries Often, SQL statements containing subqueries can be re-formulated as statements containing joins, or vice versa. The choice of which to use normally depends on taste or optimization considerations. There are some scenarios, though, which call for subqueries rather than joins: ## When you want duplicates, but not false duplicates. Suppose Table_1 has three rows -- \{1,1,2\} -- and Table_2 has two rows -- \{1,2,2\}. If you need to list the rows in Table_1 which are also in Table_2, only this subquery-based SELECT statement will give the right answer (1,1,2): SELECT Table_1.column_1 FROM Table_1 WHERE Table_1.column_1 IN (SELECT Table_2.column_1 FROM Table_2); This SQL statement won't work: SELECT Table_1.column_1 FROM Table_1,Table_2 WHERE Table_1.column_1 = Table_2.column_1; because the result will be \{1,1,2,2\} -- and the duplication of 2 is an error. This SQL statement won't work either: SELECT DISTINCT Table_1.column_1 FROM Table_1,Table_2 WHERE Table_1.column_1 = Table_2.column_1; because the result will be \{1,2\} -- and the removal of the duplicated 1 is an error too. ## When the outermost statement is not a query. The SQL statement: UPDATE Table_1 SET column_1 = (SELECT column_1 FROM Table_2); can't be expressed using a join unless some rare SQL3 features are used. ## When the join is over an expression. The SQL statement: SELECT * FROM Table_1 WHERE column_1 + 5 = (SELECT MAX(column_1) FROM Table_2); is hard to express with a join. In fact, the only way we can think of is this SQL statement: SELECT Table_1.* FROM Table_1, (SELECT MAX(column_1) AS max_column_1 FROM Table_2) AS Table_2 WHERE Table_1.column_1 + 5 = Table_2.max_column_1; which still involves a parenthesized query, so nothing is gained from the transformation. ## When you want to see the exception. For example, suppose the question is: what books are longer than Das Kapital? These two queries are effectively almost the same: SELECT DISTINCT Bookcolumn_1.* FROM Books AS Bookcolumn_1 JOIN Books AS Bookcolumn_2 USING(page_count) WHERE title = 'Das Kapital'; SELECT DISTINCT Bookcolumn_1.* FROM Books AS Bookcolumn_1 WHERE Bookcolumn_1.page_count > (SELECT DISTINCT page_count FROM Books AS Bookcolumn_2 WHERE title = 'Das Kapital'); The difference is between these two SQL statements is, if there are two editions of Das Kapital (with different page counts), then the self-join example will return the books which are longer than the shortest edition of Das Kapital. That might be the wrong answer, since the original question didn't ask for "... longer than ANY book named Das Kapital" (it seems to contain a false assumption that there's only one edition). Subquery Examples The following examples are derived, with much editing, from an SQL application suite for a public library. They illustrate the most common situations where subqueries have proven to be useful tools. When a query is on one Table, but requires a quick look at a Column in another Table -- for example, "show the number of books checked out for a particular patron". Here's a subquery that answers this: SELECT COUNT(*) FROM Circulations WHERE patron_id = ANY (SELECT patron_id FROM Patrons WHERE Surname = 'Jones'); When detail and summary data are retrieved or compared in the same SQL statement -- for example, "set a report item to show the average cost of books". Here's a subquery that does this: UPDATE Reports SET average_book_cost = (SELECT AVG(book_cost) FROM Books); When a selection involves some calculation or complexity that has nothing to do with the contents of what is ultimately selected -- for example, "who has taken out books from either branch 9 or branch 10". Here's a subquery that answers this: SELECT DISTINCT patron_id FROM Circulations WHERE book_copy_id = ANY (SELECT book_copy_id FROM Book_Copies WHERE branch = 9 OR branch = 10); Subquery Tips Make sure your scalar subqueries return a maximum of one row. You can help by (a) using DISTINCT to remove duplicates, (b) selecting a value returned by a set-function, (c) including a primary key among the selected Columns. If your DBMS won't support row subqueries, you can still avoid repeating the same subquery twice. For example, replace a construct like this: SELECT * FROM Table_1 WHERE smallint_column_1 = (SELECT smallint_column_1 FROM Table_2) AND smallint_column_2 = ALL (SELECT smallint_column_2 FROM Table_2); with a construct like this: SELECT * FROM Table_1 WHERE smallint_column_1 * 100000 + smallint_column_2 = ALL (SELECT smallint_column_1 * 100000 + smallint_column_2 FROM Table_2); Put the fastest subquery at the deepest level. Since most DBMSs will process non-correlated subqueries by travelling from innermost statements to outermost statements, you're (to some extent) controlling the order of evaluation by choosing which expression will be inner and which will be outer. Use scalar subqueries rather than Table subqueries. Since scalar subqueries are more restrictive, you are giving your DBMS more information when you use a construct that requires a scalar subquery. The DBMS might pass that extra information to its optimizer. Consider alternatives to correlated subqueries. There are some SQL statements that work better, or look more natural, if you use joins, set functions or Table operators. Dialects SQL-89 was very restrictive about subqueries. SQL-92 removed most of the restrictions and SQL3 changed very little. So most of the information in this chapter will apply for most of the DBMSs in use today. But it doesn't hurt to know what some of the historical restrictions are. Cautious programmers will avoid these situations: ## Row subqueries. ## Subqueries nested to a depth greater than 16 levels. ## Statements with more than 15 \par
s (this is a maximum in the FIPS specification). ## Subqueries that contain UNION, EXCEPT or INTERSECT. ## Scalar subqueries that contain DISTINCT, GROUP BY or HAVING. ## Subqueries which do not appear on the right side of a comparison operator within a WHERE clause. This last restriction is the most significant because it used to be the case that "WHERE expression = (SELECT ...)" was legal syntax, but almost nothing else was.\par
\page\par
Chapter 32 -- Searching with Set Operators \par
\par
SQL supports three set operators: UNION, EXCEPT and INTERSECT. We described their general effects in our discussion of set theory (see our chapter on general concepts). Here's a quick recap, using two Tables: TABLE_1 contains these three, one-Column rows: \{1,2,3\} and TABLE_2 contains these three, one- Column rows: \{1,3,5\}. ## The expression: (Table_1) UNION (Table_2) yields all non-duplicate rows from both TABLE_1 and TABLE_2, so the result is these four rows: \{1,2,3,5\}. ## The expression: (Table_1) EXCEPT (Table_2) yields all rows that are in TABLE_1 and are not also in TABLE_2, so the result is this row: \{2\}. ## The expression: (Table_1) INTERSECT (Table_2) yields all rows that are in TABLE_1 and are also in TABLE_2, so the result is these two rows: \{1,3\} The result in all three cases is, of course, another Table: UNION and EXCEPT and INTERSECT take two Tables as input, and produce one result Table as output (that's why some sources -- particularly FIPS -- refer to UNION and EXCEPT and INTERSECT as "Table operators" rather than "set operators") -- and so these constructs can also be used as a \par
in an SQL statement. In this chapter, we'll discuss both the implementation problems and the details for the three set operators. You'll notice that the list of implementation-specific restrictions is quite long, which reflects the difficulty that DBMS vendors have supporting set operators. Before we begin our discussion though, we want to emphasize that each of the set operators can be used to form what the SQL Standard calls a -- that is, an expression that results in a Table. Here is the full syntax required for a : ::= [ WITH [ RECURSIVE ] ] ::= [ \{, \}... ] ::= [ () ] AS () [ ] ::= | ::= | UNION [ ALL | DISTINCT ] [ ] | EXCEPT [ ALL | DISTINCT ] [ ] ::= | ::= | INTERSECT [ ALL | DISTINCT ] [ ] ::= | ::= | () ::= | VALUES (s) | TABLE \par
::= CORRESPONDING [ BY () ] ::= [ \{,\} ... ] ::= | | ::= SEARCH SET ::= DEPTH FIRST BY | BREADTH FIRST BY ::= CYCLE SET TO DEFAULT USING ::= [ \{,\}... ] ::= ::= Although this syntax diagram looks extremely complicated, don;t be too discouraged! Most SQL queries are fairly simple SELECT statements, and those are mostly the types of examples we'll show you. And, in this chapter, we're just going to concentrate on the set operators anyway. However, a brief description of some of the terms in the diagram is warranted. ## UNION and EXCEPT may appear in a and INTERSECT may appear in a . In none of the cases are the input Columns involved allowed to have a BLOB, CLOB or NCLOB . ## A is either a (see our chapter on searching with joins) or a . ## A is either a or a that uses INTERSECT. ## You use a to specify the second Table operand of an INTERSECT operation. A is either a , a parenthesized , a SELECT statement (i.e.: SELECT ... FROM ... WHERE ...), a Table constructor or TABLE \par
(which evaluates to SELECT * FROM \par
). If you want to restrict your code to Core SQL, don't use TABLE \par
. ## A Table constructor is the VALUES followed by a comma- delimited, parenthesized list of rows or an expression that evaluates to a Table. Here's an example of the first case: ... VALUES (10,'hello',B'1011'), (20,'goodbye',B'1111'), (30,'bobby',B'0000') ... is a Table constructor that constructs a three-Column Table with three rows. (Each value inside the VALUES clause may be any expression that evaluates to a single value.) Here's another example, this time of the second case: ... VALUES (SELECT column_1, column_5 FROM Table_1 WHERE column_1=10) ... is a Table constructor that constructs a two-Column Table. If you want to restrict your code to Core SQL, don't use a Table constructor that involves a Table expression, don't use a Table constructor anywhere but in an INSERT statement and make all your Table constructors contain exactly one row. Set Operation Syntax The required syntax for the simplest form of a set operation is: \{UNION | EXCEPT | INTERSECT\} Here's an example of each: SELECT boss_name, salary FROM Bosses UNION SELECT employee_name, salary FROM Employees; SELECT boss_name, salary FROM Bosses EXCEPT SELECT employee_name, salary FROM Employees; SELECT boss_name, salary FROM Bosses INTERSECT SELECT employee_name, salary FROM Employees; Despite the complicated syntax we showed you earlier, assume that means "SELECT ..." or "VALUES ..." or "TABLE \par
" -- we want deliberately to avoid some complications of the official syntax description. For now, it is enough to say that there are slight restrictions on the type of that can be an argument for UNION or EXCEPT, and slightly different restrictions for INTERSECT. These restrictions are obscure and have little or no practical effect. In the examples above, the first SELECT statement retrieves two Columns (BOSS_NAME, SALARY) and so does the second SELECT statement (EMPLOYEE_NAME, SALARY). This reflects a mandatory rule: each input Table must have the same number of Columns and each corresponding pair of Columns must have comparable s. This is because each pair of Columns will merge into a single Column of the result Table -- that is, BOSS_NAME and EMPLOYEE_NAME will merge into one result Column and so will SALARY and SALARY. Usually, your DBMS decides which Column to merge with which Column by looking at ordinal position: it merges the first Columns from each input Table, then the second Columns, and so on. Merging by ordinal position is the simplest method, but there are alternative ways, which we'll discuss later. First, though, we'll add a bit more to our basic set operation syntax. ALL | DISTINCT: The required syntax for a slightly more complicated form of a set operation is: \{UNION | EXCEPT | INTERSECT\} [ ALL | DISTINCT ] Although the default for all three set operations is duplicate elimination, you can instruct your DBMS otherwise. The optional ALL after UNION, EXCEPT or INTERSECT means "keep all duplicates", while the optional DISTINCT means "eliminate duplicates". In SQL-92, the DISTINCT was not valid syntax, but it has always been the default -- that is, if you do not explicitly say ALL, then the DBMS assumes that you want to eliminate duplicates. Assume that TABLE_1 contains these five, one-Column rows: \{0,1,2,2,3\} and TABLE_2 contains these five, one-Column rows: \{1,2,3,5,5\}. ## The expressions: (Table_1) UNION (Table_2) (Table_1) UNION DISTINCT (Table_2) both yield all non-duplicate rows from TABLE_1 and TABLE_2: \{0,1,2,3,5\}. ## The expression: (Table_1) UNION ALL (Table_2) yields all rows from TABLE_1 and TABLE_2: \{0,1,2,2,2,3,3,5,5\}. ## The expressions: (Table_1) EXCEPT (Table_2) (Table_1) EXCEPT DISTINCT (Table_2) both yield all non-duplicate rows that are in TABLE_1 and are not also in TABLE_2: \{0\}. ## The expression: (Table_1) EXCEPT ALL (Table_2) yields all rows that are in TABLE_1 and are not also in TABLE_2: \{0,2\}. (For EXCEPT ALL, if a row appears "x" times in the first Table and "y" times in the second Table, it will appear "z" times in the result Table (where "z" is "x"- "y" or zero, whichever is greater). ## The expressions: (Table_1) INTERSECT (Table_2) (Table_1) INTERSECT DISTINCT (Table_2) both yield all non-duplicate rows that are in TABLE_1 and are also in TABLE_2: \{1,2,3\} ## The expression: (Table_1) INTERSECT ALL (Table_2) yields all rows that are in TABLE_1 and are also in TABLE_2: \{1,2,3\}. (For INTERSECT ALL, if a row appears "x" times in the first Table and "y" times in the second Table, it will appear "z" times in the result Table (where "z" is the lesser of "x" and "y"). That is, when you use an expression like "SELECT ... SELECT ...", the effect is the same as if you'd used "SELECT DISTINCT ... SELECT DISTINCT ...". When you use an expression like "SELECT ... ALL SELECT ...", then any duplicates are paired off against each other, one by one. ** TRAP: The [ALL|DISTINCT] option also appears at the beginning of a SELECT expression (i.e.: SELECT [ALL|DISTINCT] ...). But in that case, the default is ALL, rather than DISTINCT. By contrast, after a set operator, the default is DISTINCT. There's an inconsistency here - - maybe the original assumption was that when you SELECT you don't need DISTINCT, but when you UNION you do need DISTINCT. Probably UNION ALL is a faster operation than UNION DISTINCT, but for theoretical reasons you shouldn't go out of your way to preserve duplicate rows. Use the ALL option only for those cases where duplicates don't matter, where duplicates won't happen anyway or where the result of UNION ALL is only going to be used for summary-information purposes. For the purposes of set operation, two NULLs are "duplicates" of each other. Now let's expand our set operation syntax a little more. CORRESPONDING: The required syntax for the final form of a set operation is: \{UNION | EXCEPT | INTERSECT\} [ ALL | DISTINCT ] [ CORRESPONDING [ BY () ] ] In a well-designed database, when Tables have similar Columns, the Columns have similar names. For example, suppose two Tables, VILLAS and MANSIONS, are defined with these CREATE TABLE statements: CREATE TABLE Villas ( county char(5), acreage DECIMAL(4,2), price DECIMAL(8)); CREATE TABLE Mansions ( owner char(5), acreage DECIMAL(4,2), house_rating INT, price DECIMAL(8)); Notice that two s -- ACREAGE and PRICE -- are in both Tables, although the Columns they represent don't occupy the same ordinal positions. Now, if we want a list of properties which are both villas and mansions, we can use this simple intersection: SELECT acreage, price FROM Villas INTERSECT SELECT acreage, price FROM Mansions; But such a query is lots of work. To formulate it, we must look at the definitions for each Table, figure out which Columns they have in common and then list those Columns, in the right order, in our query. It would be far simpler to be able to say: "select Columns with the same names". The optional CORRESPONDING clause for a set operation does just that. Here's an example that is equivalent to the last one: SELECT * FROM Villas INTERSECT CORRESPONDING SELECT * FROM Mansions; The CORRESPONDING, used alone after a set operator, means "instead of going by Column position as in the 'simple' format, merge all those Columns which have the same name, regardless of their position". In this case, the Columns which have the same name in both Tables are ACREAGE and PRICE, so those are the Columns that will appear in the result Table. Now suppose that we only wanted the ACREAGE Column in our result -- we're not interested in the PRICE at all. Since CORRESPONDING, by itself, automatically merges every pair of Columns with the same name, we can't use it to form a quick query for the answer we want. Frankly, the easy solution is to return to the simple format and say: SELECT acreage FROM Mansions INTERSECT SELECT acreage FROM Villas; but let's pretend that we have some reason to avoid using a SELECT in this situation. There are alternatives, one of which is the expression "TABLE ", so let's consider this expression: TABLE Mansions INTERSECT CORRESPONDING TABLE Villas; which gives us two Columns -- ACREAGE and PRICE -- and now let's consider this expression: TABLE Mansions INTERSECT CORRESPONDING BY (acreage) TABLE Villas; which gives us one Column -- ACREAGE. It's a contrived example, but if we assume that the query is not SELECT, then "INTERSECT CORRESPONDING BY ..." is the simplest way to use a set operator and merge specific same-name Columns. The rules for this operation are: ## If CORRESPONDING BY is used with a set operator, at least one must be in the comma-delimited and parenthesized BY list and each of the s in the list must identify a Column that appears in both input Tables. The number of Columns in the result Table will equal the number of Columns in the BY list. ## If CORRESPONDING is used with a set operator, you may not specify a Column list. The number of Columns in the result Table will equal the number of Columns that both Tables have in common. ## If you omit the CORRESPONDING clause entirely, the number of Columns in the result Table will equal the number of Columns that you explicitly specify in your query. To sum it up, there are three ways to pick which Columns to merge with a set operation: (a) merge "all" Columns by ordinal position (the simple format), (b) merge "all Columns with the same name" (the CORRESPONDING format) and (c) merge "specified Columns with the same name (the CORRESPONDING BY format). Result Names and ORDER BY When you're doing a set operation, if the s of two merged Columns are the same, then the merged result Column has that name too. If the s of two merged Columns are not the same, then, by default, the merged Column is given some unique temporary name by your DBMS. Why would anyone care what the name of a merged Column is? Well, if you want the rows in the result Table to come out in some specific order, you'll have to use an ORDER BY clause -- which can only operate on the result Table and that means the names of the result Table's Columns must be known. An ORDER BY clause may optionally appear after a ; here is the required syntax: [ ORDER BY ] ::= [ \{, \}... ] ::= [ COLLATE ] [ \{ASC | DESC\} ] ::= scalar_expression The ORDER BY clause provides your DBMS with a list of items to sort, and the order in which to sort them: either ascending order (ASC, the default) or descending order (DESC). It must follow a -- this means it operates on the final Table that results from the evaluation of the query; it cannot operate on any interim result Tables at all. The you specify can be any expression that evaluates to a single value that identifies a Column of the final result Table -- this is almost always a and thus our concern to know what name will result from a set operation. Suppose, then, you want to specify a sort order for the result of our earlier examples: SELECT boss_name, salary FROM Bosses UNION SELECT employee_name, salary FROM Employees; In this case, it isn't possible to add an ORDER BY clause that specifies "ORDER BY boss_name" or "ORDER BY employee_name" at the end of the query -- these names identify the original Columns, not the merged result Column. The name of the merged result Column is defined by the Standard to be implementation-dependent: that is, it will be a name provided by your DBMS, but what name will be provided doesn't even have to be documented; it's considered to be an internal thing. In SQL-92, you can solve this dilemma with an ORDER BY clause that specifies "ORDER BY 1" -- this instructs the DBMS to sort by the first result Column, no name required. This, however, is not legal in SQL3, so you'll have to force your own names for the result Columns by providing an AS clause in each select list for corresponding Columns and then using that name in the ORDER BY clause. Here's an example: SELECT boss_name AS sort_name, salary FROM Bosses UNION SELECT employee_name AS sort_name, salary FROM Employees ORDER BY sort_name; With this syntax, you're forcing the corresponding Columns in each input Table to have the same name. This name is thus the name given to the merged result Column and can therefore be used in an ORDER by clause to identify that result Column. [Obscure Rule] The Collation of a merged Column with a character string will depend on the coercibility characteristics of the two input Columns, and whether you add the optional COLLATE specification or not. If you want to restrict your code to Core SQL, don't add the COLLATE clause. Result s and Compatibility Consider this SQL statement: SELECT 'A', 5.0 FROM Table_1 UNION SELECT 'BB', 12 FROM Table_2; The two queries that make up the UNION operator's Table operands are union compatible: each corresponding pair of Columns is comparable (that is, we can compare 'A' with 'BB' and we can compare 5.0 with 12). The rules about the resultant merged Columns are: ## The first result Column has a CHAR(2) (see Rules of Aggregation for the CASE expression, in our chapter on simple search conditions), belongs to the same Character set that 'A' does (the result always belongs to the Character set of the first input Column), and has COERCIBLE coercibility. ## The second result Column has a DECIMAL or NUMERIC , with implementor-defined precision and a scale of 2 (again, see Rules of Aggregation for the CASE expression). Now consider this SQL statement: SELECT 'A', 5.0 FROM Table_1 UNION SELECT 12, 'BB' FROM Table_; This statement will fail: it's an error to try to merge Columns which are not union compatible. Set Operation Examples Earlier in this chapter, we defined two example Tables: VILLAS and MANSIONS. Let's suppose that they have these contents: VILLAS COUNTY ACREAGE PRICE Lacombe 39.00 100000 Stettler 15.78 900000 Roseland 15.77 200000 Victoria 17.90 NULL Victoria 17.90 NULL MANSIONS OWNER ACREAGE HOUSE_RATING PRICE Bodnar 15.77 NULL 200000 Melnyk 39.00 15 900000 Skoreyko 39.00 0 900000 Mudriy NULL NULL NULL Based on this data, here are some example of SQL statements that use set operators, and their results. Example Statement Result Table -- "self-union" COUNTY ACREAGE PRICE SELECT * FROM Villas Lacombe 39.00 100000 UNION DISTINCT Victoria 17.90 NULL SELECT * FROM Villas Stettler 15.78 900000 ORDER BY acreage DESC; Roseland 15.77 200000 -- "NULL = NULL" SELECT price FROM Villas PRICE EXCEPT ALL 100000 SELECT price FROM Mansions; NULL -- "NULL = NULL" SELECT DISTINCT price FROM Villas PRICE EXCEPT ALL 100000 SELECT DISTINCT price FROM Mansions; NULL SELECT * FROM Villas ACREAGE PRICE INTERSECT CORRESPONDING 15.77 200000 SELECT * FROM Mansions; SELECT acreage, 'Villa' AS type ACREAGE TYPE FROM Villas 39.00 'Villa' UNION 15.78 'Villa' SELECT acreage, 'Mansion' AS type 15.77 'Villa' FROM Mansions; 17.90 'Villa' 15.77 'Mansion' 39.00 'Mansion' NULL 'Mansion' Updatability Like joined Tables, Tables merged with a set operator aren't updatable in SQL-92. Usually, this means that a View which is based on a query containing a set operator can't be the object of a DELETE, INSERT or UPDATE statement. But such Views might be updatable in SQL3. For example, if the set operator is UNION ALL, and the original Tables are both updatable, then so is the result Table. This feature causes some complications, since the DBMS has to track the original Tables. Most DBMSs support set operations by creating new temporary Tables, therefore a data-change operation would only affect the result Table and not the original Table. Consider a situation where you want to change the rows that result from a UNION of two Tables. There are three possible situations: ## You want to delete a row. In this case, if the row you want to DELETE was derived from the first input Table, then the DELETE operation will remove that row from the first input Table. If the row you want to DELETE was derived from the second input Table, then the DELETE operation will remove that row from the second input Table. ## You want to update a row. Once again, if the row you want to UPDATE was derived from the first input Table, then the UPDATE operation will change that row in the first input Table. If the row you want to UPDATE was derived from the second input Table, then the UPDATE operation will change that row in the second input Table. ## You want to insert a row. This isn't allowed, because your DBMS wouldn't know which underlying Table the new row should be put into. Now consider a situation where you want to change the rows that result from an EXCEPT operation of two Tables. There are three possible situations: ## You want to update a row. Since every row of the result is derived from a row of the first input Table, the UPDATE operation will change that row in the first input Table. ## You want to delete a row or insert a row. Neither of these are allowed. In the first case, if you delete a row and that row was derived from a row that is duplicated in the first input Table, the row you "deleted" would still be in the result, causing confusion. In the second case, if you insert a row that also happens to be duplicated in the second input Table, the row you "inserted" wouldn't be part of the result, causing confusion. Finally, consider a situation where you want to change the rows that result from an INTERSECT operation of two Tables. There are three possible situations: ## You want to insert a row. If the first input Table doesn't contain a row with the same values, that row is inserted into the first input Table and if the second input Table doesn't contain a row with the same values, that row is inserted into the second input Table. However, if the first input Table already contains a row with the same values as the row you want to insert -- but the result Table doesn't have a row derived from that row of the first input Table, then the new row is inserted into the first input Table. The same thing holds for the second input Table too: if the second input Table already contains a row with the same values as the row you want to insert -- but the result Table doesn't have a row derived from that row of the second input Table, then the new row is inserted into the second input Table. ## You want to update a row. If the row you want to UPDATE was derived from the first input Table, then the UPDATE operation will change that row in the first input Table. If the row you want to UPDATE was derived from the second input Table, then the UPDATE operation will change that row in the second input Table. ## You want to delete a row. This isn't allowed, because your DBMS wouldn't know which underlying Table the new row should be put into. Recursive Unions [Obscure Rule] applies for this entire section. Suppose you make widgets, which are made of doohickeys and framistats, and framistats in turn are made of a certain number of screws, nails and so on. You get a request: list all parts -- that is, list all widgets, all doohickeys, all framistats, all screws and all nails. This is a "bill of materials" problem. It's not a burning issue, but it's hard to solve with SQL-92, where the only way you can generate a list of parts is to use several queries to scan the PARTS Table -- whenever your DBMS finds a part that's made up of other parts, it has to start another query to determine its components, and so on. SQL3 supports a set operation -- the RECURSIVE UNION -- to solve this problem: it follows a trail of rows for you. Let's go back to the full syntax required for a that we showed you at the beginning of this chapter. The parts we haven't talked about yet are used to form a RECURSIVE UNION. Here's the relevant syntax: ::= [ WITH [ RECURSIVE ] ] ::= [ \{, \}... ] ::= [ () ] AS () [ ] ::= | ::= | | ::= SEARCH SET ::= DEPTH FIRST BY | BREADTH FIRST BY ::= CYCLE SET TO DEFAULT USING ::= [ \{,\}... ] ::= ::= The optional WITH clause for a is made up of one or more elements, each of which is a named query that optionally includes names for the Columns that result from that query. (If you include the optional list, you must provide a name for every result Column.) The definition of a WITH element may also include the optional . A WITH clause preceding a provides a list of related element queries for a search. WITH by itself identifies a non-recursive set of element queries -- this means that an element in the list may not contain the of an element that follows it in the list. WITH RECURSIVE, on the other hand, identifies a set of element queries that are potentially recursive -- so an element can contain the of a following element. If a WITH clause's elements cycle at least once -- that is, if element one uses element two and element two uses element three and element three cycles back to use element one -- and if at least one element is a formed with UNION, then the WITH clause is RECURSIVE: a potentially recursive WITH clause's element queries each depend on the query which follows them in the list -- that is, the first element in the list is a query that contains the of the second element in the list (and so depends on that query), the second element is a query that contains the of the third element, and so on and a WITH RECURSIVE clause's element queries each depend on another element in a way that causes a least one cycle of each element query to be executed. A linearly recursive WITH clause is a clause where each element query has at most one reference to another query in the list. The optional subclause within the WITH clause allows you to specify names for the Columns returned by the query. (Note that the element query may not use an expression which would result in a result Column with a NO COLLATION coercibility attribute.) If any two Columns returned by a WITH element query have the same name, or if the WITH query is potentially recursive, you must use the subclause to uniquely name each Column of the result Table. For each element query in a WITH clause, the element is a recursive query if it depends on another element query. (Such queries may not include set operators unless the second operand includes the name of the element query this element depends on, nor may they invoke routines that affect the element query this element depends on, nor may they include table subqueries that affect the element query this element depends on, nor may they include OUTER JOIN specifications that affect a \par
that names the element query this element depends on, nor may they include a that names the element query this element depends on.) Each element query accumulates rows for the final result. An element's is the name used in an iteration of the entire to identify the parents of any row being accumulated into the result. If each accumulated row has only one parent (that is, it results from a query that uses only one other query in the WITH list), the query is a linear RECURSIVE UNION. If accumulated rows have more than one parent (that is, they result from a query that uses more than one other query in the WITH list), the query is a nonlinear RECURSIVE UNION. An expandable element query is a linearly recursive element query whose query contains UNION or UNION ALL. If a WITH clause element query is not expandable, the element definition may not include a . A WITH element query defined with a can specify a search order of either "SEARCH DEPTH FIRST BY" or "SEARCH BREADTH FIRST BY" followed, in both cases, by a and either ASC or DESC (the syntax for the is the same as the syntax we showed you earlier for the ORDER BY clause's ). SEARCH DEPTH FIRST means "travel down the tree structure first" and SEARCH BREADTH FIRST means "travel across the tree structure first". The Column named in the SET subclause that follows must be a Column with an INTEGER ; your DBMS will set that Column to a value that indicates when a row accumulated into the result was found. A WITH element query defined with a helps your DBMS determine whether a row that has already been accumulated is found a second time. This rarely happens in real life and so it probably means an error when it happens for a query. By adding a to a WITH element definition, you can avoid getting into infinite loops by setting a limit on how long you want the search to go on. The names the Columns affected by the . The SET and the USING may not identify any of the Columns returned by the query, nor may they be the same Column. The and the must both be s that are one character long. They may not be the same value. Dialects Here are just some of the many restrictions that some DBMSs had placed on set operations in the past: ## IBM DB2: the s of corresponding Columns must be exactly the same and be defined with exactly the same size. ## SQL/DS: neither of the input s may contain DISTINCT. ## Various: neither the input s nor the result Table may be used with set functions, with GROUP BY or with HAVING. ## dBASE IV, SQL Server: all set operators are unsupported, period. Those restrictions are history now. The ones which you are much more likely to encounter are the ones that are allowed for Entry-Level SQL-92: ## No derived Column list is allowed, which effectively means that you can't use s or expressions in queries that use set operators. ## Set operators are illegal inside subqueries, in INSERT ... SELECT and in View definitions. ## EXCEPT, INTERSECT and CORRESPONDING are illegal. Even if your DBMS supports SQL3, it might only be Core SQL. If you want to restrict your code to Core SQL, don't use WITH [RECURSIVE], the INTERSECT set operator, a CORRESPONDING clause with any set operator or any set operator with an explicit DISTINCT.\par
\page\par
Chapter 33 -- Searching with Groups\par
\par
This chapter deals with three optional points of a SELECT statement: the GROUP\par
BY clause, the set functions \{AVG, COUNT, MAX, MIN, SUM, EVERY, ANY, SOME,\par
GROUPING\} and the HAVING clause. Often these things appear together: the\par
common factor is summaries, or amalgams, of Columns -- with groups, rather\par
than with details. We group together where values are equal. For example,\par
confronted with the detail list \{Smith Smith Smith Jones Jones\}, we could\par
summarize it to be: "three Smiths, two Joneses". Such a summary is known in\par
SQL as a grouped Table.\par
\par
GROUP BY clause\par
\par
The GROUP BY clause is an optional portion of the SELECT statement. It defines\par
a grouped Table. The required syntax for the GROUP BY clause is:\par
\par
GROUP BY <grouping specification>\par
\par
   <grouping specification> ::=\par
   <grouping Column reference list> | \par
   ROLLUP (<grouping Column reference list>) | \par
   CUBE (<grouping Column reference list>) | \par
   GROUPING SETS (<grouping set list>) | \par
   () | \par
   <grouping set>,<grouping set list>\par
\par
      <grouping Column reference list> ::=\par
      <Column reference> [ COLLATE <Collation name> ] [ ,... ]\par
\par
      <grouping set list> ::=\par
      <grouping set> [ \{,<grouping set>\}... ] \par
\par
         <grouping set> ::=\par
         <grouping Column reference> | \par
         (<grouping column reference list>) | \par
         ROLLUP (<grouping Column reference list>) | \par
         CUBE (<grouping Column reference list>) | \par
         () \par
\par
GROUP BY defines a grouped Table: a set of groups of rows, where each group\par
consists of the rows in which all the values of the grouping Column(s) are\par
equal (the group is the entire Table if you use the HAVING clause without a\par
preceding GROUP BY clause). Here are three SELECT statements; each contains a\par
GROUP BY clause:\par
\par
   SELECT   column_1 FROM Table_1 \par
   GROUP BY column_1;\par
\par
   SELECT   column_1 FROM Table_1 \par
   WHERE    column_1 BETWEEN 10 AND 50 \par
   GROUP BY column_1;\par
\par
   SELECT   column_1 FROM Table_1 \par
   WHERE    column_1 BETWEEN 10 AND 50 \par
   GROUP BY column_1 HAVING SUM(column_1)>12;\par
\par
These examples illustrate that the GROUP BY clause contains a list of <Column\par
reference>s (the grouping Columns) and that it comes at a certain place within\par
the various optional or compulsory clauses of a SELECT statement. In each\par
case, the grouping <Column reference> names a Column that belongs to a Table\par
named in the SELECT ... FROM clause -- the argument of the GROUP BY clause is\par
a list of (optionally qualified) <Column name>s and only <Column name>s; SQL\par
doesn't allow you to use <literal>s, Column expressions, or any\par
operator/function except COLLATE in a GROUP BY clause. In addition, when a\par
SELECT statement includes GROUP BY, the statement's select list may consist\par
only of references to Columns that are single-valued per group -- this means\par
that the select list can't include a reference to an interim result Column\par
that isn't also included in the GROUP BY clause unless that Column is an\par
argument for one of the set functions (AVG, COUNT, MAX, MIN, SUM, EVERY, ANY,\par
SOME; each of which reduce the collection of values from a Column to a single\par
value). These are severe restrictions, but we'll show you ways to get around\par
some of the restrictions.\par
\par
The GROUP BY clause allows you to summarize SQL-data. For an example of how it\par
works, let's look at some basic queries on one of the sample Tables we defined\par
in our chapter on simple search conditions: the PAYROLL Table, which looks\par
like this:\par
\par
PAYROLL\par
EMPNUM      RATE        LOCATION          PAID              APPT\par
 1           6.00       10TH FLOOR        1989-10-31        10:15:00\par
 2           5.00       16TH FLOOR        1989-09-30        10:20:00\par
 3           5.00       WAREHOUSE         1989-09-30        10:30:00\par
 4           8.00       BASEMENT          1989-10-15        12:00:10\par
10          16.00       16TH FLOOR        1989-09-30        12:30:00\par
11          16.00       16TH FLOOR        1989-10-15        13:15:10\par
20           9.00       WAREHOUSE         1989-10-15        14:00:00\par
28          ?           16TH FLOOR        1989-09-15        14:10:00\par
35           9.00       10TH FLOOR        1989-10-31        14:20:00\par
40          16.00       10TH FLOOR        1989-10-31        14:35:07 \par
\par
The simplest GROUP BY example on PAYROLL groups the LOCATION Column into its\par
four different values. Here's the SELECT statement:\par
\par
   SELECT   location FROM Payroll \par
   GROUP BY location;\par
\par
To get the result for this SELECT statement, your DBMS will first evaluate the\par
FROM clause to construct an interim result Table (in this case, the entire\par
PAYROLL Table), then pass this interim result to the GROUP BY clause. When it\par
evaluates the GROUP BY clause, it breaks the interim result into groups which\par
have the same values in LOCATION (the grouping Column), then passes this\par
interim result to the select list. When it evaluates the select list, your\par
DBMS throws out all Columns which aren't named in the select list. The result,\par
then, is:\par
\par
LOCATION \par
10TH FLOOR \par
16TH FLOOR \par
WAREHOUSE \par
BASEMENT \par
\par
A slightly more complicated example groups PAYROLL's LOCATION and RATE\par
Columns. Here's the SELECT statement:\par
\par
   SELECT   location, rate FROM Payroll \par
   GROUP BY location, rate;\par
\par
To get the result for this SELECT statement, your DBMS will follow the same\par
steps we described for the last example -- up until it reaches the interim\par
result that contains groups which have the same values in LOCATION (the first\par
grouping Column). At this point, instead of passing the result to the select\par
list, the DBMS will now break the new interim result into groups which have\par
the same values in LOCATION and RATE (the second grouping Column). This\par
interim result is then passed on to the select list for evaluation. The final\par
result is (note that the NULL value in the RATE Column is in a group of its\par
own; for GROUP BY all NULLs form a single group):\par
\par
LOCATION      RATE \par
10TH FLOOR     6.00 \par
10TH FLOOR     9.00 \par
10TH FLOOR    16.00 \par
16TH FLOOR     5.00 \par
16TH FLOOR    16.00  \par
16TH FLOOR    ?  \par
WAREHOUSE      5.00 \par
WAREHOUSE      9.00 \par
BASEMENT       8.00 \par
\par
One last example: grouping with a WHERE clause. Here's a SELECT statement:\par
\par
   SELECT   location, rate FROM Payroll \par
   WHERE    rate > 6.00 \par
   GROUP BY location, rate;\par
\par
To get the result for this SELECT statement, your DBMS will get a copy of the\par
PAYROLL Table (evaluate the FROM clause), remove any rows where the RATE value\par
is less than or equal to 6 (evaluate the WHERE clause), break the result into\par
groups which have the same values in LOCATION and RATE (evaluate the GROUP BY\par
clause) and remove any groups which aren't named in the select list. The\par
result is: \par
\par
LOCATION     RATE \par
10TH FLOOR    9.00 \par
10TH FLOOR   16.00 \par
16TH FLOOR   16.00  \par
16TH FLOOR   ?  \par
WAREHOUSE     9.00 \par
BASEMENT      8.00 \par
\par
Rules For Grouping Columns:\par
In the GROUP BY clause:\par
      ## Each Column in a GROUP BY clause must unambiguously name a Column\par
that belongs to a Table named in the SELECT statement's FROM clause. The name\par
may be qualified, i.e.: it may be a <Column reference>. Such a Column is\par
called a grouping Column: its values will be grouped for the final result.\par
      ## The grouping Column <data type> may not be BLOB, CLOB, NCLOB or\par
ARRAY.\par
      ## If the grouping Column <data type> is CHAR or VARCHAR, then the\par
<Column reference> may be accompanied by COLLATE <Collation name>. This\par
addition was added to SQL with SQL-92 and may not be supported by all DBMSs.\par
The idea is that you should be able to match for upper|lower case, or use PAD\par
SPACES when you're defining a group's values. Other than COLLATE, all SQL\par
operators and functions are illegal in a GROUP BY clause.\par
\par
In the select list:\par
      ## You must follow "The Single-Value Rule" -- every Column named in the\par
select list must also be a grouping Column, unless it is an argument for one\par
of the set functions.\par
      ## The select list may include derived Columns -- <literal>s, scalar\par
functions, and <Column name>s within expressions (only the GROUP BY clause\par
disallows expressions).\par
\par
Here are some examples of grouped SELECT statements, legal and not (a is a\par
Column of Table T):\par
\par
   SELECT a FROM T GROUP BY a;\par
      -- legal: grouping Column = select Column\par
\par
   SELECT a || a FROM T GROUP BY a;\par
      -- legal: a is grouped and it applies to both instances in select list\par
\par
   SELECT MAX(a) AS b FROM T GROUP BY a;\par
      -- legal: a need not be in select list\par
\par
   SELECT a+5 FROM T GROUP BY a;\par
      -- legal: expression in select list refers to grouping Column\par
\par
   SELECT 5 FROM T GROUP BY a;\par
      -- legal: the <literal> isn't a reference to a Column of T, so it\par
doesn't have to be a grouping Column: you'll get a bunch of "5"s\par
\par
   SELECT a*5 AS b FROM T GROUP BY b;\par
      -- illegal: a is not a grouping Column and b isn't evaluated until the\par
select list is; by then it's too late\par
\par
   SELECT a,max(a) FROM T;\par
      -- illegal: GROUP BY "implied", see set functions \par
\par
   SELECT a+5 FROM T GROUP BY a+5;\par
      -- illegal: expression in GROUP BY\par
\par
** TRAP: The superficial similarity of the GROUP BY clause and the ORDER BY\par
clause often misleads people. The big difference is that grouping is done on\par
the input (that is, the Tables named in the FROM clause), while ordering is\par
done on the output (that is, the Columns named in the select list). So,\par
although you can say "ORDER BY integer" (only in SQL-92 though) and "ORDER BY\par
expression", it makes no sense to say "GROUP BY integer" or "GROUP BY\par
expression". On the other hand, grouping Columns don't have to be in the\par
select list, as sorted Columns must.\par
\par
** TRAP: The SQL Standard doesn't specify how many Columns can be grouped or\par
what the size of a grouping Column may be (except that it can't be a large\par
object string), but most DBMSs allow fairly small numbers and sizes. When\par
people create Tables, they often allot hundreds of characters for VARCHAR\par
Columns (like "address" or "comment"), thinking that there is plenty of room\par
in the row. Later they find that their DBMS can't use those Columns In a GROUP\par
BY clause, due to their size. Moral: Don't make Columns bigger than they have\par
to be.\par
\par
## The Single-Value Rule\par
The rationale for this rule is as follows. Suppose you have a list of cities\par
and countries. If this SQL statement were legal:\par
\par
   SELECT    city, country FROM Cities_And_Countries \par
   GROUP BY country;\par
\par
what value would come out in the CITY Column? There are plausible answers such\par
as "any city will do provided it's in the country", or "the DBMS should assume\par
that we want to group by both country and city". The problem with those\par
answers is that they try to compensate for a formal user error. What the user\par
really needs to know is "that does not compute".\par
\par
The rule does not mean that all values must be distinct. We could multiply\par
everything times zero, yielding zeros in every Column in the select list, and\par
we would still be specifying "single-valued per group". The true meaning is\par
that there must be, for each group, one (and only one) value which is\par
appropriate as an answer for the query. Sometimes the DBMS doesn't realize\par
this, as in a SQL statement like:\par
\par
   SELECT   capitalcity, country FROM Cities_And_Countries \par
   GROUP BY country;\par
\par
but if that's the case, we can easily tell the DBMS this is so by adding a\par
grouping Column to the statement:\par
\par
   SELECT   capitalcity, country FROM Cities_And_Countries \par
   GROUP BY country, capitalcity;\par
\par
The single-value rule is sensible and it is Standard SQL. Don't be  misled by\par
a "textbook" describing the one DBMS which does not follow the Standard.\par
\par
## Grouping by expressions\par
We said earlier that, while you can use "GROUP BY Column list" in your SELECT\par
statements, you can't use "GROUP BY expression list". This means that these\par
two SQL statements are both illegal:\par
\par
   SELECT   EXTRACT(MONTH FROM bdate) FROM Table_1 \par
   GROUP BY EXTRACT(MONTH FROM bdate);\par
\par
   SELECT   EXTRACT(MONTH FROM bdate) AS ebdate FROM Table_1 \par
   GROUP BY ebdate;\par
\par
Looks like we can't group by MONTH: we have to group by the whole date.\par
Bummer. Luckily, there is a way out if you have SQL-92 and some patience: \par
\par
   SELECT   ebdate \par
   FROM     (SELECT EXTRACT(MONTH FROM bdate) AS ebdate FROM Table_1)\par
   GROUP BY ebdate;\par
\par
This example uses a Table subquery in the FROM clause, and puts all the\par
necessary calculations inside that Table subquery. The outer SELECT does a\par
grouping of the result -- which is now legal, since the EBDATE Column is\par
clearly identified as a Column belonging to the Table named in the FROM\par
clause. If your DBMS doesn't support Table subqueries in the FROM clause, try\par
making a View, or a temporary Table, with the same logic. Whatever you do will\par
be slow, because two Tables are being produced, one for the temporary Table\par
and one for the grouping.\par
\par
New syntax:\par
Until now, all of our examples have shown GROUP BY followed by one or more\par
<Column reference>s. This was the only available option until SQL3, which adds\par
this syntax:\par
GROUP BY ROLLUP(grouping Columns)\par
GROUP BY CUBE(grouping Columns)\par
GROUP BY ()\par
GROUP BY GROUPING SETS grouping Column\par
GROUP BY GROUPING SETS (grouping Columns)\par
GROUP BY GROUPING SETS ROLLUP(grouping Columns)\par
GROUP BY GROUPING SETS CUBE(grouping Columns)\par
GROUP BY GROUPING SETS()\par
GROUP BY (grouping Columns),<grouping set list>\par
GROUP BY ROLLUP(grouping Columns),<grouping set list>\par
GROUP BY CUBE(grouping Columns),<grouping set list>\par
GROUP BY (),<grouping set list>\par
\par
"GROUP BY GROUPING SETS" effectively allows groups within groups -- in one\par
pass, it generates multiple aggregated groups that would otherwise require a\par
set operator to put the different result sets together. For example:\par
\par
   SELECT    A.id,B.name,COUNT(*) \par
   FROM     Table_1 AS A, Table_2 as B \par
   WHERE    A.number = B.number\par
   GROUP BY GROUPING SETS (A.id,(A.id,B.name));\par
\par
In this example, the GROUP BY clause determines the first requirement --\par
groups of IDs -- by grouping the A.ID values from the TABLE_1 Table. It then\par
determines the second requirement -- number of IDs by ID and NAME -- by\par
grouping the A.ID values from TABLE_1 with the B.NAME values from TABLE_2.\par
\par
The grouping forms like "GROUP BY (grouping Columns), <grouping set list>",\par
also known as concatenated grouping, puts groups together.\par
\par
A <grouping specification> of () (called grand total in the Standard) is\par
equivalent to grouping the entire result Table; i.e.: to the result returned\par
by:\par
\par
   SELECT select list FROM Tables \par
   WHERE  conditions \par
   HAVING conditions\par
\par
A <grouping specification> of ROLLUP means get one group out of all grouping\par
Columns, by rolling each group into the next until only one remains. It is\par
equivalent to the result returned by:\par
\par
   SELECT   select list FROM Tables \par
   WHERE    conditions \par
   GROUP BY GROUPING SETS ( \par
     (ROLLUP col_1,ROLLUP col_2,...,ROLLUP col_n),\par
     (ROLLUP col_1,ROLLUP col_2,...,ROLLUP col_n-1),\par
     (ROLLUP col_1,ROLLUP col_2,...,ROLLUP col_n-2),\par
      ...\par
     (ROLLUP col_1),\par
     () )\par
   HAVING   conditions\par
\par
A <grouping specification> of CUBE means get one group out of all grouping\par
Columns, by grouping all possible combinations of the grouping Columns. It is\par
equivalent to the result returned by:\par
\par
   SELECT   select list FROM Tables \par
   WHERE    conditions\par
   GROUP BY GROUPING SETS ( \par
     (CUBE col_1,CUBE col_2,...,CUBE col_n-2,CUBE col_n-1,CUBE col_n),\par
     (CUBE col_1,CUBE col_2,...,CUBE col_n-2,CUBE col_n-1),\par
     (CUBE col_1,CUBE col_2,...,CUBE col_n-2,CUBE col_n),\par
     (CUBE col_1,CUBE col_2,...,CUBE col_n-2),\par
     ...\par
     (CUBE col_1),\par
     (CUBE col_2,...,CUBE col_n-2,CUBE col_n-1,CUBE col_n),\par
     (CUBE col_2,...,CUBE col_n-2,CUBE col_n-1),\par
     (CUBE col_2,...,CUBE col_n-2,CUBE col_n),\par
     (CUBE col_2,...,CUBE col_n-2),\par
     ...\par
     (CUBE col_2),\par
     ... \par
     (CUBE col_3),\par
     ...\par
     (CUBE col_n),\par
     () )\par
   HAVING   conditions\par
\par
As an example of these new options, assume there is a Table, TABLE_1, that\par
looks like this:\par
\par
TABLE_1\par
COLUMN_1   COLUMN_2   COLUMN_3\par
1          A           .55\par
1          A           .55\par
1          B          1.00\par
1          B          1.35\par
2          A          6.00\par
2          A          1.77\par
\par
Let's do an ordinary GROUP BY, with only <Column reference>s as grouping\par
Columns, on TABLE_1:\par
\par
   SELECT   column_1,\par
            column_2,\par
            SUM(column_3) AS "SUM" \par
   FROM     Table_1 \par
   GROUP BY column_1,column_2;\par
\par
The result is:\par
\par
COLUMN_1   COLUMN_2   "SUM"\par
1          A          1.10\par
1          B          2.35\par
2          A          7.77\par
\par
Now let's do a GROUP BY with ROLLUP:\par
\par
   SELECT   column_1,\par
            column_2,\par
            SUM(column_3) AS "SUM" \par
   FROM     Table_1 \par
   GROUP BY ROLLUP(column_1,column_2);\par
\par
This time, the result is:\par
\par
COLUMN_1   COLUMN_2   "SUM"\par
1          A          1.10\par
1          B          2.35\par
1          NULL       3.45\par
2          A          7.77\par
2          NULL       7.77\par
NULL       NULL      11.22\par
\par
In addition to the same groups returned by the ordinary GROUP BY, GROUP BY\par
ROLLUP gets a group of each group: the group of COLUMN_1 "1" values (with a\par
NULL for the grouping of "A" and "B" in COLUMN_2), the group of COLUMN_1 "2"\par
values (with a NULL for the grouping of "A" in COLUMN_2) and the group of\par
COLUMN_1 "1" and "2" values (with a NULL for the grouping of "A" and "B" in\par
COLUMN_2).\par
\par
Finally, let's do a GROUP BY with CUBE:\par
\par
   SELECT   column_1,\par
            column_2,\par
            SUM(column_3) AS "SUM" \par
   FROM     Table_1 \par
   GROUP BY CUBE(column_1,column_2);\par
\par
This time, the result is:\par
COLUMN_1   COLUMN_2   "SUM"\par
1          A           1.10\par
1          B           2.35\par
1          NULL        3.45\par
2          A           7.77\par
2          NULL        7.77\par
NULL       A           8.87\par
NULL       B           2.35\par
NULL       NULL       11.22\par
\par
In addition to the same groups returned by the GROUP BY ROLLUP, GROUP BY CUBE\par
gets a group of each combination of groups: the group of COLUMN_1 "1" values,\par
the group of COLUMN_1 "2" values, the group of COLUMN_2 "A" values (with a\par
NULL for the grouping of "1" and "2" in COLUMN_1) and the group of COLUMN_2\par
"B" values (with a NULL for the grouping of "1" in COLUMN_1).\par
\par
If you want to restrict your code to Core SQL, don't use ROLLUP or CUBE, and\par
don't add a COLLATE clause to any grouping Column reference.\par
\par
Set Functions\par
\par
The SQL set functions -- more commonly called aggregate functions -- are AVG,\par
COUNT, MAX, MIN, SUM, EVERY, ANY, SOME. Each one takes the collection of\par
values from a Column and reduces the collection to a single value. The\par
required syntax for a set function specification is:\par
\par
<set function specification> ::=\par
<general set function> | \par
COUNT(*) | \par
<grouping operation>\par
\par
      <general set function> ::=\par
      <set function type> ([ \{DISTINCT | ALL\} ] Column expression)      \par
      \par
         <set function type> ::=\par
         COUNT | MAX | MIN | SUM | AVG | EVERY | ANY | SOME\par
\par
      <grouping operation> ::=\par
      GROUPING (<Column reference>)\par
\par
The Column expression that follows a <general set function> can be a <Column\par
reference>, a <literal>, a scalar function or an arithmetic expression -- in\par
short, it can be any expression (other than a query or subquery or another set\par
function) which evaluates to a Column, as long as that Column doesn't have a\par
<data type> of BLOB, CLOB or NCLOB. Each <general set function> operates on\par
the entire collection of non-null values in its Column argument -- grouping\par
rules apply because grouping is implied -- and can optionally be qualified\par
with either DISTINCT or ALL. If you specify DISTINCT, your DBMS will eliminate\par
any duplicate values from the Column before applying the set function. If you\par
specify ALL, your DBMS will apply the set function to every non-null value in\par
the Column. The default is ALL. When a set function eliminates NULLs, your\par
DBMS will return the SQLSTATE warning 01003 "warning-null value eliminated in\par
set function".\par
\par
Here's an example Table; we'll use it for the explanations of the set\par
functions that follow:\par
\par
TABLE_1 \par
COLUMN_1\par
10\par
20\par
10\par
20\par
30\par
NULL\par
\par
The COUNT function has two forms: it can have an asterisk as an argument or a\par
Column expression as an argument. It returns an integer.\par
      ## COUNT(*) returns the number of rows in the argument Table, rather\par
than the number of values in any particular Column, so this SQL statement\par
returns 6:\par
\par
   SELECT COUNT(*) FROM Table_1\par
\par
      ## COUNT(Column) and COUNT(ALL Column) are equivalent: both return the\par
number of non-null values in "Column", so these SQL statements both return 5:\par
\par
   SELECT COUNT(column_1) FROM Table_1;\par
\par
   SELECT COUNT(ALL column_1) FROM Table_1;\par
      \par
      ## COUNT(DISTINCT Column) returns the number of unique, non-null values\par
in "Column", so this SQL statement returns 3:\par
\par
   SELECT COUNT(DISTINCT column_1) FROM Table_1;\par
\par
The MAX function returns the maximum value and can't be used with Columns that\par
have a <data type> of ROW, REF, BLOB, CLOB or NCLOB, or with a UDT. The <data\par
type> and size of the result will be the same as the <data type> and size of\par
the expression itself.\par
      ## MAX(Column), MAX(ALL Column) and MAX(DISTINCT Column) are equivalent:\par
all three return the largest of the non-null values in "Column", so these SQL\par
statements all return 30:\par
\par
   SELECT MAX(column_1) FROM Table_1;\par
\par
   SELECT MAX(ALL column_1) FROM Table_1;\par
\par
   SELECT MAX(DISTINCT column_1) FROM Table_1;\par
\par
It's rare to find explicit ALL or DISTINCT with MAX.\par
\par
The MIN function returns the minimum value and can't be used with Columns that\par
have a <data type> of ROW, REF, BLOB, CLOB or NCLOB, or with a UDT. The <data\par
type> and size of the result will be the same as the <data type> and size of\par
the expression itself.\par
      ## MIN(Column), MIN(ALL Column) and MIN(DISTINCT Column) are equivalent:\par
all three return the smallest of the non-null values in "Column", so these SQL\par
statements all return 10:\par
\par
   SELECT MIN(column_1) FROM Table_1;\par
\par
   SELECT MIN(ALL column_1) FROM Table_1;\par
\par
   SELECT MIN(DISTINCT column_1) FROM Table_1;\par
\par
As with MAX, it's rare to find explicit ALL or DISTINCT with MIN.\par
\par
The SUM function returns a total and can't be used with Columns that have a\par
<data type> of ROW, REF, BLOB, CLOB or NCLOB, or with a UDT. The <data type>\par
of the expression must be numeric or INTERVAL; in the first case, the result\par
<data type> will also be numeric, with the same scale as the expression, but\par
(possibly) a larger precision. That's necessary -- consider what would happen\par
if you had a DECIMAL(2) Column containing two values: 51, 51. The result of\par
SUM would be 102, which is DECIMAL(3), so the DBMS has to be able to increase\par
the precision for the result. If you're not sure that your DBMS will give SUM\par
a great enough precision, increase the precision of the expression using a\par
CAST function. In the second case, the result <data type> will be INTERVAL\par
with the same precision as the expression.\par
      ## SUM(Column) and SUM(ALL Column) are equivalent: both return the total\par
of the non-null values in "Column", so these SQL statements both return 90:\par
\par
   SELECT SUM(column_1) FROM Table_1;\par
\par
   SELECT SUM(ALL column_1) FROM Table_1;\par
\par
      ## SUM(DISTINCT Column) returns the total of the unique, non-null values\par
in "Column", so this SQL statement returns 60:\par
\par
   SELECT SUM(DISTINCT column_1) FROM Table_1;\par
\par
The AVG function returns an average and can't be used with Columns that have a\par
<data type> of ROW, REF, BLOB, CLOB or NCLOB, or with a UDT. The <data type>\par
of the expression must be numeric or INTERVAL; in the first case, the result\par
<data type> will also be numeric, with scale and precision equal to or greater\par
than the expression's scale and precision (most DBMSs increase the scale but\par
leave the precision alone). In the second case, the result <data type> will be\par
INTERVAL with the same precision as the expression.\par
      ## AVG(Column) and AVG(ALL Column) are equivalent: both return the\par
average of the non-null values in "Column", so these SQL statements both\par
return 18:\par
\par
   SELECT AVG(column_1) FROM Table_1;\par
\par
   SELECT AVG(ALL column_1) FROM Table_1;\par
\par
      ## AVG(DISTINCT Column) returns the average of the unique, non-null\par
values in "Column", so this SQL statement returns 20:\par
\par
   SELECT AVG(DISTINCT column_1) FROM Table_1;\par
\par
The EVERY function, new to SQL with SQL3, returns a truth value and can only\par
be used with Columns that have a <data type> of BOOLEAN.\par
      ## EVERY(Column), EVERY(ALL Column) and EVERY(DISTINCT Column) are\par
equivalent: all three return FALSE if any of the values in "Column" are FALSE\par
and all three return TRUE if no value in "Column" is FALSE. For these two\par
Tables:\par
\par
TABLE_1                     TABLE_2\par
COLUMN_1                    COLUMN_1 \par
TRUE                        TRUE \par
TRUE                        TRUE \par
FALSE                       UNKNOWN\par
FALSE \par
UNKNOWN \par
\par
these SQL statements all return FALSE:\par
\par
   SELECT EVERY(column_1) FROM Table_1;\par
\par
   SELECT EVERY(ALL column_1) FROM Table_1;\par
\par
   SELECT EVERY(DISTINCT column_1) FROM Table_1;\par
\par
And these SQL statements all return TRUE:\par
\par
   SELECT EVERY(column_1) FROM Table_2;\par
\par
   SELECT EVERY(ALL column_1) FROM Table_2;\par
\par
   SELECT EVERY(DISTINCT column_1) FROM Table_2;\par
\par
The ANY function (and its, synonym, SOME), new to SQL with SQL3, returns a\par
truth value and can only be used with Columns that have a <data type> of\par
BOOLEAN.\par
      ## ANY(Column), ANY(ALL Column) and ANY(DISTINCT Column) are equivalent:\par
all three return TRUE if any of the values in "Column" are TRUE and all three\par
return FALSE if no value in "Column" is TRUE. For these two Tables:\par
\par
TABLE_1                     TABLE_2\par
COLUMN_1                    COLUMN_1 \par
TRUE                        FALSE \par
TRUE                        FALSE \par
FALSE                       UNKNOWN\par
FALSE \par
UNKNOWN \par
\par
these SQL statements all return TRUE:\par
\par
   SELECT ANY(column_1) FROM Table_1;\par
\par
   SELECT ANY(ALL column_1) FROM Table_1;\par
\par
   SELECT ANY(DISTINCT column_1) FROM Table_1;\par
\par
And these SQL statements all return FALSE:\par
\par
   SELECT ANY(column_1) FROM Table_2;\par
\par
   SELECT ANY(ALL column_1) FROM Table_2;\par
\par
   SELECT ANY(DISTINCT column_1) FROM Table_2;\par
\par
The GROUPING function, new to SQL with SQL3, operates on an argument that must\par
be a <Column reference>, where the Column referred to is a grouping Column for\par
the query. You use it in conjunction with the various grouping sets options of\par
the GROUP BY clause. It returns either an integer or the value of some Column\par
-- the Standard is unclear on this point.\par
\par
DISTINCT Set Functions:\par
Since DISTINCT <set function> is usually a slow process, it's worthwhile to\par
look for ways to avoid it. With MIN, MAX, EVERY, ANY and SOME, DISTINCT means\par
nothing, so there's no problem omitting it there. If the Column happens to be\par
a primary key or unique key, then DISTINCT will have no effect because the\par
values are all distinct anyway, so again, no problem omitting it there.\par
(Although a unique key Column might have a million NULLs in it, that won't\par
matter because the set functions ignore NULLs anyway). The only things you\par
must be sure of, if you remove the <keyword> DISTINCT because the Column is\par
primary or unique, are (a) that the PRIMARY KEY/UNIQUE Constraint is NOT\par
DEFERRABLE and (b) that there is no chance that the database definition will\par
ever change.\par
\par
** TIP: If you use ODBC then you should check whether your DBMS supports the\par
SQLRowCount function for results sets; if it does, then you won't have to use\par
COUNT(*) to find out how many rows answer a query. This is particularly a\par
time-saver if the query contains DISTINCT, since COUNT(DISTINCT ...) is a\par
particularly slow function.\par
\par
Set Functions and the "ignore NULLs" policy:\par
All the set functions ignore NULLs (the COUNT(*) function looks like an\par
exception but if you think of it as a shorthand for COUNT(1) you will realize\par
that no NULLs are ever involved there). In other words, when we calculate\par
SUM(x) we are not calculating the sum of all values of x, but the sum of all\par
known values of x. This policy is the result of practical experience: some\par
early SQL DBMSs didn't ignore NULLs, but now they all do.\par
\par
Now, this is a little inconsistent, because in most arithmetic expressions\par
that involve NULL, the result is NULL (e.g.: "5 + NULL yields NULL"). This\par
leads to a **TRAP: \par
\par
   SUM(a)+SUM(b) is not the same as SUM(a+b)! Consider these two rows:\par
\par
       a  b \par
row#1  5  NULL\par
row#2  5  5\par
\par
Since the SUM of \{5,5\} is 10, and the SUM of \{NULL,5\} is 5, the result of\par
SUM(a)+SUM(b) is 15. However, since (5+NULL) is NULL, and (5+5) is 10, and the\par
SUM of \{NULL,10\} is 10, then SUM(a+b) is 10! So which answer is correct: 15 or\par
10? The cautious person would perhaps reply: both answers are wrong -- the\par
result should be NULL. However, we have already posited that in the context of\par
set functions we want to ignore NULLs. In this context, the best answer is the\par
one that ignores the most NULLs -- to wit: 15. Therefore the correct\par
expression to use is SUM(a)+SUM(b), not SUM(a+b). A clinching argument is that\par
SUM(a)+SUM(b) involves fewer "add" operations than SUM(a+b), and is therefore\par
less subject to the cumulative effects of rounding. Similar considerations\par
apply for all set functions with expressions that contain + or - or ||\par
operators.\par
\par
Because of the "ignore NULLs" policy, it should be rare for a set function to\par
return NULL. The only cases are: for MIN or MAX or SUM or AVG, if every one of\par
the Column values is NULL, or if the SELECT returns no rows at all, the\par
function returns NULL (so in fact these functions could return NULL even if\par
the Column is defined as NOT NULL, yielding another case where you shouldn't\par
be fooled by a NOT NULL Constraint definition.) The COUNT function can never\par
return NULL -- if there are no rows returned, then the count is, naturally\par
enough, zero.\par
\par
Set functions in Subqueries:\par
Who makes more than the average salary? What is the cheapest book? That's the\par
kind of question that requires a comparison with a subquery that contains a\par
set function. In other words, you need a condition with this general format:\par
\par
... WHERE <value> <comparison-operator> (SELECT <set function> ...)\par
\par
For example: \par
\par
SELECT ... FROM  ... WHERE ... = (SELECT MIN(price) FROM book);\par
\par
This is one of the cases where it's much easier to use a subquery than a join.\par
\par
If you try to do something more complex, you will probably run into some\par
restrictions because set functions within subqueries are hard to implement.\par
We'll give just one example of a restriction (from SQL-92) -- if the set\par
function's argument is an "outer reference" Column (i.e.: the name of a Column\par
in the outer enclosing query), then that must be the only <Column reference>\par
within that argument and the set function has to appear either in a select\par
list or within a subquery that belongs to a HAVING clause. For example, this\par
complex query uses illegal syntax:\par
\par
   SELECT * FROM Table_1 WHERE 0 = (\par
      SELECT SUM(Table_1.column_1+Table_2.column_1) FROM Table_2);\par
\par
It would be even more illegal if the set function appeared in the WHERE\par
clause, or if there was a third level of subquery nesting. Nobody can remember\par
such a complex rule, and there are more like it, so the cautious programmer\par
simply avoids trying anything fancy when using set functions within\par
subqueries.\par
\par
Retrieval with a set function:\par
Here's some examples of set functions, using the sample database we defined in\par
our chapter on simple search conditions. To find the total number of employees\par
with payroll records (retrieve the number of records in a Table):\par
\par
   SELECT COUNT(*) AS pay_count \par
   FROM   Payroll;\par
\par
The result is:\par
\par
PAY_COUNT\par
10\par
\par
COUNT(*) counts all rows of a Table, regardless of NULLs.\par
\par
To find the number of employees with known pay rates (retrieve the number of\par
non-null values in a Column):\par
\par
   SELECT COUNT(rate) AS pay_count \par
   FROM   Payroll;\par
\par
The result is:\par
\par
PAY_COUNT\par
9\par
\par
COUNT(column) eliminates NULLs before counting a Column's values.\par
\par
To find the number of pay rates (retrieve the number of unique values in a\par
Column):\par
\par
   SELECT COUNT(DISTINCT rate) AS pay_count \par
   FROM   Payroll;\par
\par
The result is:\par
\par
PAY_COUNT\par
5\par
\par
The DISTINCT option eliminates duplicates before a set function is processed.\par
\par
To find the sum of the pay rates by location (group a Table into like values\par
combined with a set function):\par
\par
   SELECT   location,\par
            SUM(rate) AS sum_rate\par
   FROM     Payroll \par
   GROUP BY location;\par
\par
The result is:\par
\par
LOCATION     SUM_RATE\par
10TH FLOOR   31.00\par
16TH FLOOR   37.00\par
BASEMENT      8.00\par
WAREHOUSE    14.00\par
\par
To find the number of employees in each department:\par
\par
   SELECT   COUNT(empnum) AS emp_count,\par
            dept \par
   FROM     Employee \par
   WHERE    dept<'D' \par
   GROUP BY dept;\par
\par
The result is:\par
\par
EMP_COUNT   DEPT\par
2           A\par
4           B\par
1           C\par
\par
If you want to restrict your code to Core SQL, don't use the set functions\par
EVERY, ANY, SOME or GROUPING, don't use a set function unless it operates only\par
on a <Column reference> that refers to a Column belonging to a Table named in\par
the FROM clause, and when counting, always use COUNT(*): don't use\par
COUNT(Column) or COUNT(ALL Column) at all.\par
\par
HAVING clause\par
\par
What departments have four employees? In which branches is the smallest book's\par
size less than 40mm? Those are two questions that require comparison of an\par
absolute value with a set function, and thus represent the commonest\par
situations where we'd find it useful to bring in a HAVING clause. The HAVING\par
clause is an optional portion of the SELECT statement. It, too, defines a\par
grouped Table. The required syntax for the HAVING clause is:\par
\par
HAVING <search condition>\par
\par
The HAVING clause defines a grouped Table that contains only those groups for\par
which its search condition is TRUE and usually follows a GROUP BY clause.\par
HAVING operates on the interim result produced by the evaluation of the SELECT\par
statement at that stage:\par
      ## If the statement is "SELECT ... FROM ... HAVING ...", HAVING operates\par
on the entire FROM Table, treating it as a single group. (GROUP BY is implied,\par
but the result has no grouping Columns.)\par
      ## If the statement is "SELECT ... FROM ... WHERE ... HAVING ...",\par
HAVING operates on the rows of the FROM Table that are TRUE for the WHERE\par
conditions, again, treating the interim result as a single group.\par
      ## If the statement is "SELECT ... FROM ... WHERE ... GROUP BY ...\par
HAVING ...", HAVING operates on the interim groups returned by GROUP BY.\par
\par
The HAVING clause's search condition may include ANDs, ORs, relational\par
operators, scalar and arithmetic expressions, and so on -- much like a WHERE\par
clause's search condition. The difference between a WHERE condition and a\par
HAVING condition is implied by the clause order. The DBMS evaluates WHERE\par
before it does the grouping; it evaluates HAVING after it does the grouping --\par
thus, WHERE filters rows and HAVING filters groups. It's usually more\par
efficient to filter before grouping (because then there will be fewer rows to\par
group), so it's best to put most simple conditions in the WHERE clause and use\par
HAVING only for these situations:\par
      ## If one of the condition's operands is a set function. Since a set\par
function is not evaluated until you group, it is impossible to use one in a\par
WHERE clause.\par
      ## If there is a quirk in a particular DBMS's optimizer. For one DBMS,\par
"GROUP BY a HAVING a = 7" works well because (since the grouping Column and\par
the condition Column are the same) the two clauses can be evaluated\par
simultaneously. For most DBMSs, putting a condition in the HAVING clause is a\par
hint that you want to avoid using any indexes.\par
\par
Operands in the HAVING clause are subject to the same restrictions as in the\par
select list:\par
      ## Column expressions in both must be single-valued per group.\par
      ## Column references must be unambiguous.\par
      ## If a SELECT statement contains HAVING without a preceding GROUP BY\par
clause, the select list can't include any references to Columns belonging to a\par
Table named in the FROM clause unless those references are used with a set\par
function.\par
      ## If HAVING includes a subquery, it can't include outer Column\par
references unless those references are to grouping Columns or are used with a\par
set function.\par
\par
Let's look closely at an SQL statement which contains a HAVING clause:\par
\par
   SELECT   column_1, \par
            COUNT(column_2) \par
   FROM     Table_1 \par
   GROUP BY column_1 \par
   HAVING   COUNT(column_1) >= 5;\par
\par
In this SQL statement, the expression "COUNT(column_2)" is okay because,\par
although COLUMN_2 is not a grouping Column, it appears within a set function.\par
Suppose that TABLE_1 looks like this:\par
\par
TABLE_1 \par
COLUMN_1   COLUMN_2 \par
1          0\par
1          1\par
1          2\par
2          3\par
2          4\par
2          5\par
2          6\par
2          7\par
2          8\par
2          9\par
\par
TABLE_1 has 3 rows where COLUMN_1 is 1 and 7 rows where COLUMN_1 is 2. The\par
"COLUMN_1 = 1" group does not meet the HAVING clause's condition -- the\par
smallest acceptable count is 5. However, the "COLUMN_1 = 2" group does meet\par
HAVING's condition, and so the result of our SQL statement is:\par
\par
COLUMN_1   COLUMN_2\par
2          7\par
\par
Here is another way to get the same result, without using a HAVING clause:\par
\par
   SELECT column_1, \par
          c_count\par
   FROM   (SELECT  column_1, \par
                   COUNT(column_2) AS c_count \par
          FROM     Table_1 \par
          GROUP BY column_1)\par
   WHERE  c_count >=5;\par
\par
It is always possible to eliminate a HAVING clause and use a query expression\par
in the FROM clause instead. But most programmers prefer to stick with HAVING\par
because it is the traditional and familiar tool for solving this sort of\par
problem.\par
\par
HAVING without GROUP BY:\par
This SQL statement means "if there are more than 3 a's in the whole Table,\par
display how many a's there are":\par
\par
SELECT COUNT(a) FROM Somethings \par
HAVING COUNT(a) > 5;\par
\par
As is usual, because there is a set function in the SELECT statement, there is\par
an implied "GROUP BY ()". Therefore grouping rules apply: the select list in\par
such an SQL statement may contain only single-valued Columns.\par
\par
Retrieval using grouping:\par
Here's one more example of grouping, using the sample database we defined in\par
our chapter on simple search conditions. To find the departments with less\par
than two employees (group a Table, then eliminate all groups which do not\par
fulfill a condition):\par
\par
   SELECT   dept FROM Employee \par
   GROUP BY dept HAVING COUNT(*)<2;\par
\par
The result is:\par
\par
DEPT\par
C\par
D\par
\par
Views of Groups\par
\par
It's a straightforward exercise to make a View which is based on a grouping\par
operation -- the result is a grouped View. Here's an example:\par
\par
   CREATE VIEW Employee_Groups AS \par
      SELECT   department_id, COUNT(employee_id) AS count_employee_id \par
      FROM     Employees \par
      GROUP BY department_id;\par
\par
Now, whoever uses the EMPLOYEE_GROUPS View will see an ordinary Table with two\par
Columns: DEPARTMENT_ID and COUNT_EMPLOYEE_ID. But the user's view window won't\par
be totally transparent.\par
\par
Problem 1. Consider what happens for this SQL statement:\par
\par
   SELECT * FROM Employee_Groups \par
   WHERE  count_employee_id = 7 AND department_id = 'XX';\par
\par
Remember (from our chapter on Tables) that your DBMS may try to "transform"\par
this query into a query on the underlying Base table. The best transform is:\par
\par
   SELECT   department_id, COUNT(employee_id) FROM Employees \par
   WHERE    department_id = 'XX' \par
   GROUP BY department_id HAVING COUNT(employee_id) = 7;\par
\par
Observe that one, and only one, of the conditions of the original WHERE clause\par
has been split out and put in a new HAVING clause. Based on timings, we\par
believe that some DBMSs don't do this. We believe they put both conditions in\par
the HAVING clause. That's much less efficient.\par
\par
Problem 2. Consider what happens for this SQL statement:\par
   \par
   SELECT MAX(count_employee_id) FROM Employee_Groups;\par
\par
Your DBMS might attempt to transform this into:\par
\par
   SELECT   department_id, MAX(COUNT(employee_id)) FROM Employees \par
   GROUP BY department_id;\par
\par
that is, into a sensible question along the lines of "which department has\par
most employees". But "MAX(COUNT(employee_id))" is an illegal expression (you\par
can't nest set functions) and the result will be some error message defined by\par
your DBMS. This is legal: the SQL Standard doesn't demand that a DBMS should\par
handle groups within groups, or set functions within set functions.\par
\par
** TIP: That's why we named this View and its Column EMPLOYEE_GROUPS and\par
COUNT_EMPLOYEE_ID -- the names tip off the user that a COUNT in a grouped View\par
is involved. That lessens the confusion if the DBMS doesn't generate a clear\par
error message.\par
\par
Dialects\par
\par
The older (pre-1992) DBMSs had these restrictions on grouping:\par
      ## Any set functions in the HAVING clause had to appear in the select\par
list.\par
      ## HAVING was illegal if there was no GROUP BY clause.\par
      ## Groups within Views and subqueries worked only under a full moon (or\par
some undefined equivalent!).\par
\par
Nowadays, SQL DBMSs support grouping, set functions and HAVING clauses, in a\par
manner pretty much as we have described here, except for the new SQL3\par
features.\par
\par
It's also fairly easy to find DBMSs which will accept non-standard syntax.\par
Sybase ignores the Single-Value Rule so you can use any Column you like in the\par
select list. Oracle includes basic statistical-analysis set functions: STDDEV\par
(standard deviation) and VARIANCE. Several DBMSs allow "GROUP BY expression"\par
or even "GROUP BY ordinal position, as if the GROUP BY clause is analogous to\par
the ORDER BY clause.\par
\page\par
Chapter 34 -- Sorting Search Results\par
\par
In SQL, you can only sort search results returned by a Cursor. However, when\par
you're using Direct SQL, you're always using an implied Cursor, and so we'll\par
describe the ORDER BY clause now.\par
\par
ORDER BY clause \par
\par
The required syntax for the ORDER BY clause is:\par
\par
<query expression> [ ORDER BY <sort specification list> ]\par
\par
   <sort specification list> ::= \par
   <sort specification> [ \{,<sort specification> \}... ] \par
\par
      <sort specification> ::= \par
      <sort key> [ COLLATE <Collation name> ] [ \{ASC | DESC\} ]\par
\par
         <sort key> ::= scalar_expression\par
\par
An ORDER BY clause may optionally appear after a <query expression>: it\par
specifies the order rows should have when returned from that query (if you\par
omit the clause, your DBMS will return the rows in some random order). The\par
query in question may, of course, be a VALUES statement, a TABLE statement or\par
(most commonly) a SELECT statement. (For now, we are ignoring the possibility\par
that the SQL statement is DECLARE CURSOR, since that is strictly a matter for\par
"SQL in host programs", a later chapter.)\par
\par
The ORDER BY clause provides your DBMS with a list of items to sort, and the\par
order in which to sort them: either ascending order (ASC, the default) or\par
descending order (DESC). It must follow a <query expression> because it\par
operates on the final Table that results from the evaluation of the query; it\par
cannot operate on any interim result Tables at all. The <sort key> you specify\par
can be any expression that evaluates to a single value that identifies a\par
Column of the final result Table -- this is almost always a <Column name>.\par
Here's a simple example:\par
\par
   SELECT   column_1 \par
   FROM     Table_1 \par
   ORDER BY column_1;\par
\par
This SQL statement retrieves all COLUMN_1 values from TABLE_1, returning them\par
in ascending order. This SQL statement does exactly the same:\par
\par
   SELECT   column_1 \par
   FROM     Table_1 \par
   ORDER BY column_1 ASC;\par
\par
This SQL statement also retrieves all COLUMN_1 values from TABLE_1 -- but\par
returns them in descending order:\par
\par
   SELECT   column_1 \par
   FROM     Table_1 \par
   ORDER BY column_1 DESC;\par
\par
The optional sort <keyword>s ASC and DESC stand respectively for "ascending\par
order" and "descending order". Some examples of ascending order are \{1,2,3\}\par
and \{'A','B','C\}; examples of descending order are \{3,2,1\} and \{'C','B','A'\}.\par
If you omit the sort <keyword>, it defaults to ASC.\par
\par
Note that, because ORDER BY may operate only on a final result, you can't put\par
it in a subquery or before a set function -- that is, these two SQL statements\par
are illegal:\par
\par
   SELECT column_1 \par
   FROM   Table_1 \par
   WHERE  column_1 > ANY \par
        (SELECT   column_1 \par
         FROM     Table_2 \par
         ORDER BY column2);\par
\par
   SELECT   column_1 \par
   FROM     Table_1 \par
   ORDER BY column_1 \par
   UNION ALL \par
   SELECT   column_1 \par
   FROM    Table_2;\par
\par
An ORDER BY <sort key> is normally the name of a Column in the query's select\par
list. It cannot be a <literal> -- the SQL-92 option of putting an integer\par
after ORDER BY, to identify a Column by its ordinal position in the result\par
Table, is not allowed in SQL3. The <sort key> can, however, be an expression\par
that evaluates to a Column of the result Table (even if that Column isn't in\par
the select list). Since this is the case, it is useful to remember that such\par
Column expressions may be given explicit names using "[AS <Column name>]"\par
clauses. The "[AS <Column name>]" clause can also be useful for "unioned"\par
SELECTs. For example:\par
\par
  SELECT   column_1 AS column_1_or_column_2 \par
  FROM     Table_1 \par
  UNION ALL\par
  SELECT   column_2 AS column_1_or_column_2\par
  FROM     Table_2 \par
  ORDER BY column_1_or_column_2;\par
\par
Whatever way you identify the result Columns you want to sort though, they may\par
not have a <data type> of BLOB, CLOB or NCLOB. For a <sort key> with a\par
character string <data type>, you may also specify an explicit Collation for\par
your DBMS to use when sorting that Column's values.\par
 \par
If ORDER BY contains multiple <sort key>s, the primary ordering is by the\par
first <sort key>, the secondary ordering is by the second <sort key> and so on\par
-- this is called major-to-minor ordering. For example, here's an extract from\par
a telephone book:\par
   Dunbar L   11407 141 Ave    456-4478\par
   Duncan J   9419 101A Ave    423-0541\par
   Duncan J   14705 103 Ave    452-9565\par
   Duncan J   4911 40 Ave      450-6289\par
   Duncan L   9110 150 St      486-2075\par
\par
As one would expect in a telephone book, the entries are sorted (a) by surname\par
and then (b) by first initial. In SQL, this order would be accomplished with a\par
SELECT statement like this one:\par
  \par
   SELECT   surname, initial, address, phone\par
   FROM     Clients\par
   ORDER BY surname, initial;\par
\par
Sorting NULLs:\par
It isn't usually possible to make meaningful comparisons with null values, so\par
the following comparison rules are applicable only in the context of an ORDER\par
BY clause:\par
      ## A NULL is "equal" to a NULL for sorting purposes.\par
      ## [NON-PORTABLE] Either a NULL is greater than all non-null values or a\par
NULL is less than all non-null values -- it's non-standard because the SQL\par
Standard requires implementors to define whether NULLs sort high or low. Most\par
vendors say "NULLs are greater than all non-null values" -- in this case, a\par
Table with these rows: \{7,5,-1,NULL\} will end up in this order: \{-1,5,7,NULL\}\par
if you ask for an ascending sort.\par
            [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
sorts NULLs low: a NULL is less than all non-null values.\par
\par
The effect of DESC:\par
We've already said that if you put the <keyword> DESC after a <sort key>, the\par
ordering will be reversed for that <sort key>. Unfortunately, we have to\par
belabor what appears to  be an obvious and simple fact, because some pundits\par
have mis-stated it. The following statements, taken from SQL books available\par
at your book store, are drivel:\par
      ## "DESC is a sticky flag, so if you say "ORDER BY a DESC, b" then both\par
a and b will appear in descending order." If anyone knows how this myth got\par
started, please write to us: we're curious.\par
      ## "If a vendor says that NULLs are greater than non-NULLs, then (for\par
standard SQL) they should appear last, even if DESC is specified." In other\par
words -- taking the example we used in the last section -- if you asked for an\par
ascending sort of a Table with these rows: \{7,5,-1,NULL\}, you'd get \{-\par
1,5,7,NULL\} and if you asked for a descending sort you'd get \{7,5,-1,NULL\}. In\par
fact, standard SQL requires that the descending result be what a sane person\par
would expect: \{NULL,7,5,-1\}.\par
\par
Deprecated SQL-92 Syntax:\par
The following examples, taken from real working programs, illustrate syntax\par
that you should avoid or change for SQL3.\par
\par
   SELECT   E.dept FROM Employees E \par
   WHERE    age < 21 \par
   ORDER BY E.dept;\par
\par
Get rid of any <Column reference>s in an ORDER BY clause -- the actual name of\par
the Column in the select list is merely DEPT, despite appearances. Use an AS\par
clause to give the Column another name if there is resulting ambiguity.\par
\par
   SELECT   balance, (balance - amount) FROM Accounts \par
   ORDER BY 1, 2;\par
\par
Get rid of any Column ordinal position references in an ORDER BY clause --\par
using ordinals as Column numbers is frowned on by SQL-92 and banned by SQL3.\par
Again, the solution is to use an AS clause, so the Columns have explicit names\par
-- for example:\par
\par
   SELECT    balance, (balance - amount) AS balance_minus_amount\par
   FROM     Accounts \par
   ORDER BY balance, balance_minus_amount;\par
\par
SQL3 features:\par
These three SQL statements, which are illegal in SQL-92, are legal in SQL3:\par
\par
   SELECT   column_1 FROM Table_1 \par
   ORDER BY column_2;\par
\par
The <sort key> COLUMN_2 is not in the select list, but it does belong to\par
TABLE_1 so this type of ORDER BY works, provided that the query does not\par
contain DISTINCT, a grouped Table, a set function or a set operator.\par
\par
   SELECT   column_1 + 5 FROM Table_1 \par
   ORDER BY column_1 + 5;\par
\par
The <sort key> "COLUMN_1 + 5" is an unnamed value expression, but this type of\par
ORDER BY is legal because "COLUMN_1 + 5" appears in the query's select list.\par
Your DBMS will find it by comparing the expressions, rather than comparing\par
<Column name>s.\par
\par
   SELECT   char_column FROM Table_1 \par
   ORDER BY char_column COLLATE Schema_1.Polish;\par
\par
The COLLATE clause specified for the <sort key> overrides whatever default\par
Collation CHAR_COLUMN has.\par
\par
Essentially, these SQL3 "features" let you write sloppy code. We advise that\par
you stick with the SQL-92 rule that all <sort key>s must be names of Columns\par
in the result select list. These three SQL statements, equivalent to the ones\par
we've just shown you, are better code -- and are legal in both SQL-92 and\par
SQL3:\par
\par
   SELECT   column_1, column_2 FROM Table_1 \par
   ORDER BY column_2;\par
\par
   SELECT   column_1 + 5 AS column_1_plus_5 FROM Table_1 \par
   ORDER BY column_1_plus_5;\par
\par
   SELECT   column_1 COLLATE Schema_1.Polish AS colpolish FROM Table_1 \par
   ORDER BY colpolish;\par
\par
Sorted retrievals:\par
Here's some examples of sorted retrievals, using the sample database we\par
defined in our chapter on simple search conditions. To retrieve an\par
alphabetical list of departments, either of these SQL statements will work:\par
\par
   SELECT dept FROM Department ORDER BY dept ASC;\par
\par
   SELECT dept FROM Department ORDER BY dept;\par
\par
The result is:\par
\par
DEPT\par
A\par
B\par
C\par
D\par
E\par
\par
ORDER BY defaults to a sort in ascending order when no sort order is\par
specified.\par
\par
To retrieve departments in descending order:\par
\par
   SELECT dept FROM Department ORDER BY dept DESC;\par
\par
This time, the result is:\par
\par
DEPT\par
E\par
D\par
C\par
B\par
A\par
\par
To find an alphabetic list of employee names grouped by their departments\par
sorted in descending order (retrieve multiple Columns with nested sort\par
levels):\par
\par
   SELECT dept,surname FROM Employee ORDER BY dept DESC,surname;\par
\par
The result is:\par
\par
DEPT  SURNAME\par
E     FRANCIS\par
E     OLSEN\par
D     MORGAN\par
C     JONES\par
B     JONES\par
B     MARSH\par
B     TURNER\par
B     WARREN\par
A     KOO\par
A     SMITH\par
\par
To find employee numbers and rates for employees with employee numbers less\par
than 20, and to sort these by employee number within descending pay rate\par
order, within descending location order:\par
\par
   SELECT   empnum,rate,location FROM Payroll WHERE empnum<20 \par
   ORDER BY location DESC,rate DESC,empnum;\par
\par
The result is:\par
\par
EMPNUM   RATE   LOCATION\par
 3        5.00  WAREHOUSE\par
 4        8.00  BASEMENT\par
10       16.00  16TH FLOOR\par
11       16.00  16TH FLOOR\par
 2        5.00  16TH FLOOR\par
 1        6.00  10TH FLOOR\par
\par
To sort employee numbers in descending order within the daily pay rate:\par
\par
   SELECT   empnum,'Daily Rate=' AS comment, RATE*8 AS d_rate  FROM Payroll \par
   ORDER BY d_rate,empnum DESC;\par
\par
The result is:\par
\par
EMPNUM   COMMENT       D_RATE\par
 3       Daily Rate=    40.00\par
 2       Daily Rate=    40.00\par
 1       Daily Rate=    48.00\par
 4       Daily Rate=    64.00\par
35       Daily Rate=    72.00\par
20       Daily Rate=    72.00\par
40       Daily Rate=   128.00\par
11       Daily Rate=   128.00\par
10       Daily Rate=   128.00\par
28       Daily Rate=   NULL\par
\par
Dialects\par
\par
All SQL DBMSs support the ORDER BY clause. Some of them even allow the "ORDER\par
BY <expression>" syntax described above as an SQL3 feature, or some variant\par
thereof -- we expect they all will fairly soon.\par
\page\par
Chapter 35 -- Changing SQL-data\par
\par
The SQL-data change statements are INSERT, UPDATE and DELETE. Many people call\par
these the SQL "update" statements -- which is okay, provided you don't mix up\par
"update" (lower case, meaning INSERT or UPDATE or DELETE) with UPDATE (upper\par
case, meaning only UPDATE). We prefer the term "data change statements"\par
because it's unambiguous.\par
\par
In this chapter, we'll discuss changes to SQL-data in all aspects, including\par
hidden changes, changes of Views, the syntax of INSERT, UPDATE and DELETE,\par
access (Privilege) rules and the new SQL3 feature: changes to joined Tables.\par
But we won't talk about four important and relevant matters because they rate\par
chapters of their own:\par
      ## Multiple data changes and transactions, discussed on our chapter on transactions.\par
      ## Data changes and Constraints, discussed on our chapter on constraints and assertions.\par
      ## Data changes and Triggers, discussed on our chapter on triggers.\par
      ## Data changes through Cursors, discussed on our chapter on embedded SQL -- in particular, data changes with "positioned" UPDATE/DELETE.\par
\par
After reading this chapter, you'll know everything that there is to know about\par
the SQL data-change statements taken in isolation. But we give you fair\par
warning: we'll revisit some of these points when we put them in context later on.\par
\par
The SQL-data Change Statements\par
\par
In SQL, there are fundamentally only three conceivable data-change operations\par
that can be performed at the row level: the addition of a new row, the editing\par
of an existing row and the removal of an existing row. So the only SQL\par
statements that you'll ever need to change SQL-data are (respectively):\par
INSERT, UPDATE and DELETE. Before getting into the details of each individual\par
statement, we'll note those features or restrictions which are common to two\par
or more of them.\par
\par
The "set at a time" rule --\par
If multiple rows are involved in a data change operation, you must abandon\par
"row at a time" thinking. For example, a WHERE clause is completely evaluated\par
before a DELETE operation beings to remove rows, and an UPDATE operation is\par
not affected by a change to the last row for "uniqueness" purposes.\par
\par
The "updatable Table" rule --\par
Although the object of a data-change statement can be a View (or a derived\par
Table), ultimately the changes actually happen to one or more Base tables.\par
Sometimes, though, an operation won't make sense if applied to the appropriate\par
Base table and so the SQL-data change statement won't work.\par
\par
The "read only" rule --\par
SQL provides a statement that is used to prevent any data changes from\par
happening: if you execute "SET TRANSACTION READ ONLY", then all INSERT, UPDATE\par
and DELETE statements will fail: your DBMS will return the SQLSTATE error\par
25006 "invalid transaction state-read-only transaction".\par
\par
The "default values" rule --\par
Remember that any <Column definition> or Domain definition can include the\par
clause "DEFAULT value". Your DBMS uses the value specified to provide a value\par
for a Column that is implicitly the object of a data change operation. You can\par
also use this value explicitly by specifying the <keyword> DEFAULT in an\par
INSERT statement or an UPDATE statement -- this has the effect of setting a\par
Column to its default value. If you didn't use a DEFAULT clause when you\par
defined a Column or Domain, that's okay -- it still has a default value: NULL\par
(provided, of course, that there isn't also a NOT NULL Constraint on the\par
Column or Domain).\par
\par
The "Column integrity" rule --\par
At the same time that you defined a Column, you declared what its <data type>\par
is. The <data type> limits the values that the Column can contain. For\par
example, if it's a DATE, then you can't insert the character string 'Hello,\par
world' into it. This limitation -- that a Column's data must conform to its\par
<data type> -- is enforced on any assignment: it is an implicit Constraint on\par
the Column. This implicit Constraint isn't like the explicit Constraints we\par
talked about in out chapter on constraints and assertions, though. The big\par
difference between them is that Column integrity is checked when the SQL-data\par
change statement starts, while explicit Constraints are checked when the SQL-\par
data change statement ends. In other words, your DBMS vets your INSERTs and\par
UPDATEs; it won't let utter garbage through no matter how you insist.\par
\par
The "no data" condition --\par
Any SQL-data change statement can be a perfect success -- and still affect\par
zero rows. INSERT, UPDATE and DELETE all depend to some extent on "search\par
conditions", so it should be clear that sometimes there will be no rows to\par
insert or update or delete. In that case, the SQL-data change statement hasn't\par
failed -- it just hasn't found anything that fulfills your requirements for a\par
change. In such cases, your DBMS will return the SQLSTATE warning 02000 "no\par
data". (If you're a programmer who'll want to know the exact number of rows\par
that any SQL-data change statement affects, see our discussion of the\par
SQLRowCount function in our chapter on SQL/CLI diagnostics.)\par
\par
The "data change object" condition --\par
For each SQL-data change statement, there is a syntax diagram that has "<Table\par
reference>" in a prominent place. This somewhat anticipates the conclusion of\par
the chapter, since a <Table reference> can include <Correlation name>s,\par
parentheses and various Table operators. As usual, we suggest that, until\par
you've read through the entire chapter, you should interpret <Table reference>\par
as <Table name>.\par
\par
The "tentative" condition --\par
Finally, you'll note that in the description of each SQL-data change\par
statement, we use the word "tentatively" when telling you what it does. This\par
is not a standard term -- we use it merely to indicate that any new row is "on\par
probation": it's not too late to take your move back until COMMIT time.\par
\par
INSERT statement\par
\par
The INSERT statement's job is to tentatively add new rows to a Table. If\par
INSERT succeeds, there will be a number (zero or more) of new rows in your\par
target Table. The required syntax for the INSERT statement is:\par
\par
INSERT INTO <Table reference>\par
[ (<Column name> [ \{,<Column name>\} ... ]) ] <query expression> |\par
DEFAULT VALUES\par
\par
The INSERT statement has two forms. The first evaluates a query to construct\par
one or more rows to be inserted into a Table. The second constructs one row --\par
containing default values for every Column -- and inserts it into a Table. The\par
<Table reference> identifies your target Table: the Table that you want INSERT\par
to add rows to. The target Table must be updatable -- that is, it must either\par
be a Base table, or a View that is not a read-only Table. If <Table reference>\par
does not include a <Schema name> qualifier, your target Table must belong to\par
the SQL-session default Schema. \par
\par
To execute INSERT, your current <AuthorizationID> needs the INSERT Privilege\par
on every Column directly affected by the insert operation -- and, if an object\par
Column is a derived Column (as it is in the case of a View), your current\par
<AuthorizationID> also needs the INSERT Privilege on every underlying Table\par
that makes up your target Table.\par
\par
INSERT Column list:\par
In the first form of INSERT, you can optionally specify a parenthesized object\par
Column list, wherein you provide your DBMS with the unqualified names of the\par
Columns that are the targets for each value returned by the <query\par
expression>. Each Column named must belong to the Table named in the INTO\par
clause; <Column name>s may not be repeated in the list but you may list the\par
Columns in any order; the number of Columns in the list must match the number\par
of result Columns returned by the query. INSERT places data into the Columns\par
of the target Table in the order that you list them in the INSERT Column\par
clause: the first value specified is assigned to the first Column named, the\par
second value is assigned to the second Column named, and so on. Any Columns of\par
the target Table that are omitted from the INSERT Column clause are assigned\par
their default value. For example, these SQL statements create a new Table and\par
insert one row of data into it (the default value for a Column that is\par
specifically defined with one is NULL):\par
\par
   CREATE TABLE Table_1 (\par
      column_1 INTEGER, column_2 CHARACTER(7), column_3 DATE); \par
\par
   INSERT INTO Table_1 (column_3, column_1) \par
   VALUES (DATE '1996-12-31', 20);\par
\par
If you omit the Column list clause from an INSERT statement, your DBMS will\par
assume you mean "all Columns in the Table, in their ordinal position order".\par
In this case, INSERT places data into the Columns of the target Table in the\par
implied order listed: the first value specified is assigned to the first\par
Column of the target Table, the second value is assigned to the second Column\par
of the target Table, and so on. For example, these SQL statements create a new\par
Table and insert one row of data into it:\par
   \par
   CREATE TABLE Table_1 (\par
      column_1 INTEGER, column_2 CHARACTER(7), column_3 DATE);\par
\par
   INSERT INTO Table_1 \par
   VALUES (20, 'GOODBYE', DATE '1996-12-31');\par
\par
<query expression>:\par
The <query expression> that makes up the first form of INSERT is usually a\par
SELECT statement, but it's also common to see the Table constructor "VALUES\par
(value commalist)" here (usually with only a single row). In this latter case,\par
you can use the specifications DEFAULT (for insert default value), NULL (for\par
insert null value), ARRAY??(??) or ARRAY[] (for insert an empty array) within\par
the "value commalist" to specify a value for a Column. The order and number of\par
the values must correspond to the order and number of the Columns in the\par
INSERT Column list. If you're using a <query expression>, the INSERT's <Table\par
reference> may not identify a Table that also appears in any FROM clause in\par
that <query expression>. The <query expression> provides zero or more rows of\par
data values when it is evaluated: its search conditions are effectively\par
evaluated for each row before any rows are added to the target Table. Here's\par
an example:\par
\par
   INSERT INTO Table_1 (column_1, column_3) \par
      SELECT column_1, column_3 FROM Table_2; \par
\par
You can insert a null value into a Column either by placing the <keyword> NULL\par
in the INSERT ... VALUES clause, or by omitting a Column that has no defined\par
default value from an explicit <Column name> clause. For example, given this\par
Table definition:\par
\par
   CREATE TABLE Table_1 (\par
      column_1 INTEGER, column_2 CHARACTER(7), column_3 DATE);\par
\par
these INSERT statements, which insert one row of data into TABLE_1 using\par
<literal>s and/or the <keyword> NULL, are equivalent:\par
\par
   INSERT INTO Table_1 (column_2, column_3) \par
   VALUES ('GOODBYE', DATE '1996-12-31'); \par
\par
   INSERT INTO Table_1 (column_1, column_2, column_3) \par
   VALUES (NULL, 'GOODBYE', DATE '1996-12-31'); \par
\par
   INSERT INTO Table_1 \par
   VALUES (NULL, 'GOODBYE', DATE '1996-12-31');\par
\par
Note: All three of these examples result in a new record in TABLE_1, with the\par
specified values "GOODBYE" in COLUMN_2 and "1996-12-31" in COLUMN_3, and the\par
null value in COLUMN_1.\par
      ## In the first example, the null value is implied since no explicit\par
value is specified for COLUMN_1 (this, of course, assumes that there is no\par
other default value for COLUMN_1). It is necessary to provide a <Column name>\par
clause list of the Columns you want to assign the values to if your INSERT\par
statement contains fewer source values than the target Table has Columns.\par
      ## In the second and third examples, the null value is explicitly stated\par
as the value to be assigned to TABLE_1.COLUMN_1 and therefore the <Column\par
name> clause can be (but does not have to be) omitted. The explicit use of the\par
<keyword> NULL over-rides the assignment of a default value to a Column that\par
is omitted from a <Column name> clause. This, of course, assumes that the\par
Column has not been defined with a NOT NULL Constraint.\par
\par
You can insert a default value into a Column either by placing the <keyword>\par
DEFAULT in the INSERT ... VALUES clause, or by omitting a Column that has a\par
defined default value from an explicit <Column name> clause. For example,\par
given this Table definition: \par
\par
   CREATE TABLE Table_1 (\par
      column_1 INTEGER DEFAULT 35, \par
      column_2 CHARACTER(7), \par
      column_3 DATE); \par
\par
these INSERT statements, which insert one row of data into TABLE_1 using\par
<literal>s and/or the <keyword> DEFAULT, are equivalent: \par
\par
   INSERT INTO Table_1 (column_2, column_3) \par
   VALUES ('GOODBYE', DATE '1996-12-31'); \par
\par
   INSERT INTO Table_1 (column_1, column_2, column_3) \par
   VALUES (DEFAULT, 'GOODBYE', DATE '1996-12-31');\par
\par
   INSERT INTO Table_1 \par
   VALUES (DEFAULT, 'GOODBYE', DATE '1996-12-31'); \par
\par
Note: All three of these examples result in a new record in TABLE_1, with the\par
specified values "GOODBYE" in COLUMN_2 and "1996-12-31" in COLUMN_3, and the\par
default value "35" in COLUMN_1.\par
      ## In the first example, the default value is implied since no explicit\par
value is specified for COLUMN_1.\par
      ## In the second and third examples, the default value is explicitly\par
stated as the value to be assigned to TABLE_1.COLUMN_1 and therefore the\par
<Column name> clause can be (but does not have to be) omitted.\par
\par
DEFAULT VALUES:\par
You can write your INSERT statement with the <keyword>s DEFAULT VALUES instead\par
of with a <query expression> if every Column belonging to your target Table is\par
to get its default value for a single row. These two INSERT statements are\par
thus equivalent:\par
\par
   INSERT INTO Table_1 (column_1,column_2,column_3) \par
   VALUES (DEFAULT,DEFAULT,DEFAULT);\par
\par
   INSERT INTO TABLE_1 DEFAULT VALUES;\par
\par
INSERT will fail if attempts are made to insert:\par
      ## a value which does not match a Column's <data type>; \par
      ## the null value into a Column defined with a NOT NULL Constraint;\par
      ## a duplicate value into a Column defined with a UNIQUE Constraint; \par
      ## a value not found in the corresponding PRIMARY KEY Column, into a\par
Column defined as part of a FOREIGN KEY Constraint; or \par
      ## a value which does not fall into a Column's CHECK Constraint\par
guidelines.\par
\par
Note: If the access mode of the current SQL transaction is read-only and the\par
target Table is not a temporary Table, an INSERT statement will fail: your\par
DBMS will return the SQLSTATE error 25000 "invalid transaction state".\par
\par
INSERT Examples:\par
Here are some examples of INSERT statements. First, let's assume that two\par
Tables, named AUTHORS_1 and AUTHORS_2, have these definitions:\par
\par
   CREATE TABLE Authors_1 ( \par
      id INTEGER CONSTRAINT constraint_1 PRIMARY KEY, \par
      name VARCHAR(6) DEFAULT 'none');\par
\par
   CREATE TABLE Authors_2 ( \par
      id INTEGER DEFAULT 12,\par
      name VARCHAR(6));\par
\par
To add a single row to AUTHORS_1, we have three choices:\par
\par
   -- INSERT with no INSERT Column list\par
   INSERT INTO Authors_1 \par
   VALUES (1,'Jonson');\par
\par
   -- INSERT with INSERT Column list\par
   INSERT INTO Authors_1 (id,name) \par
   VALUES (1,'Jonson');\par
\par
   -- INSERT with INSERT Column list, reversed\par
   INSERT INTO Authors_1 (name,id) \par
   VALUES ('Jonson',1);\par
\par
To add several rows at a time to AUTHORS_1, we can do this:\par
\par
   INSERT INTO Authors_1 (id,name) \par
   VALUES (2,'Smith'), \par
          (3,'Jones'), \par
          (4,'Martin'),\par
          (5,'Samuels'),\par
          (6,DEFAULT),\par
          (7,NULL);\par
\par
The DEFAULT specification inserts the Column's default value (or NULL, if no\par
default was defined). The NULL specification inserts a null value. At this\par
point, AUTHORS_1 looks like this:\par
\par
AUTHORS_1\par
ID   NAME\par
1    Jonson\par
2    Smith\par
3    Jones\par
4    Martin\par
5    Samuels\par
6    none\par
7    NULL\par
\par
To add all the rows in AUTHORS_1 to AUTHORS_2, we can do either of these:\par
\par
   INSERT INTO Authors_2\par
      SELECT id,name FROM Authors_1;\par
\par
   INSERT INTO Authors_2 (id,name) \par
      SELECT id,name FROM Authors_1;\par
\par
   INSERT INTO Authors_2 (name,id) \par
      SELECT name,id FROM Authors_1;\par
\par
   INSERT INTO Authors_2 (id,name) \par
      TABLE Authors_1;\par
\par
To add an "all default values" row to AUTHORS_2, try:\par
\par
   INSERT INTO Authors_2 \par
   VALUES (DEFAULT, DEFAULT);\par
\par
   INSERT INTO Authors_2 (id,name) \par
   VALUES (DEFAULT, DEFAULT);\par
\par
   INSERT INTO Authors_2 (name,id) \par
   VALUES (DEFAULT, DEFAULT);\par
\par
   INSERT INTO Authors_2 DEFAULT VALUES;\par
\par
At this point, AUTHORS_2 looks like this (the first 7 rows come from\par
AUTHORS_1, the last row is the default row we just inserted):\par
\par
AUTHORS_2\par
ID   NAME\par
1    Jonson\par
2    Smith\par
3    Jones\par
4    Martin\par
5    Samuels\par
6    none\par
7    NULL\par
12   NULL\par
\par
INSERT Physics:\par
Most DBMSs simply append newly inserted rows to the end of the target Table.\par
But some (more sophisticated) DBMSs will put new rows wherever they can find\par
space (there might be gaps left by earlier DELETE statements). And a few DBMSs\par
will put new rows in order, according to the target Table's primary key (this\par
is called "clustering"; variants of clustering are practiced by DB2 and\par
Oracle).\par
\par
A general recommendation -- which we often ignore -- is that the optional\par
INSERT Column list should always be explicitly stated. That way, if someday\par
the target Table is altered and a Column is dropped, the INSERT will fail and\par
you'll be reminded that you have to change that particular operation.\par
\par
If you want to restrict your code to Core SQL, don't use a <query expression>\par
with EXCEPT, INTERSECT or CORRESPONDING in an INSERT statement, don't use a\par
<query expression> that names an underlying Table of your target Table in an\par
INSERT statement, don't use the <query expression> TABLE <Table name> in an\par
INSERT statement, if you use the <query expression VALUES (value commalist) in\par
an INSERT statement, make sure it constructs only one new row, don't use the\par
DEFAULT VALUES form of the INSERT statement and make sure all your INSERT\par
<Table reference>s are actually <Table name>s, with no <Correlation name>s or\par
<derived Column list>s.\par
\par
UPDATE statement\par
\par
The UPDATE statement's job is to tentatively edit existing rows in a Table. If\par
UPDATE succeeds, there will be a number (zero or more) of changed rows in your\par
target Table. The required syntax for the UPDATE statement is:\par
\par
UPDATE <Table reference> SET \par
<Column name>=scalar_expression [ \{,<Column name>=scalar_expression\} ... ] | \par
ROW=row_expression \par
[ WHERE <search condition> ]\par
\par
UPDATE works by changing one or more values in zero or more rows of the target\par
Table, Column by Column. The <Table reference> identifies your target Table:\par
the Table that you want UPDATE to change rows of. The target Table must be\par
updatable -- that is, it must either be a Base table, or a View that is not a\par
read-only Table. If <Table reference> does not include a <Schema name>\par
qualifier, your target Table must belong to the SQL-session default Schema.\par
\par
There are two forms of UPDATE: the first lets you specify multiple Column\par
changes that don't necessarily change every value in a row, the second lets\par
you specify changes to every value in a row with a single SET clause. To\par
execute UPDATE, your current <AuthorizationID> needs the UPDATE Privilege on\par
every Column directly affected by the update operation -- and, if an object\par
Column is a derived Column (as it is in the case of a View), your current\par
<AuthorizationID> also needs the UPDATE Privilege on every underlying Table\par
that makes up your target Table -- or, if your target Table is a <joined\par
Table> made with LEFT OUTER JOIN, RIGHT OUTER JOIN, FULL OUTER JOIN or UNION\par
JOIN, your current <AuthorizationID> also needs the INSERT Privilege on every\par
underlying Table that makes up your target Table.\par
\par
SET Column:\par
In the first form of UPDATE -- UPDATE <Table> SET <Column>=<value> -- you must\par
specify at least one Column change expression. The Column named must, of\par
course, belong to your target Table; you can change multiple Columns of the\par
same Table (in any order), but you can't change the same Column more than once\par
in a single UPDATE statement. The "scalar_expression" you use to assign a new\par
value to a Column may be any expression (except one that contains a set\par
function) that evaluates to a single value that is assignable to that Column's\par
<data type>, including the specifications DEFAULT (for change to default\par
value), NULL (for change to null value), ARRAY??(??) or ARRAY[] (for change to\par
an empty array). Most often, "scalar_expression" will be a <literal>. For\par
example, using the AUTHORS_1 and AUTHORS_2 Tables from our discussion of the\par
INSERT statement, we could do this:\par
\par
   UPDATE Authors_1 SET \par
      name='Finch' \par
      WHERE id=7;\par
\par
This UPDATE statement changes the last row of AUTHORS_1 from \{7,NULL\} to\par
\{7,'Finch'\} -- if you don't specify that a Column should be changed, the DBMS\par
leaves it alone; it keeps its original value.\par
\par
SET ROW:\par
In the second form of UPDATE -- UPDATE <Table> SET ROW=row_expression -- you\par
may specify only the one change expression: it will change the entire\par
applicable row. The "row_expression" may be any expression that evaluates to a\par
row of values, equal in number to, and <data type> compatible with, every\par
Column in your target Table (usually, this is a <row value constructor, but it\par
could also be a <row subquery>). For example, we could change a whole row with\par
either of these two statements:\par
\par
   UPDATE Authors_1 SET \par
      ROW = ROW(9,'Allan') \par
   WHERE id=7;\par
\par
   UPDATE Authors_1 SET \par
     id=9, \par
     name='Allan'\par
   WHERE id=7;\par
\par
As we've shown, you can add the optional WHERE clause in both forms of UPDATE,\par
to define the rows you want to change. If you omit the WHERE clause, your DBMS\par
will assume that the condition is TRUE for all rows (and so UPDATE every row\par
of the target Table). The WHERE clause's <search condition> can be any\par
condition at all, as long as it doesn't invoke an SQL-invoked routine that\par
possibly modifies SQL-data. The WHERE clause's search condition is effectively\par
evaluated for each row of the target Table before any of the Table's rows are\par
changed; each <subquery> in a WHERE clause's search condition is effectively\par
executed for each row of the target Table and the results are then used to\par
apply the search condition to the given row. Here's some examples:\par
\par
   -- to change all names to upper case\par
   UPDATE Authors_1 SET \par
      name = UPPER(name);\par
\par
   -- to change all names to lower case\par
   UPDATE Authors_1 SET \par
     name = LOWER(name);\par
\par
   -- to change all names to 'Johnson'\par
   UPDATE Authors_1 SET \par
     name = 'Johnson';\par
\par
UPDATE Examples:\par
To change the last row in AUTHORS_1 so that the ID Column is the last ID\par
belonging to AUTHORS_2, and the NAME Column is NULL:\par
\par
   UPDATE Authors_1 SET \par
     id   = (SELECT MAX(id) FROM Authors_2), \par
     name = NULL\par
   WHERE id = 9;\par
\par
To add 1 to the ID Column and cast the ID value to a character string, putting\par
the result in the NAME Column:\par
\par
   UPDATE Authors_1 SET \par
     id   = id + 1,\par
     name = CAST(id AS VARCHAR(6))\par
   WHERE id =1;\par
\par
This example is even sillier than it looks, since real people very rarely\par
change the value in a primary key Column -- but we put it here to bring up an\par
important fact. Consider the result of this statement, which is the row:\par
\{2,'1'). Why isn't the result: (2,'2')? Because the assignments in the SET\par
clause happen all at once, rather than in a sequence -- so the ID value in the\par
"CAST(id AS VARCHAR(6))" expression is the original value (1), rather than the\par
value we're changing it to (2). This "all at once" effect is typical of SQL.\par
Because of it, Column value swaps are easy.\par
\par
Let's try to do some updates which will cause errors. The first UPDATE\par
statement in this set of examples will result in a "constraint violation"\par
error, the next two will result in a "syntax" error:\par
\par
   UPDATE Authors_1 SET \par
     id = NULL;\par
   -- fails because ID is a primary key and must thus be non-null\par
\par
   UPDATE Authors_1 SET\par
     name = DATE '1994-01-03'; \par
   -- fails because a date can't be assigned to a character string Column\par
\par
   UPDATE Authors_1 SET \par
     id = 1, \par
     id = 1;\par
   -- fails because the same Column can't be changed more than once in a\par
single UPDATE statement\par
\par
Here's an UPDATE statement that sets the AUTHORS_1 NAME Column to a\par
corresponding authors_2 NAME value:\par
\par
   UPDATE Authors_1 SET \par
     name=(SELECT name FROM Authors_2 WHERE id<=7 and id=Authors_1.id);\par
\par
This example will only work if AUTHORS_2 has a row, with a matching ID, for\par
every applicable row in AUTHORS_1.\par
\par
At this point, AUTHORS_1 and AUTHORS_2 look like this:\par
\par
AUTHORS_1                    AUTHORS_2\par
ID   NAME                    ID   NAME\par
1    Jonson                  1    Jonson\par
2    Smith                   2    Smith\par
3    Jones                   3    Jones\par
4    Martin                  4    Martin\par
5    Samuels                 5    Samuels\par
6    none                    6    none\par
12   NULL                    7    NULL\par
                             12   NULL\par
\par
UPDATE Physics:\par
Most DBMSs fit a changed row in the same place as the old one -- a good idea,\par
because if UPDATEs always caused changes in row location, there would be much\par
more disk activity (especially if there are indexes which point to the\par
original row location). But your DBMS might shift rows if you change the\par
primary key or if you change a variable size Column and it becomes longer. (In\par
the latter case, there might not be enough room to fit the changed row in the\par
original location.) These, of course, are "implementation-dependent"\par
considerations, but we suggest that you hesitate slightly before you change\par
primary key or variable size Columns.\par
\par
Some general recommendations -- try to group all updates for the same Table\par
into the same UPDATE statement, do not substitute a DELETE plus an INSERT for\par
an UPDATE and keep in mind that UPDATE can be a relatively slow operation.\par
\par
If you want to restrict your code to Core SQL, don't use a <search condition>\par
that names an underlying Table of your target Table in an UPDATE statement and\par
make sure all your UPDATE <Table reference>s are actually <Table name>s, with\par
no <Correlation name>s or <derived Column list>s.\par
\par
DELETE statement\par
\par
The DELETE statement's job is to tentatively remove existing rows from a\par
Table. If DELETE succeeds, there will be a fewer number (zero or more) of rows\par
in your target Table. The required syntax for the DELETE statement is:\par
\par
DELETE FROM <Table reference>\par
[ WHERE <search condition> ]\par
\par
The rules for DELETE are analogous to the rules for UPDATE: the <Table\par
reference must identify an updatable Table that belongs to the SQL-session\par
default Schema if you don't provide an explicit <Schema name> qualifier; if\par
the WHERE clause is omitted, the DBMS will assume that the condition is TRUE\par
for all rows (and so DELETE every row); the WHERE clause's <search condition>\par
can be any condition at all, as long as it doesn't invoke an SQL-invoked\par
routine that possibly modifies SQL-data; the WHERE clause's search condition\par
is effectively evaluated for each row of the target Table before any of the\par
Table's rows are marked for deletion; each <subquery> in a WHERE clause's\par
search condition is effectively executed for each row of the target Table and\par
the results are then used to apply the search condition to the given row. To\par
execute DELETE, your current <AuthorizationID> needs the DELETE Privilege on\par
the target Table -- and, if the target Table is a derived Table (as it is in\par
the case of a View), your current <AuthorizationID> also needs the DELETE\par
Privilege on every underlying Table that makes up your target Table.\par
\par
DELETE Examples:\par
Here's some examples of DELETE statements:\par
\par
   DELETE FROM Authors_1 WHERE name = name;\par
      -- deletes if name is not null\par
\par
   DELETE FROM Authors_1 WHERE name IS NOT NULL;\par
      -- deletes if name is not null\par
\par
   DELETE FROM Authors_1 WHERE name IS NULL;\par
      -- deletes if name is NULL\par
\par
   DELETE FROM Authors_2 WHERE id < 2;\par
     -- deletes some rows\par
\par
   DELETE FROM Authors_2;\par
     -- deletes all rows\par
\par
DELETE Physics:\par
With most DBMSs, a deleted row disappears from view in the Table, but actually\par
remains in the underlying file for a while. Consider: if row #1 is at file\par
offset 0, row #2 is at file offset 100 and row#3 is file offset 200 -- and you\par
delete row #1 -- should your DBMS now move row #2 to file offset 0, move row\par
#3 to file offset 100, change all indexes and truncate the file? That would\par
take a long time, so the typical response is to put a "record deleted" flag at\par
file offset 0 instead.\par
\par
There are some DBMSs which will eventually reclaim this space. Of course\par
that's usually good -- otherwise they wouldn't do it -- but it could cause\par
trouble if you use a non-standard "row id" address which is derived from a\par
row's location. If row ids can change without warning, you've got trouble.\par
With such DBMSs, it might be useful to put a row in limbo rather than delete\par
it: set all Columns to NULL. Once that's done, the row effectively disappears\par
because most searches are never TRUE for NULL Columns. But the row stays in\par
position, reserved, and won't be reclaimed.\par
\par
If you want to restrict your code to Core SQL, don't use a <search condition>\par
that names an underlying Table of your target Table in a DELETE statement and\par
make sure all your DELETE <Table reference>s are actually <Table name>s, with\par
no <Correlation name>s or <derived Column list>s.\par
\par
Data Change Operations\par
\par
Generalizing shamelessly, we compare here the steps required to do an UPDATE\par
with the step required to do a SELECT:\par
\par
UPDATE                                          SELECT\par
Read row from file                              Read row from file\par
Ensure new values are valid for <data type>\par
Add to log\par
Change indexes\par
Check for Constraint violation\par
Write row back to file\par
\par
The bottom line is: changes cost more than queries. Be consoled by the thought\par
that updates are less frequent than reads (in a bank that we used to work for,\par
we measured the ratio as 1 to 1,000). In fact, both programmers and users are\par
willing to sacrifice a lot of extra trouble during data changes --\par
constructing an index, say -- if the result is a little less trouble during\par
queries. The investment should not merely be to save speed, but to save\par
trouble. That is why there are many mechanisms for guaranteeing that the data\par
is valid. The makers of SQL were well aware that updates need care and\par
protection.\par
\par
Bulk Changes:\par
A bulk change is an operation that affects a significant percentage of the\par
rows in a Table. Since all updates are slow, a fortiori, bulk changes are\par
extremely slow. There are some DBMS-specific ways to reduce the pain:\par
      ## Use a vendor utility for multiple insertions (such as Oracle's SQLLOAD).\par
      ## Pass and retrieve arrays of rows with one call (ODBC's SQLBulkOperations).\par
      ## Access the underlying DBMS files directly (possible if the DBMS uses a non-proprietary file format such as comma-delimited, or .dbf).\par
      ## Drop indexes and re-create them after the update.\par
\par
But none of those tricks are portable and the third one isn't recommended.\par
We're more interested in ways to reduce data change time in standard SQL. Here\par
are two ways that work for everybody, sometimes.\par
\par
## Reduce the row count.\par
This suggestion is more than a bromide. A way to reduce the row count will\par
suggest itself if you look hard at the SET clause. Here's an example:\par
\par
   UPDATE Table_1 SET\par
     column_1 = 'Jonson';\par
\par
And here's an equivalent UPDATE statement that might be a bit faster:\par
\par
   UPDATE Table_1 SET\par
     column_1 = 'Jonson'\par
    WHERE column_1 <> 'Jonson' OR column_1 IS NULL;\par
\par
The reasoning here is that if COLUMN_1 already has 'Jonson' in it, there's no\par
point setting it to 'Jonson'. It's a mechanical process: just look at what's\par
in the SET clause, and put the reverse in the WHERE clause. Here's another example:\par
\par
   UPDATE Table_1 SET\par
     column_1 = column_1 * 1.1;\par
\par
And here's an equivalent UPDATE statement that might be a bit faster:\par
\par
   UPDATE Table_1 SET\par
     column_1 = column_1 * 1.1\par
   WHERE column_1 <> 0;\par
\par
The reasoning here is that if COLUMN_1 is zero or NULL, then multiplication\par
can't affect it. There are analogous observations for addition, division and subtraction.\par
\par
## Do multiple updates in one pass.\par
Think of year-end or month-end, when you must: (a) pay 1% interest to clients\par
with positive balances and (b) charge 2% interest to clients with negative\par
balances. Here's how to do it in two passes:\par
\par
   UPDATE Clients SET\par
      balance = balance * 1.01\par
   WHERE balance > 0;\par
\par
   UPDATE Clients SET\par
     balance = balance * 1.02\par
   WHERE balance < 0;\par
\par
And here's how to do it faster, in one pass:\par
\par
   UPDATE Clients SET\par
     balance = CASE balance\par
                 WHEN balance > 0 THEN balance * 1.01\par
                 ELSE balance * 1.02\par
                 WHERE balance <> 0\par
               END;\par
\par
Often it's just a matter of anticipating what other jobs are likely to come up in the near future, for the same data.\par
\par
Dialects\par
\par
Data change is a stable section of SQL. All vendors support it, few vendors\par
offer any variations or extensions. The ones that you might run into are:\par
      ## Dropped INTO clause, for example "INSERT Employees VALUES (...);", supported by Sybase.\par
      ## Multi-column SET clauses, for example "UPDATE Employees SET (column1,column2) = (column3,column4)", supported by Oracle.\par
      ## TRUNCATE -- to delete all rows but leave definition intact, supported by Oracle 7.\par
\par
At the time of writing, we know of no vendor with complete support for the\par
SQL3 "update a join" feature. Many have partial support, though. This is the\par
sort of feature that attracts awed attention (it's hard to implement), but the\par
important things are before that: it's best to look for a clean, simple implementation.\par
\page\par
Chapter 36 -- SQL Transactions\par
\par
"An SQL-transaction (transaction) is a sequence of executions of\par
SQL-statements that is atomic with respect to recovery. That is to say: either\par
the execution result is completely successful, or it has no effect on any SQL-schemas or SQL-data."\par
   -- The SQL Standard\par
\par
A transaction is an ordered set of operations (of SQL statements). The effects\par
of a transaction -- the data changes and Catalog changes -- are considered as\par
an indivisible group. Either all the effects happen, or none of them do. This\par
all-or-nothing requirement is called atomicity. Atomicity is actually one of\par
four requirements of an ideal transaction:\par
   ## Atomic -- the group of operations can't be broken up.\par
   ## Consistent -- at transaction beginning and end, the database is consistent.\par
   ## Isolated -- other transactions have no affect on this transaction.\par
   ## Durable -- once a change happens it's persistent (i.e.: permanent).\par
From the initial letters of these requirements, these are called the ACID requirements.\par
\par
There are one to many operations in a transaction. There are one to many\par
transactions in an SQL-session. Transactions within an SQL-session do not\par
overlap each other. The initiation of a transaction happens (generally\par
speaking) with the first SQL data-access statement. The end of a transaction\par
happens with one of the two -- vitally important! -- "transaction terminator" statements: COMMIT or ROLLBACK.\par
\par
A logical grouping of operations --\par
Maybe dBASE and Paradox programmers (who haven't encountered transactions\par
before) will ask: why is Atomicity a transaction requirement? We could answer:\par
it is analogous to the way that SQL deals with sets rather than individual\par
rows and that we prefer to deal with groups, it's policy. More cogently, we\par
could answer: if a set of operations are a logical unity, then they should\par
also be a physical unity. Let us prove that with a much-used conventional example, the bank transfer:\par
\par
   [[ logical start of transaction ]]\par
   Withdraw $1000 from Joe's savings account.\par
   Deposit $1000 to Joe's chequing account.\par
   [[ logical end of transaction ]]\par
\par
Now, suppose that some external event separated Joe's withdrawal from his\par
deposit -- a system crash, or a tick of the clock so that the operations take\par
place on two different days, or a separate overlapping transaction on the same\par
accounts. Any of these would cause us to end up with a bad "database state",\par
because the data will show a withdrawal that shouldn't happen according to\par
company rules or accounting principles -- to say nothing of what Joe will think!\par
\par
In SQL, such a state of affairs is theoretically impossible. First of all, if\par
the system crashes and we bring it up again, we will not see any record of the\par
withdrawal -- that's what "atomic with respect to recovery" guarantees.\par
Second, the clock does not tick -- CURRENT_TIME and all other niladic datetime\par
function values are frozen throughout the life of a transaction. And third,\par
there can be no overlapping transaction -- due to the principle of Isolation,\par
which we'll examine in greater detail as part of multi-user and multi-tasking considerations in our chapter on concurrency.\par
\par
The point of the example is to show that the withdrawal and the deposit must\par
succeed together, or fail together. The transaction criterion is that all SQL\par
statements within it must constitute a logical unit of work -- that is, a\par
sequence (ordered set) of operations (executions of SQL statements) that take\par
the DBMS from a consistent state to a consistent state (possibly by changing\par
nothing -- a transaction can consist of a series of SELECT statements).\par
\par
It's your job to figure out what operations fit together as a logical unit of work. It's the DBMS's job to ensure that the operations will all fail, or all succeed, together.\par
\par
Initiating Transactions\par
\par
A transaction begins, if it hasn't already begun, when one of these SQL statements is executed:\par
      ## Any SQL-Schema statement: ALTER, CREATE, DROP, GRANT, REVOKE.\par
      ## The SQL-data statements OPEN, CLOSE, FETCH, SELECT, INSERT, UPDATE, DELETE, FREE LOCATOR, HOLD LOCATOR.\par
      ## One of the new SQL3 statements START TRANSACTION, COMMIT AND CHAIN, ROLLBACK AND CHAIN.\par
      ## The SQL-control statement RETURN, if it causes the evaluation of a subquery when there is no current transaction.\par
\par
It's usually a bad idea to start a transaction with an SQL-Schema statement,\par
and usually you'll find that the new SQL3 statements aren't implemented yet,\par
so in practice: your DBMS initiates a transaction when you issue INSERT,\par
UPDATE, DELETE or any variant of SELECT. Once a transaction is initiated, all\par
subsequent SQL operations will be part of the same transaction until an SQL\par
termination (COMMIT or ROLLBACK) happens.\par
\par
Here's an example of an SQL-session, showing transaction boundaries. It\par
contains two transactions, illustrated by a series of SQL statements\par
(technically, the SQL-session and transactions are executions of these\par
statements, not the statements themselves.) Not every SQL statement shown is\par
within a transaction -- CONNECT, SET SESSION AUTHORIZATION and DISCONNECT are\par
not transaction-initiating statements. (Look for explanations of these\par
statements in our chapter on SQL-sessions.)\par
\par
   CONNECT TO 'TEST' USER 'TEST';\par
   SET SESSION AUTHORIZATION 'TRANSFEROR';\par
      -- first transaction begins\par
     UPDATE chequing SET balance = balance - 1000.00 WHERE client = 'Joe';\par
     UPDATE saving SET balance = balance + 1000.00 WHERE client = 'Joe';\par
     COMMIT;\par
     -- first transaction ends\par
   SET SESSION AUTHORIZATION 'REPORTER';\par
      -- second transaction begins\par
      SELECT balance FROM chequing WHERE client = 'Joe';\par
      COMMIT;\par
      -- second transaction ends\par
   DISCONNECT ALL;\par
\par
Terminating Transactions\par
\par
There are two transaction-terminating statements: COMMIT and ROLLBACK. The\par
first saves all changes, while the second destroys all changes. Although they\par
don't do exactly the same thing, they both have several similar effects on\par
your SQL-data. We'll talk about these similarities first.\par
\par
When COMMIT or ROLLBACK are executed, the transaction ends. There is no\par
Privilege for COMMIT or ROLLBACK: any <AuthorizationID> can issue a COMMIT\par
statement or a ROLLBACK statement; they are always legal.\par
\par
[Obscure Rule -- we'll talk about Cursors in our chapters on binding styles,\par
prepared statements in our chapter on SQL/CLI statements and locks in our\par
chapter on concurrency.]\par
      ## The effect of a COMMIT statement or a ROLLBACK statement on any\par
Cursors that are open at the time is that those Cursors are normally closed.\par
This means that, if you've instructed your DBMS to retrieve some rows and are\par
going through those rows with a FETCH statement, you'll have to instruct your\par
DBMS to get those rows for you again -- the rule is that COMMIT and ROLLBACK\par
cause destruction of result sets. The exception to this rule is that some\par
advanced DBMSs have an option, called the holdable Cursor, which allows Cursor\par
work to go on after COMMIT, at considerable cost in performance. Even holdable\par
Cursors are destroyed by ROLLBACK.\par
      ## The effect of a COMMIT statement or a ROLLBACK statement on prepared\par
SQL statements is that they might become unprepared. This is one of the few\par
"implementation-dependent" behaviour characteristics which has real\par
significance to programmers. It simply means that if you have prepared SQL\par
statements, you might have to prepare them again.\par
      ## The effect of a COMMIT statement or a ROLLBACK statement on locks is that they are released.\par
\par
Any information that you gained in the last transaction might have become\par
untrue for the next transaction -- transactions are supposed to be isolated\par
from each other. So it's understandable that the transaction terminators cause\par
Cursors to be closed, statements to be unprepared and locks to be released. If\par
you want to be sure what the exact behaviour of a particular DBMS is, there's\par
a CLI function -- SQLGetInfo -- that gives that information. But the easy way\par
to write portable code is to assume the worst: always close all Cursors before\par
COMMIT or ROLLBACK and  always re-prepare all SQL statements after COMMIT or ROLLBACK.\par
\par
COMMIT statement\par
\par
The COMMIT statement ends a transaction, saving any changes to SQL-data so\par
that they become visible to subsequent transactions. The required syntax for the COMMIT statement is:\par
\par
COMMIT [ WORK ] [ AND [ NO ] CHAIN ]\par
\par
COMMIT is the more important transaction terminator, as well as the more\par
interesting one. (Though some would use the word "troublesome" rather than\par
"interesting" here.) The basic form of the COMMIT statement is its SQL-92\par
syntax: simply the <keyword> COMMIT (the <keyword> WORK is simply noise and can be omitted without changing the effect).\par
\par
The optional AND CHAIN clause is a convenience for initiating a new\par
transaction as soon as the old transaction terminates. If AND CHAIN is\par
specified, then there is effectively nothing between the old and new\par
transactions, although they remain separate. The characteristics of the new\par
transaction will be the same as the characteristics of the old one -- that is,\par
the new transaction will have the same access mode, isolation level and\par
diagnostics area size (we'll discuss all of these shortly) as the transaction\par
just terminated. The AND NO CHAIN option just tells your DBMS to end the\par
transaction -- that is, these four SQL statements are equivalent:\par
\par
   COMMIT;\par
\par
   COMMIT WORK;\par
\par
   COMMIT AND NO CHAIN;\par
\par
   COMMIT WORK AND NO CHAIN;\par
\par
All of them end a transaction without saving any transaction characteristics. The only other options, the equivalent statements:\par
\par
   COMMIT AND CHAIN;\par
\par
   COMMIT WORK AND CHAIN;\par
\par
both tell your DBMS to end a transaction, but to save that transaction's\par
characteristics for the next transaction. If you want to restrict your code to\par
Core SQL, don't use AND CHAIN or AND NO CHAIN with COMMIT.\par
\par
What's supposed to happen with COMMIT is:\par
      ## SQL Cursors are closed, SQL statements are unprepared and locks are released, as noted earlier. Any savepoints established in the current transaction are also destroyed.\par
      ## Any temporary Table whose definition includes ON COMMIT DELETE ROWS gets its rows deleted.\par
      ## All deferred Constraints are checked. Any Constraint that is found to be violated will cause a "failed COMMIT": your DBMS will implicitly and automatically do a ROLLBACK.\par
      ## If all goes well, any changes to your SQL-data -- whether they are changes to Objects or to data values -- become "persistent", and thus visible to subsequent transactions.\par
\par
Once a change is committed, you've reached the point of no turning back (or no\par
rolling back, to carry on with SQL terms). The most important effects are that\par
committed changes are no longer isolated (other transactions can "see" them\par
now), and they are durable -- if you turn all your computers off, then turn\par
them back on again, then look at your data, you will still see the changes. If\par
your computers are conventional, there's an easy explanation for that: the\par
DBMS must write to disk files.\par
\par
For once the easy explanation is the true one, but the mechanics aren't as\par
easy as you might think. For one thing, during a transaction, your DBMS can't\par
simply overwrite the information in the current database files because if it\par
did, the "before" state of the database (before the transaction started) would\par
become unknown. In that case, how could ROLLBACK happen? So instead of writing\par
changes as they happen, your DBMS has to keep information about the before and\par
after states as long as the transaction is going on. There are two ways to do\par
this: with a backup copy and with a log file.\par
\par
The backup copy solution is familiar to anyone who has ever made a .BAK file\par
with a text editor. All the DBMS has to do is make a copy of the database\par
files when the transaction starts, make changes to the copied files when SQL\par
statements that change something are executed and then, at COMMIT time,\par
destroy the original files and rename the copies. (And if ROLLBACK happens\par
instead, it simply destroys the copies.) Though the plan is simple, the backup\par
copy solution has always suffered from the problem that database files can be\par
large, and therefore in practice a DBMS can only back up certain parts of\par
certain files -- which makes tracking the changes complex. And the\par
complexities grow in SQL3, because "savepoints" -- which we'll discuss shortly\par
-- require the existence of an indefinite number of backup copies. So this\par
solution will probably be abandoned soon.\par
\par
The log file solution is therefore what most serious DBMSs use today. Every\par
change to the database is written to a log file, in the form of a copy of the\par
new row contents. For example, suppose that there is a Table called SAVINGS,\par
containing three rows (Sam, Joe, Mary) with balances of ($1000, $2000, $3000)\par
respectively. If you issue this SQL statement:\par
\par
   UPDATE savings SET balance = balance + 1000.00 WHERE client = 'Joe';\par
\par
a DBMS that uses log files will write a new row in the log file to reflect the\par
required change: it won't make any changes (yet) in the original database\par
file. It then has a situation that looks something like this:\par
\par
SAVINGS Table           LOG\par
CLIENT  BALANCE         ACTION  TABLE IDENTIFIER  CLIENT  BALANCE\par
Sam     1000.00         update  savings           Joe     3000.00\par
Joe     2000.00\par
Mary    3000.00\par
\par
This is called a write-ahead log, because the write to the log file occurs\par
before the write to the database. Specifically, it's a by-row write-ahead log,\par
because the entries in the log are copies of rows. The plan now, for any later\par
accesses during this transaction, is:\par
      ## If a SELECT happens, then the search must include a search of the log\par
file as well as the main file. Any entries in log will override the\par
corresponding row in the SAVINGS Table.\par
      ## If another UPDATE happens, or an INSERT happens, a new entry will be\par
inserted into the log file.\par
      ## If a DELETE happens, a new entry will be inserted in the log file\par
too, this time with the action field set to delete.\par
      ## Most conveniently, if the system crashes, then the log is cleared.\par
\par
There is a different log for each user and the file IO can get busy. One thing\par
to emphasize about this system is that the log file is constantly growing:\par
every data change operation requires additional disk space. And after each\par
data change, the next selection will be a tiny bit slower, because there are\par
more log-file records to look aside at. For efficiency reasons, some DBMSs\par
offer options for batched operations: you can suppress log-file writing and\par
write directly to the main database files, and/or you can clear the log at the\par
end of every transaction. If log-file writing is suppressed, performance\par
improves but safety declines and transaction management becomes impossible.\par
\par
Let us say that a COMMIT at last happens, and it's time to "terminate the\par
transaction while making all data changes persistent". The DBMS now has to\par
issue an "OS commit", then read all the rows from the log file and put them in\par
the database, then issue another "OS commit". We're using the phrase "OS\par
commit" (operating-system commit) for what Microsoft usually calls "flushing\par
of write buffers". The DBMS must ensure that the log file is physically\par
written to the disk before the changes start, and ensure that the database\par
changes are physically written to the disk after the changes start. If it\par
cannot ensure these things, then crash recovery may occasionally be\par
impossible. Some operating systems will refuse to co-operate here because\par
safety considerations get in the way of clever tricks like "write-ahead\par
caching" and "elevator seeking". The DBMS won't detect OS chicanery, so you\par
should run this experiment:\par
      ## One: UPDATE a large number of rows (at least ten thousand).\par
      ## Two: Issue a COMMIT.\par
      ## Three: Run to the main fuse box and cut off power to all computers in the building. Make sure the cutoff happens before the COMMIT finishes.\par
      ## Four: Restore power and bring your system back up. Look around for temporary files, inconsistent data or corrupt indexes.  If you find them, then your OS is not co-operating with your DBMS,\par
so be sure to always give both your DBMS and your OS plenty of time to write all changes.\par
Note: Since this test usually fails, you should backup your database first!\par
\par
Adding up all the operations, we can see that a secure DBMS data change plus\par
COMMIT is quite a slow job. At a minimum -- ignoring the effect on SELECTs --\par
there is one write to a log file, one read of a log file and one write to a\par
DBMS file. If the OS co-operates, this is done with full flushing, so these\par
are physical uncached file IO operations. The temptation is to skip some of\par
the onerous activity, in order to make the DBMS run faster. Since most\par
magazine reviews include benchmarks of speed but not of security, the DBMS\par
vendor is subject to this temptation too.\par
\par
The Two-Phase COMMIT:\par
In an ordinary situation, COMMIT is an instruction to the DBMS, and it's been\par
convenient to say that the DBMS is handling all the necessary operations (with\par
the dubious help of the operating system, of course). That convenient\par
assumption becomes untrue if we consider very large systems. To be precise, we\par
have to take into account these possibilities:\par
      ## there are multiple DBMS servers;\par
      ## there is a DBMS server, and some other program which also needs to "commit".\par
\par
In such environments, the COMMIT job must be handled by some higher authority\par
-- call it a transaction manager -- whose job is to coordinate the various\par
jobs which want the commit to happen. The transaction manager then becomes\par
responsible for the guarantee that all transactions are atomic, since it alone\par
can ensure that all programs commit together, or not at all.\par
\par
The coordination requires that all COMMITs take place in two phases -- first\par
lining up the ducks, then shooting them. The transaction manager in Phase One\par
will poll all the programs, asking: are you ready? If any of the responses is\par
no, or any response is missing, the system-wide commit fails. Meanwhile, all\par
the polled programs are gearing up, refusing other requests for attention, and\par
standing ready for the final order to fire. In Phase Two, the transaction\par
manager issues a final instruction, system-wide, and the synchronized commit\par
actually happens. In this scenario, there is one global transaction which\par
encompasses several subordinate transactions. It will always be possible that\par
the encompassing transaction can fail even though any given DBMS server is\par
ready to proceed. In such a case -- once again -- you might get a ROLLBACK when you ask for a COMMIT.\par
\par
And that is what two-phase commit is. It's strictly a problem for very large\par
and secure environments, but it's reassuring to know there are mechanisms for\par
coordinating different and heterogeneous servers.\par
\par
SAVEPOINT statement\par
\par
The SAVEPOINT statement establishes a savepoint at the current point in the current transaction. The required syntax for the SAVEPOINT statement is:\par
\par
SAVEPOINT <savepoint name> | <simple target specification>\par
\par
You can establish multiple savepoints for a single transaction (up to some\par
maximum defined by your DBMS). You specify a savepoint either with a simple\par
target specification that has an integer data type -- that is, with a <host\par
parameter name> (e.g.: SAVEPOINT :savepoint_integer_variable), an <SQL\par
parameter name> (e.g.: SAVEPOINT savepoint_integer) or a "known not nullable"\par
<Column reference> (e.g.: SAVEPOINT Table_1.integer_column) -- or with a <savepoint name>.\par
\par
The modern convention is to label with names rather than numbers, so we\par
suggest that you concentrate on <savepoint name>, which must be an unqualified\par
<regular identifier> or <delimited identifier> and has a scope that includes\par
the entire transaction that you define it in. An example of a savepoint\par
specification using a savepoint name is:\par
\par
   SAVEPOINT point_we_may_wish_to_rollback_to;\par
\par
Savepoint names must be unique within their transaction. If there is already a SAVEPOINT statement with the same name in the transaction, it will be overwritten.\par
\par
If you want to restrict your code to Core SQL, don't use the SAVEPOINT statement.\par
\par
ROLLBACK statement\par
\par
The ROLLBACK statement rolls back ends a transaction, destroying any changes\par
to SQL-data so that they never become visible to subsequent transactions. The\par
required syntax for the ROLLBACK statement is:\par
\par
ROLLBACK [ WORK ] [ AND [ NO ] CHAIN ]\par
[ TO SAVEPOINT \{<savepoint name> | <simple target specification>\} ]\par
\par
The ROLLBACK statement will either end a transaction, destroying all data\par
changes that happened during any of the transaction, or it will just destroy\par
any data changes that happened since you established a savepoint. The basic\par
form of the ROLLBACK statement is its SQL-92 syntax: simply the <keyword>\par
ROLLBACK (the <keyword> WORK is simply noise and can be omitted without changing the effect).\par
\par
The optional AND CHAIN clause is a convenience for initiating a new\par
transaction as soon as the old transaction terminates. If AND CHAIN is\par
specified, then there is effectively nothing between the old and new\par
transactions, although they remain separate. The characteristics of the new\par
transaction will be the same as the characteristics of the old one -- that is,\par
the new transaction will have the same access mode, isolation level and\par
diagnostics area size (we'll discuss all of these shortly) as the transaction\par
just terminated. The AND NO CHAIN option just tells your DBMS to end the\par
transaction -- that is, these four SQL statements are equivalent:\par
\par
   ROLLBACK;\par
\par
   ROLLBACK WORK;\par
\par
   ROLLBACK AND NO CHAIN;\par
\par
   ROLLBACK WORK AND NO CHAIN;\par
\par
All of them end a transaction without saving any transaction characteristics. The only other options, the equivalent statements:\par
\par
   ROLLBACK AND CHAIN;\par
\par
   ROLLBACK WORK AND CHAIN;\par
\par
both tell your DBMS to end a transaction, but to save that transaction's characteristics for the next transaction.\par
\par
ROLLBACK is much simpler than COMMIT: it may involve no more than a few\par
deletions (of Cursors, locks, prepared SQL statements and log-file entries).\par
It's usually assumed that ROLLBACK can't fail, although such a thing is\par
conceivable (for example, an encompassing transaction might reject an attempt\par
to ROLLBACK because it's lining up for a COMMIT).\par
\par
ROLLBACK cancels all effects of a transaction. It does not cancel effects on\par
objects outside the DBMS's control (for example the values in host program\par
variables or the settings made by some SQL/CLI function calls). But in\par
general, it is a convenient statement for those situations when you say "oops,\par
this isn't working" or when you simply don't care whether your temporary work becomes permanent or not.\par
\par
Here is a moot question. If all you've been doing is SELECTs, so that there\par
have been no data changes, should you end the transaction with ROLLBACK or\par
COMMIT? It shouldn't really matter because both ROLLBACK and COMMIT do the\par
same transaction-terminating job. However, the popular conception is that\par
ROLLBACK implies failure, so after a successful series of SELECT statements\par
the convention is to end the transaction with COMMIT rather than ROLLBACK.\par
\par
Some DBMSs support rollback of SQL-data change statements, but not of SQL-\par
Schema statements. This means that if you use any of (CREATE, ALTER, DROP,\par
GRANT, REVOKE), you are implicitly committing at execution time. Therefore, this sequence of operations is ambiguous:\par
\par
   INSERT INTO Table_2 VALUES(5);\par
   DROP TABLE Table_3 CASCADE;\par
   ROLLBACK;\par
\par
With a few DBMSs, the result of this sequence is that nothing permanent\par
happens because of the ROLLBACK. With other DBMSs -- the majority -- the\par
result will be that both the INSERT and the DROP will go through as separate\par
transactions so the ROLLBACK will have no effect. Both results are valid\par
according to the SQL Standard -- this is just one of those implementation-defined things that you have to be alert for. The best policy is to assume that an SQL-Schema statement implies a new transaction, and so cannot be rolled back.\par
\par
ROLLBACK ... TO SAVEPOINT:\par
The most beneficial new SQL3 feature, in transaction contexts, is the ability\par
to limit how much will be rolled back by ROLLBACK. With savepoints, you can\par
specify from what point the changes will be cancelled. In underlying terms,\par
this means you can specify where to truncate the log file. First, though, you\par
have to establish a savepoint somewhere in your transaction. You do it with the SAVEPOINT statement.\par
\par
If you've established a savepoint for a transaction, you can roll all\par
operations that have happened in that transaction back to that point with the\par
ROLLBACK statement's optional TO SAVEPOINT clause. For example, to ROLLBACK to\par
the savepoint established in the previous example, you would issue this SQL statement:\par
\par
   ROLLBACK TO SAVEPOINT point_we_may_wish_to_rollback_to;\par
\par
This form of ROLLBACK is not a transaction terminator statement: it merely\par
causes a restoration of state. A ROLLBACK statement that contains the AND CHAIN clause may not also contain a TO SAVEPOINT clause.\par
\par
If you want to restrict your code to Core SQL, don't use AND CHAIN, AND NO CHAIN or TO SAVEPOINT with ROLLBACK.\par
\par
RELEASE SAVEPOINT statement\par
\par
The RELEASE SAVEPOINT statement destroys one or more savepoints in the current transaction. The required syntax for the RELEASE SAVEPOINT statement is:\par
\par
RELEASE SAVEPOINT <savepoint name> | <simple target specification>\par
\par
The RELEASE SAVEPOINT statement removes the specified savepoint, as well as any subsequent savepoints you established for the current transaction. For example, this SQL statement:\par
\par
   RELEASE SAVEPOINT point_we_may_wish_to_rollback_to;\par
\par
removes the savepoint we established earlier. If we had established any other savepoints after "point_we_may_wish_to_rollback_to", those savepoints would also disappear.\par
\par
If you want to restrict your code to Core SQL, don't use the RELEASE SAVEPOINT statement.\par
\par
Using savepoints\par
\par
A savepoint may be thought of as a label of a moment between operations. For illustration, suppose a transaction that consists of these SQL statements:\par
\par
   INSERT INTO Table_1 (column_1) VALUES (5);\par
\par
   SAVEPOINT after_insert;\par
\par
   UPDATE Table_1 SET column_1 = 6;\par
\par
   SAVEPOINT after_update;\par
\par
   DELETE FROM Table_1;\par
\par
At this point in the transaction, the SQL statement:\par
\par
   ROLLBACK TO SAVEPOINT after_update;\par
\par
will cause the DBMS to cancel the effects of the DELETE  statement, the SQL statement:\par
\par
   ROLLBACK TO SAVEPOINT after_insert;\par
\par
will cause the DBMS to cancel the effects of both the DELETE statement and the UPDATE statement and the SQL statement:\par
\par
   ROLLBACK;\par
\par
will cause the DBMS to cancel the effects of the entire transaction, as well as to end the transaction. When a transaction ends, all savepoints are destroyed.\par
\par
The savepoint option is good for tentative branching. We can follow some line\par
of DBMS activity, and if it doesn't work we can go back a few steps, then\par
pursue a different course. The option's also good for separating ROLLBACK's\par
two tasks, "transaction terminate" and "cancel", from each other. The\par
incidental effects (such as closing of Cursors) happen regardless of whether\par
ROLLBACK alone or ROLLBACK TO SAVEPOINT is used.\par
\par
Transaction Tips\par
\par
The following tips are viable only if the DBMS is alone, is following the SQL\par
Standard's specifications and uses logs as we have described them. But if not,\par
there shouldn't be much harm done by at least considering them.\par
      ## COMMIT or ROLLBACK quickly after INSERT, UPDATE OR DELETE. A quick transaction end will flush the log, and thus speed up most accesses.\par
      ## COMMIT or ROLLBACK slowly after SELECT. Transaction terminators tend to wipe out items that might be reusable (prepared statements, Cursors and locks). It's convenient to get maximum use from these items before releasing them.\par
      ## Use temporary Tables. If you're making temporary data, no matter how\par
much, the place to store temporary data is in temporary tables with ON COMMIT\par
DELETE ROWS. Since there is no need to worry about recovering any data in such\par
Tables, your DBMS might be able to optimize by doing direct writes to the\par
database files without a log.\par
      ## SELECT first. Since SELECT can be slower after an UPDATE than before an UPDATE, it might help to get selections out of the way before doing data changes.\par
      ## Keep out non-database work. If there are lengthy calculations to do in your host program, they should happen outside the SQL transaction. Do them before the transaction initiator, and after the transaction terminator.\par
The same applies for the SQL statements that don't access SQL data, such as the SQL-session SET statements.\par
\par
A final piece of advice, which is not a tip but a concession to reality, is\par
that you will occasionally have to break up logical units of work because\par
they're too big. For example, if you're going through every row in a huge\par
Table, adding 1 to a particular Column, you might want to break up the\par
transaction so that there's a COMMIT after every few changes. This, though, is\par
only safe because you can keep track of where you left off, and you can write\par
your own "rollback" (subtracting 1) if necessary. The primary rule should\par
remain that the logical unit of work should be the physical unit (transaction)\par
too. Departures from that rule are not the stuff of everyday programming work.\par
Security (consistency) first, performance second.\par
\par
See Also\par
\par
All SQL operations have something to do with transactions. This chapter has\par
singled out only the major points, with particular attention to the COMMIT and\par
the ROLLBACK statements. There is more relevant information in our chapter on\par
constraints and assertions (where we talk about deferred Constraints), in our\par
chapter on concurrency (particularly with regard to the SET TRANSACTION statement) and throughout our chapters on binding styles.\par
\par
Dialects\par
\par
SQL has supported transaction work since the early days (SQL-86). There are\par
some packages which graft SQL-like statements onto non-SQL environments (dBASE\par
III contained an example), but if you are using a true SQL DBMS then you at\par
least can depend on the essentials of "COMMIT [WORK];" or "ROLLBACK [WORK]".\par
The main differences between DBMSs are in the areas of:\par
      ## What incidental items are destroyed by transaction termination.\par
      ## Whether SQL-Schema statements form transactions of their own.\par
      ## Whether CHAIN and SAVEPOINT features are supported (both of these are SQL3, neither is a Core SQL requirement, so support should not be expected.\par
\par
Sybase has been refining "Log work" for several years. This was one of the\par
first DBMSs to feature "savepoints". The log is visible as a table. There is\par
an option for suspending logging.\par
\par
The ODBC specification is that auto-commit should happen. This requirement can\par
be turned off (to what Microsoft calls "manual commit" mode), but auto-commit\par
is the default so ODBC programmers should either turn it off (which looks like\par
a good idea!) or get used to the quirks that auto-commit brings on. Namely, in\par
auto-commit mode every statement gets committed, so ROLLBACK is meaningless.\par
However, it appears that execution of a SELECT statement is not followed by an\par
automatic commit -- ODBC's documentation is unclear about this, but it would\par
make little sense to SELECT (which usually opens a cursor) and immediately\par
COMMIT (which usually closes all cursors). Also -- apparently -- the ODBC\par
function SQLCloseCursor implies a COMMIT. ODBC's "auto-commit" default mode is\par
a departure from the SQL Standard, but we must understand that ODBC is\par
designed to accommodate a wide variety of data sources. It is usually not prescriptive.\par
\page\par
Chapter 37 -- SQL Transaction Concurrency\par
\par
Although there is never more than one current SQL transaction between your\par
DBMS and your application program at any point in time, the operational\par
problem -- although perhaps we should call it a "challenge" or an\par
"opportunity" -- is that many DBMSs run in multi-tasking or multi-user\par
scenarios. These may range from the fairly simple (for example, an MS-Windows\par
background task running in conjunction with a foreground task) to the fairly\par
complex (for example a heterogeneous mix of computers connected over a network\par
via TCP/IP). The problem/challenge/opportunity has grown larger in recent\par
years, with the demand for "24x7" (twenty-four hour by seven-day)\par
accessibility, and with the demand for DBMS servers that can operate on\par
Internet hosts (especially with WindowsNT and Linux operating systems).\par
\par
In SQL, the primary unit of work is the "transaction", as we saw in the previous chapter. The interesting difficulties lie with transaction concurrency, which we define as:\par
\par
   Concurrency.\par
      The running together of two transactions, which may access the same database rows during overlapping time periods. Such simultaneous accesses, called "collisions", may result in errors or inconsistencies if not handled\par
      properly. The more overlapping that is possible, the greater the concurrency.\par
\par
The proper handling of collisions requires some work on the part of the\par
application programmer. It is possible to leave the whole matter in the hands\par
of the DBMS, but that would almost certainly lead to performance which\par
everyone would call unacceptable. Therefore your requirement for this part of\par
the job is to understand how errors or inconsistencies can arise during\par
collisions, to use the somewhat paucous SQL options which can increase\par
concurrency, and to help the DBMS along with a variety of settings or\par
application plans. ** Footnote -- Though we use the singular word "DBMS", we\par
note once again that there may in fact be several co-operating agencies responsible for transaction management.\par
\par
Isolation Phenomena\par
\par
What sort of errors and inconsistencies can creep in during concurrent\par
operations? Database groupies generally use four categories, which they call\par
-- in order by seriousness -- Lost Update, Dirty Read, Non-Repeatable Read and Phantom.\par
\par
In the descriptions that follow, the conventions are that "Txn#1" and "Txn#2"\par
are two concurrent transactions, that "change" has its usual sense of "an\par
INSERT or UPDATE or DELETE", and "read" means "FETCH" or some close\par
equivalent. The charts are time lines with time points, so that events shown\par
lower down in the chart are taking place later in time.\par
\par
LOST UPDATE\par
      Txn#1                   Txn#2\par
      ...                     Read\par
      Read                    ...\par
      Change                  ...\par
      ...                     Change\par
      Commit                  ...\par
      ...                     Commit\par
\par
The "lost update" is the change made by Txn#1. Since Txn#2 makes a later change, it supersedes Txn#1's change. The result is as if Txn#1's change never happened.\par
\par
DIRTY READ\par
      Txn#1                   Txn#2\par
      Read                    ...\par
      Change                  ...\par
      ...                     Read\par
      Rollback                ...\par
      ...                     Rollback\par
\par
Here the key is that Txn#2 "reads" after Txn#1 "changes", and so Txn#2 "sees"\par
the new data that Txn#1 changed to. That change was ephemeral though: Txn#1\par
rolled back the change. So Txn#1's change really never happened, but Txn#2\par
based its work on that change anyway. The old name for the Dirty Read phenomenon is "uncommitted dependency".\par
\par
NON-REPEATABLE READ\par
      Txn#1                   Txn#2\par
      ...                     read\par
      read                    ...\par
      ...                     change\par
      read                    ...\par
      ...                     Commit\par
      Commit                  ...\par
\par
The supposition here is that Txn#1 will "read" the same row twice. The second\par
time, though, the values in the row will be different. This is by no means as\par
serious an inconsistency (usually) as LOST UPDATE or DIRTY READ, but it does\par
certainly break the requirements of an ACID transaction.\par
\par
PHANTOM\par
      Txn#1                             Txn#2\par
      SELECT FROM t WHERE col=5;         ...\par
      ...                               INSERT INTO t(col) VALUES(5);\par
      ...                               UPDATE t SET col=5 WHERE col=6;\par
      SELECT FROM t WHERE col=5;         ...\par
\par
This now-you-don't-see-it-now-you-do phenomenon is one that often slips\par
through, especially with older or dBASE-like DBMSs. The reason is that DBMSs\par
might notice concurrent access to rows, but fail to notice concurrent access\par
to the paths to those rows. Phantoms can affect transactions which contain at\par
least two <search condition>s which in some way overlap or depend on one\par
another. Phantoms are rare and are usually tolerable, but can cause surprise\par
errors because even some good DBMSs let them through, unless you take explicit\par
measures to signal "no phantoms please".\par
\par
Pessimistic Concurrency: LOCKING\par
\par
The most common and best-known way to eliminate some or all of the transaction concurrency phenomena is locking. Typically, a lock works like this:\par
\par
      Txn#1                               Txn#2\par
      "LOCK" the desired object           ...\par
      ...                                 Wait: desired object is locked\par
      read and/or change                  ...\par
      read and/or change                  ...\par
      Commit (which releases locks)       ...\par
      ...                                 "LOCK" the desired object\par
\par
Here, the Object being locked might be a Column, a row, a page, a Table or the\par
entire database. Incidentally, when a lock is on a Column, locks are said to\par
be "finely granular"; when a lock is on a page or Table or database, locks are\par
said to be "coarsely granular". DBMSs with coarse-granularity locking have\par
less concurrency (because a lock on row#1 causes an unnecessary lock on other\par
rows as well), but are efficient despite that because: the coarser the\par
granularity, the fewer locks exist, and therefore searching the list of locks\par
is quicker. At this moment, it appears that the majority of important DBMSs\par
support locking by row, with some (non-standard) optional syntax that allows\par
locking by Table.\par
\par
A lock is much like a reservation in a restaurant. If you find that your desired seat has already been taken by someone who came before you, you must either wait or go elsewhere.\par
\par
Usually an SQL DBMS supports at least two kinds of locks: "shared locks" and\par
"exclusive locks". A shared lock exists because there is nothing wrong with\par
letting two transactions read the same row; concurrency can only cause trouble\par
if one transaction or the other is updating. Therefore, at retrieval time, a\par
shared lock is made, and this shared lock does not block other transactions\par
from accessing the same row (with another retrieval). At change time, the\par
shared lock is upgraded to an exclusive lock, which blocks both reads and\par
writes by other transactions. The use of different kinds of locks is something\par
that distinguishes an SQL DBMS from a DBMS that depends on the operating\par
system (operating systems like MS-DOS support exclusive locks only).\par
\par
The famous irritant with a lock-based concurrency resolution mechanism is the "deadlock" (or deadly embrace), which goes like this:\par
\par
      Txn#1                               Txn#2\par
      Lock Row #1                         ...\par
      ...                                 Lock Row #2\par
      Attempt to Lock Row #2 --           ...\par
      WAIT, because it's locked\par
      ...                                 Attempt to Lock Row #1 --\par
                                          WAIT, because it's locked\par
      WAIT                                WAIT\par
\par
Since Txn#1 is waiting for Txn#2 to release its lock, but Txn#2 is waiting for Txn#1 to release its lock, there can be no progress. The DBMS must detect situations like this and force one transaction or the other to "rollback" with an error.\par
\par
Locking is reliable and popular. However, it is sometimes criticized for being\par
based on an excessively pessimistic assumption: that something which you read\par
could be something that you will change. The result is a profusion of "shared\par
locks", the great majority of which turn out to be unnecessary because only a relatively small number of rows are actually updated.\par
\par
Optimistic Concurrency: TIMESTAMPING\par
\par
There are several ways to control concurrency without locking. The most common\par
ones can be grouped together as the "optimistic assumption" ways, and the most\par
common of those ways is timestamping. With timestamping, there are no locks\par
but there are two situations which cause transaction failure:\par
      ## If a younger transaction has "read" the row, then an attempt by an older transaction to "change" that row will fail.\par
      ## If a younger transaction has "changed" the row, then an attempt by an older transaction to "read" that row will fail.\par
\par
The general effect of these rules is that concurrency is high, but failure is\par
frequent. Indeed, it is quite possible that a transaction will fail many\par
times. But what the heck, one can put the transaction in a loop and keep retrying until it goes through.\par
\par
Some DBMSs enhance the concurrency further by actually "reading" a row which\par
has been changed by another transaction, and deciding whether the change is\par
significant. For example, it often happens that the same Column is being\par
updated so that it has the same value for both transactions. In that case, there may be no need to abort.\par
\par
Most optimistic concurrency mechanisms are not particularly good for detecting Non-Repeatable Reads or Phantoms.\par
\par
SET TRANSACTION statement\par
\par
By now, we've come to expect that SQL statements aren't used to specify\par
methods. Instead, they state what the requirements are. That's the idea behind\par
the SET TRANSACTION statement. It tells the DBMS -- somewhat indirectly --\par
what sort of concurrency phenomena are intolerable for the next transaction,\par
but it does not say how they are to be prevented. That detail is left up to\par
the DBMS itself -- that is, the choice of concurrency protocol (locking,\par
timestamping or some other method) is implementation-defined. The required syntax for the SET TRANSACTION statement is:\par
\par
SET [ LOCAL ] TRANSACTION <transaction mode> [ \{,<transaction mode>\}... ]\par
\par
   <transaction mode> ::=\par
   <transaction access mode> |\par
   <isolation level> |\par
   <diagnostics size>\par
\par
      <transaction access mode> ::=\par
      READ ONLY | READ WRITE\par
\par
      <isolation level> ::=\par
      ISOLATION LEVEL\par
        \{READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE\}\par
\par
      <diagnostics size> ::=\par
      DIAGNOSTICS SIZE <number of conditions>\par
\par
         <number of conditions> ::= <simple value specification>\par
\par
The SET TRANSACTION statement sets certain characteristics for the next transaction. There are three options, any or all of which can be set by a single SET TRANSACTION statement.\par
\par
The first transaction characteristic is its access mode: a transaction can\par
either be a READ ONLY transaction or a READ WRITE transaction. The second\par
transaction characteristic is its isolation level: a transaction can either\par
allow READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ or SERIALIZABLE\par
operations. The final transaction characteristic is the size of its\par
diagnostics area: you set this to the number of conditions you want your DBMS\par
to be able to provide you with information on (it must be at least one). The\par
<diagnostics size> is a transaction characteristic which has nothing to do\par
with concurrency, so we won't discuss it further here -- look for it in our\par
chapters on binding styles. That leaves us with the choice of specifying "READ\par
ONLY" versus "READ WRITE", and the choice of specifying one of: "READ\par
UNCOMMITTED", "READ COMMITTED", "REPEATABLE READ" or "SERIALIZABLE" for a\par
transaction. Here's some example SQL statements:\par
\par
   SET TRANSACTION\par
      READ WRITE\par
      ISOLATION LEVEL REPEATABLE READ;\par
\par
   SET TRANSACTION\par
      READ ONLY\par
      ISOLATION LEVEL READ UNCOMMITTED;\par
\par
As the name suggests, SET TRANSACTION is only good for setting the\par
characteristics of one transaction (though there are a few exceptions to this\par
rule when we add the optional <keyword> LOCAL, a SQL3 feature). Unless you're\par
using the SQL3 START TRANSACTION statement (which we'll discuss later in this\par
chapter), the SET TRANSACTION statement should precede all other statements in\par
a transaction. If you don't specify it, the default situation is:\par
\par
   SET TRANSACTION\par
      READ WRITE\par
      ISOLATION LEVEL SERIALIZABLE;\par
\par
Access mode:\par
If the transaction's isolation level is READ UNCOMMITTED, then READ ONLY is\par
the default (and only legal) access mode option. For all other isolation\par
levels, either READ ONLY or READ WRITE are legal options, and the default is READ WRITE.\par
\par
The declaration READ ONLY tells the DBMS that all statements in the upcoming\par
transactions will be "read" statements: they only read SQL data, they don't\par
make any changes. The declaration READ WRITE tells the DBMS that there may be\par
either "read" or "change" statements in the upcoming transaction. (Note:\par
Changes to TEMPORARY Tables don't count as "changes", since TEMPORARY Tables\par
aren't shared between different transactions anyway. So regardless of what you\par
do with TEMPORARY Tables, as long as you make no changes to SQL-data or\par
persistent SQL Objects (e.g.: Schemas, Tables, Domains and so on), you can\par
declare a transaction's access mode to be READ ONLY.\par
\par
There are no guarantees that specifying READ ONLY will do any good at all, but\par
it certainly won't hurt -- and it might result in performance gains. Here's\par
why: If your DBMS sees that all transactions are READ ONLY, then it doesn't\par
have to set any locks at all -- no isolation phenomena can arise when all jobs\par
are doing nothing but reading. If only one transaction is READ ONLY, there is\par
still a good strategy available: the DBMS can make a temporary copy of the\par
Tables that you SELECT from (or at least of the rows in the result sets).\par
Following that, all FETCH statements are operating on the temporary copy,\par
instead of on the original Table, and therefore collisions are impossible.\par
Typical application situations where READ ONLY is called for include: report\par
writers, screen displayers, file dumps. The option might have a particularly\par
good effect if the transaction contains statements which contain set functions.\par
\par
Isolation level:\par
The <isolation level> characteristic you specify in a SET TRANSACTION\par
statement determines the degree of "isolation" of the upcoming transaction.\par
This effectively means that the value you choose will tell your DBMS which\par
concurrency phenomena are tolerable or intolerable for the transaction. It's\par
up to the DBMS to decide how precisely it will follow your instruction -- the\par
Standard allows it to upgrade the specification (but never to downgrade it,\par
you're always guaranteed at least the isolation level you've asked for). For\par
example, your DBMS could take a READ UNCOMMITTED specification and set the\par
next transaction's isolation level to SERIALIZABLE (a higher level of\par
isolation) instead. But since your DBMS cannot downgrade the specification,\par
there is no harm in setting the <isolation level> as precisely as possible.\par
\par
## READ UNCOMMITTED\par
READ UNCOMMITTED is the lowest level of transaction isolation. If you specify\par
READ UNCOMMITTED, you are risking that the transaction -- no matter what it is\par
doing -- might deliver a "wrong" answer. Because it is always unacceptable for\par
the database itself to contain wrong data, it is illegal to execute any\par
"change" statements during a READ UNCOMMITTED transaction. That is, READ UNCOMMITTED implies READ ONLY.\par
\par
READ UNCOMMITTED means "allow reading of rows which have been written by other\par
transactions, but not committed" -- so Dirty Reads, Non-Repeatable Reads and\par
Phantoms are all possible with this type of transaction. However, Lost Update\par
is not possible for the simple reason that, as already stated, changes of any\par
kind are illegal. Lost Updates are, in fact, prevented in all the standard SQL\par
isolation levels. The concurrency level is as high as it can be -- in a\par
locking situation, no locks would be issued and no locks would be checked for.\par
We could say that, for this transaction, concurrency checking is turned off.\par
\par
The READ UNCOMMITTED level is a good choice if (a) the transaction is usually\par
slow, (b) errors are likely to be small and (c) errors are likely to cancel\par
each other out. The most certain example of such a situation is a single\par
SELECT statement containing a set function such as COUNT(*). Any "report"\par
where the user isn't likely to care about details, is also a good candidate.\par
You tolerate a huge degree of error every time they use a search engine on the World Wide Web.\par
\par
## READ COMMITTED\par
READ COMMITTED is the next level of transaction isolation. READ COMMITTED\par
means "allow reading of rows written by other transactions only after they\par
have been committed" --  so Non-Repeatable Reads or Phantoms are both possible\par
with this type of transaction, but Update and Dirty Read are not. The READ\par
COMMITTED level allows for a reasonably high level of concurrency -- in a\par
locking situation, shared locks must be made, but they can be released again\par
before the transaction ends. For any "optimistic" concurrency resolution\par
mechanism, READ COMMITTED is the favored level. Conventional wisdom says that\par
concurrency based on optimistic assumptions gets very slow if the isolation level is high.\par
\par
The READ COMMITTED level is always safe if there is only one SQL statement in\par
the transaction. Logic tells us that there will be no Repeatable Read errors if there is only one "read".\par
\par
## REPEATABLE READ\par
REPEATABLE READ is the next level of transaction isolation. By specifying\par
REPEATABLE READ, you are saying to your DBMS: don't  tolerate Non-Repeatable\par
Reads (or, for that matter, Dirty Reads or Lost Updates) for the next\par
transaction. Phantoms continue to be tolerated. With REPEATABLE READ, the\par
concurrency drops sharply. In a locking situation, the DBMS will be obliged\par
to put a "shared lock" on every row it fetches, and keep the lock throughout\par
the transaction. From the DBMS's point of view, the difference between this\par
level and the previous one is: with READ COMMITTED the locks can be released\par
before the transaction ends, with REPEATABLE READ they can't be.\par
\par
The REPEATABLE READ level is what most programmers prefer for multi-statement\par
transactions that involve "changes". Examples would be bank transfers or library book checkouts.\par
\par
## SERIALIZABLE\par
SERIALIZABLE is the highest level of transaction isolation. At the\par
SERIALIZABLE isolation level, no concurrency phenomena -- even Phantoms -- can\par
arise to plague the programmer. This is the lowest level for concurrency.\par
Often the DBMS must respond by coarsening the granularity, and locking whole\par
Tables at once. Because the result is likely to be poor performance, this is\par
usually not the isolation level that the DBMS vendor manuals suggest --\par
they'll steer you to REPEATABLE READ. But SERIALIZABLE is the default\par
isolation level in standard SQL and it's the only level that all\par
standards-compliant vendors are guaranteed to support (theoretically a vendor\par
could ignore the lower levels and just "upgrade" all <isolation level> specifications to SERIALIZABLE).\par
\par
Since the SERIALIZABLE level won't tolerate Phantoms, it's especially\par
indicated for transactions which contain multiple SELECT statements, or for\par
when you don't know what the statements will be, as in dynamic SQL. It is the\par
only level which assures safe, error-free transactions every time. If your\par
application consists wholly of short (i.e. fast-executing) statements which\par
affect only a few records at a time, don't get fancy -- leave everything at\par
the default SERIALIZABLE level. Nevertheless, we suspect that SERIALIZABLE is\par
used somewhat more often than appropriate. The choice of isolation level is\par
something you should at least give a moment's thought to, on a case-by-case basis.\par
\par
The word SERIALIZABLE reflects the idea that, given two overlapping\par
transactions -- Txn#1 and Txn#2 -- we can get the same results as we would get\par
if the transactions were "serial" rather than "overlapping" -- that is, if\par
Txn#1 followed Txn#2, or Txn#2 followed Txn#1, in time the end result would be\par
the same. This does not mean that the transactions are replayable, though. The\par
DBMS can only take responsibility for data stored in the database. It can not\par
guarantee that a transaction's statements are replayable if the parameter\par
values from the host (application) program change or if the SQL statements\par
contain niladic functions such as CURRENT_DATE, CURRENT_TIME, CURRENT_TIMESTAMP or CURRENT_USER.\par
\par
SET LOCAL TRANSACTION:\par
If your DBMS supports transaction that may affect more than one SQL-server,\par
you can use the <keyword> LOCAL (new to SQL with SQL3) to set the transaction\par
characteristics for the next local transaction. If you omit LOCAL, you're\par
instructing your DBMS to set the transaction characteristics for the next\par
transaction executed by the program, regardless of location. If LOCAL is\par
specified, then you may not also specify the size of the transaction's diagnostics area.\par
\par
Certain errors can arise when you try to use the SET TRANSACTION statement:\par
      ## If you try to issue it when a transaction has already begun, SET TRANSACTION will fail: your DBMS will return the SQLSTATE error 25001 "invalid transaction state-active SQL-transaction".\par
      ## If you issue it when there are holdable-cursors still open from the\par
previous transaction and the isolation level of that transaction is not the\par
same as the isolation level you're specifying for the next transaction, SET\par
TRANSACTION will fail: your DBMS will return the SQLSTATE error 25008 "invalid\par
transaction state-held cursor requires same isolation level".\par
      ## If you issue SET LOCAL TRANSACTION and your DBMS doesn't support transactions that affect multiple SQL-servers, SET LOCAL TRANSACTION will fail: your DBMS will return the SQLSTATE error 0A001\par
"feature not supported-multiple server transactions".\par
\par
If you want to restrict your code to Core SQL, don't use SET LOCAL TRANSACTION and don't set any transaction's isolation level to anything but SERIALIZABLE.\par
\par
START TRANSACTION statement\par
\par
In SQL3, you don't need the SET TRANSACTION statement, except for setting the\par
characteristics of local transactions. Instead, you can use the START\par
TRANSACTION statement to both initiate the start of a new transaction and to\par
set that transaction's characteristics. The required syntax for the START TRANSACTION statement is:\par
\par
START TRANSACTION <transaction mode> [ \{,<transaction mode>\}...]\par
\par
   <transaction mode> ::=\par
   <isolation level> |\par
   <transaction access mode> |\par
   <diagnostics size>\par
\par
Each of the transaction characteristics -- <isolation level>, <transaction\par
access mode> and <diagnostics size> -- works the same, and has the same\par
options as those we discussed for the SET TRANSACTION statement. The only real\par
difference between the two statements is that SET TRANSACTION is considered to\par
be outside of a transaction -- it defines the characteristics for the next\par
transaction coming up -- while START TRANSACTION is considered as the\par
beginning of a transaction -- it defines the characteristics of the transaction it begins.\par
\par
One other thing of note: The characteristics of a transaction that you start\par
with a START TRANSACTION statement are as specified in that statement -- even\par
if the specification is implicit because you leave out one or more of the\par
transaction mode options. That is, even if one or more characteristics are\par
omitted from START TRANSACTION, they will default to the appropriate values --\par
they will not take on any non-default characteristics even if you issue a SET\par
TRANSACTION statement that includes other specifications for those characteristics just before you begin the transaction.\par
\par
If you want to restrict your code to Core SQL, don't use the START TRANSACTION statement.\par
\par
Special problems\par
\par
The SQL-Schema change statements (CREATE, ALTER, DROP, GRANT, REVOKE) require\par
drastic solutions to ensure concurrency. Typically, a DBMS must lock all the\par
INFORMATION_CATALOG descriptors. That means that SQL-Schema statements cannot run concurrently with anything else.\par
\par
The INSERT statement is more concurrent than the UPDATE or DELETE statements.\par
By definition, any "new" row is a not-yet-committed row and therefore is\par
invisible to all other transactions (except transactions which are running at\par
the READ UNCOMMITTED isolation level). Where INSERT will have problems is in\par
cases where the target Table includes a Column with a serial data type (which\par
is non-standard) -- in such cases, the DBMS cannot guarantee that the value\par
will truly be serial unless the isolation level of all transactions is SERIALIZABLE.\par
\par
It is fairly easy to lock a "row" in a Base table, since there is usually some\par
fixed physical file address which corresponds to the row. However, an "index\par
key" in an index file is a slipperier thing. Index keys can move, as anyone\par
who has studied B+trees can tell you. So, when you update a row, remember that\par
you may be locking not only the row, but an entire page of an index.\par
\par
Regardless of isolation level, none of the isolation phenomena should occur during:\par
      (a) implied reading of Schema definitions (that is, while finding\par
Objects during the "prepare" phase ... as opposed to "explicit" reading, which\par
is what happens if you SELECT ... FROM INFORMATION_SCHEMA.<Table name>);\par
      (b) processing of integrity Constraints (but not Triggers).\par
The implication is that standard SQL DBMSs have to lock the whole database when preparing a statement, and at the end of a statement's execution phase. This is a difficult requirement.\par
\par
Transactions and Constraint Checking\par
\par
There is one other SQL transaction management statement: SET CONSTRAINTS. We\par
talked about SET CONSTRAINTS a bit in our chapter on constraints and\par
assertions; basically, it allows you to tell the DBMS when you want it to\par
check any deferrable Constraints that were affected during a transaction. A\par
transaction always begins with an initial default constraint mode for every\par
Constraint that is used during the course of the transaction. A Constraint's\par
initial constraint mode, specified when the Constraint was created, determines\par
when the Constraint will be checked for violation of its rule: immediately at\par
the end of each SQL statement executed, or later on in the transaction. The\par
SET CONSTRAINTS statement is used to specify a different constraint mode for\par
one or more DEFERRABLE Constraints during the course of a transaction.\par
\par
SET CONSTRAINTS statement\par
\par
The required syntax for the SET CONSTRAINTS statement is:\par
\par
SET CONSTRAINTS <Constraint name list> \{DEFERRED | IMMEDIATE\}\par
\par
   <Constraint name list> ::=\par
   ALL |\par
   <Constraint name> [ \{,<Constraint name>\}... ]\par
\par
Remember that all Constraints and Assertions are defined with a deferral mode\par
of either NOT DEFERRABLE or DEFERRABLE. A deferral mode of NOT DEFERRABLE\par
means that the Constraint must be checked for violation as soon as the SQL\par
statement that affects it is executed -- this type of Constraint can't be\par
affected by the SET CONSTRAINTS statement and we'll ignore it here. A deferral\par
mode of DEFERRABLE, on the other hand, allows you to specify when you want\par
your DBMS to check the Constraint for violation -- the choices are at\par
statement end or at transaction end -- and such Constraints may be affected by the SET CONSTRAINTS statement.\par
\par
Every transaction has a constraint mode for each integrity Constraint affected\par
by that transaction. If the Constraint is a NOT DEFERRABLE Constraint, the\par
constraint mode is always IMMEDIATE. But if the Constraint is a DEFERRABLE\par
Constraint, then its constraint mode at the beginning of a transaction will\par
either be IMMEDIATE or DEFERRED, depending on the way you defined the\par
Constraint -- if you defined it as DEFERRABLE INITIALLY IMMEDIATE, the\par
Constraint's constraint mode at transaction start will be IMMEDIATE and if you\par
defined it as DEFERRABLE INITIALLY DEFERRED, the Constraint's constraint mode\par
at transaction start will be DEFERRED. You can use the SET CONSTRAINTS\par
statement to change these default constraint mode settings for one or more\par
Constraints -- but only for the duration of the transaction that you use it\par
in. (You can actually issue SET CONSTRAINTS at two different times. If you\par
issue it during a transaction, you're changing the constraint mode of only\par
those Constraints that are affected during that same transaction. If you issue\par
it when there is no current transaction, you're changing the constraint mode\par
of only those Constraints that are affected during the very next transaction.)\par
\par
The SQL statement:\par
\par
   SET CONSTRAINTS ALL IMMEDIATE;\par
\par
has the effect of setting the constraint mode of every DEFERRABLE Constraint\par
to IMMEDIATE. IMMEDIATE means that the Constraints must be checked for\par
violation after the execution of every SQL statement -- including after SET CONSTRAINTS.\par
\par
The SQL statement:\par
\par
   SET CONSTRAINTS ALL DEFERRED;\par
\par
has the effect of setting the constraint mode of every DEFERRABLE Constraint\par
to DEFERRED. DEFERRED means that the Constraints should not be checked for\par
violation after the execution of every SQL statement, but should instead be\par
checked at some later time, but no later than the end of the current\par
transaction. (COMMIT includes an implied "SET CONSTRAINTS ALL IMMEDIATE"\par
statement, so that all Constraints are checked at transaction end.)\par
\par
If you provide a list of <Constraint name>s instead of using the <keyword>\par
ALL, the constraint mode of only those Constraints is affected. For example, if you have these Constraints:\par
\par
   Constraint_1 DEFERRABLE INITIALLY IMMEDIATE\par
   Constraint_2 DEFERRABLE INITIALLY IMMEDIATE\par
   Constraint_3 DEFERRABLE INITIALLY IMMEDIATE\par
   Constraint_4 DEFERRABLE INITIALLY DEFERRED\par
   Constraint_5 DEFERRABLE INITIALLY DEFERRED\par
   Constraint_6 DEFERRABLE INITIALLY DEFERRED\par
\par
and you issue this SQL statement:\par
\par
   SET CONSTRAINTS Constraint_1,Constraint_3,Constraint_4 DEFERRED;\par
\par
the result is that Constraint_1, Constraint_3, Constraint_4, Constraint_5 and\par
Constraint_6 will all have a constraint mode of DEFERRED and Constraint_2 will\par
continue to have a constraint mode of IMMEDIATE.\par
\par
All Constraints with a constraint mode of IMMEDIATE are checked for violation\par
at SQL statement. Constraints with a constraint mode of deferred, on the other\par
hand, are not checked until transaction end. This let's you do operations\par
which temporarily puts your data into an unsound state and can thus be very useful.\par
\par
Dialects\par
\par
Some DBMSs support locking, some support timestamping, some support both. Beyond that fundamental point of difference, there are many implementation-dependent features.\par
For example: the granularity (by Column or row or page or Table or database), the number of distinct isolation levels that are actually supported (remember\par
that pseudo-support is possible by simply upgrading to  the next level), and whether to support SQL-92 or SQL3 syntax. Regrettably, most DBMSs are still idiosyncratic with respect to support for the SET TRANSACTION statement.\par
\par
IBM's DB2 and its imitators have explicit statements for locking Tables: "LOCK TABLE <name> IN \{EXCLUSIVE|SHARED\} MODE;". This reduces the total number of locks, and actually enhances concurrency\par
if your intention is to access every row in the Table.\par
\par
ODBC specifies a variety of options which essentially are options for row\par
identifiers used in scrolling. There are also CLI-specific commands for\par
setting transaction isolation or other concurrency-related characteristics.\par
\par
Oracle has Locks Display and other utilities that help administrators to monitor concurrency.\par
\par
Goodies\par
\par
The OCELOT DBMS that comes with this book supports concurrency. These are the specifications:\par
   Concurrency Resolution Mechanism:          Locking\par
   Maximum number of concurrent connections:  2\par
   Isolation Levels Actually Supported:       SERIALIZABLE\par
   Granularity:                               database\par
   Additional Features:                       none\par
\page\par
Chapter 38 -- SQL Sessions\par
\par
An SQL-session spans the execution of one or more consecutive SQL statements\par
by a single user. In order to execute any SQL statements, your DBMS has to\par
establish an SQL-Connection (using the CONNECT statement) -- the SQL-session\par
thus initiated is then associated with that SQL-Connection. If you don't\par
explicitly do a CONNECT statement on your own, your DBMS will effectively\par
execute a default CONNECT statement to establish an SQL-Connection for you --\par
this is known as the default SQL-Connection.\par
\par
An SQL-Connection has two possible states: it is either current or dormant.\par
Only one SQL-Connection (and its associated SQL-session) can be current at a\par
time. A SQL-Connection is initially established by a CONNECT statement as the\par
current SQL-Connection, and it remains the current SQL-Connection unless and\par
until another CONNECT statement or a SET CONNECTION statement puts it (and its\par
associated SQL-session) into a dormant state by establishing another\par
SQL-Connection as the current SQL-Connection. When would you use SET\par
CONNECTION? Well, the SQL Standard says that your DBMS must support at least\par
one SQL-Connection -- but it may support more than one concurrent\par
SQL-Connection. In the latter case, your application program may connect to\par
more than one SQL-server, selecting the one it wants to use (the current, or\par
active SQL-Connection) with a SET CONNECTION statement.\par
\par
An SQL-Connection ends either when you issue a DISCONNECT statement or in some\par
implementation-defined way following the last call to an <externally-invoked\par
procedure> within the last active SQL-client Module.\par
\par
Every SQL-session has a user <AuthorizationID>, to provide your DBMS with an\par
<AuthorizationID> for Privilege checking during operations on SQL-data. You\par
can specify this <AuthorizationID> with the CONNECT statement, or allow it to\par
default to an <AuthorizationID> provided by your DBMS. You can also change the\par
<AuthorizationID> during the SQL-session.\par
\par
Every SQL-session also has a default local time zone offset, to provide your\par
DBMS with a time zone offset when a time or a timestamp value needs one. When\par
you begin an SQL-session, your DBMS sets the default time zone offset to a\par
value chosen by your vendor. You can change this to a more appropriate value\par
with the SET TIME ZONE statement.\par
\par
Every SQL-session has what the SQL Standard calls "enduring characteristics" -\par
- these all have initial default values at the beginning of an SQL-session,\par
but you change any of them with the SET SESSION CHARACTERISTICS statement.\par
SQL-sessions also have a "context": characteristics of the SQL-session that\par
your DBMS preserves when an SQL-session is made dormant, so that it can\par
restore the SQL-session properly when it is made current again. The context of\par
an SQL-session includes the current SESSION_USER, the CURRENT_USER, the\par
CURRENT_ROLE, the CURRENT_PATH, the identities of all temporary Tables, the\par
current default time zone offset, the current constraint mode for all\par
Constraints, the current transaction access mode, the position of all open\par
Cursors, the current transaction isolation level, the current transaction\par
diagnostics area limit, the value of all valid locators and information of any\par
active SQL-invoked routines.\par
\par
SQL-Connections\par
\par
You can establish an SQL-Connection either explicitly, by issuing a CONNECT\par
statement; or implicitly, by invoking a procedure that works on SQL-data when\par
there is no current SQL-session (in this case, your DBMS acts as if you\par
explicitly issued: "CONNECT TO DEFAULT;"). You can change the state of an SQL-\par
Connection (from current to dormant, and back again) with the SET CONNECTION\par
statement. You can also end an SQL-Connection (and therefore its associated\par
SQL-session) with the DISCONNECT statement. Here's how.\par
\par
CONNECT statement\par
\par
The CONNECT statement explicitly establishes an SQL-Connection. The\par
establishment of an SQL-Connection gives you access to the SQL-data on an SQL-server in your environment and thus starts an SQL-session. The required syntax for the CONNECT statement is:\par
\par
CONNECT TO\par
   DEFAULT |\par
   <SQL-server name> [ AS <Connection name> ] [ USER <AuthorizationID> ]\par
\par
The CONNECT statement may not be executed during a transaction unless your DBMS supports transactions that affect multiple SQL-servers.\par
\par
DEFAULT Connection:\par
The SQL Standard does not require an explicit CONNECT statement to start an\par
SQL-session. If the first SQL statement in an SQL-session is anything other\par
than a CONNECT statement, your DBMS will first execute this SQL statement:\par
\par
   CONNECT TO DEFAULT;\par
\par
to establish the default SQL-Connection before proceeding further. You can\par
also issue an explicit "CONNECT TO DEFAULT;" statement if you want to\par
deliberately establish your DBMS's default SQL-Connection. In either case, if\par
the default SQL-Connection has already been established -- e.g.: it was\par
already the subject of a CONNECT statement or a SET CONNECTION statement and\par
no DISCONNECT statement has been issued for it -- CONNECT will fail: your DBMS\par
will return the SQLSTATE error 08002 "connection exception-connection name in use".\par
\par
[NON-PORTABLE] The effect of "CONNECT TO DEFAULT;" is non-standard because the\par
SQL Standard requires implementors to define what the default SQL-Connection\par
and the default SQL-server are.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book treats the (explicit or implicit) SQL statement:\par
\par
   CONNECT TO DEFAULT;\par
\par
as equivalent to this SQL statement:\par
\par
   CONNECT TO 'ocelot' AS 'ocelot' USER 'ocelot';\par
\par
This CONNECT statement causes the OCELOT DBMS to establish a SQL-Connection to a default Cluster (or default SQL-server) called OCELOT, using a default <Connection name> of OCELOT and a default user <AuthorizationID> of OCELOT.\par
If the default Cluster can't be found, the DBMS will create it.\par
\par
<SQL-Server name> clause:\par
The other form of the CONNECT statement has three possible arguments, only one\par
of which is mandatory. The syntax "CONNECT TO <SQL-server name>;", e.g.:\par
\par
   CONNECT TO 'some_server';\par
\par
establishes an SQL-Connection to the SQL-server named. (Remember that the SQL-\par
server is that portion of your environment that actually carries out the\par
database operations.) <SQL-server name> is either a <character string\par
literal>, a <host parameter name> or an <SQL parameter reference> whose value\par
represents a valid <SQL-server name>. The SQL Standard is deliberately vague\par
about just what an SQL-server is, and consequently leaves the method for\par
determining its location and the communication protocol required to access it up to the DBMS.\par
\par
AS clause:\par
The syntax "CONNECT TO <SQL-server name> AS <Connection name>;", e.g.:\par
\par
   CONNECT TO 'some_server' AS 'connection_1';\par
\par
establishes an SQL-Connection named CONNECTION_1 to the SQL-server named.\par
<Connection name> is a simple <value specification -- e.g. a <character string\par
literal>, <host parameter name> or <SQL parameter reference> -- whose value\par
represents a valid <Connection name>. (If <Connection name> does not evaluate\par
to a valid <Connection name>, CONNECT will fail: your DBMS will return the\par
SQLSTATE error 2E000 "invalid connection name".)\par
\par
[NON-PORTABLE] A <Connection name> must be a <regular identifier> or a\par
<delimited identifier> that is no more than 128 octets in length, but the\par
value of a valid <Connection name> is non-standard because the SQL Standard\par
requires implementors to define what a valid <Connection name> may be and what\par
Character set <Connection name>s belong to.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book\par
defines a <Connection name> as any valid <regular identifier> or <delimited\par
identifier> whose characters belong to the INFORMATION_SCHEMA.SQL_TEXT Character set.\par
\par
If your CONNECT statement doesn't include the optional AS <Connection name>\par
clause, the value of <Connection name> defaults to the value of <SQL-server\par
name>. The following SQL statements are therefore equivalent (assuming that\par
the default SQL-Connection is to an SQL-server named "SOME_SERVER"):\par
\par
   CONNECT TO DEFAULT;\par
\par
   CONNECT TO 'some_server';\par
\par
   CONNECT TO 'some_server' AS 'some_server';\par
\par
Note: The AS clause can only be omitted from the first CONNECT statement\par
issued for a particular SQL-server. On the second, and subsequent,\par
Connections, an explicit <Connection name> must be provided to your DBMS\par
because <Connection name>s must be unique for the entire SQL-environment at\par
any given time. You'll use the <Connection name> with the SET CONNECTION\par
statement to switch between different SQL-Connections. If <Connection name>\par
evaluates to a <Connection name> that is already in use -- e.g. it was the\par
subject of CONNECT TO or SET CONNECTION and DISCONNECT has not been issued for\par
it -- CONNECT TO will fail: the DBMS will return the SQLSTATE error 08002 "connection exception-connection name in use".\par
\par
USER clause:\par
The syntax "CONNECT TO <SQL-server name> USER <AuthorizationID>;", e.g.:\par
\par
   CONNECT TO 'some_server' USER 'bob';\par
\par
establishes an SQL-Connection, with an SQL-session <AuthorizationID> of BOB,\par
to the SQL-server named. <AuthorizationID> is a simple <value specification --\par
e.g. a <character string literal>, <host parameter name> or <SQL parameter\par
reference> -- whose value represents a valid <AuthorizationID>. (If\par
<AuthorizationID> does not evaluate to a valid user <AuthorizationID>, CONNECT\par
will fail: your DBMS will return the SQLSTATE error 28000 "invalid authorization specification".)\par
\par
If your CONNECT statement doesn't include the optional USER <AuthorizationID>\par
clause, the value of the SQL-session user defaults to an <AuthorizationID>\par
chosen by your DBMS. The following SQL statements are therefore equivalent\par
(assuming that the default SQL-Connection is to an SQL-server named "SOME_SERVER"):\par
\par
   CONNECT TO DEFAULT;\par
\par
   CONNECT TO 'some_server';\par
\par
   CONNECT TO 'some_server' AS 'some_server' USER 'default_user';\par
\par
[NON-PORTABLE] The effect of omitting the optional USER clause from a CONNECT\par
statement is non-standard because the SQL Standard requires implementors to\par
define their own initial default SQL-session <AuthorizationID>.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book has an initial default <AuthorizationID> of 'OCELOT'.\par
\par
CONNECT Examples:\par
This SQL statement:\par
\par
   CONNECT TO 'some_server';\par
\par
establishes an SQL-Connection to the SQL-server specified. The <Connection name> defaults to 'SOME_SERVER'; the SQL-session <AuthorizationID> is set to the DBMS's initial default <AuthorizationID>.\par
\par
This SQL statement:\par
\par
   CONNECT TO 'some_server' AS 'Connection_1';\par
\par
establishes an SQL-Connection named CONNECTION_1 to the SQL-server specified. The SQL-session <AuthorizationID> is set to the DBMS's initial default <AuthorizationID>.\par
\par
This SQL statement:\par
\par
   CONNECT TO 'some_server' USER 'bob';\par
\par
establishes an SQL-Connection to the SQL-server specified. The <Connection name> defaults to 'SOME_SERVER'; the SQL-session <AuthorizationID> is set to 'BOB'.\par
\par
And this SQL statement:\par
\par
   CONNECT TO 'some_server' AS 'Connection_1' USER 'bob';\par
\par
establishes an SQL-Connection named CONNECTION_1 to the SQL-server specified. The SQL-session <AuthorizationID> is set to 'BOB'.\par
\par
Executing the CONNECT statement has the effect that the SQL-Connection\par
established becomes the current SQL-Connection, and its associated SQL-session\par
becomes the current SQL-session. The SQL-Connection and SQL-session that were\par
current when you executed CONNECT (if any) become dormant, with their context\par
information preserved by the DBMS so that they can be properly restored later\par
on. If the CONNECT statement fails, the current SQL-Connection and its\par
associated SQL-session (if any) remain the current SQL-Connection and current SQL-session.\par
\par
If CONNECT fails because your DBMS is unable to establish the SQL-Connection,\par
you'll get the SQLSTATE error 08001 "connection exception-SQL-client unable to\par
establish SQL-connection". If CONNECT fails because the SQL-server refuses to\par
accept the SQL-Connection, you'll get the SQLSTATE error 08004 "connection\par
exception-SQL-server rejected establishment of SQL-connection".\par
\par
If you want to restrict your code to Core SQL, don't use the CONNECT statement.\par
\par
SET CONNECTION statement\par
\par
[NON-PORTABLE] An SQL-compliant DBMS can either limit the number of concurrent\par
SQL-Connections to one, or it can support multiple concurrent SQL-Connections.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
multiple concurrent SQL-Connections to be made; each begins a separate\par
SQL-session for the <Cluster name> specified. Thus, OCELOT supports multi-user\par
operations -- one or more Users may connect to the same Cluster simultaneously\par
-- and OCELOT supports multi-tasking operations -- the same user may connect\par
to multiple Clusters simultaneously. Each such connection is a separate\par
SQL-Connection (it must be identified by a unique <Connection name>) and is associated with a separate SQL-session.\par
\par
The SET CONNECTION statement is used to select an SQL-Connection from all\par
available SQL-Connections -- it makes a dormant SQL-Connection current. As a\par
consequence, any other SQL-Connection that was current then becomes dormant.\par
The required syntax for the SET CONNECTION statement is:\par
\par
SET CONNECTION DEFAULT | <Connection name>\par
\par
The SET CONNECTION statement activates a dormant SQL-Connection and makes it\par
the current SQL-Connection. SET CONNECTION may not be executed during a\par
transaction unless your DBMS supports transactions that affect multiple SQL-servers.\par
\par
The SQL statement:\par
\par
 SET CONNECTION DEFAULT;\par
\par
will establish your DBMS's default SQL-Connection as the current SQL-Connection. If there is no current or dormant default SQL-Connection (that is, if "CONNECT TO DEFAULT;" wasn't previously issued during the SQL-session),\par
SET CONNECTION will fail: your DBMS will return the SQLSTATE error 08003 "connection exception-connection does not exist".\par
\par
The syntax "SET CONNECTION <Connection name>;" will establish the SQL-\par
Connection specified as the current SQL-Connection. <Connection name> must be\par
a simple <value specification -- e.g. a <character string literal>, <host\par
parameter name> or <SQL parameter reference> -- whose value identifies the\par
current, or a dormant, SQL-Connection. (If <Connection name> does not evaluate\par
to either the current or a dormant SQL-Connection, SET CONNECTION will fail:\par
your DBMS will return the SQLSTATE error 08003 "connection\par
exception-connection does not exist". For example, this SQL statement:\par
\par
   SET CONNECTION 'connection_2';\par
\par
makes the SQL-Connection called 'CONNECTION_2' the current SQL-Connection and\par
puts the previous (if any) SQL-Connection into a dormant state. If your DBMS\par
is unable to activate 'CONNECTION_2', SET CONNECTION will fail and your DBMS\par
will return the SQLSTATE error 08006 "connection exception-connection failure".\par
\par
If you want to restrict your code to Core SQL, don't use the SET CONNECTION statement.\par
\par
DISCONNECT statement\par
\par
The DISCONNECT statement is used to terminate an inactive SQL-Connection. A\par
SQL-Connection can be closed whether it is the current SQL-Connection or a\par
dormant SQL-Connection, but may not closed while a transaction is on-going for\par
its associated SQL-session. The required syntax for the DISCONNECT statement is:\par
\par
DISCONNECT <Connection name> | DEFAULT | CURRENT | ALL\par
\par
The DISCONNECT statement terminates an inactive SQL-Connection. DISCONNECT may\par
not be executed during a transaction -- if you attempt to terminate an\par
SQL-Connection that is processing a transaction, DISCONNECT will fail: your\par
DBMS will return the SQLSTATE error 25000 "invalid transaction state".\par
\par
You can disconnect a specific SQL-Connection by naming it (with "DISCONNECT\par
<Connection name>;"), you can disconnect your DBMS's default SQL-Connection\par
(with "DISCONNECT DEFAULT;"), you can disconnect the current SQL-Connection\par
(with "DISCONNECT CURRENT;") or you can disconnect the current and all dormant\par
SQL-Connections at once (with "DISCONNECT ALL;"). For example, this SQL\par
statement closes an inactive SQL-Connection called CONNECTION_1, whether it is current or dormant;\par
\par
   DISCONNECT 'connection_1';\par
\par
As usual, <Connection name> must be a simple <value specification -- e.g. a\par
<character string literal>, <host parameter name> or <SQL parameter reference>\par
-- whose value identifies the current, or a dormant, SQL-Connection. (If\par
<Connection name> is not the name of either the current SQL-Connection or a\par
dormant SQL-Connection, DISCONNECT will fail: your DBMS will return the\par
SQLSTATE error 08003 "connection exception-connection does not exist".) If\par
<Connection name> names the current SQL-Connection and DISCONNECT executes\par
successfully, there will no longer be a current SQL-Connection until another\par
CONNECT statement or SET CONNECTION statement establishes one.\par
\par
This SQL statement:\par
\par
   DISCONNECT DEFAULT;\par
\par
terminates the DBMS's default SQL-Connection, whether it is\par
current or dormant. (If the DBMS's default SQL-Connection is neither the\par
current SQL-Connection nor a dormant SQL-Connection, DISCONNECT will fail:\par
your DBMS will return the SQLSTATE error 08003 "connection\par
exception-connection does not exist".)If the default SQL-Connection is the\par
current SQL-Connection and DISCONNECT executes successfully, there will no\par
longer be a current SQL-Connection until another CONNECT statement or SET CONNECTION statement establishes one.\par
\par
This SQL statement:\par
\par
   DISCONNECT CURRENT;\par
\par
terminates the current SQL-Connection. If there is no current SQL-Connection,\par
DISCONNECT will fail: your DBMS will return the SQLSTATE error 08003\par
"connection exception-connection does not exist". If DISCONNECT executes\par
successfully, there will no longer be a current SQL-Connection until another\par
CONNECT statement or SET CONNECTION statement establishes one.\par
\par
This SQL statement:\par
\par
   DISCONNECT ALL;\par
\par
closes the current, and all dormant, SQL-Connections. If there are no current\par
or dormant SQL-Connections, DISCONNECT will fail: your DBMS will return the\par
SQLSTATE error 08003 "connection exception-connection does not exist". If\par
DISCONNECT executes successfully, there will no longer be any SQL-Connection\par
(current or dormant) until another CONNECT statement or SET CONNECTION statement establishes one.\par
\par
Any errors other than SQLSTATE 08003 or SQLSTATE 25000 that are detected by\par
your DBMS while DISCONNECT is being executed will not cause DISCONNECT to\par
fail. Instead, DISCONNECT will execute successfully and your DBMS will return\par
the SQLSTATE warning 01002 "warning-disconnect error".\par
\par
The SQL Standard suggests that DISCONNECT should be automatic when an\par
SQL-session ends -- but lets the DBMS decide when this has occurred.\par
Recommendation: To be absolutely sure of correct results, always end your SQL-sessions with the explicit DISCONNECT statement:\par
\par
   DISCONNECT ALL;\par
\par
If you want to restrict your code to Core SQL, don't use the DISCONNECT statement.\par
\par
SQL-session management\par
\par
SQL provides four statements that help you manage your SQL-session. Each one\par
lets you specify a value for one or more SQL-session characteristics. The SQL-session management statements are SET SESSION CHARACTERISTICS, SET SESSION AUTHORIZATION, SET ROLE and SET TIME ZONE.\par
\par
SET SESSION CHARACTERISTICS statement\par
\par
The SET SESSION CHARACTERISTICS statement sets the value of one or more\par
transaction characteristics for the current SQL-session. The required syntax for the SET SESSION CHARACTERISTICS statement is:\par
\par
SET SESSION CHARACTERISTICS AS <transaction mode> [ \{,<transaction mode>\}... ]\par
\par
   <transaction mode> ::=\par
   <isolation level> |\par
   <transaction access mode> |\par
   <diagnostics size>\par
\par
You can set the same characteristics for all the transactions in an entire\par
SQL-session as you can for a single transaction. Each of the transaction\par
characteristics -- <isolation level>, <transaction access mode> and\par
<diagnostics size> -- works the same, and has the same options as those we\par
discussed for the SET TRANSACTION statement in the last chapter. The values\par
you specify for any transaction characteristic in a SET SESSION\par
CHARACTERISTICS statement are enduring values -- should you cause the current\par
SQL-session to go dormant and then reactivate it later, your DBMS will reset\par
each characteristic to the value you specified the last time you issued SET\par
SESSION CHARACTERISTICS for that SQL-session. Here's an example:\par
\par
   SET SESSION CHARACTERISTICS AS\par
     READ WRITE\par
     ISOLATION LEVEL REPEATABLE READ\par
     DIAGNOSTICS SIZE 5\par
\par
If you want to restrict your code to Core SQL, don't use the SET SESSION CHARACTERISTICS statement.\par
\par
SET SESSION AUTHORIZATION statement\par
\par
The SET SESSION AUTHORIZATION statement sets the session user <AuthorizationID> for the current SQL-session. The required syntax for the SET SESSION AUTHORIZATION statement is:\par
\par
SET SESSION AUTHORIZATION <value specification>\par
\par
When you start an SQL-session, your DBMS sets the value of the session user\par
<AuthorizationID> for the SQL-session to the <AuthorizationID> specified with\par
the CONNECT statement. The session user <AuthorizationID> is the value\par
returned by the SESSION_USER function and is usually also the value returned\par
by the CURRENT_USER (or USER) function. Your DBMS uses the session\par
<AuthorizationID> as a default <AuthorizationID> in cases where no explicit\par
<AuthorizationID> overrides it -- for example, whenever you run a Module that\par
wasn't defined with an explicit AUTHORIZATION clause, your DBMS assumes the\par
owner of the Module is the SQL-session <AuthorizationID>. The owner of any\par
temporary Tables defined for the SQL-session is the SQL-session <AuthorizationID>.\par
\par
[NON-PORTABLE] SET SESSION AUTHORIZATION may always be executed at the start\par
of an SQL-session. Whether you can use the SET SESSION AUTHORIZATION statement\par
at any other time is non-standard because the SQL Standard requires\par
implementors to define whether the SQL-session <AuthorizationID> may be changed once an SQL-session has begun.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book allows\par
the SQL-session <AuthorizationID> to be changed at any time (except during a transaction).\par
\par
You can change the value of the SQL-session <AuthorizationID> with the SET\par
SESSION AUTHORIZATION statement; simply issue SET SESSION AUTHORIZATION\par
followed by a <character string literal>, a character string <host parameter\par
name> (with optional indicator), a character string <SQL parameter reference>\par
or a user function (either CURRENT_ROLE, CURRENT_USER, SESSION_USER,\par
SYSTEM_USER or USER). Whichever you use, the value represented by the <value\par
specification> must be a valid user <AuthorizationID> -- if it isn't, SET\par
SESSION AUTHORIZATION will fail: your DBMS will return the SQLSTATE error\par
28000 "invalid authorization specification".\par
\par
SET SESSION AUTHORIZATION can only be issued outside of a transaction. If you\par
try to execute the statement and a transaction is currently active, SET\par
SESSION AUTHORIZATION will fail: your DBMS will return the SQLSTATE error\par
25001 "invalid transaction state-active SQL-transaction".\par
\par
For an example of SET SESSION AUTHORIZATION, assume that the session user\par
<AuthorizationID> for your SQL-session is BOB and you'd like to switch it to SAM. Here's three different ways to do it:\par
\par
   SET SESSION AUTHORIZATION 'sam';\par
\par
   SET SESSION AUTHORIZATION :char_variable;\par
     -- assume the value of the host variable "char_variable" is SAM\par
\par
   SET SESSION AUTHORIZATION CURRENT_USER;\par
     -- assume the value of CURRENT_USER is SAM\par
\par
If you want to restrict your code to Core SQL, don't use the SET SESSION AUTHORIZATION statement.\par
\par
SET ROLE statement\par
\par
The SET ROLE statement sets the enabled Roles for the current SQL-session. The required syntax for the SET ROLE statement is:\par
\par
SET ROLE <value specification> | NONE\par
\par
When you start an SQL-session, your DBMS sets the value of the current Role\par
<AuthorizationID> for the SQL-session to the <AuthorizationID> specified with\par
the CONNECT statement (or to NULL, if the CONNECT statement doesn't provide a\par
<Role name>). The current Role <AuthorizationID> is the value returned by the\par
CURRENT_ROLE function. Either one of CURRENT_USER or CURRENT_ROLE may be NULL\par
at any time, but they may not both be NULL at the same time -- the non-null\par
identifier is the SQL-session's current <AuthorizationID>. That is, if\par
CURRENT_ROLE is set to some <Role name>, then CURRENT_USER must be NULL and\par
your DBMS will use the current Role for Privilege checking before processing\par
any SQL statements in the SQL-session.\par
\par
You can change the value of CURRENT_ROLE with the SET ROLE statement: simply\par
issue SET ROLE followed by a <character string literal>, a character string\par
<host parameter name> (with optional indicator), a character string <SQL\par
parameter reference> or a user function (either CURRENT_ROLE, SESSION_USER,\par
SYSTEM_USER or USER). Whichever you use, the value represented by the <value\par
specification> must be a valid <Role name> and that name must identify a Role\par
that has been granted either to PUBLIC or to the SQL-session <AuthorizationID>\par
-- if it isn't, SET ROLE will fail: your DBMS will return the SQLSTATE error\par
0P000 "invalid role specification". You can also change the value of\par
CURRENT_ROLE to NULL by issuing SET ROLE followed by the <keyword> NONE.\par
\par
SET ROLE can only be issued outside of a transaction. If you try to execute\par
the statement and a transaction is currently active, SET ROLE will fail: your\par
DBMS will return the SQLSTATE error 25001 "invalid transaction state-active\par
SQL-transaction".\par
\par
For an example of SET ROLE, assume that the current Role for your SQL-session\par
is NULL and you'd like to switch it to TELLER_ROLE. Here's two different ways to do it:\par
\par
   SET ROLE 'Teller_Role';\par
\par
   SET ROLE :char_variable;\par
     -- assume the value of the host variable "char_variable" is TELLER_ROLE\par
\par
If you want to restrict your code to Core SQL, don't use the SET ROLE statement.\par
\par
SET TIME ZONE statement\par
\par
[NON-PORTABLE] An SQL-session always begins with an initial default time zone\par
offset that is non-standard because the SQL Standard requires implementors to\par
define their own initial default time zone offset.\par
      [OCELOT Implementation] The OCELOT DBMS that comes with this book has an\par
initial default time zone that represents UTC -- its default time zone offset\par
is INTERVAL +'00:00' HOUR TO MINUTE.\par
\par
The SQL-session default time zone offset is used to specify the related time\par
zone for all times and timestamps that don't include an explicit <time zone\par
interval>. You can use the SET TIME ZONE statement to change the default time\par
zone offset for the current SQL-session. The required syntax for the SET TIME ZONE statement is:\par
\par
SET TIME ZONE LOCAL | interval_expression\par
\par
The SET TIME ZONE statement changes the current SQL-session's default time\par
zone offset. It has two possible arguments: the <keyword> LOCAL or an\par
expression that evaluates to some non-null INTERVAL HOUR TO MINUTE value\par
between INTERVAL -'12:59' HOUR TO MINUTE and INTERVAL +'13:00' HOUR TO MINUTE.\par
(If you specify an interval that is NULL, or an interval that falls outside\par
the proper range, SET TIME ZONE will fail: your DBMS will return the SQLSTATE\par
error 22009 "data exception-invalid time zone displacement value".)\par
\par
SET TIME ZONE can only be issued outside of a transaction. If you try to\par
execute the statement and a transaction is currently active, SET TIME ZONE\par
will fail: your DBMS will return the SQLSTATE error 25001 "invalid transaction state-active SQL-transaction".\par
\par
The effect of this SQL statement:\par
\par
   SET TIME ZONE LOCAL;\par
\par
is to set the time zone offset for the current SQL-session to your DBMS's initial default time zone offset.\par
\par
The SQL syntax "SET TIME ZONE interval_expression" is used to set the time\par
zone offset for the current SQL-session to the value that results when\par
"interval_expression" is evaluated. For example, this SQL statement:\par
\par
   SET TIME ZONE INTERVAL -'03:00' HOUR TO MINUTE;\par
\par
uses the <interval literal> INTERVAL -'03:00' HOUR TO MINUTE to set the time\par
zone offset for the current SQL-session to minus three hours, i.e.: UTC time minus 3 hours equals local time.\par
\par
If you want to restrict your code to Core SQL, don't use the SET TIME ZONE statement.\par
\page\par
Chapter 39 -- Embedded SQL Binding Style\par
\par
SQL DBMSs communicate with SQL applications through a common programming\par
language interface that is invoked through one of the SQL Standard-defined\par
binding styles, or interface options. The programming language used -- either\par
Ada, C, COBOL, Fortran, MUMPS, Pascal or PL/I -- is called a host language. An\par
SQL DBMS must support the use of at least one host language, either for\par
embedded SQL programming or for invoking external routines and/or procedures.\par
Depending on your DBMS then, you can use SQL to set up and maintain SQL-data\par
from an application program in one of two ways: by incorporating SQL\par
statements or standard routines in a specifically designed programming module\par
or by embedding SQL statements directly into your program.\par
\par
Binding Styles\par
\par
The SQL Standard defines these binding styles, at least one of which must be supported by an SQL DBMS:\par
\par
Module binding style:\par
The SQL-client Module binding style is defined in SQL/Foundation. In this\par
binding style, SQL-client Modules are run, executing SQL operations. One\par
special version of this binding style is known as the Direct SQL Invocation\par
binding style, where SQL statements are directly executed through a front-end.\par
(The SQL statements are gathered together into a default SQL-session Module\par
whose existence is usually not apparent to the user.) Direct SQL is defined in\par
SQL/Bindings. Another special version of the Module binding style is known as\par
the SQL/CLI binding style, where SQL-data operations are performed when SQL\par
applications invoke one of a number of standard routines, passing appropriate\par
arguments. (The routines are gathered together into a default SQL-server\par
Module whose existence is usually not apparent to the user.) The SQL/CLI\par
binding style is defined in SQL/CLI.\par
\par
Embedded SQL binding style:\par
The embedded SQL binding style is defined in SQL/Bindings. In this binding\par
style, SQL statements are directly coded into a host language program and some\par
method (usually a precompiler)is then used to (a) generate an\par
externally-invoked procedure from each embedded SQL statement and (b) replace\par
each embedded SQL statement with an invocation of that generated procedure.\par
(The generated procedures are collected together into a programming module\par
which can then be used as an SQL-client Module by your DBMS, so this ia also a\par
special version of the Module binding style.)\par
\par
There are thus three main approaches to writing complete programs with SQL:\par
      ## With embedded SQL, you can put SQL statements directly into "host\par
programs" (programs written in Ada, C, COBOL, FORTRAN, MUMPS, Pascal or PL/I)\par
-- making them part of the host program's source code. Since the host\par
language's compiler won't recognize SQL statements as valid statements of its\par
language, some sort of preprocessor is required to make this work.\par
      ## With SQL/CLI, you can call a SQL DBMS's library from a host program.\par
The SQL statements you want to execute are parameters of the call. Because\par
SQL's modus operandi won't quite match the host language's, helper functions\par
are required for the interface definition.\par
      ## With the Module language, you can dispense with host programs and\par
write entire Modules in SQL. You'll still have to call these Modules from one\par
of the standard host languages though.\par
\par
Reflecting what we believe is their relative importance, this book contains\par
one chapter on embedded SQL, then several chapters on SQL/CLI, then one\par
chapter on th Module binding style. This is the embedded SQL chapter.\par
\par
Because we believe that SQL/CLI will quickly become the SQL interface of\par
choice, this chapter omits large amounts of detail, in favour of providing the\par
necessary detail in our chapters on SQL/CLI. Still, this chapter is a good\par
opportunity to introduce the basic concepts in a simple way. Embedded SQL is\par
easy to read, so we have a trouble-free first viewing of the problems that a\par
program writer must solve. Watch in particular for solutions of the "impedance\par
mismatch" problem (getting SQL objects to link with host-language analogs),\par
the "Weltanschauung" problem (handling one-row-at-a-time rather than\par
whole-set-at-a-time) and the "control" problem (adjusting host program flow based on SQL execution information).\par
\par
What is embedded SQL?\par
\par
Embedded SQL was once the predominant standard way to mix SQL statements with\par
host languages. It lets you mix SQL statements directly into an application\par
program written in some common computer programming language. It is especially\par
associated with COBOL or PL/I programs and IBM's DB2 and big iron; however.\par
Most of the big DBMS vendors support it on microcomputers too. Support is weak\par
among small DBMS vendors, and especially weak for computer host languages that\par
aren't currently in vogue.\par
\par
SQL can be embedded into many host languages, but support varies depending on\par
the vendor and depending on the language. The following are the standard host\par
languages (that is, the ones mentioned in the SQL Standard). A DBMS that\par
supports the embedded SQL binding style must support SQL embedded into at\par
least one of these languages:\par
      ## Ada: Standard. Weakly supported.\par
      ## C: Standard. Well supported.\par
      ## COBOL: Standard. Packages are sometimes supplied by the COBOL vendor. For example, Micro Focus offers XDB SQL as an optional add-on, along with appropriate interfacing.\par
      ## Fortran: Standard. Well supported, but interfacing is sometimes awkward.\par
      ## MUMPS: Standard. Weakly supported.\par
      ## Pascal: Standard. Not everybody supports Borland Delphi's special characteristics such as Pchar null-terminated string references.\par
      ## PL/I: Standard. Weakly supported.\par
\par
Here are some other host languages that have some importance but are not (yet) standard:\par
      ## BASIC: Not supported by the SQL Standard. The vendor support which exists is usually restricted to a single dialect (such as Microsoft BASIC or PowerBASIC).\par
      ## Java: Not supported by the SQL Standard. Probably Java will achieve recognition as an "official" host language for SQL, but most current efforts are for a CLI standard called JDBC.\par
\par
For all of these languages, support is better via the SQL/CLI.\par
\par
So, to begin with, you start with a host language, writing your code in the\par
normal way. When you get to a point where a database operation needs to be\par
carried out, use embedded SQL statements (rather than routines written in the\par
host language; an executable SQL statement can be put into a program anywhere\par
that an executable host language statement can be) to carry them out -- the\par
host code "calls" SQL statements. You can pass data between the host and SQL:\par
SQL-data values go to variables in the host code, host program values go to\par
SQL Columns or functions or some other appropriate database target. Before\par
compiling your program, you'll need to go through a preprocessing step -- hence the name: Precompiler.\par
\par
To make it all possible, you have to follow rigid conventions:\par
      ## Begin every SQL statement with the SQL prefix appropriate for the host language.\par
      ## End every SQL statement with the SQL terminator appropriate for the host language.\par
      ## Declare all host-language program variables which will be shared with SQL in a special DECLARE section.\par
      ## Declare additional program variables for error handling.\par
\par
Precompilers\par
\par
Most precompilers are standalone utility programs. A few are integrated with\par
the compiler itself. Regardless of their startup method, all precompilers must\par
do a certain series of operations which turn an embedded-SQL module into a\par
module that the host compiler can compile. These are the operations which the\par
sample Precompiler that comes with this book does for a C program:\par
\par
      1. Open the Input File (the file containing embedded SQL).\par
         Open the Output File (the file which the compiler needs).\par
\par
      2. Read a token from the Input File. At end: exit.\par
\par
      3. If the token is not "EXEC", or the next token is not "SQL": Write the token to the output file.\par
         Goto 2.\par
\par
      4. If the next tokens are "BEGIN DECLARE SECTION":\par
         /* The following tokens must be variable definitions */\par
Read and write the following tokens. While doing so, keep track of and store: variable name, variable size, variable type. Since this is supposed to be a C program, certain keywords are expected, such as "char" or "short".\par
Stop when the next tokens are "END DECLARE SECTION".\par
         Goto 2.\par
\par
      5. If the next token is "CREATE" or "INSERT" or some other SQL <keyword> indicating that this is the beginning of an executable SQL statement:\par
         Write the words "SQLExecDirect(-1,".\par
         Read and write until ";" is seen. (";" is the "terminator" of SQL in C.)\par
         Write ",-3)".\par
         Goto 2.\par
NB: While reading and writing, a "host variable" token may be encountered, of the form: <colon><host-variable-name>. The precompiler must convert this to whatever the appropriate form is for a pass-by-address parameter,\par
and output a statement like "SQLBindCol(...,&hostvariable);".\par
\par
If the precompiler finishes without severe errors, there is an output program.\par
The output from the precompiler is the input for the compiler. From that, the\par
compiler produces an object file. Then the linker comes into play. The linker\par
will encounter some external references, for example the SQLExecDirect call\par
that the precompiler produced. To resolve these references, the linker will\par
look in a library -- which is another essential part of the DBMS package for use with precompilers.\par
\par
In theory, a precompiler could act differently provided it met the functional specification. We have described what we know best: this book's sample Precompiler.\par
\par
SQL Prefixes and Terminators\par
\par
The precompiler lacks the smarts to figure out the syntax of the host language\par
program. After all, host language code can get pretty complex. All the\par
precompiler can do is look for signals that say "embedded SQL starts here" or\par
"embedded SQL ends here". Or, to use the formal terms, embedded SQL statements\par
must have a prefix and a terminator. Usually the prefix is EXEC SQL and the\par
terminator is a semicolon. There is a bit of variation among the standard host languages:\par
      ## For Ada, use: EXEC SQL ... ;\par
      ## For C, use: EXEC SQL ... ;\par
      ## For COBOL, use: EXEC SQL ... END-EXEC\par
      ## For Fortran, use: EXEC SQL ... <no end> (i.e.: no explicit terminator)\par
      ## For MUMPS, use: &SQL( ... )\par
      ## For Pascal, use: EXEC SQL ... ;\par
      ## For PL/I, use: EXEC SQL ... ;\par
\par
Our preferred languages for discussion are C and Pascal, so it's just as easy\par
to say: "all SQL statements must be prefixed by 'EXEC SQL' and terminated by\par
';'". The case of the <keyword>s EXEC SQL (or the other prefixes) doesn't\par
matter, but it is compulsory that they be together (rather than on separate\par
lines). Everything between EXEC SQL and ; must be legal SQL -- host language\par
statements or comments have no place here. Aside from that, format is fairly free, as this example snippet shows:\par
\par
   ...\par
   \{                    /* Braces around SQL statements are a good idea. */\par
   EXEC sql\par
      CREATE DOMAIN d5 INTEGER;\par
      EXEC SQL\par
      CREATE DOMAIN     /* This is a new-style comment not a C comment */\par
      d6 INTEGER\par
   ;\par
   \}\par
   ...\par
\par
Host Variables\par
\par
Embedded SQL statements can contain host language variables in the same places\par
that any other scalar expression can be placed. The host variables allow you\par
to pass data between the program and your SQL-data. In an SQL statement, a\par
<host variable name> must be preceded by a colon, to distinguish it from an\par
SQL Object name. Host variables may not be qualified or subscripted, and must\par
return only scalar values.\par
\par
An important and inevitable part of any embedded SQL program is the declare\par
section -- the variable declarations that appear between "EXEC SQL BEGIN DECLARE SECTION;" and "EXEC SQL END DECLARE SECTION;", as in:\par
\par
   EXEC SQL BEGIN DECLARE SECTION;\par
      int   x;\par
      char  y[5];\par
   EXEC SQL END DECLARE SECTION;\par
\par
In this example, x and y are host variables. They are defined according to the\par
rules of the host language (in this case, C). But the definitions must be\par
comprehensible to the precompiler too, because the precompiler must know the\par
data type, size and name of each host variable. The trick, for making a\par
variable that both the host and SQL can understand, is to keep the definition\par
simple. Only a few data types are legal, and tricks usually aren't -- even\par
simple tricks like enumerations or constants or macros will confuse the precompiler.\par
\par
SQL <data type> and Host variable correspondence:\par
Host variable data types must be compatible with the <data type> of the SQL-\par
data values they'll be receiving or sending. The appropriate data type analogs\par
for each host language, as defined by the SQL Standard, are as follows (L\par
stands for length, P for precision, S for scale, T for time fractional seconds\par
precision, Q for <interval qualifier> and N for the implementation-defined\par
size of a structured type reference; assume an 8-bit character set is in use):\par
\par
## For Ada --\par
SQL <data type>      Ada data type\par
SQLSTATE             SQL_STANDARD.SQLSTATE_TYPE\par
CHAR(L)              SQL_STANDARD.CHAR, with P'LENGTH of L\par
VARCHAR(L)           None\par
CLOB(L)              None\par
BIT(L)               SQL_STANDARD.BIT, with P'LENGTH of L\par
BIT VARYING(L)       None\par
BLOB(L)              None\par
BOOLEAN              SQL_STANDARD.BOOLEAN\par
SMALLINT             SQL_STANDARD.SMALLINT\par
INTEGER              SQL_STANDARD.INT\par
DECIMAL(P,S)         None\par
NUMERIC(P,S)         None\par
REAL                 SQL_STANDARD.REAL\par
DOUBLE PRECISION     SQL_STANDARD.DOUBLE_PRECISION\par
FLOAT(P)             None\par
DATE                 None\par
TIME(T)              None\par
TIMESTAMP(T)         None\par
INTERVAL(Q)          None\par
UDT                  None\par
REF                  SQL_STANDARD.CHAR, with P'LENGTH of N\par
\par
## For C --\par
SQL <data type>      C Data Type\par
SQLSTATE             char, with length 6\par
CHAR(L)              char, with length (L+1)\par
VARCHAR(L)           char, with length (L+1)\par
CLOB(L)              struct \{\par
                       long x_reserved\par
                       unsigned long x_length\par
                       char x_data[L];\par
                            \}\par
BIT(L)               char, with length L/8\par
BIT VARYING(L)       None\par
BLOB(L)              struct \{\par
                       long x_reserved\par
                       unsigned long x_length\par
                       char x_data[L];\par
                            \}\par
BOOLEAN              pointer to long\par
SMALLINT             pointer to short\par
INTEGER              pointer to long\par
DECIMAL(P,S)         None\par
NUMERIC(P,S)         None\par
REAL                 pointer to float\par
DOUBLE PRECISION     pointer to double\par
FLOAT(P)             None\par
DATE                 None\par
TIME(T)              None\par
TIMESTAMP(T)         None\par
INTERVAL(Q)          None\par
UDT                  None\par
REF                  char, with length N\par
\par
## For COBOL --\par
SQL <data type>      COBOL Data Type\par
SQLSTATE             PICTURE X(5)\par
CHAR(L)              alphanumeric, with length L\par
VARCHAR(L)           None\par
CLOB(L)              01 XXXX.\par
                      49 XXXX-RESERVED PIC S9(9) USAGE IS BINARY.\par
                      49 XXXX-LENGTH PIC S9(9) USAGE IS BINARY.\par
                      49 XXXX-DATA PIC X(L).\par
BIT(L)               alphanumeric, with length L/8+1\par
BIT VARYING(L)       None\par
BLOB(L)              01 XXXX.\par
                      49 XXXX-RESERVED PIC S9(9) USAGE IS BINARY.\par
                      49 XXXX-LENGTH PIC S9(9) USAGE IS BINARY.\par
                      49 XXXX-DATA PIC X(L).\par
BOOLEAN              PICTURE X\par
SMALLINT             PICTURE S9(SPI) USAGE BINARY, where SPI is\par
                     implementation-defined\par
INTEGER              PICTURE S9(PI) USAGE BINARY, where PI is                  \par
                     implementation-defined\par
DECIMAL(P,S)         None\par
NUMERIC(P,S)         USAGE DISPLAY SIGN LEADING SEPARATE, \par
                     with PICTURE as specified[2]\par
REAL                 None\par
DOUBLE PRECISION     None\par
FLOAT(P)             None\par
DATE                 None\par
TIME(T)              None\par
TIMESTAMP(T)         None\par
INTERVAL(Q)          None\par
UDT                  None\par
REF                  alphanumeric with length N\par
Notes: 1. If S=P, then a PICTURE with an 'S' followed by a 'V' followed by P\par
'9's. If P>S>0, then a PICTURE with an 'S' followed by P-S '9's followed by a\par
'V' followed by S '9's. If S=0, then a PICTURE with an 'S' followed by P '9's\par
optionally followed by a 'V'.\par
\par
## For Fortran --\par
SQL <data type>      Fortran Data Type\par
SQLSTATE             CHARACTER, with length 5\par
CHAR(L)              CHARACTER, with length L\par
VARCHAR(L)           None\par
CLOB(L)              CHARACTER XXXX(L+8)\par
                       INTEGER*4 XXXX_RESERVED\par
                       INTEGER*4 XXXX_LENGTH\par
                       CHARACTER XXXX_DATA\par
                       EQUIVALENCE(XXXX(5), XXXX_LENGTH)\par
                       EQUIVALENCE(XXXX(9), XXXX_DATA)\par
BIT(L)               CHARACTER, with length L/8+1\par
BIT VARYING(L)       None\par
BLOB(L)              CHARACTER XXXX(L+8)\par
                       INTEGER*4 XXXX_RESERVED\par
                       INTEGER*4 XXXX_LENGTH\par
                       CHARACTER XXXX_DATA\par
                       EQUIVALENCE(XXXX(5), XXXX_LENGTH)\par
                       EQUIVALENCE(XXXX(9), XXXX_DATA)\par
BOOLEAN              LOGICAL\par
SMALLINT             None\par
INTEGER              INTEGER\par
DECIMAL(P,S)         None\par
NUMERIC(P,S)         None\par
REAL                 REAL\par
DOUBLE PRECISION     DOUBLE PRECISION\par
FLOAT(P)             None\par
DATE                 None\par
TIME(T)              None\par
TIMESTAMP(T)         None\par
INTERVAL(Q)          None\par
UDT                  None\par
REF                  CHARACTER with length N\par
\par
## For MUMPS --\par
SQL <data type>      MUMPS Data Type\par
SQLSTATE             character, with maximum length at least 5\par
CHAR(L)              None\par
VARCHAR(L)           character with maximum length L\par
CLOB(L)              None\par
BIT(L)               None\par
BIT VARYING(L)       None\par
BLOB(L)              None\par
BOOLEAN              None\par
SMALLINT             None\par
INTEGER              character\par
DECIMAL(P,S)         character\par
NUMERIC(P,S)         character\par
REAL                 character\par
DOUBLE PRECISION     None\par
FLOAT(P)             None\par
DATE                 None\par
TIME(T)              None\par
TIMESTAMP(T)         None\par
INTERVAL(Q)          None\par
UDT                  None\par
REF                  character\par
\par
## For Pascal --\par
SQL <data type>      Pascal Data Type\par
SQLSTATE             PACKED ARRAY [1..5] OF CHAR\par
CHARACTER(1)         CHAR\par
CHAR(L), L>1         PACKED ARRAY [1..L] OF CHAR\par
VARCHAR(L)           None\par
CLOB(L)              None\par
BIT(L)               PACKED ARRAY [L/8] OF CHAR\par
BIT VARYING(L)       None\par
BLOB(L)              None\par
BOOLEAN              BOOLEAN\par
SMALLINT             None\par
INTEGER              INTEGER\par
DECIMAL(P,S)         None\par
NUMERIC(P,S)         None\par
REAL                 REAL\par
DOUBLE PRECISION     None\par
FLOAT(P)             None\par
DATE                 None\par
TIME(T)              None\par
TIMESTAMP(T)         None\par
INTERVAL(Q)          None\par
UDT                  None\par
REF                  PACKED ARRAY[1..N] OF CHAR\par
\par
## For PL/I --\par
SQL <data type>      PL/I Data Type\par
SQLSTATE             CHARACTER(5)\par
CHAR(L)              CHARACTER(L)\par
VARCHAR(L)           CHARACTER VARYING(L)\par
CLOB(L)              DCL level. lvchar\par
                       49 len1 FIXED BINARY (31)\par
                       49 len2 FIXED BINARY (31)\par
                       49 data CHAR (n)\par
BIT(L)               BIT(L)\par
BIT VARYING(L)       BIT VARYING(L)\par
BLOB(L)              DCL level. lvchar\par
                       49 len1 FIXED BINARY (31)\par
                       49 len2 FIXED BINARY (31)\par
                       49 data CHAR (n)\par
BOOLEAN              BIT(1)\par
SMALLINT             FIXED BINARY(SPI), where SPI is                           \par
                     implementation-defined\par
INTEGER              FIXED BINARY(PI), where PI is                             \par
                     implementation-defined\par
DECIMAL(P,S)         FIXED DECIMAL(P,S)\par
NUMERIC(P,S)         None\par
REAL                 None\par
DOUBLE PRECISION     None\par
FLOAT(P)             FLOAT BINARY (P)\par
DATE                 None\par
TIME(T)              None\par
TIMESTAMP(T)         None\par
INTERVAL(Q)          None\par
UDT                  None\par
REF                  CHARACTER VARYING(N)\par
\par
Input and output variables:\par
A host variable can be either an input host variable or an output host\par
variable. (We always speak from the perspective of the DBMS, so "input" means\par
"input to the DBMS" and "output" means "output from the DBMS".)\par
\par
Here is a set of embedded SQL and C statements; x and y appear as input host variables:\par
\par
   EXEC SQL CREATE TABLE Table_1 (\par
               column_1 INT, column_2 CHAR(4));\par
\par
   x = 1; strcpy(y,"1234");\par
\par
   EXEC SQL INSERT INTO Table_1\par
            VALUES (:x,:y);\par
\par
   EXEC SQL DELETE FROM Table_1\par
            WHERE column_2 = :y;\par
\par
   EXEC SQL UPDATE Table_1 SET\par
               column_2 = :x;           /* ERROR! */\par
\par
In each case, it's easy to see the host variables -- they're the names with\par
colons in front. In the last SQL statement in the example, the use of :x is an\par
error, because x is an "int" and COLUMN_2 has a CHAR <data type>. Usually the\par
precompiler will catch that type of error -- if it doesn't, there will be an\par
error message at runtime. The subject of data type compatibility is a tortuous\par
one, but if you paid attention while reading our chapters on the various SQL\par
predefined <data type>s, it should hold no terrors for you. Nevertheless, it\par
is difficult to write language-independent embedded SQL code -- inevitably,\par
one has the host language's data type in mind when putting together the SQL code.\par
\par
Indicator Variables:\par
No host language can handle NULLs. So how can a host program receive an SQL\par
output host variable with a NULL value? And how can a host program pass an\par
input host variable with a NULL value? In both cases, the answer is that you\par
have to pass two parameters by address: one to the data itself and one to a\par
numeric variable containing a flag for "is NULL" or "is not NULL". This numeric variable is called an indicator variable.\par
\par
Indicator variables are "signed numeric with scale zero". In practice, they are almost always 32-bit integers. They too should appear within a declare section. For example:\par
\par
   EXEC SQL BEGIN DECLARE SECTION;\par
      var host : Integer;           \{Variable, intended for use as data\}\par
      var host_indicator : Longint; \{Variable, intended for use as indicator\}\par
   EXEC SQL END DECLARE SECTION;\par
\par
In an embedded SQL statement, indicators follow host variables. The required syntax is:\par
\par
   :<host variable name> [ [ INDICATOR ] :<indicator name> ]\par
\par
Here are two equivalent examples:\par
\par
   EXEC SQL INSERT INTO Table_1\par
            VALUES (:host INDICATOR :host_indicator);\par
\par
   EXEC SQL INSERT INTO Table_1\par
            VALUES (:host :host_indicator);\par
\par
For input host variables: any indicator value less than zero means the value\par
passed was NULL and any indicator value greater than or equal to zero means\par
the value passed was a non-null value. For output host variables, the DBMS\par
uses the specific indicator value -1 to mean the value passed was NULL and the\par
specific value zero to mean the value passed was a non-null value. If the\par
indicator variable value means NULL, then the host variable's contents are irrelevant.\par
\par
Use of indicators is optional. There is no need for them if there is no chance\par
that NULL values will occur. However, since "nullability" is a transient\par
characteristic, many programmers use indicators as a matter of course after every host variable.\par
\par
Here is an embedded SQL statement in which x appears as an output host variable:\par
\par
   EXEC SQL SELECT column_1 INTO :x FROM Table_1;\par
\par
but it's not a particularly good example, because it only works if you know in\par
advance that there's a maximum of one row in TABLE_1. (Think: if there were\par
two rows, there would be two values for COLUMN_1, but there's only one host\par
variable for the output: x.) Because of this assumption that there will never\par
be more than one row retrieved, this form of SELECT is referred to as a\par
"singleton SELECT". A more flexible approach exists for getting output SELECT\par
results, as output host variables, from SQL to the host language: the SQL Cursor.\par
\par
Cursors\par
\par
The most famous of the impedance-mismatch problems is that SQL operates on\par
sets, while host languages operate on set members. Therefore an SQL query --\par
by which we almost always mean a SELECT statement -- is returning more data\par
than a host variable can store. It's not enough to reply "use an array then".\par
Although sometimes arrays are indeed helpful, we have to keep in mind that (a)\par
the set might be gigantic and (b) there might be a two-way requirement (that\par
is, rows which go out might also come back in). Either of these considerations\par
make array definitions inappropriate for a general solution. The true and\par
standard solution is the Cursor. With a Cursor, you can get only one row at a\par
time -- namely the row that the Cursor is "positioned on".\par
\par
To understand the role of a Cursor, remember that your DBMS builds a result\par
Table that contains all of the rows retrieved by an SQL query executed in an\par
application program. Your DBMS uses a Cursor to make the rows of the result\par
Table available to the program: the Cursor identifies, or points to, the\par
current row of the result Table. When a Cursor is pointing to a row, it is\par
said to be positioned on that row -- and you can UPDATE or DELETE that row\par
using the "positioned" forms of the UPDATE and DELETE statements.\par
\par
To get it all working, you need to do four things: DECLARE a Cursor, OPEN the\par
Cursor, FETCH (repeatedly) from the Cursor (manipulating the rows one by one)\par
and CLOSE the Cursor. This Pascal program does all four things, in the form of\par
a classic FETCH loop which is familiar to all SQL programmers.\par
\par
   \{ Pascal program, using fetch loop \}\par
   var\par
   EXEC SQL BEGIN DECLARE SECTION;\par
      sample_integer : Integer;\par
      sample_boolean : Boolean;\par
   EXEC SQL END DECLARE SECTION;\par
   j : Integer;\par
\par
   begin\par
     EXEC SQL CONNECT TO DEFAULT;\par
     EXEC SQL DECLARE sample_cursor CURSOR FOR SELECT * FROM sample_table;\par
     EXEC SQL OPEN sample_cursor;\par
     for j := 1 to 100 do begin\par
       EXEC SQL FETCH sample_cursor INTO :sample_integer, :sample_boolean;\par
       end;\par
     EXEC SQL CLOSE sample_cursor;\par
     EXEC SQL DISCONNECT DEFAULT;\par
   end.\par
\par
The DECLARE CURSOR statement defines the query (usually a SELECT statement)\par
that will get the SQL-data you want. It is not an executable statement, it is\par
only (as the name implies) declarative. The action begins with the OPEN\par
statement. When OPEN happens, the SELECT actually takes place, so now the DBMS\par
has a set of rows waiting to be fetched -- these rows are called the current\par
active set, or the result Table. The FETCH statement is the host program's way\par
of asking the DBMS "may I have the next record please". In this example we\par
have assumed that the DBMS will always answer YES and put values into the host\par
variables SAMPLE_INTEGER and SAMPLE_BOOLEAN -- realistically, of course, we\par
should also check whether the FETCH in fact succeeds. This is a check which\par
we'll perform in a later example. Anyway, once the loop is done, the CLOSE\par
statement will throw out the set of rows that the OPEN statement produced, thus closing the Cursor.\par
\par
Some of the things you can do with Cursors, besides merely FETCH from them, include:\par
      ## DELETE and UPDATE rows at the current Cursor position.\par
      ## FETCH something other than the "next" row (this option is called the SCROLL Cursor option).\par
\par
DECLARE CURSOR statement\par
\par
The DECLARE CURSOR statement defines a Cursor. The required syntax for the DECLARE CURSOR statement is:\par
\par
DECLARE <Cursor name> [ <cursor sensitivity> ]\par
   [ SCROLL ] CURSOR [ WITH HOLD ] [ WITH RETURN ]\par
   FOR <cursor specification>\par
\par
   <cursor sensitivity> ::=\par
   SENSITIVE |\par
   INSENSITIVE |\par
   ASENSITIVE\par
\par
   <cursor specification> ::=\par
   <query expression> [ <order by clause> ]\par
   [ FOR \{READ ONLY | UPDATE [ OF <Column name> list ]\} ]\par
\par
Each Cursor you define must have a unique name in the Module it's defined in.\par
Its <cursor specification> results in a Table when evaluated. An INSENSITIVE\par
Cursor is a Cursor that effectively causes a separate copy of its result Table\par
to be created; the Cursor accesses that copy, rather than the original result,\par
so any changes made to the original result by other methods won't be visible\par
to this Cursor. A SENSITIVE Cursor is a Cursor that works directly on its\par
result Table: it makes no copy, so other changes made to the result Table will\par
be visible to this Cursor. An ASENSITIVE Cursor may or may not make a copy of\par
its result Table; whether other changes to its result Table will be visible is\par
implementation-defined. The default is an ASENSITIVE Cursor.\par
\par
Normally, you can access the Cursor's result Table, one row at a time, only in\par
the order that your DBMS gets the rows. A SCROLL Cursor is a Cursor that can\par
hop around in its result set. In the first case, then, only FETCH NEXT is\par
allowed, while for a SCROLL Cursor, all forms of FETCH are allowed.\par
\par
The optional updatability clause defaults to FOR READ ONLY if the Cursor's\par
definition includes either INSENSITIVE, SCROLL or an ORDER BY clause, or if\par
the Cursor's result Table is not an updatable Table. If none of these are\par
true, you can either specify FOR UPDATE OF, followed by a list of the result\par
Columns you want to update, or the Cursor definition will default to that state.\par
\par
FOR READ ONLY means the Cursor is not updatable -- that is, UPDATE and DELETE\par
operations won't be allowed on this Cursor. FOR UPDATE OF, permitted only on\par
an updatable Cursor, means that the Columns specified may be the target of an\par
UPDATE operation. If you include a Column list, only those Columns can be\par
updated by the Cursor. If you omit the Column list, the effect is the same as\par
if you included a list that names every Column of the result Table.\par
\par
If DECLARE CURSOR includes the optional WITH HOLD clause, the Cursor is a\par
holdable Cursor. This means that if the Cursor is open when a transaction is\par
terminated with a COMMIT statement, it won't be closed -- it will stay open\par
into the next transaction. A holdable Cursor is always closed by ROLLBACK.\par
\par
If your Cursor definition includes the optional WITH RETURN clause, the Cursor\par
is called a result set Cursor. A result set Cursor that is declared in an\par
SQL-invoked procedure returns a result set if it is open when the procedure ends.\par
\par
Here's an example of DECLARE CURSOR, based on the sample Tables we defined in our chapter on simple search conditions:\par
\par
   DECLARE emps_cursor SCROLL CURSOR FOR\par
          SELECT   dept,empnum,surname,gname,address\par
          FROM     Employee WHERE dept <= 'C'\par
          ORDER BY dept,empnum\par
       FOR UPDATE OF surname,address;\par
\par
This Cursor definition will allow you to get all the rows of the EMPLOYEE\par
Table where the DEPT value is A, B or C. It will also allow you to UPDATE the\par
values of the DEPT, SURNAME and ADDRESS Columns of the retrieved rows.\par
\par
If you want to restrict your code to Core SQL, don't declare a Cursor with\par
either SENSITIVE, INSENSITIVE or ASENSITIVE, don't declare a Cursor with\par
SCROLL, don't declare a Cursor with WITH RETURN and don't declare a Cursor\par
with ORDER BY if you've declared it with FOR UPDATE with, or without, a Column list.\par
\par
OPEN statement\par
\par
The OPEN statement opens a Cursor. The required syntax for the OPEN statement is:\par
\par
OPEN <Cursor name>\par
\par
The OPEN statement processes the Cursor's query (it's an error if the Cursor is already open). In order to OPEN a Cursor, then, your current <AuthorizationID> has to have all the Privileges required to process that query.\par
\par
While it is open, a Cursor identifies a result Table, as well as a certain\par
position within the rows of that Table: it can be one some row of the Table,\par
before some row of the Table or after the last row of the Table. Immediately\par
after you execute OPEN, the Cursor is positioned before the first row of its result Table.\par
\par
Here's an example of OPEN, based on the sample Cursor we defined in the last section:\par
\par
   OPEN emps_cursor;\par
\par
This SQL statement will evaluate the Cursor query:\par
\par
   SELECT   dept,empnum,surname,gname,address\par
   FROM     Employee\par
   WHERE    dept<='C'\par
   ORDER BY dept,empnum\par
\par
and position the Cursor before the first row of the result Table.\par
\par
FETCH statement\par
\par
The FETCH statement positions a Cursor on a specific row of its result Table,\par
and retrieves that row's values into host variables. The required syntax for the FETCH statement is:\par
\par
FETCH [ [ <fetch orientation> ] FROM ] <Cursor name>\par
INTO <fetch target list>\par
\par
   <fetch orientation> ::=\par
   NEXT |\par
   PRIOR |\par
   FIRST |\par
   LAST |\par
   \{ABSOLUTE | RELATIVE\} <simple value specification>\par
\par
   <fetch target list> ::=\par
   <target specification> [ \{,<target specification>\}... ]\par
\par
The FETCH orientation specification is one of the <keyword>s listed before the\par
<Cursor name>: it defines which row of the Cursor's result Table FETCH will\par
get next. FETCH NEXT (row), FETCH PRIOR (row), FETCH FIRST (row) and FETCH\par
LAST (row) are self-explanatory. FETCH NEXT is the default, and is the only\par
legal option if the Cursor is not a SCROLL Cursor. For FETCH ABSOLUTE and\par
FETCH RELATIVE, let "n" be the <simple value specification> (it must be a\par
<literal>, SQL parameter or host variable that represents an integer): FETCH\par
ABSOLUTE "n" moves the Cursor to the nth row of its result Table (counting\par
backward from the end if "n" is negative) and FETCH RELATIVE "n" moves the\par
Cursor to the nth row from the current position (again, counting backward if\par
"n" is negative). Assuming that the fetch orientation does identify a row of\par
the result Table (e.g.: that there is a NEXT row), then the Cursor is\par
positioned on that row and the SQL-data values are retrieved from that row. If\par
the fetch orientation has gone beyond the result Table -- that is, if there is\par
no NEXT row because FETCH already retrieved the final row -- then the Cursor\par
is positioned either after the last row or before the first row of the result\par
Table (depending on which way the fetch orientation was moving) and no SQL-data is retrieved.\par
\par
<Cursor name> is the name of the OPEN Cursor whose result Table you want to\par
FETCH. The values retrieved from each row are placed into a list of host\par
variables by FETCH. You provide your DBMS with the comma-delimited list of\par
output host variables (and their optional indicators) in FETCH's INTO clause.\par
The first value in the row that the Cursor is positioned on is assigned to the\par
first host variable in the list, the second value is assigned to the second\par
host variable, and so on (the number of Columns in the result Table and the\par
number of host variables must, of course, match -- as must their <data type>s).\par
\par
Here's some examples of FETCH, based on the sample Cursor we opened in the last section:\par
\par
   FETCH NEXT FROM emps_cursor\par
     INTO :dept,\par
          :empnum,\par
          :surname :surname_indicator,\par
          :gname :gname_indicator,\par
          :address :address_indicator;\par
\par
This SQL statement will position the Cursor on the next row of the result\par
Table (which happens to be the first row in this example), and assign the SQL-data values from each Column in that row to the corresponding host variables.\par
Since we declared the Cursor as a SCROLL Cursor, we could use this FETCH statement instead:\par
\par
   FETCH ABSOLUTE 4 FROM emps_cursor\par
     INTO :dept,\par
          :empnum,\par
          :surname :surname_indicator,\par
          :gname :gname_indicator,\par
          :address :address_indicator;\par
\par
This SQL statement will position the Cursor on the fourth row of the result\par
Table, and assign the SQL-data values from each Column in that row to the corresponding host variables.\par
\par
If you want to restrict your code to Core SQL, don't use FETCH with a <fetch orientation>: always let it default to FETCH NEXT.\par
\par
Singleton SELECT statement\par
\par
If you know that a result Table will contain only one row of SQL-data, you\par
don't need to declare a Cursor to get that result into your application\par
program. Instead, you can use the form of the SELECT statement called the\par
singleton SELECT: it puts the values found in a single row into a set of host\par
variables. The required syntax for a singleton SELECT is:\par
\par
SELECT [ ALL | DISTINCT ] <select list>\par
INTO <target specification> [ \{,<target specification>\}... ]\par
<table expression>\par
\par
The singleton SELECT statement can only be embedded in an application program.\par
It can only retrieve one row of SQL-data. It is an error if more than one row\par
might satisfy the query -- you must use a Cursor to manipulate the data instead.\par
\par
The singleton SELECT looks exactly like a regular SELECT statement except for\par
the INTO clause that comes between the select list and the <table expression>\par
(i.e.: FROM ... WHERE ... etc.). The INTO clause works like the INTO clause in\par
the FETCH statement: you provide your DBMS with a comma-delimited list of\par
output host variables (and their optional indicators) therein and your DBMS\par
places the first value in the result row into the first host variable in the\par
list, the second value in the result row into the second host variable, and so\par
on (the number of Columns in the result row and the number of host variables\par
must, of course, match -- as must their <data type>s).\par
\par
Here's an example of a singleton SELECT, based on the sample Tables we defined in our chapter on simple search conditions:\par
\par
   SELECT dept,empnum,surname,gname,address\par
   INTO   :dept,\par
          :empnum,\par
          :surname :surname_indicator,\par
          :gname :gname_indicator,\par
          :address :address_indicator;\par
   FROM   Employee\par
   WHERE  empnum=10;\par
\par
This SQL statement will evaluate the query:\par
\par
   SELECT dept,empnum,surname,gname,address\par
   FROM   Employee\par
   WHERE  empnum=10\par
\par
and assign the SQL-data values from each Column in that row to the corresponding host variables.\par
\par
INSERT statement\par
\par
A special form of the INSERT statement exists for use with a Cursor. The required syntax is:\par
\par
INSERT INTO <Cursor name> [ (<Column name> [ , ... ]) ]\par
\{<query expression> | DEFAULT VALUES\}\par
\par
This form of the INSERT statement works exactly the same as the INSERT we\par
described in our chapter on the SQL-data change statements, except that you\par
put a <Cursor name> instead of a <Table reference> in the INTO clause. That\par
is, the target of the INSERT operation is the Cursor's result Table. Here's an example:\par
\par
   INSERT INTO emps_cursor\par
   VALUES (:dept,\par
           :empnum,\par
           :surname :surname_indicator,\par
           :gname :gname_indicator,\par
           :address :address_indicator);\par
\par
If you want to restrict your code to Core SQL, don't use this form of the INSERT statement.\par
\par
Positioned UPDATE statement\par
\par
The positioned UPDATE statement lets you UPDATE the Cursor's current row. The required syntax for the positioned UPDATE statement is:\par
\par
UPDATE [ <Table reference> ] SET\par
\{<Column name>=scalar_expression [ \{, ... ] | ROW=row_expression\}\par
WHERE CURRENT OF <Cursor name>\par
\par
This form of the UPDATE statement works exactly the same as the UPDATE we\par
described in our chapter on the SQL-data change statements, except that you\par
put "WHERE CURRENT OF <Cursor name>" after the SET assignments instead of the\par
(optional) "WHERE condition" clause and that you can omit the <Table\par
reference> after UPDATE, since the <Cursor name> in the WHERE clause identifies the UPDATE target Table anyway.\par
\par
The Cursor must be open, must be an updatable Cursor and must be positioned on\par
a row of its result Table. That row (the current row) is the row that will be\par
updated. Each Column that is a target of the SET clause must have been\par
mentioned in the FOR UPDATE OF clause of the Cursor's definition. Any updated\par
Column may not be named in the Cursor's ORDER BY clause.\par
\par
Here's an example of a positioned UPDATE, based on the sample Cursor we fetched with earlier:\par
\par
   UPDATE Employee SET\par
     surname = :new_surname :new_surname_indicator,\par
     address = :new_address :new_address_indicator\par
   WHERE CURRENT OF emps_cursor;\par
\par
This SQL statement changes the values of the SURNAME and ADDRESS Columns in\par
the current row of the Cursor's result Table. After the UPDATE, the Cursor\par
remains on its current row. It won't move until another FETCH statement is executed.\par
\par
If you want to restrict your code to Core SQL, don't omit the <Table\par
reference> from a positioned UPDATE statement, don't add an ORDER BY clause to\par
your Cursor definition, and don't have an UPDATE target that is a <literal>, host variable or SQL parameter.\par
\par
Positioned DELETE statement\par
\par
The positioned delete statement lets you DELETE the Cursor's current row. The required syntax for the positioned DELETE statement is:\par
\par
DELETE [ FROM <Table reference> ] WHERE CURRENT OF <Cursor name>\par
\par
This form of the DELETE statement works exactly the same as the DELETE we\par
described in our chapter on the SQL-data change statements, except that you\par
use "WHERE CURRENT OF <Cursor name>" instead of the (optional) "WHERE\par
condition" clause and that you can omit the FROM <Table reference> clause\par
after DELETE, since the <Cursor name> in the WHERE clause identifies the DELETE target Table anyway.\par
\par
The Cursor must be open, must be an updatable Cursor and must be positioned on\par
a row of its result Table. That row (the current row) is the row that will be\par
deleted. Here's an example of a positioned DELETE, based on the sample Cursor we fetched with earlier:\par
\par
   DELETE FROM Employee WHERE CURRENT OF emps_cursor;\par
\par
This SQL statement deletes the current row of the Cursor's result Table. After\par
the DELETE, the Cursor is positioned before the row that follows the deleted\par
row (or after the last row, if the deleted row was the last row). It won't be\par
positioned on another row until another FETCH statement is executed.\par
\par
CLOSE statement\par
\par
The CLOSE statement closes a Cursor. The required syntax for the CLOSE statement is:\par
\par
CLOSE <Cursor name>\par
\par
The CLOSE statement destroys the Cursor's result Table (it's an error if the\par
Cursor isn't open). Closing a Cursor causes your DBMS to immediately check all\par
Constraints that were affected by Cursor operations for violation and to\par
execute any triggered actions that were deferred during the Cursor operations. Here's an example:\par
\par
   CLOSE emps_cursor;\par
\par
A Cursor is also closed by ROLLBACK and (unless it's a holdable Cursor) by COMMIT.\par
\par
Embedded SQL Examples\par
\par
Here is an example program which selects and fetches ten rows in Table T, and\par
displays the contents. This program watches for NULL values, which it\par
indicates by displaying a question mark rather than a number. (The use of "?"\par
to mean "NULL" is conventional in displays and printouts, but sometimes blanks are used instead.)\par
\par
   #include <stdio.h>                         /* Example <xx> */\par
   EXEC SQL BEGIN DECLARE SECTION;\par
      int x;\par
      int x_indicator;\par
   EXEC SQL END DECLARE SECTION;\par
   int i;\par
   void main ()\par
  \{\par
     EXEC SQL CONNECT TO database_or_server USER Josephine;\par
     EXEC SQL DECLARE example_cursor CURSOR FOR SELECT col_1 FROM T;\par
     EXEC SQL OPEN example_cursor;\par
     for (i=0; i<10; ++i) \{\par
       EXEC SQL FETCH example_cursor INTO :x INDICATOR :x_indicator;\par
       if (x_indicator < 0) printf("?\\n");\par
       else printf("%d\\n",x); \}\par
     EXEC SQL CLOSE example_cursor;\par
     EXEC SQL DISCONNECT database_or_server; \}\par
\par
Diagnostics\par
\par
"I beseech you in the bowels of Christ, consider that you may be wrong."\par
   -- Cromwell\par
\par
After any embedded SQL statement, you can add code to ask the DBMS: "has\par
anything gone wrong?", and if so "what has gone wrong?". The DBMS's answers --\par
diagnostics -- are categorized and coded in a standard way, so you have some\par
advance knowledge about what the possible scenarios are. The basic piece of diagnostic information is SQLSTATE.\par
\par
Originally, the basic item of diagnostic information was an integer variable\par
called sqlcode (or, in Fortran: SQLCOD). After every SQL statement, the DBMS\par
would put a value in sqlcode. If the value was less than zero, that meant\par
"error". If the value was zero, that meant "success". If the value was greater\par
than zero, that meant "success with additional information", that is, a\par
warning. The most common warning was +100, which meant "no data". This was an\par
easy system to follow, and it was common practice to add lines like these after every SQL statement:\par
\par
  if (sqlcode < 0) \{\par
    printf("Error!\\n"); /*or some more sophisticated error-handling action*/\par
    exit(1); \}\par
\par
It is still common today to see sqlcode checking, especially since all DBMS\par
vendors still allow for it. However, the SQL-92 Standard "deprecated" use of\par
sqlcode and the SQL3 Standard doesn't recognize it at all. SQLSTATE is the modern basic item of diagnostic information.\par
\par
A big advantage of SQLSTATE is that the possible values are standardized for\par
each error category, a level of agreement that was never achieved with the\par
sqlcode values. SQLSTATE is a 5-character variable which you should define in\par
the declare section. After every SQL statement, the DBMS will put a value (the\par
status code) into SQLSTATE. The status code consists of digits or upper case\par
letters between A and Z. The first two letters or digits are the "class" (the\par
general category), the next three letters or digits are the "subclass" (the\par
specific category, if any). You can see a complete list of status codes, and\par
descriptions thereof, in our chapter on SQL/CLI diagnostics. For now, content\par
yourself with the knowledge of the most important classes:\par
      ## Class '00' is 'SUCCESS'. When you see this, everything's going fine.\par
      ## Class '01' is 'SUCCESS WITH INFO', or 'WARNING'. For example, perhaps some precision was lost during an arithmetic calculation. There is usually no cause to change the course of your program's flow,\par
but displaying a message is often an appropriate action for your program to take.\par
      ## Class '02' is 'NO DATA'. Every FETCH loop should watch for this one, since FETCH will cause 'NO DATA' if there is nothing more to fetch.\par
      ## All other classes are 'ERROR'. The SQL statement has failed. Check paranoidly. If SQLSTATE contains anything other than '00' or '01' or '02', you might have to take some corrective action or even abort the job.\par
\par
Let us now rewrite our FETCH loop program. This time we'll check SQLSTATE.\par
\par
#include <stdio.h>                         /* Example <xx - b> */\par
EXEC SQL BEGIN DECLARE SECTION;\par
int x;\par
int x_indicator;\par
char sqlstate[6]; /* SQLSTATE is 5 characters. In C, allow for '\\0' too. */\par
EXEC SQL END DECLARE SECTION;\par
int i;\par
void main ()\par
\{\par
  EXEC SQL CONNECT TO database_or_server USER Josephine;\par
  if (... <> "00" && ... != "01")\par
    printf("Connection failed. sqlstate = %s.\\n",sqlstate);\par
  EXEC SQL DECLARE example_cursor CURSOR FOR SELECT col_1 FROM T;\par
  /* There is no need to check for errors after a DECLARE statement. */\par
  EXEC SQL OPEN example_cursor;\par
  if (... <> "00" && ... != "01")\par
    printf("OPEN failed. sqlstate = %s.\\n",sqlstate);\par
    goto disconnect_database; \}\par
  for (;;) \{  /* This loop is not infinite. There are break; statements. */\par
    EXEC SQL FETCH example_cursor INTO :x INDICATOR :x_indicator;\par
    if (... == '02') \{\par
      /* The 'NO DATA' class just means there's nothing more to fetch. */\par
      break; \}\par
    if (... == '01') printf("(Warning: sqlstate=%s.\\n",sqlstate);\par
    if (... <> '00' && ... <> '01' && ... <> '02') \{\par
      printf("FETCH failed. sqlstate = %s.\\n",sqlstate);\par
      break; \}\par
    if (x_indicator < 0) printf("?\\n");\par
    else printf("%d\\n",x); \}\par
  EXEC SQL CLOSE example_cursor;\par
  /* Doubtless a CLOSE will always succeed, but let's check anyway. */\par
  if (... <> "00") printf("After close, sqlstate=%s.\\n",sqlstate);\par
disconnect_database:\par
  EXEC SQL DISCONNECT database_or_server; \}\par
  /* We're ending the program, but let's check anyway. */\par
  if (... <> "00") printf("After disconnect, sqlstate=%s.\\n",sqlstate); \}\par
\par
If you find it tedious to check SQLSTATE after every single error, there is an SQL directive to automate the procedure: the WHENEVER statement.\par
\par
WHENEVER statement\par
\par
The required syntax for the WHENEVER statement (omitting some details) is:\par
\par
   WHENEVER <condition> \{GOTO | GO TO\} <target of goto>\par
\par
or\par
\par
   WHENEVER <condition> CONTINUE\par
\par
The WHENEVER <condition> is one of:\par
      ## SQLWARNING ... true if SQLSTATE contains the '01' status code class.\par
      ## NOT FOUND ... true for the SQLSTATE '02' class.\par
      ## SQLEXCEPTION ... true for any other SQLSTATE class. (The old SQL-92 name for this is SQLERROR.)\par
      ## SQLSTATE (list) ... an SQL3 innovation, rarely supported.\par
      ## CONSTRAINT (name) ... an SQL3 innovation, rarely supported.\par
\par
The WHENEVER target is a label or address which would be legal as the argument\par
of a GOTO statement in the host language. The WHENEVER directive is not an\par
executable statement; it's a signal to the precompiler. The precompiler\par
responds to it by generating appropriate "if ... goto ..." statements after every SQL statement.\par
\par
** TIP: When you write a program for the first time, put "EXEC SQL WHENEVER\par
SQLEXCEPTION GOTO error_abort;" at the start. After you've got the program\par
working, edit it and put in error testing that's more specific.\par
\par
Serious programs contain considerably more than basic SQLSTATE checks. To\par
begin with, they have different reactions depending on the specific class and\par
subclass in the status code. They also make use of SQL's GET DIAGNOSTICS\par
statement. With GET DIAGNOSTICS, one can ask more about the context, get an\par
implementation-defined error message, and perhaps retrieve several different\par
diagnostics (it's possible, for instance, that the DBMS generated several\par
warnings before it ultimately gave up and generated an error).\par
\par
GET DIAGNOSTICS statement\par
\par
The GET DIAGNOSTICS statement gets exception or completion condition information from the diagnostics area. The required syntax for the GET DIAGNOSTICS statement is:\par
\par
GET DIAGNOSTICS \{<statement information> | <condition information>\}\par
\par
   <statement information> ::=\par
   <statement information item> [ \{,<statement information item>\}... ]\par
\par
       <statement information item> ::=\par
       <simple target specification> = <statement item name>\par
\par
         <statement information item name> ::=\par
         NUMBER |\par
         MORE |\par
         COMMAND_FUNCTION |\par
         COMMAND_FUNCTION_CODE |\par
         ROW_COUNT |\par
         TRANSACTIONS_COMMITTED |\par
         TRANSACTIONS_ROLLED_BACK |\par
         TRANSACTION_ACTIVE\par
\par
   <condition information> ::=\par
   EXCEPTION <condition number> <condition information item> [ \{,<condition information item>\}... ]\par
\par
      <condition information item> ::=\par
      <simple target specification> = <condition item name>\par
\par
         <condition information item name> ::=\par
         CONDITION_IDENTIFIER |\par
         CONDITION_NUMBER |\par
         RETURNED_SQLSTATE |\par
         CLASS_ORIGIN |\par
         SUBCLASS_ORIGIN |\par
         SERVER_NAME |\par
         CONNECTION_NAME |\par
         CONSTRAINT_CATALOG |\par
         CONSTRAINT_SCHEMA |\par
         CONSTRAINT_NAME |\par
         TRIGGER_CATALOG |\par
         TRIGGER_SCHEMA |\par
         TRIGGER_NAME |\par
         CATALOG_NAME |\par
         SCHEMA_NAME |\par
         TABLE_NAME |\par
         COLUMN_NAME |\par
         CURSOR_NAME |\par
         ROUTINE_CATALOG |\par
         ROUTINE_SCHEMA |\par
         ROUTINE_NAME |\par
         SPECIFIC_NAME |\par
         PARAMETER_NAME |\par
         MESSAGE_TEXT |\par
         MESSAGE_LENGTH |\par
         MESSAGE_OCTET_LENGTH\par
\par
      <condition number> ::= <simple value specification>\par
\par
There are two forms of the GET DIAGNOSTICS statement. The first gets\par
information about the overall execution of the immediately preceding SQL\par
statement, while the second form gets more specific information about one or\par
more specific errors. Here are some examples of GET DIAGNOSTICS:\par
\par
   GET DIAGNOSTICS :smallint_host_variable = ROW_COUNT;\par
\par
   GET DIAGNOSTICS :char_host_variable = DYNAMIC_FUNCTION;\par
\par
   GET DIAGNOSTICS EXCEPTION 1 :char_host_variable = SUBCLASS_ORIGIN;\par
\par
Not wanting to bore you twice, we'll defer the detailed discussion of the\par
diagnostics area's fields till a later time -- when we talk about the\par
SQL/CLI's SQLGetDiagRec and SQLGetDiagField functions.\par
\par
Dynamic SQL\par
\par
In the examples so far, we've assumed that we know some things in advance\par
about the database and the SQL statements we're going to execute. For example,\par
in our FETCH loop examples, we make the assumptions that the <Table name> is\par
T, that T a Column called COL_1, that COL_1 has a numeric <data type>, and so\par
on. A program which contains such assumptions is called a static SQL program,\par
because its SQL statements are changeless. Let us now suppose that we lack\par
advance knowledge about the program. The classic supposition is: what if the\par
user types in a SELECT command on the keyboard? We need to use a more flexible\par
(and somewhat less efficient) tool set: the components of dynamic SQL.\par
\par
Start with the basic supposition: that the user types in an SQL statement on\par
the keyboard. There is a simple embedded SQL statement which parses and\par
executes strings at runtime: EXECUTE IMMEDIATE. Here is an example:\par
\par
      ...\par
      gets(a_string);                           EXAMPLE A\par
      for (i=0; i<1000; ++i) \{\par
        EXEC SQL EXECUTE IMMEDIATE :a_string; \}\par
      ...\par
\par
In this example, a_string is a character string host variable. If it contains\par
the string "INSERT INTO T VALUES (5)", then the above statement is equivalent to:\par
\par
      for (i=0; i<1000; ++i) \{\par
        EXEC SQL INSERT INTO T VALUES (5); \}\par
\par
The good news about dynamic SQL is that you have an SQL interpreter available.\par
That's remarkable when you compare SQL with a host language. You can't write\par
equivalent code which will parse and execute a C statement from C, or a Pascal\par
statement from Pascal! The result is that your SQL code is more capable than\par
your host language code. The bad news is that interpreters are slow. Faced\par
with repetitive operations like the ones in our example above, we would rather\par
replace "parse and execute many times" with "parse once, execute many times".\par
Luckily, there are embedded SQL statements for that -- PREPARE and EXECUTE.\par
Here is a replacement example, which does the same thing but is maybe more efficient:\par
\par
      ...\par
      gets(a_string);                            EXAMPLE B\par
      EXEC SQL PREPARE :a_string;\par
      for (i=0; i<1000; ++i)\par
        EXEC SQL EXECUTE :a_string; \}\par
\par
(Note: Some smart DBMSs can detect simple situations like the one in this\par
example and optimize accordingly. For example, if you program with Oracle you\par
will gain nothing by replacing Example A with Example B.)\par
\par
The ultimate in embedded-SQL complexity is a dynamically executed query, such\par
as a SELECT statement. We can't define host variables and indicators in\par
advance, because we don't know what the <data type>s of the result Columns are\par
-- or even how many Columns the query will return. The first time you see\par
dynamic SQL query code, you may have trouble understanding it. But the second\par
time, you'll have less trouble -- because it will be the same. Most\par
programmers use a boilerplate, so the program structure turns out to be\par
similar in every program. In pseudocode that structure looks like this:\par
\par
  if (the statement is a query) do begin:\par
    Execute the statement.   || Variation: just prepare the statement.\par
    Ask the DBMS: "how many Columns were there?"\par
      Let the response be C.\par
    for (Column-number = 1 to C) do:\par
      Ask the DBMS: "for Column[Column-number], what is the data type etc.?"\par
      Using the DBMS's response, allocate appropriate RAM in host program.\par
      end.\par
    ...\par
    OPEN Cursor.\par
    Loop:\par
      FETCH. The fetch targets are the allocated areas in the host program.\par
      if (no-data) exit loop.\par
\par
At this point, code varies depending on what we want to do with the dynamically retrieved data. For instance we could display it:\par
\par
      display data.\par
      Next.\par
    CLOSE Cursor.\par
    end.\par
\par
Principally, you're asking the DBMS to DESCRIBE what it finds. The key statements for the purpose are:\par
   ## ALLOCATE DESCRIPTOR ... which tells the DBMS to allocate an area internally (i.e. within the DBMS) for storing the description.\par
   ## DESCRIBE <SQL statement name> <using descriptor> ... which fills the descriptor with information about the SQL statement.\par
   ## GET DESCRIPTOR ... which takes descriptor fields's values and puts them into host program variables.\par
   ## DEALLOCATE DESCRIPTOR ... which gets rid of what ALLOCATE DESCRIPTOR made.\par
\par
As with GET DIAGNOSTICS, we'll defer the detailed discussion of the descriptor area's fields till a later time -- when we talk about the SQL/CLI's desc functions.\par
\par
Summary\par
\par
An embedded SQL host language program is an application program that contains\par
both host language programming statements and SQL statements. Embedded SQL\par
programs may be written in any of the high-level languages -- ADA, C, COBOL,\par
FORTRAN, MUMPS, PASCAL and PL/I -- supported by the SQL Standard. Such\par
programs use SQL, instead of routines written in the host language, to carry\par
out database operations.\par
\par
Embedded SQL statements are either static SQL statements or dynamic SQL\par
statements. Static SQL is static in the sense that the embedded SQL statement\par
is fully known, and coded, when your program is written. Executing the program\par
does not change the SQL statement in any way. Dynamic SQL is so-called because\par
the embedded SQL statement is not fully known when your program is written.\par
Some part of it will be generated during the execution of the program.\par
\par
SQL statements embedded in an application program must reference host\par
variables to pass values between the program and SQL-data. Host variables are\par
host language variables referenced in an embedded SQL statement. They must be\par
declared within a "declare section" that is delimited by the BEGIN DECLARE\par
SECTION and END DECLARE SECTION statements. The declare section must precede\par
any use of the host variables. Since host variables must map to host language\par
variables, they are not nullable unless they are coupled with an indicator\par
variable.\par
\par
An indicator variable is a host language variable that acts as an indicator\par
for another host variable. The purpose of an indicator variable is to\par
highlight null values and overflow conditions for the host variable it's\par
coupled with. Embedded SQL application programs must prepare for passing null\par
values by pairing an indicator with any host variable that might be assigned a null value.\par
\par
SQL provides a status host variable -- SQLSTATE -- whose values indicate\par
whether or not an SQL statement was successfully executed. All embedded SQL\par
programs must contain at least one status host variable declaration.\par
\par
The major problem in combining SQL with any host language is the inability of\par
most other languages to handle multiple records at one time; one of the major\par
SQL features. The SQL Object "Cursor" is provided by the SQL Standard to give\par
the host languages a facility for dealing with a set of retrieved SQL-data records, one at a time.\par
\par
An excellent summary of the embedded SQL specification appears in the SQL Standard. Part five says:\par
      ## Embedded SQL is "syntax for embedding SQL-statements in a compilation unit that otherwise conforms to the standard for a particular programming language (host language)."\par
      ## Embedded SQL specifies "how an equivalent compilation unit may be\par
derived that conforms to the particular programming language standard. In that\par
equivalent compilation unit, each embedded SQL-statement has been replaced by\par
one or more statements in the host language, some of which invoke an SQL\par
externally-invoked procedure that, when executed, has an effect equivalent [to] executing the SQL-statement."\par
\par
Dialects\par
\par
Embedded SQL is well specified by part five of the SQL Standard: ISO/IEC\par
9075-2 Part 5: SQL/Bindings. The differences between SQL-92 and SQL3 in this\par
area are minor, but you may find that older programs handle dynamic-SQL\par
"descriptors" in a different way. Instead of declaring that descriptors are\par
internal to the DBMS, old programs may allocate an area within the host\par
program itself. This area, usually called SQLDA (SQL Dynamic Area) or\par
something similar, is a structure like this:\par
\par
   #define  MV    64\par
   struct sqlda \{\par
     char sqldaid[8];     /* "SQLDA   " */\par
     long int sqldabc;    /* length of sqlda  */\par
     int sqln;            /* max sqlvar occurrences = MV */\par
     int sqld;            /* current sqlvar occurrences */\par
     struct sqlvar \{      /* defined sqln times, actually occurs sqld times */\par
      int sqltype;        /* <data type> of Column  */\par
      int sqllen;         /* size of Column */\par
       char far *sqldata; /* pointer --> host variable */\par
       int far *sqlind;   /* pointer --> indicator */\par
       struct sqlname \{   /* string, up to 30 bytes long */\par
        int length;       /* 1-word size of name */\par
        char data[30]; \} sqlname; \} sqlvar[MV]; \};\par
   struct sqlda sqlda=\{"SQLDA",0,64,0\};\par
\par
The job of the DESCRIBE statement is to fill in the entire SQLDA. Then the host program can access the fields by simply referring to the structure's components.\par
\par
As we mentioned, it is possible to integrate the precompiler with the\par
compiler. Thus the process of precompiling and compiling appears to be a\par
single step. IBM's DB2 is particularly noteworthy for this convenient feature.\par
\par
Another convenience is the allowance of "SQL" keywords for data type\par
descriptions within the declare section. This usually goes hand in hand with\par
macros or typedefs within a header file supplied by the vendor. Thus, one could have:\par
\par
   EXEC SQL BEGIN DECLARE SECTION;\par
     SQLCHAR x(5);\par
     SQLINTEGER y;\par
   EXEC SQL END DECLARE SECTION;\par
\par
This enables programmers to use similar declarations for a variety of host\par
languages. Since the same header file can be used in the SQL/CLI, it's easy to\par
put together packages which use some embedded SQL modules and some SQL/CLI modules.\par
\page\par
Chapter 40 -- SQL/CLI Binding Style\par
\par
SQL DBMSs communicate with SQL applications through a common programming\par
language interface that is invoked through one of the SQL Standard-defined\par
binding styles, or interface options. There are three main approaches to\par
writing complete programs with SQL:\par
      ## With embedded SQL, you can put SQL statements directly into host programs. We described this binding style in the last chapter.\par
      ## With the Module binding style, you can dispense with host programs\par
and write entire Modules in SQL. You'll still have to call these Modules from\par
one of the standard host languages though. We'll describe this binding style last.\par
      ## With SQL/CLI, you can call a SQL DBMS's library from a host program.\par
The SQL statements you want to execute are parameters of the call. Because\par
SQL's modus operandi won't quite match the host language's, helper functions\par
are required for the interface definition. This binding style is the subject\par
of the next several chapters.\par
\par
The SQL/CLI, or Call-level Interface binding style, is defined in part three\par
of the SQL Standard. In this chapter, we'll give you an introduction to this SQL binding style.\par
\par
Embedded SQL used to be the most important way of putting SQL statements into\par
application programs. Nowadays, the CLI is the most important. Not because it's simpler -- far from it! The CLI's real advantages are:\par
      ## There's no precompiler (this makes debugging easier).\par
      ## DLLs can be substituted (bringing the usual advantages of modularity).\par
      ## ODBC -- the best-known SQL CLI -- is very popular.\par
\par
Onward, then, to the CLI essentials. CLI stands for Call Level Interface. You\par
have probably heard of an API (Application Programming Interface), which is a\par
non-SQL name for the same sort of thing. The CLI defines a set of public\par
functions which can be called from a host language. Each function has a name,\par
a parameter list and a required algorithm (what the DBMS must do when you call it using this function).\par
\par
EXAMPLE1.C\par
\par
Here's a short C program that uses the CLI (the prototypes and short code\par
examples that follow throughout our description of the CLI are all in C):\par
\par
#include "sqlcli.h"                                             /* [Note 1] */\par
SQLHENV     henv;                                               /* [Note 2] */\par
SQLHDBC     hdbc;\par
SQLHSTMT    hstmt;\par
void main ()\par
\{\par
  SQLAllocHandle(SQL_HANDLE_ENV,NULL,&henv);                    /* [Note 3] */\par
  SQLAllocHandle(SQL_HANDLE_DBC,henv,&hdbc);\par
  SQLConnect(hdbc,...,SQL_NTS);\par
  SQLAllocHandle(SQL_HANDLE_HSTMT,hdbc,&hstmt);\par
  SQLExecDirect(hstmt,"CREATE TABLE World(hello INT);",SQL_NTS);/* [Note 4] */\par
  SQLFreeHandle(SQL_HANDLE_STMT,hstmt);                         /* [Note 5] */\par
  SQLDisconnect(hdbc);\par
  SQLFreeHandle(SQL_HANDLE_DBC,hdbc);\par
  SQLFreeHandle(SQL_HANDLE_ENV,henv); \}\par
\par
This sample program has all the necessary CLI ingredients. It will take\par
several pages to say how they all work, but the main points are noted in the\par
code as follows:\par
      ## [Note 1]: Include the SQL/CLI header file. The standard name is\par
"sqlcli.h" but you might see this statement -- include "sql.h" -- instead. The\par
header file has the prototypes of all the CLI functions and #defines for all\par
the constants. The function names begin with SQL and the constant names begin\par
with SQL_ -- that's the convention in C programs. You can program standard SQL\par
without following this convention, but it seems reasonable to follow it.\par
      ## [Note 2]: Variable declarations. The convention this time is: h\par
stands for handle -- so a henv is a handle of an env, a hdbc is a handle of a\par
dbc and a hstmt is a handle of a stmt. And now, since those abbreviated words\par
will appear many times in the next 200 pages, we'd advise you to memorize\par
them:\par
            ## env is an "allocated thing [resource] used for an environment".\par
            ## dbc is an "allocated thing [resource] used for a database connection".\par
            ## stmt is an "allocated thing [resource] used for a statement".\par
For the record, the Standard's usual names for env, dbc and stmt are\par
"allocated SQL-environment", "allocated SQL-connection" and "allocated\par
SQL-statement", respectively. We will always use the abbreviations because\par
they are what appear in sqlcli.h, and in all programs. Besides, we believe\par
it's crazy to call a stmt a statement -- a stmt is a RESOURCE; a statement is\par
a STRING. Let's not confuse the peanut with the shell. As it happens, the\par
sqlcli.h header file has "typedef"s for SQLHENV and the other handles: they're\par
all 32-bit integers. Other important typedefs are SQLINTEGER ("long int"),\par
SQLSMALLINT ("short int"), SQLCHAR ("char") and SQLRETURN ("short int", used\par
for return codes only). Using, say, "SQLINTEGER x" in a program rather than\par
"long int x" helps make it clear that "x" will see use in an SQL function.\par
      ## [Note 3]: Setup functions. The bare minimum procedure involves making\par
an env, making a dbc, connecting using the dbc and making a stmt. Notice the\par
&s in the program code: these are "output" parameters ("output" from the DBMS\par
point of view). They're passed by address because the DBMS fills in the values for them.\par
      ## [Note 4]: Meat. The only actual SQL-language statement in our program\par
is a string argument for a CLI function call. This is the actual database work.\par
      ## [Note 5]: Tear-down functions. In a reverse of the setup procedure,\par
we call functions for destroying a stmt, disconnecting using the dbc,\par
destroying the dbc and destroying the env. Notice that every function call\par
used a handle -- that's normal. Doubtless the DBMS is merely malloc'ing a bit\par
of memory for each of our "allocated things", but we can't access the fields\par
directly. Instead, we use a henv or a hdbc or a hstmt.\par
\par
SQLCHAR, SQLINTEGER and other typedefs\par
\par
Here are the type definitions in the sqlcli.h header file. We use these names for declarations of C variables in all our examples.\par
\par
typedef unsigned char  SQLCHAR;      /* 8-bit-octet strings */\par
typedef long int       SQLINTEGER;   /* 32-bit, signed */\par
typedef short int      SQLSMALLINT;  /* 16-bit, signed */\par
typedef float          SQLREAL;      /* see heading: IEEE */\par
typedef double         SQLDOUBLE;    /* see heading: IEEE */\par
typedef void*          SQLPOINTER;   /* pointer, untyped */\par
typedef long int       SQLHENV;      /* 32-bit env handle */\par
typedef long int       SQLHDBC;      /* 32-bit dbc handle */\par
typedef long int       SQLHSTMT;     /* 32-bit hstmt handle */\par
typedef long int       SQLHDESC;     /* 32-bit desc handle */\par
\par
Note: In the ODBC 3.0 header file, SQLHENV and SQLHDBC and SQLHSTMT and\par
SQLHDESC are all "typedef void*" instead of "typedef long int". In older\par
versions of the ODBC header file, the names were HENV, HDBC, HSTMT, etc.\par
\par
SQLRETURN\par
\par
All CLI functions return a 16-bit value. We refer to this value as the SQLRETURN value because sqlcli.h contains this line:\par
\par
  typedef SQLSMALLINT SQLRETURN;\par
\par
In standard SQL there are only six possible SQLRETURN values:\par
      ## -2 "invalid handle".\par
      ## -1 "error".\par
      ## 0 "success".\par
      ## 1 "success with info".\par
      ## 99 "need data".\par
      ## 100 "no data".\par
\par
Programs should check these values, but for space reasons we leave SQLRETURN out of many of our examples.\par
\par
Handle relationships\par
\par
A handle is a 32-bit integer which can be used as a unique identifier of a\par
"resource". The following chart shows all the resources which have handles.\par
The relationships between resources are either optional ("zero-to-many" --\par
shown with double arrows) or mandatory (either "one-to-one" or "zero-to-one" -- shown with single arrows).\par
\par
env\par
||\par
vv\par
dbc --------------->\par
||                 ||\par
||                 vv\par
||                 desc\par
vv\par
stmt---->------->------->\par
|       |       |       |\par
v       v       v       v\par
ARD     APD     IRD     IPD\par
(desc)  (desc)  (desc)  (desc)\par
\par
How to run example programs\par
\par
This book contains several example programs that we use to illustrate the\par
SQL/CLI. Each example program is also included on the CD that came with this\par
book, numbered in order of appearance (for example the "example C program"\par
shown earlier is example1.c). To try out any of the example programs, follow these steps.\par
\par
If you use Microsoft Windows 3.x:\par
      ## Copy these files from the CD to your working directory: OCELOT16.DLL, OCELOT16.LIB, SQLCLI.H and the C program file.\par
      ## Using a standard-C package, compile and link. For example, this is a sequence for Borland C++ version 3.1 (with the MS-DOS command line):\par
path=c:\\borlandc\\bin;c:\\borlandc\\lib;c:\\borlandc\\include\par
bcc /I\\borlandc\\include /L\\borlandc\\lib /W /M /N /ml example1.c ocelot16.lib\par
      ## Run the program from the MS-DOS command line.\par
\par
If you use Microsoft Windows 95:\par
      ## Copy these files from the diskette to your working directory: OCELOT32.DLL, OCELOT32.LIB, SQLCLI.H and the C program file.\par
      ## Using a standard-C package, compile and link. For example, this is a sequence for Symantec C++ version 7.0 (with the MS-DOS command line):\par
path=c:\\sc\\bin;c:\\sc\\lib;c:\\sc\\include\par
sc /I\\sc\\include /WA /g /mn /s /L/M example1.c kernel32.lib ocelot32.lib\par
      ## Run the program from the MS-DOS command line.\par
\par
Recommendation: Add your own screen-display statements so you'll see the\par
values of program variables when you run the program. If there's a CLI\par
function that you want to get experience with, put it into your own program,\par
link with the library supplied with this book, and run. As well as being good\par
practice, this will help you learn what is NOT standard SQL, since we\par
deliberately kept out "implementation-defined" features when we wrote this DBMS.\par
\par
"Standard SQL CLI" equals "Core ODBC API"\par
\par
History: Microsoft published the ODBC 1.0 specification in 1992. It became\par
popular. Soon there were supporting interfaces for all the major DBMSs that\par
worked under Microsoft Windows. ODBC became a de facto standard specification\par
for calling SQL from host programs without a precompiler. The ISO Standard CLI\par
came out in 1995. The influence of ODBC on the standard CLI is apparent in\par
almost every routine. Indeed, it sometimes is hard to understand the official\par
Standard document without studying Microsoft's ODBC manual too. On its part,\par
Microsoft made major changes in ODBC 3.0 (1998). They added several new\par
functions and deprecated several old ones, in order to get closer to the SQL\par
Standard. Microsoft's ODBC 3.0 manual makes these claims:\par
\par
"ODBC aligns with the following specifications and standards that deal with the Call-Level Interface (CLI). (ODBC's features are a superset of each of these standards.)\par
  -- The X/Open CAE Specification "Data Management: SQL Call-Level Interface (CLI)\par
  -- ISO/IEC 9075-3:1995 (E) Call-Level Interface (SQL/CLI)\par
\par
As a result of this alignment, the following are true:\par
  -- An application written to the X/Open and ISO CLI specifications will work\par
with an ODBC 3.0 driver or a standards-compliant driver when it is compiled\par
with the ODBC 3.0 header files and linked with ODBC 3.0 libraries, and when it\par
gains access to the driver through the ODBC 3.0 Driver Manager.\par
  -- A driver written to the X/Open and ISO CLI specifications will work with\par
an ODBC 3.0 application or a standards-compliant application when it is\par
compiled with the ODBC 3.0 header files and linked with ODBC 3.0 libraries,\par
and when the application gains access to the driver through the ODBC 3.0 Driver Manager.\par
\par
The Core interface conformance level encompasses all the features in the ISO\par
CLI and all the non-optional features in the X/Open CLI. Optional features of\par
the X/Open CLI appear in higher interface conformance levels. Because all ODBC\par
3.0 drivers are required to support the features in the Core interface\par
conformance level, the following are true:\par
  -- An ODBC 3.0 driver will support all the features used by a standards-compliant application.\par
  -- An ODBC 3.0 application using only the features in ISO CLI and the non-optional features of the X/Open CLI will work with any standards-compliant driver."\par
\par
Whoa! The SQL Standard CLI isn't quite as close to Core ODBC as Microsoft is\par
suggesting. There are a few incompatibilities in names, there are two\par
differences in prototype definitions (of SQLColumnAttr and SQLGetInfo) and\par
ODBC's default behaviour for "commits" is sui generis. But we'll note those\par
bugs as we step on them. Once you know what they are, you'll be able to adjust.\par
\par
Since this is a book on the SQL Standard, our chapters on the CLI won't show\par
you the various extra features that appear in ODBC but not in the standard\par
CLI. And we note only once -- now -- that any feature which is marked "SQL3" is a feature of the standard CLI but not necessarily of ODBC.\par
\par
How Each CLI Function Will Be Described\par
\par
In these chapters, we will describe each CLI function separately. We've put\par
them in order according to this rule: if we can't describe A without knowing\par
about B, then B should come before A. This means that some tedious minor\par
functions precede some important ones, but the advantage is that you can read\par
from front to back. Better to slog, rather than jump around.\par
\par
The structure of each CLI-function description is semi-rigid. You can expect\par
to find these things, in this order:\par
      ## Function prototype. This is the prototype as it appears in the header\par
file, sqlcli.h. It gives a quick idea of what the function's name is and what\par
<data type>s the parameters have. There is a comment beside each parameter\par
indicating whether it's an "input" parameter (its value goes from the\par
application to the DBMS) or an "output" parameter (its value goes from the DBMS to the application).\par
      ## Job. A one-sentence description of what the function is for. This may\par
be followed by an indication of whether the function is essential or not.\par
Several functions are obsolete or redundant, so you can skip the details on\par
your first pass through these chapters.\par
      ## Algorithm. Exactly what does the DBMS do with this function? This\par
section is in a sort of pseudocode. We're trying to make the instructions\par
readable, but we won't spare you from mind-numbing (but necessary) details.\par
      ## Notes. Whatever strikes us as worthy of remark about a function.\par
      ## Example. A code snippet written in C. Usually the example will be an\par
incomplete program, with ... to indicate that we haven't repeated stuff which\par
doesn't advance the story. Most commonly, we leave out the "setup" and "tear-\par
down" phases illustrated in the example program shown at the beginning of this chapter.\par
      ## ODBC. Anything that relates specifically to ODBC, but not to the\par
standard CLI. If a standard CLI procedure doesn't exactly match the ODBC spec,\par
it gets noted here. If ODBC has a truly significant feature that is not in the standard CLI, we mention it curtly.\par
\par
Having said that, let's get on with the descriptions. Here's a quick list of\par
the 62 standard CLI functions:\par
\par
NAME                 CATEGORY     FUNCTION\par
SQLAllocConnect      dbc          Obsolescent: Make a dbc\par
SQLAllocEnv          env          Obsolescent: Make an env\par
SQLAllocHandle       dbc,env,stmt Essential: Make env, dbc, stmt or desc\par
SQLAllocStmt         stmt         Obsolescent: Make a stmt\par
SQLBindCol           desc         Useful: Associate Column descriptor to stmt\par
SQLBindParameter     desc         Useful: Associate parameter to stmt\par
SQLCancel            D parameters Minor: Stop unfinished statement execution\par
SQLCloseCursor       Cursors      Essential: Close cursor\par
SQLColAttribute      desc         Useful: Get info re result set structure\par
SQLColumnPrivileges  Catalog      Junk: Get metadata re Column privileges\par
SQLColumns           Catalog      Junk: Get metadata re Columns\par
SQLConnect           dbc          Essential: Connect to SQL-server/database\par
SQLCopyDesc          desc         Minor: Make copy of descriptor\par
SQLDataSources       general      Minor: List available servers\par
SQLDescribeCol       desc         Useful: Get info re result set structure\par
SQLDisconnect        dbc          Essential: Disconnect SQL-server/database\par
SQLEndTran           Statements   Essential: Commit or Rollback\par
SQLError             Diagnostics  Obsolete: Get diagnostics information\par
SQLExecDirect        Statements   Useful: Prepare + Execute a statement\par
SQLExecute           Statements   Essential: Execute a prepared statement\par
SQLFetch             Cursors      Useful: Bring in next result-set row\par
SQLFetchScroll       Cursors      Essential: Bring in any result-set row\par
SQLForeignKeys       Catalog      Junk: Get metadata re foreign keys\par
SQLFreeConnect       dbc          Obsolescent: Destroy dbc\par
SQLFreeEnv           env          Obsolescent: Destroy env\par
SQLFreeHandle        Handles      Essential: Destroy env, dbc, stmt or desc\par
SQLFreeStmt          stmt         Obsolescent: Destroy stmt and other things\par
SQLGetConnectAttr    dbc          Useless: Get attribute of dbc\par
SQLGetCursorName     Cursors      Minor: Get Cursor name\par
SQLGetData           desc         Useful: Get value from result set\par
SQLGetDescField      desc         Essential: Get 1 desc field\par
SQLGetDescRec        desc         Useful: Get 7 desc fields\par
SQLGetDiagField      Diagnostics  Essential: Get diagnostics information\par
SQLGetDiagRec        Diagnostics  Useful:  Get diagnostics information\par
SQLGetEnvAttr        env          Minor: Get attribute of env\par
SQLGetFunctions      general      Minor: List CLI functions supported\par
SQLGetInfo           general      Essential: Get attribute of dbc etc.\par
SQLGetLength         locator      Minor: Length of CLOB/BLOB\par
SQLGetParamData      desc         Minor: Get data from procedure parameters\par
SQLGetPosition       locator      Minor: Indicate substring start position\par
SQLGetStmtAttr       stmt         Essential: Get attribute of stmt\par
SQLGetSubstring      locator      Minor: Get portion of CLOB/BLOB\par
SQLGetTypeInfo       Catalog      Junk: Get metadata re data types\par
SQLMoreResults       Cursors      Minor: See if more result sets\par
SQLNumResultCols     desc         Useful: Get selected-Column count\par
SQLParamData         D parameters Minor: For passing data piecemeal\par
SQLParameters        Catalog      Junk: Get metadata re parameters\par
SQLPrepare           Statements   Essential: Prepare a statement\par
SQLPrimaryKeys       Catalog      Junk: Get metadata re primary keys\par
SQLPutData           D parameters Minor: For passing data piecemeal\par
SQLRoutinePrivileges Catalog      Junk: Get metadata re Privileges\par
SQLRoutines          Catalog      Junk: Get metadata re routines\par
SQLRowCount          Diagnostics  Useful:  Get affected-rows count\par
SQLSetConnectAttr    dbc          Useless: Change dbc attribute\par
SQLSetCursorName     Cursors      Essential: Change Cursor name\par
SQLSetDescField      desc         Essential:  Change 1 desc field\par
SQLSetDescRec        desc         Useful: Change 7 desc fields\par
SQLSetEnvAttr        env          Useless: Change env attribute\par
SQLSetStmtAttr       stmt         Useful: Change stmt attribute\par
SQLSpecialColumns    Catalog      Junk: Get metadata re search Columns\par
SQLTablePrivileges   Catalog      Junk: Get metadata re Table Privileges\par
SQLTables            Catalog      Junk: Get metadata re Tables\par
\par
And that concludes our brief introduction to the CLI. Before we begin\par
describing each of the functions in this list in detail, though, we'll show\par
you a sample function description, using a common CLI function subroutine -- CharacterStringRetrieval.\par
\par
CharacterStringRetrieval\par
\par
Function Prototype:\par
  void CharacterStringRetrieval (\par
    SQLCHAR *Target,                  /* CHAR* output */\par
    SQLCHAR *Source,                  /* CHAR* input */\par
    SQLINTEGER MaxTargetOctetLength,  /* 32-bit output */\par
    SQLINTEGER *SourceOctetLength     /* 32-bit output */\par
    );\par
\par
Job:\par
The common subroutine for Character String Retrieval appears in 24 CLI\par
functions. You don't directly call it, but you see the effects. We thought\par
this would be a  good way to introduce the format we use for CLI function\par
descriptions.\par
\par
Algorithm:\par
      If (MaxTargetOctetLength <= 0)\par
        return error: HY090 CLI-specific condition-invalid string length or buffer length\par
      If (SourceOctetLength is not a null pointer)\par
        /* We set *SourceOctetLength = the size of the source string, even if we don't actually copy the entire source to target. */\par
        Set *ReturnedOctetLength = strlen (Value)\par
      If (we don't use null-termination in this environment)\par
        /* In COBOL or FORTRAN you wouldn't expect null-termination, since strings don't end with a '\\0' in those languages. But we never take this path. */\par
      Else\par
        /* In C, and also in Pascal, strings end with '\\0'. We'll assume null-termination then. But now you're aware that it's a characteristic of the host language we're using, not a requirement of standard SQL. */\par
        If (we're using WideChar i.e. 16 bits per character)\par
          sizeof(null-terminator) = 2\par
        Else sizeof(null-terminator) = 1\par
        Set # of octets to copy = MaxTargetOctetLength-sizeof(null-terminator)\par
        If (# of octets to copy < 0)\par
          /* Put out '\\0' if possible, but there's no room for copying */\par
        Else\par
          If (# of octets to copy > strlen(Source))\par
            Set # of octets to copy = strlen(source)\par
            Copy:\par
              Set # of octets to copy=strlen(Source) - sizeof(null-terminator)\par
              From: Source\par
              To: Target\par
          Append null-terminator to Target.\par
        If (strlen(Target) < Strlen(Source)\par
          warning - string data, right truncation\par
\par
Notes:\par
      ## The idea is simply to copy the *Source string to the *Target string,\par
but there's a safeguard against overflowing *Target (that's why we pass\par
MaxTargetOctetLength) and there's a place to store the original size (that's\par
why we pass *ReturnedOctetLength).\par
      ## The *Target string will always be null-terminated, unless TargetOctetLength=0.\par
      ## There are variations of this routine where ...OctetLength is 16-bit.\par
      ## There is a slight variation of this routine for BLOB retrieval: it works the same way, but ignores anything to do with null terminators.\par
      ## CharacterStringRetrieval(target,source,max,&sourcelength) is expressible using the standard-C <string.h> function strxfrm: sourcelength = strxfrm(target,source,max);\par
\par
Example:\par
      / * SPECIMEN ONLY -- you don't really want to call this function */\par
      #include "sqlcli.h"     /* includes definitions of SQL... stuff */\par
      SQLCHAR target[100];    /* SQLCHAR is 8-bit ISO if Windows98 */\par
      SQLINTEGER returnsize;  /* SQLINTEGER is always 32-bit signed */\par
      ...\par
      CharacterStringRetrieval(target,"ABC",5,&returnsize);\par
      /* Now target has: ABC\\0 and returnsize = 5. */\par
      ...\par
      CharacterStringRetrieval(target,"ABC",3,&returnsize);\par
      /* Now target has: AB\\0 and returnsize = 2. */\par
\par
ODBC: In ODBC 1.0's documentation there was some contradictory information\par
about the workings of Character String Retrieval, but everything is settled now.\par
\page\par
Chapter 41 -- SQL/CLI: env Functions\par
\par
In this chapter, we'll describe the first essential CLI resource: the env. For\par
CLI programs, the env is the all-encompassing context area -- all CLI programs\par
begin by establishing an env. The env contains some information directly\par
("attributes" and "diagnostics"), but what's important is that an env contains\par
zero or more dbcs (although there's no point in having an env without a dbc).\par
Here's a closeup view of an env:\par
\par
      ----------------------\par
      - [env Attributes]   -\par
      - [env Diagnostics]  -\par
      ----------------------\par
      | |\par
      | |\par
      v v\par
      ... to dbcs\par
\par
Null Termination\par
\par
Traditionally, there have been three ways to define character strings:\par
      ## They are fixed length. Example: a COBOL PIC X(5) variable.\par
      ## They are variable length and a separate variable tells us the size.\par
Example: the 16-bit octet-length -- SIZE% -- in a BASIC string var$, or the\par
8-bit octet-length which is the first byte of a Turbo Pascal string.\par
      ## They are variable length and the end is marked by a termination code.\par
Example: the 8-bit byte = '\\0' which ends strings in C programs. This code,\par
which in a wide-character string would be a 16-bit word 0x0000, is the null\par
terminator. Inprise Pascal (Delphi) uses the same convention for PChar variables.\par
\par
We've assumed that any DBMS which supports C/Pascal interfaces  will go with\par
null termination. That affects the CLI in only one way: you can receive\par
null-terminated strings from the DBMS whenever Character String Retrieval is\par
called for. Going the other way -- passing null-terminated strings to the DBMS\par
-- is legal regardless of the setting of NULL TERMINATION. That's because you\par
indicate null termination of input strings using SQL_NTS for "size".\par
\par
Sixteen of the CLI functions accept an input-string parameter. In these\par
functions, the parameter immediately following the input-string parameter is\par
the "input-string length" -- for example:\par
\par
   <function name> (... input_string, input_string_length);\par
\par
The input length should be the number of octets in the input string, not\par
including the null termination octet(s). However, you can pass SQL_NTS (-3)\par
instead -- this stands for "null terminated string" -- and let the DBMS\par
calculate the string size. Remember, though, that programs which pass SQL_NTS\par
are many nanoseconds slower than programs which pass an absolute length.\par
\par
There are six CLI functions for creating envs, dropping envs, getting env\par
attributes and setting env attributes. Their descriptions follow.\par
\par
SQLAllocHandle(SQL_HANDLE_ENV,...)\par
\par
Function Prototype:\par
  SQLRETURN SQLAllocHandle(\par
    SQLSMALLINT HandleType,         /* 16-bit input = SQL_HANDLE_ENV */\par
    SQLINTEGER InputHandle,         /* 32-bit input */\par
    SQLINTEGER *OutputHandle        /* pointer to 32-bit output, a henv */\par
    );\par
\par
Job:\par
Allocate an env.\par
\par
## How to make an env\par
Usually the first SQL-related instruction is the call to make an env:\par
\par
#include "sqlcli.h"\par
SQLHENV     henv;                   /* declare a henv, name it: henv */\par
SQLRETURN   sqlreturn;              /* code returned by SQL function */\par
...\par
  sqlreturn = SQLAllocHandle(SQL_HANDLE_ENV,SQL_NULL_HANDLE,&henv);\par
  ...\par
\par
The first parameter (HandleType) is SQL_HANDLE_ENV.\par
\par
The second parameter (InputHandle) doesn't matter here. As a style note: we\par
follow a convention that "if the parameter value doesn't matter then use a\par
constant containing the word NULL". This convention helps make it clear that\par
the value we're passing has no significance.\par
\par
The third parameter (*OutputHandle) must be an address of an environment\par
handle. As explained before, we prefer to call an environment handle a "henv".\par
But use a descriptive name for your program variable if you have one.\par
\par
If the function succeeds: you have a new env. Keep the henv, you'll need it\par
later for input to other functions.\par
\par
## Testing for error returns\par
[Obscure Rule] Error-testing is a bit unusual because the DBMS may put\par
something into OutputHandle even if the function fails. This annotated code\par
snippet shows the scenarios:\par
\par
sqlreturn = SQLAllocHandle(SQL_ALLOC_ENV,SQL_HANDLE_NULL,&henv);\par
if (sqlreturn < 0) \{\par
  /* There was an error so SQLAllocHandle returned a negative value. */\par
  if (sqlreturn == SQL_NULL_HANDLE) \{               /* SQL_NULL_HANDLE=-2 */\par
    /* SQL_HANDLE_ENV is not a valid code -- an "impossible" error */ \}\par
  else \{\par
    /* sqlreturn must be SQL_ERROR (-1), the only other possibility */\par
    if (&henv==0)\par
      /* The problem is "invalid use of null pointer" -- the last parameter -- OutputHandle -- was zero. This error too is "impossible". */\par
    if (henv<>SQL_NULL_HENV) \{\par
      /* The DBMS has placed a "skeleton env handle" in henv. It's not good for much, but you can use henv to get an error message with the SQLGetDiagRec function. */ \}\par
    else \{\par
      /* The DBMS has placed zero in henv. There was an error, there is no skeleton env handle to get error messages with. You'll have to guess that there wasn't enough memory. */ \} \}\par
else \{\par
  /* There was no error. */ \}\par
\par
There are several other possible errors/exception conditions that the\par
SQLAllocHandle function might "raise". If they occur, the function will return\par
a negative number: -2 (SQL_INVALID_HANDLE) or -1 (SQL_ERROR). For more\par
detailed information, look up the SQLSTATE codes beginning with HY, HY001 or\par
HY014 in our chapter on SQL/CLI diagnostics.\par
\par
Algorithm:\par
If (HandleType == SQL_HANDLE_ENV) \{\par
  The DBMS allocates an object in memory. The DBMS creates a 32-bit handle for this object, its unique identifier. The DBMS puts the handle in the memory location addressed by OutputHandle. \}\par
\par
Notes:\par
      ## This is one of several SQLAllocHandle variants. The HandleType input\par
parameter may contain any one of:\par
            ## (implementation-defined)  <  1\par
            ## SQL_HANDLE_ENV               1  /* handle of an env */\par
            ## SQL_HANDLE_DBC               2  /* handle of a dbc */\par
            ## SQL_HANDLE_HSTMT             3  /* handle of a stmt */\par
            ## SQL_HANDLE_DESC              4  /* handle of a desc */\par
            ## (implementation-defined)  >100\par
In discussions of other CLI functions, we will usually ignore the\par
"implementation-defined" possibilities.\par
\par
ODBC: The SQLAllocHandle function is new in ODBC 3.0. Error information will\par
not be available until you call the "connect" function.\par
\par
SQLAllocEnv\par
\par
Function prototype:\par
  SQLRETURN SQLAllocEnv(\par
    SQLHENV *henv                   /* pointer to 32-bit output, a henv */\par
    );\par
\par
Job:\par
Make an env.\par
\par
Algorithm:\par
sqlreturn = SQLAllocEnv(&henv);\par
is the same as\par
sqlreturn = SQLAllocHandle(SQL_HANDLE_ENV,SQL_NULL_HANDLE,&henv);\par
\par
Notes:\par
      ## Implicit Calls\par
In the algorithm description, the words "is the same as" mean that, in effect,\par
the DBMS calls SQLAllocHandle when you call SQLAllocEnv. So you have called\par
SQLAllocHandle indirectly, or -- as the Standard puts it -- "implicitly". For\par
purposes of interpreting the somewhat legalistic Standard, it makes absolutely\par
no difference whether you perform an operation explicitly or implicitly.\par
      ## Obsolescent Handle Functions\par
SQLAllocEnv is one of six functions -- SQLAllocEnv, SQLFreeEnv,\par
SQLAllocConnect, SQLFreeConnect, SQLAllocStmt, SQLFreeStmt - which are\par
nowadays, mostly redundant. They are a legacy of the days when there were only\par
three kinds of resources: env, dbc and stmt. Mostly, you will see them in\par
programs written for early versions of ODBC. The Standard does not "deprecate"\par
these functions, so we may assume that they will continue to be part of\par
standard SQL for the indefinite future. However, their presence will make a\par
program look old-fashioned. The only exception is SQLFreeStmt, which has a few\par
useful options.\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLHENV     henv;\par
      SQLRETURN   sqlreturn;\par
      ...\par
      sqlreturn = SQLAllocEnv(&henv);\par
      if (sqlreturn == SQL_ERROR) \{\par
        printf("Error: could not make an env.\\n");\par
        exit(1); \}\par
\par
ODBC: The SQLAllocEnv routine has been in ODBC since version 1.0. The ODBC 3.0\par
manual deprecates it, suggesting that users should switch to using SQLAllocHandle(SQL_HANDLE_ENV,...).\par
\par
SQLGetEnvAttr\par
\par
Function Prototype:\par
  SQLRETURN  SQLGetEnvAttr(\par
    SQLHENV henv,                   /* 32-bit input */\par
    SQLINTEGER Attribute,           /* 32-bit input */\par
    SQLPOINTER Value,               /* ANY* pointer to output */\par
    SQLINTEGER BufferLength,        /* 32-bit input */\par
    SQLINTEGER *StringLength);      /* 32-bit pointer to output */\par
\par
Job:\par
Get an env attribute. At the moment there is only one standard env attribute:\par
a flag saying whether strings are null-terminated. The flag has this #define in sqlcli.h:\par
\par
#define SQL_ATTR_OUTPUT_NTS 10001 /* NULL TERMINATION env attribute */\par
\par
Algorithm:\par
If (henv is not a henv or env is a skeleton env)\par
   return with error: CLI-specific condition - invalid handle\par
   Empty env's diagnostics area.\par
   If (Attribute <> SQL_ATTR_OUTPUT_NTS)\par
      return with error: HY092 CLI-specific condition-invalid attribute identifier\par
      Set *Value = env's NULL TERMINATION env attribute\par
      /* This value is 1 (TRUE) if the DBMS uses null termination; it is 0 (FALSE) if not. */\par
\par
Notes:\par
      ## The BufferLength and StringLength parameters are unused. They're\par
there in case a future edition of the SQL Standard requires more information.\par
Or, as with all functions, there is a chance that your particular DBMS stores\par
attribute information that the Standard doesn't officially require.\par
\par
Example:\par
  #include "sqlcli.h"\par
  SQLHENV    henv;\par
  SQLINTEGER attribute;\par
  ...\par
  SQLGetEnvAttr(henv,SQL_ATTR_OUTPUT_NTS,&attribute,NULL,NULL);\par
\par
ODBC: The SQLGetEnvAttr function is new in ODBC 3.0. There are also a few\par
other env options which are specific to ODBC.\par
\par
SQLSetEnvAttr\par
\par
Function Prototype:\par
  SQLRETURN  SQLSetEnvAttr(\par
    SQLHENV henv,             /* 32-bit input -- env handle */\par
    SQLINTEGER Attribute,     /* 32-bit input */\par
    SQLPOINTER Value,         /* ANY* input */\par
    SQLINTEGER StringLength   /* 32-bit input */\par
    );\par
\par
Job:\par
Set an env attribute. At the moment there is only one standard env attribute:\par
whether output strings are null-terminated -- see the discussion of the\par
SQLGetEnvAttr function for some detailed remarks on the subject of Null\par
Termination. It is probably sufficient to know that you do not want to change\par
this attribute if you program in C or Pascal.\par
\par
Algorithm:\par
If (henv is not a henv) or (env is skeleton env)\par
  return with error: CLI-specific condition-invalid handle\par
Empty the env's diagnostics area.\par
If (there is a dbc in this env)\par
  /* You should call SQLSetEnvAttr before calling SQLAllocHandle(SQL_HANDLE_DBC,...) */\par
  return with error: HY011 CLI-specific condition-attribute cannot be set now\par
If (Attribute <> SQL_ATTR_OUTPUT_NTS)\par
  return with error: HY092 CLI-specific condition-invalid attribute identifier\par
If (Attribute == SQL_ATTR_OUTPUT_NTS)\par
/* in sqlcli.h there is a line: "#define 10001 SQL_ATTR_OUTPUT_NTS" */\par
  If (*Value == TRUE) then set env's NULL TERMINATION attribute = TRUE.\par
  Else If (*Value == FALSE) then set NULL TERMINATION attribute = FALSE.\par
  Else return with error: HY024 CLI-specific condition-invalid attribute value\par
\par
Notes:\par
      ## There might be some other, implementation-defined, env attributes.\par
That is why there is a StringLength parameter -- in case there is an\par
implementation-defined attribute which is represented as a character string.\par
\par
Example:\par
#include "sqlcli.h"\par
SQLHENV     henv;\par
SQLINTEGER  Value=1;\par
void main ()\par
\{\par
  if (SQLAllocHandle(SQL_HANDLE_ENV,SQL_NULL_HANDLE,&henv)<0) \{\par
    printf("Error: can't create the env\\n");\par
    exit(1); \}\par
  if (SQLSetEnvAttr(henv,SQL_ATTR_OUTPUT_NTS,&Value,NULL)<0) \{\par
    printf("Error: can't set the NULL TERMINATION env attribute\\n");\par
    exit(1); \}\par
  exit(0); \}\par
\par
ODBC: The SQLSetEnvAttr function is new in ODBC 3.0. It is impossible to\par
change the NULL TERMINATION env attribute. There are other attributes. For\par
example, to explicitly state that your application is written for ODBC version\par
3.0, say:  version = SQL_OV_ODBC3;        /* 00000003L */\par
           SQLSetEnvAttr(henv,SQL_ATTR_ODBC_VERSION,&version,NULL);\par
\par
SQLFreeHandle(SQL_HANDLE_ENV,...)\par
\par
Function Prototype:\par
  SQLRETURN SQLFreeHandle(\par
    SQLSMALLINT HandleType,   /* 16-bit input */\par
    SQLINTEGER Handle         /* 32-bit input (must be a henv) */\par
    );\par
\par
Job:\par
Destroy an env. This is the reverse of the SQLAllocHandle(SQL_HANDLE_ENV,...) function.\par
\par
Algorithm:\par
If (Handle is not a henv)\par
  return error: CLI-specific condition-invalid handle\par
Empty the env's diagnostics area.\par
If (there is a dbc associated with the env)\par
  return error: HY010 CLI-specific condition-function sequence error\par
Deallocate env and anything associated with it, such as RAM.\par
The handle is now invalid.\par
\par
Notes:\par
      ## This is usually the last function call in a CLI program.\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLHENV     henv;\par
      ...\par
      SQLFreeHandle(SQL_HANDLE_ENV,henv);\par
\par
ODBC: The SQLFreeHandle function is new in ODBC 3.0.\par
\par
SQLFreeEnv\par
\par
Function Prototype:\par
  SQLRETURN SQLFreeEnv(\par
    SQLHENV henv                    /* 32-bit input */\par
    );\par
\par
Job:\par
Destroy an env. This is the reverse of the SQLAllocEnv function. SQLFreeEnv is\par
redundant.\par
\par
Algorithm:\par
sqlreturn = SQLFreeEnv(henv);\par
is the same thing as\par
sqlreturn = SQLFreeHandle(SQL_HANDLE_ENV,henv);\par
\par
Notes:\par
      ## The Standard does not say that the SQLFreeEnv function is deprecated. All DBMSs should support it.\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLHENV     henv;\par
      ...\par
      SQLAllocEnv(&henv);\par
      ...\par
      SQLFreeEnv(henv);\par
      /* henv is now an invalid handle */\par
      ...\par
\par
ODBC: The SQLFreeEnv function has been in ODBC since version 1.0. The ODBC 3 manual deprecates it, suggesting that users should switch to using SQLFreeHandle(SQL_HANDLE_ENV,...).\par
\par
And that's it for the env functions. In the next chapter, we'll take a look at the dbc functions.\par
\page\par
Chapter 42 -- SQL/CLI: dbc Functions\par
\par
In this chapter, we'll describe the second essential CLI resource: the dbc.\par
For CLI programs, the dbc is at the level below env and above stmt. The env\par
may contain multiple dbcs, and the dbc may contain multiple stmts (the dbc may\par
also contain multiple descs, but only of the "user" kind). Here's a closeup view of a dbc:\par
\par
      ... from env\par
      | |\par
      | |\par
      v v\par
      -------------------------------------\par
      - [Attributes]     |                -\par
      -                  | [Connection]   -\par
      - [Diagnostics]    |                -\par
      -   ...            |                -\par
      -------------------------------------\par
                         | |           | |\par
                         | |           | |\par
                         v v           v v\par
                         ... to stmts  ... to user descs\par
\par
There are eight CLI functions for creating dbcs, dropping dbcs, getting dbc attributes, setting dbc attributes, connecting and  disconnecting. Their descriptions follow.\par
\par
SQLAllocHandle(SQL_HANDLE_DBC,...)\par
\par
Function Prototype:\par
  SQLRETURN SQLAllocHandle (\par
    SQLSMALLINT HandleType,         /* 16-bit input = SQL_HANDLE_DBC */\par
    SQLINTEGER InputHandle,         /* 32-bit input, must be a henv */\par
    SQLINTEGER *OutputHandle        /* pointer to 32-bit output, a hdbc */\par
    );\par
\par
Job:\par
Allocate a dbc.\par
\par
Algorithm:\par
if (HandleType) == SQL_HANDLE_DBC) \{\par
  The DBMS allocates a new dbc, and associates it with the env (the env's\par
handle is passed in InputHandle) and returns the handle of the new dbc into\par
the memory location addressed by OutputHandle. \}\par
\par
That is, If (HandleType == SQL_HANDLE_DBC), then the job is to allocate a new\par
dbc.\par
\par
Notes:\par
      ## The second parameter, InputHandle, must be a valid henv so this function call happens after SQLAllocHandle(SQL_ALLOC_ENV,...).\par
      ## Keep the hdbc, you'll need it later for SQLAllocHandle(SQL_HANDLE_STMT, ...), for SQLFreeHandle(SQL_HANDLE_DBC, ...) and for other functions.\par
\par
Example:\par
#include "sqlcli.h"\par
SQLHENV     henv;             /* handle of an env */\par
SQLHDBC     hdbc;             /* handle of a dbc */\par
SQLRETURN   sqlreturn;        /* code returned by SQL function */\par
...\par
  sqlreturn = SQLAllocHandle(SQL_HANDLE_DBC,henv,&hdbc);\par
  ...\par
\par
ODBC: The SQLAllocHandle function is new in ODBC 3.0. Error information will\par
not be available until you call the "connect" function.\par
\par
SQLAllocConnect\par
\par
Function Prototype:\par
  SQLRETURN SQLAllocConnect (\par
    SQLHENV henv,       /* 32-bit input, must be a henv */\par
    SQLHDBC *hdbc       /* pointer to 32-bit output, a hdbc */\par
    );\par
\par
Job:\par
Make a new dbc. SQLAllocConnect is obsolete.\par
\par
Algorithm:\par
sqlreturn = SQLAllocConnect(henv,&hdbc);\par
is the same as:\par
sqlreturn = SQLAllocHandle(SQL_HANDLE_DBC,henv,&hdbc);\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLHENV     henv;\par
      SQLHDBC     hdbc;\par
      SQLRETURN   sqlreturn;\par
      ...\par
      if (SQLAllocEnv(&henv)>0) \{\par
        if (SQLAllocConnect(henv,&hdbc)>0) \{\par
          ... a hdbc exists \} \}\par
\par
Notes:\par
      ## Although SQLAllocConnect is in the "obsolescent" category, it is still a standard function supported by all DBMSs.\par
\par
ODBC: The SQLAllocConnect routine has been in ODBC since version 1.0. The ODBC 3.0 manual deprecates it, suggesting that users should switch to using SQLAllocHandle(SQL_HANDLE_DBC,...).\par
\par
SQLConnect\par
\par
Function Prototype:\par
  SQLRETURN  SQLConnect(\par
    SQLHDBC hdbc,                   /* 32-bit input */\par
    SQLCHAR *ServerName,            /* CHAR* input */\par
    SQLSMALLINT NameLength1,        /* 16-bit input (ServerName length)*/\par
    SQLCHAR *UserName,              /* CHAR* input */\par
    SQLSMALLINT NameLength2,        /* 16-bit input (UserName length) */\par
    SQLCHAR *Authentication,        /* CHAR* input */\par
    SQLSMALLINT NameLength3         /* 16-bit input (Authentication length)*/\par
    );\par
\par
Job:\par
Establish an SQL-Connection for a dbc. The details of "how to connect" depend\par
largely on the implementation. We describe two broad cases: a Single-Tier\par
Scenario (everything on one computer) and a Two-Tier Scenario (Client on one\par
computer, Server on another computer). One or the other will be fairly close\par
to what your specific implementation does.\par
\par
## Single-Tier scenario\par
      ## Step 1. The client (which is effectively the same thing as "the\par
DBMS") verifies that the parameters have valid data. Specifically, it must be\par
true that:\par
(a) The dbc exists. If it doesn't, the return is CLI-specific condition:\par
invalid handle. Read up on the SQLAllocHandle function to see how to set up\par
the handle.\par
(b) There is no SQL transaction running on this Connection. (Actually some\par
sophisticated systems allow this, but we assume the normal case.) If there is\par
one, the return is 0A001 feature not supported: multiple transactions. It's\par
okay if you have a transaction going on a different SQL-Connection -- this\par
just means you can't connect twice using the same dbc handle. Read up on\par
SQLDisconnect if you're already connected.\par
(c) The ServerName parameter is valid. This should be a string, with a maximum\par
length of 128 octets (as usual the length is passed along with the string, in\par
NameLength1, and may be SQL_NTS). If it's not valid, the return is HY090\par
invalid string length or buffer length.\par
(d) The UserName is valid. The contents of this string will become the\par
<AuthorizationID>, so the string should contain a valid identifier, such as:\par
'USER_1' or ' USER_1 ' (lead and trail spaces don't matter).\par
(e) The authentication is valid. Usually a blank is acceptable: ''.\par
      ## Step 2. The DBMS "opens" the database named ServerName. This may seem\par
like a misuse of the parameter, but the fact is, we don't need to contact a\par
server -- but we do need to open a database. And it's fairly common that there\par
will be more than one database on a computer, so names are necessary.\par
\par
## Two-Tier scenario\par
      ## Step 1. The client (the local task which your application is calling)\par
verifies that the parameters have valid data. This step is local, the only\par
likely difference is that the client will not bother to verify the\par
"authentication" parameter, since that's usually the server's problem.\par
      ## Step 2. If ServerName = "DEFAULT":\par
If (User Name Length <> 0) invalid string or buffer length\par
If (Authentication Length <> 0) invalid string or buffer length\par
If (Somebody else already in as default) connection name in use\par
                Otherwise:\par
(Compare the effect of a "CONNECT TO DEFAULT;" statement.)\par
      ## Step 3. Using RDA, the client finds the server identified by the\par
parameter ServerName, and sends a message to the server containing the\par
parameter values (UserName and Authentication). If the network's down, or the\par
server's not out there, then the return is 08001 connection exception-SQL-client unable to establish SQL-session\par
      ## Step 4. The server does its own validation of UserName and\par
Authentication. One possibility is that the Authentication is designed to be a\par
password, and it doesn't match what that UserName's password is supposed to\par
be. In this case, the return is 08004 connection exception-SQL-server rejected\par
establishment of SQL-session. Notice the difference between this error and the\par
one described in Step 3 -- SQLSTATE is '08001' if the client can't talk to the\par
server; SQLSTATE is '08004' is if they can talk, but the server says no.\par
      ## Step 5. All having gone well, we now have a new SQL-session. If there\par
was already an SQL-session in progress, it becomes dormant. The new\par
SQL-session becomes the current SQL-session. The new SQL-session's session\par
<AuthorizationID> becomes UserName -- that is, if the UserName parameter is\par
'X', and you use the niladic function SESSION_USER in an SQL statement, you'll get 'X'.\par
\par
Example:\par
  /* EXAMPLE2.C */\par
  /* This is a program example. Connection is to the default database for the\par
DBMS that came with this book. For variety, we test sqlreturn each time. Tear-\par
down calls are omitted. */\par
  #include "sqlcli.h"\par
  SQLHENV    henv;\par
  SQLHDBC    hdbc;\par
  SQLRETURN  sqlreturn;\par
  void main ()\par
  \{\par
    sqlreturn = SQLAllocHandle(SQL_HANDLE_ENV,SQL_NULL_HANDLE,&henv);\par
    if (sqlreturn == SQL_SUCCESS || sqlreturn == SQL_SUCCESS_WITH_INFO) \{\par
      sqlreturn = SQLAllocHandle(SQL_HANDLE_DBC,henv,&hdbc);\par
      if (sqlreturn == SQL_SUCCESS || sqlreturn == SQL_SUCCESS_WITH_INFO) \{\par
        sqlreturn = SQLConnect(hdbc,\par
                    (SQLCHAR*)"OCELOT",SQL_NTS,\par
                    (SQLCHAR*)"OCELOT",SQL_NTS,\par
                    (SQLCHAR*)"",SQL_NTS);\par
        if (sqlreturn == SQL_SUCCESS || sqlreturn == SQL_SUCCESS_WITH_INFO) \{\par
          printf("connected successfully.\\n"); \} \} \} \}\par
\par
ODBC: SQLConnect has been a supported function since ODBC 1.0. But there are\par
other, non-standard, ODBC functions which can be used to connect. The\par
alternatives take advantage of the Windows environment (by putting up dialog\par
boxes etc.), and assume that Microsoft's Driver Manager software will take\par
care of some details.\par
\par
CONNECT versus SQLConnect:\par
There is an SQL statement which we've already discussed:\par
\par
   CONNECT TO <SQL-server-name> [AS <Connection name>] USER <AuthorizationID>;\par
\par
You are not supposed to execute this SQL statement using the CLI! The business\par
of connecting is to be handled exclusively through the SQLConnect function. So\par
if you write a program which accepts user commands in the form of SQL\par
statements, you must intercept any that begin with "CONNECT ..." and call the\par
SQLAllocConnect and SQLConnect functions for them. Unfortunately, this is\par
difficult because there is an imperfect mapping between the arguments of the\par
CONNECT statement and the parameters of SQLConnect.\par
\par
Similar interceptions will be necessary for the three other SQL statements\par
which must not be executed directly using the CLI: DISCONNECT, COMMIT and\par
ROLLBACK. For each of these statements there is an approximate CLI-function\par
analogue: SQLDisconnect, SQLEndTran(...SQL_COMMIT) and SQLEndTran(...SQL_ROLLBACK).\par
\par
SQLDisconnect\par
\par
Function Prototype:\par
  SQLRETURN SQLDisconnect(\par
    SQLHDBC hdbc                    /* 32-bit input */\par
    );\par
\par
Job:\par
End an SQL session which was started by calling the SQLConnect function. Analogous to the SQL DISCONNECT statement.\par
\par
Algorithm:\par
If (hdbc parameter is not a handle of a dbc)\par
  return error: CLI-specific condition-invalid handle\par
Empty the diagnostics area associated with dbc.\par
If (there is no connection associated with dbc)\par
 /* i.e. we didn't call SQLConnect or we already called SQLDisconnect */\par
  return error: 08003 connection exception-connection does not exist\par
For (each stmt associated with the dbc)\par
   If (there is a deferred parameter number)\par
     return error: HY010 CLI-specific condition-function sequence error\par
If (a transaction is active)\par
  /* Before disconnecting you must end the transaction,\par
     try calling SQLEndTran */\par
  return error: 25001 invalid transaction state-active SQL-transaction\par
For (each stmt associated with the dbc)\par
  Free the stmt's descs (ARD, APD, IRD, IPD)\par
  Free the stmt\par
Free any descs which are directly associated with the dbc\par
If (Client/Server)\par
  Tell the server that this connection is over.\par
  If (server won't reply / server won't let go)\par
    /* This is only a warning, by now the disconnect is unstoppable */\par
    there will be a warning: 01002 warning-disconnect error\par
If (the connection we just disconnected was the current connection)\par
  There is now no current connection\par
\par
Notes:\par
      ## A connected dbc takes up space, and in a multi-user scenario there\par
might be conflicts with other SQL-sessions using the same server. You should\par
always call SQLDisconnect to end an SQL-session, although some single-tier\par
DBMSs don't require it. After you call SQLDisconnect, you can either\par
re-connect (see SQLConnect) or finish the tear-down process by freeing the dbc\par
(see SQLFreeHandle(SQL_HANDLE_DBC...)).\par
      ## There is a side effect: a previously-dormant SQL-Connection might become current. That can only happen if the DBMS allows double-connections on the same dbc.\par
\par
Example:\par
      /* All function calls except SQLDisconnect are in skeletal form. */\par
      #include "sqlcli.h"\par
      SQLHENV henv;\par
      SQLHDBC hdbc;\par
      ...\par
      SQLAllocHandle(...);     /* SQLAllocHandle call for env */\par
      SQLAllocHandle(...);     /* SQLAllocHandle call for dbc */\par
      SQLConnect(hdbc,...);    /* connect: see previous example */\par
      /* we could now call SQLAllocHandle(SQL_HANDLE_STMT,...);\par
        and then perform various functions related to the stmt */\par
      SQLDisconnect(hdbc);\par
      SQLFreeHandle(hdbc,...); /* SQLFreeHandle call for dbc */\par
      SQLFreeHandle(...); \}    /* SQLFreeHandle call for env */\par
\par
ODBC: The SQLDisconnect function has been around since ODBC 1.0. SQLDisconnect\par
causes automatic dropping of all statements and descriptors open on the\par
connection.\par
\par
SQLGetConnectAttr\par
\par
Function Prototype:\par
  SQLRETURN  SQLGetConnectAttr(\par
    SQLHDBC hdbc,                   /* 32-bit input */\par
    SQLINTEGER Attribute,           /* 32-bit input */\par
    SQLPOINTER Value,               /* pointer to 32-bit output */\par
    SQLINTEGER BufferLength,        /* 32-bit input */\par
    SQLINTEGER *StringLength        /* pointer to 32-bit output */\par
    );\par
\par
Job:\par
Get the value of a dbc attribute. The standard implementation of the\par
SQLGetConnectAttr function doesn't do anything important, but there might be\par
non-standard, implementation-defined attributes that you can retrieve using\par
SQLGetConnectAttr. The standard connection attribute has this #define in\par
sqlcli.h:\par
\par
#define SQL_ATTR_AUTO_IPD 10001\par
\par
It is, of course, an integer and may not be set by SQLSetConnectAttr.\par
SQL_ATTR_AUTO_IPD stands for SQL Attribute: Automatically Populate IPD. This\par
is a flag integer with a value of either TRUE (1) or FALSE (0).\par
SQL_ATTR_AUTO_IPD is the only standard attribute for a connection. If\par
SQL_ATTR_AUTO_IPD is TRUE, the DBMS "populates" the IPD (implementation\par
parameter descriptor) whenever you prepare an SQL statement. That means that\par
there will be, automatically, one parameter descriptor for every parameter\par
marker (symbolized by "?") inside your SQL statement. For example, if you\par
execute this SQL statement:\par
\par
   INSERT INTO Table_1 VALUES (?);\par
\par
there will be an automatic IPD. IPD contents are the subject of a later chapter.\par
\par
Algorithm:\par
If (hdbc is not a hdbc)\par
  return error: CLI-specific condition-invalid handle\par
Empty the dbc's diagnostics area.\par
If (Attribute <> SQL_ATTR_AUTO_IPD)\par
  return error: HY092 CLI-specific condition-invalid attribute identifier\par
If (Attribute == SQL_ATTR_AUTO_IPD)\par
  If (SQLConnect not done)\par
    return error: 08003 connection exception-connection does not exist\par
  Set *Value = value of dbc's SQL_ATTR_AUTO_IPD attribute field (0 or 1).\par
\par
Notes:\par
      ## There might be several implementation-defined attributes for\par
connections. The Standard allows for that. That's why BufferLength and\par
*Stringlength -- which aren't needed for SQL_ATTR_AUTO_IPD -- are defined\par
parameters. They're there in case someday it's necessary to return a character string value.\par
      ## Some things which we think of as "connection attributes" are not retrieved with SQLGetConnectAttr. They are:\par
            ## The default time zone offset -- get it by extracting the <time zone interval> from SQL's CURRENT_TIME function.\par
            ## The default Catalog -- get it by selecting from the INFORMATION_SCHEMA_CATALOG_NAME View, or by using SQLGetInfo with SQL_CATALOG_NAME.\par
            ## The default Schema -- get it by using SQLGetDiagField after any erroneous statement.\par
            ## The default Character set -- get it by using SQLGetDiagField after any erroneous statement.\par
            ## The default Collation -- get it by using SQLGetInfo with SQL_COLLATING_SEQUENCE.\par
            ## The <Connection name> -- get it by using SQLGetDiagField after any erroneous statement.\par
            ## The <SQL-server name> -- get it by using SQLGetInfo with SQL_DATA_SOURCE_NAME or SQLGetInfo with SQL_SERVER_NAME.\par
            ## The SQL-session user -- get it from SQL's SESSION_USER function, or by using SQLGetInfo with SQL_USER_NAME.\par
\par
Example:\par
  #include "sqlcli.h"\par
  SQLHDBC         hdbc;\par
  SQLINTEGER      popid;\par
  ...\par
  if (SQLGetConnectAttr(hdbc,SQL_ATTR_AUTO_IPD,&popid,NULL,NULL) < 0) \{\par
    printf("Error.\\n");\par
  else \{\par
    if (popid==1) printf("It's true.\\n");\par
    if (popid==0) printf("It's false (which means DBMS isn't full SQL\\n"); \}\par
  /* Going on from here: if popid is true, we can make SQL statements with\par
parameters (?s). Then we can assign buffers/variables based on the IPD. Or we\par
can make sure our currently-assigned parameters are okay. If pop is false: we\par
can still use parameters, but we have to fill in IPD values "manually". */\par
\par
ODBC: The SQLGetConnectAttr function is new to ODBC 3.0, but a very similar\par
function (SQLGetConnectOption) existed in ODBC 2.0. ODBC allows for 16\par
possible Attributes. One is SQL_ATTR_AUTO_IPD. Most of the others are related\par
to ODBC's optional features (timeout, trace file, network packet size, etc.).\par
\par
SQLSetConnectAttr\par
\par
Function Prototype:\par
  SQLRETURN SQLSetConnectAttr(\par
    SQLHDBC hdbc,             /* 32-bit input -- SQL-connection handle */\par
    SQLINTEGER Attribute,     /* 32-bit input */\par
    SQLPOINTER Value,         /* pointer to *ANY input */\par
    SQLINTEGER StringLength   /* 32-bit input */\par
    );\par
\par
Job:\par
Set the value of a dbc attribute.\par
\par
Algorithm:\par
If (hdbc is not really a handle of a dbc)\par
  return error: CLI-specific condition-invalid handle\par
Empty dbc's diagnostics area.\par
If (Attribute <> SQL_ATTR_AUTO_IPD)\par
  return error: HY092 CLI-specific condition-invalid attribute identifier\par
If (Attribute == SQL_ATTR_AUTO_IPD)\par
  /* the SQL_ATTR_AUTO_IPD attribute may not be set */\par
  return error: HY092 CLI-specific condition-invalid attribute identifier\par
\par
Notes:\par
      ## This function is useless unless there are implementation-defined dbc attributes.\par
\par
Example:\par
  #include "sqlcli.h"\par
  SQLHDBC hdbc;\par
  ...\par
  sqlreturn = SQLSetConnectAttr(hdbc,SQL_ATTR_AUTO_IPD,(void*)5,NULL);\par
  if (sqlreturn == SQL_SUCCESS || sqlreturn == SQL_SUCCESS_WITH_INFO) \{\par
    /* function call succeeded -- which it shouldn't */\par
  else\par
    /* function call failed, as expected */\par
\par
ODBC: The SQLSetConnectAttr function is new in ODBC 3.0, but ODBC 2.0 had a\par
broadly similar function (SQLSetConnectOption). ODBC allows for 16 dbc attributes, of various types.\par
\par
SQLFreeHandle(SQL_HANDLE_DBC,...)\par
\par
Function Prototype:\par
  SQLRETURN SQLFreeHandle(    /* function returns SMALLINT */\par
      SQLSMALLINT HandleType, /* 16-bit input, = SQL_HANDLE_DBC */\par
      SQLINTEGER Handle       /* 32-bit input, must be a hdbc */\par
      );\par
\par
Job:\par
Destroy a dbc.\par
\par
Algorithm:\par
If (HandleType == SQL_HANDLE_DBC)\par
   If (Handle is not really a handle of a dbc)\par
       return error: CLI-specific condition-invalid handle\par
   Empty the dbc's diagnostics area.\par
   If (dbc is still connected)\par
   /* you must call SQLDisconnect before you can destroy a dbc */\par
       return error: HY010 CLI-specific condition-function sequence error\par
   Deallocate the connection and anything associated with it.\par
   The handle becomes invalid.\par
\par
Notes:\par
      ## If SQLFreeHandle returns SQL_ERROR, then the handle is still live and you can get diagnostics.\par
      ## The name SQLFreeHandle is unfortunate. We are not "freeing a handle".\par
We are destroying the resource that the handle refers to. In embedded SQL\par
contexts, the preferred word for this process is "deallocate".\par
      ## Before you call SQLFreeHandle(SQL_HANDLE_DBC...), you must call SQLDisconnect. Therefore, by this time, there are no stmts or descs associated with the dbc.\par
\par
Example:\par
Typically, an SQL application ends with a flurry of freeings:\par
\par
      SQLDisconnect(hdbc);                /* ends the SQL-session */\par
      SQLFreeHandle(SQL_HANDLE_DBC,hdbc);\par
      SQLFreeHandle(SQL_HANDLE_ENV,henv);  /* ends the application */\par
\par
ODBC: The SQLFreeHandle function is new in ODBC 3.0. There will be some differences in behaviour if you use ODBC-specific features, such as tracing or environment sharing.\par
\par
SQLFreeConnect\par
\par
Function Prototype:\par
  SQLRETURN SQLFreeConnect(\par
    SQLHDBC hdbc                      /* 32-bit input */\par
    );\par
\par
Job:\par
Destroy a dbc. This is the reverse of the SQLAllocConnect function. SQLFreeConnect is redundant.\par
\par
Algorithm:\par
sqlreturn = SQLFreeConnect(hdbc);\par
is the same thing as\par
sqlreturn = SQLFreeHandle(SQL_HANDLE_DBC,hdbc);\par
\par
Notes:\par
      ## The Standard does not say that the SQLFreeConnect function is deprecated. Nevertheless, SQLFreeHandle(SQL_HANDLE_DBC,...) is more modern.\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLHENV     henv;\par
      SQLHDBC     hdbc;\par
      ...\par
      SQLAllocConnect(henv,&hdbc);\par
      ...\par
      SQLFreeConnect(hdbc);\par
      /* hdbc is now an invalid handle */\par
      ...\par
\par
ODBC: The SQLFreeConnect function has been in ODBC since version 1.0. The ODBC 3.0 manual deprecates it, suggesting that users should switch to using SQLFreeHandle(SQL_HANDLE_DBC...).\par
\par
And that's it for the dbc functions. In the next chapter, we'll take a look at the stmt functions.\par
\page\par
Chapter 43 -- SQL/CLI: stmt Functions\par
\par
In this chapter, we'll describe the third essential CLI resource: the stmt.\par
For CLI programs, the stmt is at the level below dbc and (usually) above desc.\par
The dbc may contain multiple stmts, and the stmt may contain four descs.\par
Here's a closeup view of a stmt:\par
\par
      ... from dbc\par
      | |\par
      | |\par
      v v\par
      -------------------------------------\par
      - [Attributes]                      -\par
      -                                   -\par
      - [Diagnostics]                     -\par
      -                                   -\par
      - [Cursor] [Result Set] [Statement] -\par
      -------------------------------------\par
      |           |           |           |\par
      |           |           |           |\par
      v           v           v           v\par
      ... to IPD  ... to IRD  ... to APD  ... to ARD\par
\par
There are six CLI functions for creating stmts, dropping stmts, getting stmt attributes and setting stmt attributes. Their descriptions follow.\par
\par
SQLAllocHandle(SQL_HANDLE_STMT,...)\par
\par
Function Prototype:\par
  SQLRETURN SQLAllocHandle (\par
    SQLSMALLINT HandleType,   /* 16-bit input = SQL_HANDLE_STMT */\par
    SQLINTEGER InputHandle,   /* 32-bit input, must be a hdbc */\par
    SQLINTEGER *OutputHandle  /* pointer to 32-bit output, a hstmt */\par
    );\par
\par
Job:\par
Allocate a stmt.\par
\par
Algorithm:\par
If (HandleType == SQL_HANDLE_STMT) \{\par
      If InputHandle is not a valid hdbc:\par
        return error: CLI-specific condition-invalid handle\par
      The dbc's diagnostics area is emptied.\par
      If hdbc is not "connected":\par
        Set *OutputHandle = 0\par
        return error: 08003 connection exception-connection does not exist\par
      If maximum number of stmts has already been made:\par
        Set *OutputHandle = 0\par
        return error: CLI-specific condition-limit on number of handles exceeded\par
      If (dbc's connection is not the current connection)\par
        Change current connection = dbc's connection\par
      If (memory-allocation failure while trying to allocate the new stmt)\par
        Set *OutputHandle = 0\par
        return error: CLI-specific condition-memory allocation error\par
      Make four descs: an IPD, an IRD, an APD, an ARD.\par
      (The four descs have some pre-set values, described in the next chapter.)\par
      Set *OutputHandle = handle of new stmt. \}\par
\par
Notes:\par
      ## You cannot allocate a stmt until you have allocated a dbc and connected (with SQLConnect).\par
      ## The handle of the new stmt is "unique", which means that there is no\par
other stmt in the env with the same value. This uniqueness would not be\par
guaranteed if there were two envs, but that's usually impossible anyway.\par
      ## The Standard calls it the "handle of the allocated SQL-statement",\par
but in all our examples we name it a hstmt, which is the general fashion.\par
      ## Keep the hstmt. You'll need it later for\par
SQLFreeHandle(SQL_HANDLE_STMT...) and for quite a few other things. In fact,\par
the majority of CLI functions (42 of the 62) take a hstmt as input.\par
\par
Example:\par
      #include "sqlcli.h"\par
      ...\par
      SQLHDBC     hdbc;\par
      SQLHSTMT    hstmt;\par
      ...\par
      sqlreturn = SQLAllocHandle(SQL_HANDLE_STMT,hdbc,&hstmt);\par
\par
ODBC: The SQLAllocHandle function is new in ODBC 3.0.\par
\par
SQLAllocStmt\par
\par
Function Prototype:\par
  SQLRETURN SQLAllocStmt(\par
    SQLHDBC hdbc,             /* 32-bit input, must be a hdbc */\par
    SQLHSTMT *hstmt           /* pointer to 32-bit output, a hstmt */\par
    );\par
\par
Job:\par
Make a new stmt.\par
\par
Algorithm:\par
SQLRETURN = SQLAllocStmt(hdbc,&hstmt);\par
is the same as\par
SQLRETURN = SQLAllocHandle(SQL_HANDLE_STMT,hdbc,&hstmt);\par
\par
Notes:\par
      ## The Standard does not deprecate SQLAllocStmt. All DBMSs should continue to support it. It is, however, redundant.\par
\par
Example:\par
      #include "sqlcli.h"\par
      ...\par
      SQLHDBC     hdbc;\par
      SQLHSTMT    hstmt;\par
      ...\par
      SQLAllocStmt(hdbc,&hstmt);\par
      ...\par
\par
ODBC: The SQLAllocStmt function has been in ODBC since version 1.0. The ODBC\par
3.0 manual deprecates it, suggesting that users should switch to using\par
SQLAllocHandle(SQL_HANDLE_STMT...).\par
\par
SQLGetStmtAttr\par
\par
Function Prototype:\par
  SQLRETURN SQLGetStmtAttr(\par
      SQLHSTMT hstmt,               /* 32-bit input -- statement handle */\par
      SQLINTEGER Attribute,         /* 32-bit input */\par
      SQLPOINTER Value,             /* pointer to ANY* output */\par
      SQLINTEGER BufferLength,      /* 32-bit input */\par
      SQLINTEGER *StringLength);    /* pointer to 32-bit output */\par
\par
Job:\par
Retrieve one attribute of a stmt.\par
\par
Algorithm:\par
      If (Attribute == SQL_ATTR_APP_ROW_DESC)\par
        Set *Value = (SQLHDESC) stmt's ARD handle.\par
      If (Attribute == SQL_ATTR_APP_PARAM_DESC)\par
        Set *Value = (SQLHDESC) stmt's APD handle.\par
      If (Attribute == SQL_ATTR_IMP_ROW_DESC)\par
        Set *Value = (SQLHDESC) stmt's IRD handle.\par
      If (Attribute == SQL_ATTR_IMP_PARAM_DESC)\par
        Set *Value = (SQLHDESC) stmt's IPD handle.\par
      If (Attribute == SQL_ATTR_CURSOR_SCROLLABLE)\par
        If (DBMS supports scrollable Cursors)\par
          Set *Value = "Cursor scrollable" attribute (0 or 1) (false or true)\par
        Else\par
          return error: HYC00 CLI-specific condition-optional feature not implemented\par
      If (Attribute == SQL_ATTR_CURSOR_SENSITIVITY)\par
        If (implementation supports sensitive Cursors)\par
          Set *Value = "Cursor sensitivity" attribute (0 or 1 or 2)\par
        Else\par
          return error: HYC00 CLI-specific condition-optional feature not implemented\par
      If (Attribute == SQL_ATTR_METADATA_ID)\par
        Set *Value = "metadata ID" attribute (0 or 1)\par
      If (Attribute == SQL_ATTR_CURSOR_HOLDABLE)\par
        If (implementation supports holdable Cursors)\par
          Set *Value = "Cursor holdable" attribute (0 or 1)\par
        Else\par
          return error: HYC00 CLI-specific condition-optional feature not implemented\par
      If (Attribute == none of the above)\par
        return error: HY092 CLI-specific condition-invalid attribute identifier\par
\par
Notes:\par
      ## Here is a list of the standard stmt attributes:\par
VALUE  #DEFINE IN SQLCLI.H          SETTABLE?  DATA TYPE   REMARKS\par
-3     SQL_ATTR_CURSOR_HOLDABLE     yes        SQLINTEGER  ANSI SQL3 only\par
                                                           0=nonholdable\par
                                                           1=holdable\par
-2     SQL_ATTR_CURSOR_SENSITIVITY  yes        SQLINTEGER  0=asensitive\par
                                                           1=insensitive\par
                                                           2=sensitive\par
-1     SQL_ATTR_CURSOR_SCROLLABLE   yes        SQLINTEGER  ANSI SQL3 only\par
                                                           0=nonscrollable\par
                                                           1=scrollable\par
10010  SQL_ATTR_APP_ROW_DESC        yes        SQLHDESC    ARD\par
10011  SQL_ATTR_APP_PARAM_DESC      yes        SQLHDESC    APD\par
10012  SQL_ATTR_IMP_ROW_DESC        no         SQLHDESC    IRD\par
10013  SQL_ATTR_IMP_PARAM_DESC      no         SQLHDESC    IPD\par
10014  SQL_ATTR_METADATA_ID         yes        SQLINTEGER  SQL3 only\par
                                                           0=false\par
                                                           1=true\par
Other stmt attributes may be defined in particular implementations. (Reminder:\par
SQLHDESC stands for "handle of a desc", a 32-bit value.)\par
      ## When you allocate a stmt (with SQLAllocHandle or SQLAllocStmt), the\par
DBMS automatically sets up four descs: the ARD, the APD, the IRD and the IPD.\par
You can pick up the handles of these descs by calling SQLGetStmtAttr with\par
SQL_ATTR_APP_ROW_DESC, SQL_ATTR_APP_PARAM_DESC, SQL_ATTR_IMP_ROW_DESC and\par
SQL_ATTR_IMP_PARAM_DESC, respectively -- you'll need these because there are\par
several CLI functions which use a desc handle as input.\par
      ## When you get a result set (by calling SQLExecDirect or SQLExecute for\par
a query expression such as "SELECT ..."), the DBMS implicitly declares a\par
Cursor. What kind of Cursor? That depends on the "cursor" attributes:\par
            ## SQL_ATTR_CURSOR_SCROLLABLE\par
if 0 = "false" = SQL_NONSCROLLABLE: you can only fetch NEXT.\par
if 1 = "true" = SQL_SCROLLABLE: you can fetch FIRST, NEXT, PRIOR, LAST,\par
ABSOLUTE and RELATIVE.\par
The default is 0, but you can call SQLSetStmtAttr to change that.\par
            ## SQL_ATTR_CURSOR_SENSITIVITY\par
if 0 = SQL_ASENSITIVE = SQL_UNSPECIFIED: sensitivity isn't known.\par
if 1 = SQL_INSENSITIVE: changes made elsewhere won't be seen here.\par
if 2 = SQL_SENSITIVE: changes made elsewhere will be seen here.\par
The default is 0, but you can call SQLSetStmtAttr to change that.\par
            ## SQL_ATTR_CURSOR_HOLDABLE\par
if 0 = "false" = SQL_NONHOLDABLE: Cursor disappears at transaction end.\par
if 1 = "true" = SQL_HOLDABLE: Cursor remains at transaction end.\par
The default is probably 0 (you'd have to call SQLGetInfo to be certain) but\par
you can call SQLSetStmtAttr to change that.\par
      ## When you use a Catalog function (such as SQLColumns or SQLTables),\par
the DBMS has to search the "metadata", that is, the INFORMATION_SCHEMA Views.\par
The SQL_ATTR_METADATA_ID attribute indicates how searches are conducted with\par
Catalog functions. We discuss this in more detail in our chapter on SQL/CLI\par
Catalog functions.\par
      ## The BufferLength and StringLength parameters aren't currently in use.\par
They're there in case we ever have a statement attribute that contains a string value.\par
\par
Example:\par
      #include "sqlcli.h"\par
      HSTMT hstmt;\par
      HDESC hipd;\par
      ...\par
      SQLGetStmtAttr(\par
            hstmt,                        /* handle of stmt */\par
            SQL_ATTR_IMP_PARAM_DESC,      /* we want the IPD handle */\par
            &hipd,                        /* put the handle here */\par
            NULL,                          /* "don't care" */\par
            NULL);                         /* "don't care" */\par
\par
ODBC: The SQLGetStmtAttr function is new in ODBC 3.0 (in ODBC 2.0 there was a\par
nearly-equivalent function, SQLGetStmtOption).\par
\par
SQLSetStmtAttr\par
\par
Function Prototype:\par
  SQLRETURN SQLSetStmtAttr(\par
    SQLHSTMT hstmt,              /* 32-bit input - statement handle */\par
    SQLINTEGER Attribute,        /* 32-bit input */\par
    SQLPOINTER Value,            /* pointer to ANY* input */\par
    SQLINTEGER StringLength      /* 32-bit input */\par
    );\par
\par
Job:\par
Set an attribute of the stmt -- to change the DBMS's behaviour for Cursor\par
control, to change the handle used for an application desc, or to change the\par
search method for Catalog functions.\par
\par
There are eight standard stmt attributes, listed in the previous section.\par
\par
Algorithm:\par
      If (Attribute is not one of the settable attributes)\par
        return error: HY092 CLI-specific condition-invalid attribute identifier\par
      If (Attribute == SQL_ATTR_APD_HANDLE)\par
        If (*Value is not the handle of a desc)\par
          return error: HY024 CLI-specific condition-invalid attribute value\par
        If (desc's SQL_ALLOC_TYPE field == 'AUTOMATIC')\par
          If (desc is not stmt's default/automatic APD)\par
            return error: HY017 CLI-specific condition-invalid use of automatically-allocated descriptor handle.\par
         Desc becomes associated with this stmt, as its APD, non-exclusively.\par
      If (Attribute == SQL_ATTR_ARD_HANDLE)\par
        If (*Value is not the handle of a desc)\par
          return error: HY024 CLI-specific condition-invalid attribute value\par
        If (desc's ALLOC_TYPE field == 'AUTOMATIC')\par
          If (desc is not stmt's default/automatic ARD)\par
            return error: HY017 CLI-specific condition-invalid use of automatically-allocated descriptor handle.\par
         Desc becomes associated with this stmt, as its ARD, non-exclusively.\par
      If (Attribute == SQL_ATTR_CURSOR_SCROLLABLE)\par
        If (the DBMS does not support scrollable Cursors)\par
          return error: HYC00 CLI-specific condition-optional feature not implemented\par
        If (stmt already has an open Cursor)\par
          /* You can't change how a Cursor works while the Cursor is open */\par
          return error: HY011 CLI-specific condition-attribute cannot be set now\par
        If (*Value is not SQL_SCROLLABLE (1) or SQL_NONSCROLLABLE (0))\par
          return error: HY011 CLI-specific condition-attribute cannot be set now\par
        Stmt's Cursor's "scrollable" attribute = *Value.\par
      If (Attribute == SQL_ATTR_CURSOR_SENSITIVITY)\par
        If (the DBMS does not support sensitive Cursors)\par
          return error: HYC00 CLI-specific condition-optional feature not implemented\par
        If (there is already an open Cursor for stmt)\par
          return error: HY011 CLI-specific condition-attribute cannot be set now\par
        If (*Value is not SQL_SENSITIVE (2) or SQL_INSENSITIVE (1) or UNSPECIFIED (0))\par
          return error: HY024 CLI-specific condition-invalid attribute value\par
        Stmt's Cursor's "sensitivity" attribute = *Value.\par
      If (Attribute == SQL_ATTR_METADATA_ID)\par
        If (*Value not TRUE or FALSE)\par
          return error: HY024 CLI-specific condition-invalid attribute value\par
        Set stmt's "metadata id" attribute = *Value.\par
      If (Attribute == SQL_ATTR_CURSOR_HOLDABLE)\par
        If (the DBMS does not support holdable Cursors)\par
          return error: HYC00 CLI-specific condition-optional feature not implemented\par
        If (stmt already has an open Cursor)\par
          return error: HY011 CLI-specific condition-attribute cannot be set now\par
        If (*Value is not SQL_HOLDABLE (1) or SQL_NONHOLDABLE (0))\par
          return error: HY024 CLI-specific condition-invalid attribute value\par
        Set stmt's Cursor's "holdable" attribute = Value.\par
\par
Notes:\par
      ## The specification allows for implementation-defined attributes and\par
for the possibility of future change. That's why the StringLength parameter\par
exists, although it's not currently used.\par
      ## SQL_ATTR_APP_ROW_DESC and SQL_ATTR_APP_PARAM_DESC are listed as\par
settable attributes, so you can change the stmt's ARD and APD. (You can't\par
change the stmt's IRD and IPD.) The Value parameter must point to the handle\par
of a user desc. This option makes it possible to save or share application descs.\par
      ## SQL_ATTR_CURSOR_SCROLLABLE and SQL_ATTR_CURSOR_HOLDABLE are used to\par
specify whether a stmt's Cursor is "scrollable" and/or "holdable".\par
      ## SQL_ATTR_METADATA_ID is an abbreviation for "the attribute for\par
metadata identifiers", for example the names of Tables in INFORMATION_SCHEMA.\par
      ## It's easy to forget that the Value parameter is described as\par
SQLPOINTER. Don't make the mistake of passing "hdesc" (handle of a desc); pass\par
"&hdesc" (address of a handle of a desc) instead.\par
\par
Example:\par
Change the settings of all settable stmt attributes. This example only shows\par
what the syntax looks like for the various options. More realistic examples\par
will appear in the chapters on "Cursors", "descs", and "Catalog functions".\par
\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  SQLHDESC hdesc1,hdesc2;\par
  SQLINTEGER scrollable = SQL_SCROLLABLE;\par
  SQLINTEGER sensitivity = SQL_INSENSITIVE;\par
  SQLINTEGER metadata_id = SQL_FALSE;\par
  SQLINTEGER holdable = SQL_NONHOLDABLE;\par
  ...\par
  SQLSetStmtAttr(hstmt,SQL_ATTR_APP_ROW_DESC,&hdesc1,NULL);\par
  SQLSetStmtAttr(hstmt,SQL_ATTR_APP_PARAM_DESC,&hdesc2,NULL);\par
  SQLSetStmtAttr(hstmt,SQL_ATTR_CURSOR_SCROLLABLE,&scrollable,NULL);\par
  SQLSetStmtAttr(hstmt,SQL_ATTR_CURSOR_SENSITIVITY,&sensitivity,NULL);\par
  SQLSetStmtAttr(hstmt,SQL_ATTR_METADATA_ID,&metadata_id,NULL);\par
  SQLSetStmtAttr(hstmt,SQL_ATTR_CURSOR_HOLDABLE,&holdable,NULL);\par
\par
ODBC: The SQLSetStmtAttr function is new in ODBC 3.0 but there was a similar function in ODBC 2.0 (SQLSetStmtOption).\par
\par
SQLFreeHandle(SQL_HANDLE_STMT,...)\par
\par
Function Prototype:\par
  SQLRETURN SQLFreeHandle(    /* function returns SMALLINT */\par
      SQLSMALLINT HandleType, /* 16-bit input, = SQL_HANDLE_STMT */\par
      SQLINTEGER Handle       /* 32-bit input, must be a hstmt */\par
      );\par
\par
Job:\par
Destroy a stmt.\par
\par
Algorithm:\par
      If (HandleType == SQL_HANDLE_STMT)\par
        If (Handle is not a hstmt)\par
          return error: CLI-specific condition-invalid handle\par
        Empty the stmt's diagnostics area.\par
        The stmt's dbc becomes the "current dbc".\par
        If (there is a deferred parameter associated with stmt)\par
          return error: HY010 CLI-specific condition-function sequence error\par
        If (there is an open Cursor associated with the stmt)\par
          Throw away all information about the Cursor's result set\par
           Close the Cursor\par
        Deallocate the stmt's four automatic descs: ARD, APD, IRD, IPD.\par
        Deallocate stmt.\par
\par
Notes:\par
      ## Correctly speaking, this functions "frees the stmt"; it doesn't merely free the stmt's handle.\par
      ## The DBMS calls SQLFreeHandle(SQL_HANDLE_STMT...) implicitly, for all stmts in a dbc, as part of an SQLDisconnect operation.\par
      ## There is a mention here of a "current" dbc. If there are multiple dbcs, the DBMS will implicitly switch, when necessary, to the dbc whose handle\par
is passed in the function call (or, as in this case, to the dbc associated\par
with the stmt whose handle is passed in the function call). This switching is\par
transparent. There is no need, when using the CLI, for any analogue of the\par
basic SQL "SET CONNECTION ..." statement.\par
      ## Freeing a statement causes an implicit "close Cursor" operation, but not an implicit "end transaction" operation.\par
      ## Quite often, programmers allocate a stmt only once, and re-use the same stmt throughout the SQL-session. So SQLFreeHandle(SQL_HANDLE_STMT...) may be seen only infrequently.\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLHDBC     hdbc;\par
      SQLHSTMT    hstmt;\par
      ...\par
      SQLAllocHandle(SQL_HANDLE_STMT,hdbc,&hstmt);\par
      ...\par
      SQLFreeHandle(SQL_HANDLE_STMT,hstmt);\par
\par
ODBC: The SQLFreeHandle function is new in ODBC 3.0.\par
\par
SQLFreeStmt\par
\par
Function Prototype:\par
  SQLRETURN SQLFreeStmt(\par
    SQLHSTMT hstmt,            /* 32-bit input */\par
    SQLSMALLINT Option;        /* 16-bit input */\par
    );\par
\par
Job:\par
SQLFreeStmt has five different jobs, depending on the value of Option:\par
      ## If Option is 0, SQLFreeStmt's job is to close a Cursor.\par
      ## If Option is 1, SQLFreeStmt's job is to destroy a stmt.\par
      ## If Option is 2, SQLFreeStmt's job is to unbind Columns.\par
      ## If Option is 3, SQLFreeStmt's job is to unbind parameters.\par
      ## If Option is 4, SQLFreeStmt's job is to reallocate.\par
\par
Algorithm:\par
      If (Option == SQL_CLOSE (0))\par
        If (there is a Cursor)\par
          Cancel all information about the result set.\par
          Close the Cursor.\par
      If (Option == SQL_DROP (1))\par
        /* SQLFreeStmt(...,SQL_DROP) is the reverse of SQLAllocStmt(...).\par
        sqlreturn = SQLFreeStmt(hstmt,SQL_DROP);\par
        is the same as:\par
        sqlreturn = SQLFreeHandle(SQL_HANDLE_STMT,hstmt);\par
      If (Option == SQL_UNBIND (2))\par
        /* This affects the application row descriptor (ARD). In\par
           effect, it cancels out any SQLBindCol calls made on stmt. */\par
        For (i=1; i<=ARD.SQL_DESC_COUNT;++i)\par
          Set ARD.IDA[i].SQL_DESC_DATA_POINTER = 0\par
      If (Option == SQL_RESET_PARAMS (3))\par
        /* This affects the application parameter descriptor (APD). In\par
           effect, it cancels out any SQLBindParameter calls made on stmt. */\par
        For (i=1; i<=APD.SQL_DESC_COUNT;++i)\par
          Set APD.IDA[i].SQL_DESC_DATA_POINTER = 0\par
      If (Option == SQL_REALLOCATE (4))\par
        Destroy the stmt's statement and Cursor parts\par
      If (Option == none of the above)\par
        return error: HY092 CLI-specific condition-invalid attribute identifier\par
\par
Notes:\par
      ## Regrettably, we are forced to mention a few details before their time\par
for full discussion is come. For the immediate purpose, we hope it is enough\par
to say that:\par
            ## RESULT SETS are temporary Tables which result from the\par
execution of an SQL query.\par
            ## Cursors are named interface objects through which result sets\par
can be retrieved one row at a time.\par
            ## BINDINGS are associations between a host program's host\par
variables (i.e.: pointers to data buffers and indicator variables) and their\par
corresponding SQL Objects (Columns and/or parameter markers). Often Columns\par
are bound with the SQLBindCol function, while parameters are bound with the\par
SQLBindParameter function.\par
      ## Because SQLFreeHandle is now the main function for freeing resources,\par
the name SQLFreeStmt is now a misnomer -- we don't use SqlFreeStmt for freeing\par
stmts nowadays. However, it maintains a residue of usefulness. It's good for\par
"partial stmt freeing", freeing things associated with stmts that might be\par
taking up space, or whose continued existence might cause conflict with other\par
operations.\par
      ## SQLFreeStmt(...,SQL_CLOSE) does exactly the same thing as the\par
SQLCloseCursor function, except for one detail: if there is no Cursor\par
currently open, then SQLCloseCursor returns an error, while\par
SQLFreeStmt(...,SQL_CLOSE) does not return an error.\par
      ## SQLFreeStmt(hstmt,SQL_DROP) is now just another way of saying:\par
SQLFreeHandle(SQL_HANDLE_STMT,hstmt).\par
      ## SQLFreeStmt(...,SQL_UNBIND) and SQLFreeStmt(...,SQL_RESET_PARAMS) are\par
handy ways of "disassociating" the application's RAM from the DBMS, so that\par
there won't be inadvertent access to memory that's no longer valid. Here's an example:\par
\par
    x=malloc(1024);                   /* malloc an area */\par
    SQLBindCol(...,x,...);            /* Now there is a binding to the malloc'd area */\par
    free(x);                          /* uh oh. x is no longer a valid pointer */\par
    SQLFreeStmt(...,UNBIND ColumnS);  /* okay, chances of GPF are reduced */\par
\par
However, only the "data pointer" field is cleared -- not the "indicator\par
pointer" field (this is probably an inadvertent omission from the Standard).\par
      ## SQLFreeStmt(...,SQL_REALLOCATE) can be used to clear parts of stmts:\par
            ## The "statement" (a copy of the SQL statement string which was last prepared or executed for this stmt, including "select" source statements).\par
            ## The "Cursor", including the Cursor's result set. These things\par
take up space, so presumably SQLFreeStmt(...,SQL_REALLOCATE) is useful under\par
low-memory conditions. But normally it's unnecessary: "statement" and "Cursor"\par
are superseded in any case when an SQL statement is re-prepared/re-executed.\par
\par
Example:\par
Since SQLFreeStmt(...,SQL_DROP) is the reverse of SQLAllocStmt(...), we show both these obsolescent calls together.\par
\par
  #include "sqlcli.h"\par
  SQLHDBC hdbc;\par
  SQLHSTMT hstmt;\par
  ...\par
  SQLAllocStmt(hdbc,&hstmt);        /* allocate a stmt */\par
  SQLBindCol(hstmt,...);            /* bind a stmt Column */\par
  SQLFreeStmt(hstmt,SQL_UNBIND);    /* unbind all stmt Columns */    ...\par
  SQLFreeStmt(hstmt,SQL_DROP);      /* free a stmt */\par
\par
ODBC: The SQLFreeStmt function has been in ODBC since version 1.0. The ODBC\par
3.0 manual deprecates the use of SQLFreeStmt(...,SQL_DROP), suggesting that\par
the user should switch to using SQLFreeHandle(SQL_HANDLE_STMT,...). The ODBC\par
action for SQL_UNBIND is different: ARD.SQL_DESC_COUNT is set to 0. The ODBC\par
action for SQL_RESET_PARAMS is different: APD.SQL_DESC_COUNT is set to 0. The\par
SQL_REALLOCATE option is not supported.\par
\par
And that's it for the stmt functions. In the next chapter, we'll take a look at the statement functions.\par
\page\par
Chapter 44 -- SQL/CLI Statement Functions\par
\par
Of the 62 CLI functions, only three actually handle what we know as "SQL\par
statements". There are two steps in SQL statement handling: the "prepare" step\par
and the "execute" step. You can do these steps separately, using the\par
SQLPrepare and SQLExecute functions or you can roll them together and just use\par
the SQLExecDirect function. The following flowchart shows the steps involved:\par
\par
      [[ SQL statement ]]\par
      |\par
      |\par
      |     -\par
      >   -   -\par
        -       -               ----------------\par
      -  Is the  -              -              -\par
     - statement - ---> no ---> - Return error -\par
      -  valid?  -              - diagnostics  -\par
        -       -               -              -\par
          -   -                 ----------------\par
            -\par
           |\par
           |               PREPARE PHASE\par
           v\par
          yes\par
           |\par
           |\par
           v\par
      -----------------------------\par
      - Make "Prepared statement" -\par
      - associated with stmt      -\par
      -----------------------------\par
          |\par
          |\par
          v\par
      ------------------------------\par
      - Execute prepared statement -        EXECUTE PHASE\par
      ------------------------------\par
          |\par
          |\par
          v\par
           -\par
          -   -\par
        -       -\par
      -  Is the  -              --------\par
     - statement - ---> no ---> - done -\par
      - a query? -              --------\par
        -       -\par
          -   -\par
            -\par
           |\par
           |\par
           v\par
          yes\par
           |\par
           |\par
           v\par
      ------------------------------------\par
      - associate Cursor with result set -\par
      ------------------------------------\par
           |\par
           v\par
      --------\par
      - done -\par
      --------\par
\par
Preparable SQL statements\par
\par
Some SQL statements are not preparable. Here's the list of all possibilities, showing whether the SQL statement can be prepared.\par
\par
SQL STATEMENT         SQL STATEMENT CLASS  PREPARABLE?\par
ALTER                 Schema               yes\par
CALL                  control              yes\par
CLOSE                 data                 NO\par
COMMIT                transaction          NO    [Note 2]\par
CONNECT               Connection           NO    [Note 1]\par
CREATE                Schema               yes\par
DELETE                data change          yes\par
DISCONNECT            Connection           NO    [Note 1]\par
DROP                  Schema               yes\par
FETCH                 data                 NO\par
GET DIAGNOSTICS       diagnostics          NO\par
GRANT                 Schema               yes\par
INSERT                data change          yes\par
OPEN                  data                 NO\par
RELEASE SAVEPOINT     transaction          yes\par
RETURN                control              yes\par
REVOKE                Schema               yes\par
ROLLBACK              transaction          NO    [Note 2]\par
SAVEPOINT             transaction          yes\par
SELECT with no INTO   query                yes\par
SELECT with INTO      query                NO\par
SET CONNECTION        Connection           NO    [Note 1]\par
SET CONSTRAINTS MODE  transaction          yes\par
SET LOCAL TIME ZONE   SQL-session          yes\par
SET ROLE              SQL-session          yes\par
SET SESSION           SQL-session          yes\par
SET TRANSACTION       transaction          yes\par
START TRANSACTION     transaction          yes\par
UPDATE                data change          yes\par
\par
Notes: The "preparable statements" for embedded SQL are as above, except:\par
      ## [Note 1] Connection statements are "directly executable" with embedded SQL, but not preparable.\par
      ## [Note 2] COMMIT and ROLLBACK are "preparable" with embedded SQL.\par
\par
There are some SQL statements which you may use in other contexts (such as\par
embedded SQL or SQL/PSM), but their use is inappropriate with the CLI because\par
their functionality is included in special function calls which require a henv\par
or hdbc as the input handle --  and the SQLPrepare function requires a hstmt.\par
For such SQL statements there will usually be an analogous CLI function. For\par
example: CONNECT and DISCONNECT statements are not preparable, but there are\par
SQLConnect and SQLDisconnect functions; GET DIAGNOSTICS is not preparable but\par
there are SQLGetDiag... functions; COMMIT and ROLLBACK are not preparable but\par
there is an SQLEndTran ("end transaction") function.\par
\par
SQLPrepare\par
\par
Function Prototype:\par
  SQLRETURN SQLPrepare(\par
    SQLHSTMT hstmt,           /* 32-bit input */\par
    SQLCHAR *StatementText,   /* pointer to CHAR* input = SQL statement */\par
    SQLINTEGER TextLength     /* 32-bit input */\par
    );\par
\par
Job:\par
Check a SQL statement for syntax or access errors. If all is well, make this\par
string the "prepared SQL statement" associated with stmt. It is then ready to execute.\par
\par
Algorithm:\par
      If (there is an open Cursor associated with stmt)\par
        /* You must close Cursor before re-using the stmt */\par
        return error: 24000 - invalid Cursor state -\par
      Get the string using StatementText and TextLength. This is a typical\par
example of a pass of a character string, except that TextLength is an integer\par
rather than a smallint. TextLength may be SQL_NTS.\par
      If the TextLength value doesn't make sense:\par
        return error: HY090 CLI-specific condition-invalid string length or buffer length\par
      If (the string contains "DELETE|UPDATE ... WHERE CURRENT OF ...")\par
        If (Cursor is not the name of a Cursor associated with another stmt of the same dbc)\par
          return error: 34000 invalid Cursor name\par
        /* Note the word "another" -- don't use positioned UPDATE|DELETE with the same stmt you executed the SELECT with */\par
      If (statement violates a format rule, syntax rule, or access rule)\par
      Or (statement is not a preparable statement)\par
      Or (statement is a <simple comment>)\par
      Or (statement has a ? parameter marker in an invalid position)\par
        return error: (exact error depends on the nature of the violation)\par
                      (often 42000 Syntax error or access rule violation)\par
\par
      Determine the data types of the ? parameter markers.\par
      /* An example of a ? in an invalid position is: SELECT -? FROM t; */\par
      Destroy some things which are associated with stmt, left over from\par
      the last time we called SQLPrepare for the same stmt:\par
            -- the "prepared statement", and\par
            -- the "Cursor" (if any).\par
      /* Leftovers exist because stmts are re-usable objects. */\par
      Note: destroying a Cursor can have a cascading effect: if there is\par
      another prepared statement that references that Cursor (e.g. DELETE\par
      FROM t WHERE CURRENT OF <Cursor name>), it too is destroyed.\par
      Note: destroying a Cursor does not imply destroying the Cursor name.\par
\par
      Now we have "prepared". The statement is called a "prepared statement".\par
\par
      If (prepared statement is a SELECT)\par
        /* The prepared SELECT statement is called the "select source". */\par
        If (there is no Cursor name) (as set by SQLSetCursorName)\par
          Set Cursor name = an implementation-dependent identifier beginning\par
          with the letters SQL_CUR or SQLCUR.\par
\par
Notes:\par
      ## You can process SQL statements in two separate phases using the\par
SQLPrepare and SQLExecute functions. Usually, you would want to do the two\par
phases separately if the SQL statement appeared in a loop -- you'd call\par
SQLPrepare before entering the loop, and you'd call SQLExecute within the\par
loop. That way, you'd only be preparing once, but executing many times. If you\par
used the alternative -- SQLExecDirect -- you'd be preparing and executing with\par
every iteration of the loop.\par
      ## The prepare and execute phases of SQL resemble the compile and\par
execute phases of most computer languages. If we were going to make a\par
distinction between preparing and compiling, we would point out that: (a)\par
preparing fails if an SQL statement refers to an inaccessible Table, but\par
compiling does not fail if a file is unavailable at compile time; and (b)\par
compiling results in executable code, but preparing results only in a\par
descriptive "plan" which needs some interpretation at run time. Such, at\par
least, is the state of SQL today. There are no true SQL compilers.\par
      ## If SQLPrepare finds an error, the stmt's state is unchanged. A SQL\par
statement that was previously prepared continues to be "live". For example:\par
\par
   SQLPrepare(hstmt,"UPDATE t SET t_column = t_column + 1;",SQL_NTS);\par
   SQLExecute(hstmt);\par
   SQLPrepare(hstmt,"SELCT * FROM t;",SQL_NTS); /* sic-"SELCT" */\par
   SQLExecute(hstmt);\par
\par
The second SQLPrepare won't work because "SELCT" is bad SQL syntax -- but what\par
happens to the SQLExecute that follows it? Answer: it executes the "UPDATE t\par
..." statement a second time. Silly, eh? Well it wouldn't happen if we had\par
made sure to check what the SQLPrepare call returned.\par
      ## Some DBMSs do nothing during SQLPrepare. They defer even syntax\par
checking until SQLExecute time. You have to be ready for such non-standard\par
behaviour: do not assume that an SQL statement is grammatical until it's been executed.\par
      ## There is no "UnPrepare" function. Instead, prepared statements are removed by:\par
            ## Calling SQLPrepare again for the same stmt.\par
            ## Calling SQLFreeStmt(...,SQL_REALLOCATE).\par
            ## Cascade effects -- for example, if the prepared statement depends on a Cursor which is destroyed.\par
            ## (Usually) calling SQLEndTran (the "transaction-end" function\par
which is used instead of COMMIT or ROLLBACK). It is best to assume that SQL\par
statements need re-preparing after transaction end, though some DBMSs preserve\par
prepared statements. You can find out what your DBMS does by calling the\par
SQLGetInfo function. (In any case, if a Cursor is holdable, its result set\par
survives if the termination is with COMMIT.)\par
      ## In standard SQL, the SQL statement does not have to end with a semicolon.\par
\par
Example:\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  ...\par
  SQLPrepare(hstmt,"DELETE FROM t",SQL_NTS);\par
  /* Now we need to call SQLExecute. */\par
\par
ODBC: The SQLPrepare function has been part of ODBC since ODBC version 1.0.\par
\par
SQLExecute\par
\par
Function Prototype:\par
  SQLRETURN SQLExecute(\par
    SQLHSTMT hstmt                        /* 32-bit input */\par
    );\par
\par
Job:\par
Execute a prepared SQL statement. You must do an SQLPrepare first.\par
\par
Algorithm:\par
      If (SQLPrepare has not been performed for this stmt)\par
        return error: HY010 CLI-specific condition-function sequence error\par
      If (there is an open Cursor associated with this stmt)\par
        /* This would happen if you don't close the Cursor after the last\par
           execution of a SELECT statement; see SQLCloseCursor */\par
        return error: 24000 Invalid Cursor state -\par
      If (there are input parameters)\par
        Get parameter addresses and do appropriate "casting" (described in our chapter on SQL/CLI desc functions)\par
      Execute the prepared statement. It is now the "executed statement".\par
      If (the statement was SELECT)\par
        Set up a Cursor (described in our chapter on SQL/CLI Cursor functions)\par
        Change the row descriptors (described in our chapter on SQL/CLI desc functions)\par
      If (there are output parameters)\par
        Get parameter addresses and do appropriate "casting"\par
      Change the Diagnostics Area\par
\par
Since there are many possible SQL statements, the range of possible problem\par
conditions is wide -- see especially the SQLSTATE errors in class 22000 (data\par
exception) and class 23000 (integrity constraint violation) in our chapter on\par
SQL/CLI diagnostics. Watch also for warnings and even "No data" conditions\par
(for example, execution of "UPDATE Table_1 SET column_1 = 0;" will result in\par
SQLSTATE 02000 "Data not found" if there are no rows in TABLE_1).\par
\par
Notes:\par
      ## Calls to SQLExecute always follow calls to SQLPrepare (for the same stmt), but other function calls may intervene.\par
\par
Example:\par
In this example we prepare and execute two SQL statements. We use two\par
different stmts, so that we can get all the preparing done before we start executing.\par
\par
  #include "sqlcli.h"\par
  ...\par
  SQLHSTMT hstmt1, hstmt2;\par
  ...\par
  SQLPrepare(hstmt1,"INSERT INTO t VALUES (1)",SQL_NTS);\par
  SQLPrepare(hstmt2,"INSERT INTO t VALUES (2)",SQL_NTS);\par
  ...\par
  SQLExecute(hstmt1);\par
  SQLExecute(hstmt2);\par
\par
ODBC: The SQLExecute function has been around since ODBC 1.0.\par
\par
SQLExecDirect\par
\par
Function Prototype:\par
  SQLRETURN  SQLExecDirect(\par
    SQLHSTMT hstmt,                 /* 32-bit input -- statement handle */\par
    SQLCHAR *StatementText,         /* CHAR* input */\par
    SQLINTEGER TextLength           /* 32-bit input */\par
    );\par
\par
Job:\par
Prepare and execute an SQL statement.\par
\par
Algorithm:\par
SQLRETURN = SQLExecDirect(hstmt,"text",text-length);\par
is the same as\par
SQLRETURN = SQLPrepare(hstmt,"text",text-length);\par
if (sqlreturn <> SQL_ERROR && sqlreturn <> SQL_INVALID_HANDLE) \{\par
   sqlreturn = SQLExecute(hstmt); \}\par
\par
Notes:\par
      ## Technically, SQLExecDirect is redundant: you can do the same thing by\par
calling SQLPrepare and SQLExecute. But programmers prefer to use SQLExecDirect\par
for SQL statements that will only be prepared and executed once.\par
      ## Since SQLExecDirect includes a "prepare" step, it follows that\par
non-preparable SQL statements cannot be arguments of SQLExecDirect. Such\par
statements include CONNECT, DISCONNECT, COMMIT, ROLLBACK -- refer to the list\par
of "Preparable and Non-Preparable SQL Statements", shown earlier.\par
      ## Does the size of a string include the null terminator?\par
            ## If you are passing a string's octet length: NO. For example:\par
\par
   SQLExecDirect(hstmt,"abcd",4);\par
\par
            ## If you are passing (maximum) target octet length: YES. For example:\par
\par
   char x[8];\par
   ...\par
   SQLGetCursorName(hstmt,x,8,&strlen_or_ind);\par
\par
            ## If the DBMS is returning the (actual) target octet length: NO. Using the previous example: if a null-terminated string "abcd\\0" is returned, then strlen_or_ind will equal 4.\par
            ## If the string is a BIT or BINARY string: NO.\par
\par
Example:\par
Take a value at run time, incorporate it in an SQL statement. This is how you\par
can pass a parameter value without using a desc function.\par
\par
  #include "sqlcli.h"\par
  ...\par
  void measurement_update (float measurement, SQLHSTMT hstmt)\par
  \{\par
    int len;\par
    SQLCHAR statement[50];\par
    len = sprintf(statement, "UPDATE t SET measurement = %f", measurement);\par
    SQLExecDirect(hstmt, update_statement, len); \}\par
\par
EXAMPLE3.C: basic "Interactive SQL" program\par
If you want to put together a program that accepts SQL statements from the\par
keyboard and displays results on the screen, this is the skeletal arrangement:\par
\par
  #include "sqlcli.h"\par
  ...\par
  SQLAllocHandle(); SQLAllocHandle(); SQLConnect(); SQLAllocHandle();\par
  ...\par
  for (;;)\par
    printf("Type in an SQL statement, O user: \\n");\par
    gets(user_statement);\par
    if (SQLExecDirect(StatementHandle,user_statement,SQL_NTS)>=0) \{\par
      printf("OK\\n"); \}\par
    else \{\par
      printf("Error\\n"); \}\par
  ...\par
  SQLFreeHandle(); SQLDisconnect(); SQLFreeHandle(); SQLFreeHandle();\par
\par
In this code, notice how SQLExecDirect is fundamental -- it's the only CLI\par
function that must be called for every iteration of the loop. In later\par
examples, we'll show you other things that are necessary here (e.g.: how to\par
exit from the loop, what to do with errors and how queries need special handling).\par
\par
ODBC: The SQLExecDirect function has been around since ODBC 1.0.\par
\par
SQLEndTran\par
\par
Function Prototype:\par
  SQLRETURN SQLEndTran(\par
    SQLSMALLINT HandleType,         /* 16-bit input */\par
    SQLINTEGER Handle,              /* 32-bit input */\par
    SQLSMALLINT CompletionType      /* 16-bit input */\par
    );\par
\par
Job:\par
End a transaction, either with COMMIT or with ROLLBACK. SQLEndTran is not a\par
"statement" function, but we believe that it fits in this chapter because it's\par
used to COMMIT or ROLLBACK the results of SQL statements that have been\par
processed with SQLExecute or SQLExecDirect.\par
\par
Algorithm:\par
      If (HandleType is not one of: SQL_HANDLE_ENV, SQL_HANDLE_DBC, SQL_HANDLE_STMT)\par
        return error: CLI-specific condition-invalid handle\par
      If (HandleType == SQL_HANDLE_STMT)\par
        If (Handle is not a hstmt)\par
          return error: HY092 CLI-specific condition-invalid attribute identifier\par
           The COMMIT/ROLLBACK will be done for the dbc associated with this stmt\par
      If (HandleType == SQL_HANDLE_DBC)\par
        If (Handle is not a hdbc)\par
          return error: HY092 CLI-specific condition-invalid attribute identifier\par
        The dbc's diagnostics area is emptied.\par
           The COMMIT/ROLLBACK will be done for the specified dbc\par
      If (HandleType == SQL_HANDLE_DESC)\par
        If (Handle is not a hdesc)\par
          return error: HY092 CLI-specific condition-invalid attribute identifier\par
           The COMMIT/ROLLBACK will be done for the dbc associated with this desc\par
      If (HandleType == SQL_HANDLE_ENV)\par
        If (Handle is not a henv, or env is a skeleton env)\par
          return error: HY092 CLI-specific condition-invalid attribute identifier\par
           The COMMIT/ROLLBACK will be done for all dbcs associated with this env\par
      If (CompletionType is not either COMMIT (0) or ROLLBACK (1))\par
        return error: HY012 CLI-specific condition-invalid transaction operation code\par
      If (the current transaction is part of an encompassing transaction)\par
        If (transaction control is not controlled by this DBMS alone)\par
          return error: 2D000 Invalid transaction termination -\par
      /* The rest of the algorithm might iterate several times if the\par
         Handle is a henv, and there are multiple active dbcs */\par
      For (each stmt in the dbc)\par
        If (a deferred parameter number is associated with the stmt)\par
          return error: HY010 CLI-specific condition-function sequence error\par
      For each stmt in the dbc:\par
        If (there is a non-holdable Cursor associated with the stmt)\par
          Close the Cursor and destroy its copy of the select source\par
          Remove any associated fetched row\par
      If (CompletionType == SQL_COMMIT (0))\par
        Commit.\par
        /* The usual "commit" operations happen, as described in the\par
           Transactions chapter. For example: if a temporary Table was\par
           created with the ON COMMIT DELETE [ROWS] option, all its rows\par
           are deleted. Warning: checking of deferred Constraints might result\par
            in: 40002 Transaction rollback-integrity constraint violation */\par
        If (any other error prevents commitment now)\par
          /* For example, writing to disk causes a "disk full" error */\par
          return error: 40??? Transaction rollback-implementation-defined subclass value\par
      If (CompletionType == SQL_ROLLBACK)\par
        Rollback.\par
        /* The usual "rollback" operations happen, as described in the Transactions chapter. */\par
      The transaction is now terminated.\par
\par
Notes about the algorithm:\par
      ## See the SQLSTATE error codes HY010, HY092 and 40002 in our chapter on\par
SQL/CLI diagnostics. Pay particular attention to 40002, which implies that\par
ROLLBACK occurred when you asked for COMMIT.\par
      ## Since COMMIT and ROLLBACK are non-preparable SQL statements, the\par
correct way to end a transaction is to call SQLEndTran. Some DBMSs accept\par
SQLExecDirect(hstmt,"COMMIT;",SQL_NTS); anyway, but it's not legal according\par
to the SQL Standard and you can't be sure exactly what will happen.\par
      ## It is not clear why one would pass a hstmt or hdesc to SQLEndTran.\par
These are new (SQL3) options. The safe thing is to use only hdbc or henv for the handle.\par
      ## When there is only one env and one dbc, the convention is to use the\par
henv for this function:\par
\par
   SQLEndTran(SQL_HANDLE_ENV,henv,SQL_COMMIT)\par
\par
      ## Have a look at our chapter on transactions before you try to use\par
SQLEndTran.\par
\par
Example:\par
  #include "sqlcli.h"\par
  SQLHDBC hdbc;\par
  SQLHSTMT hstmt;\par
  ...\par
  SQLAllocHandle(SQL_HANDLE_STMT,hdbc,&hstmt);\par
  /* Do an SQL statement using a stmt associated with dbc */\par
  SQLExecDirect(hstmt,"INSERT INTO t1 SELECT * FROM t2",SQL_NTS);\par
  /* Commit the statement results using the dbc */\par
  SQLEndTran(SQL_HANDLE_DBC,hdbc,SQL_COMMIT);\par
\par
ODBC: The SQLEndTran function was added in ODBC 3.0, but there was a\par
nearly-equivalent function in ODBC 2.0 (SQLTransact). With ODBC, if the\par
HandleType value is not SQL_HANDLE_ENV or SQL_HANDLE_DBC, the return is HY092\par
(invalid attribute/option identifier), rather than "invalid handle".\par
\par
With ODBC, the default behaviour is "autocommit" (i.e.: perform an automatic\par
"commit" after every SQL statement), so SQLEndTran has nothing to do. THIS IS\par
A MAJOR DIFFERENCE BETWEEN ODBC AND STANDARD SQL. The suggested way to resolve\par
it is to call an ODBC function which turns the "autocommit" flag off:\par
SQLSetConnectAttr(hdbc,SQL_ATTR_AUTOCOMMIT,SQL_AUTOCOMMIT_OFF);\par
\par
And that's it for the statement functions. In the next chapter, we'll take a look at the Cursor functions.\par
\page\par
Chapter 45 -- SQL/CLI: Cursor Functions\par
\par
When you execute a query, you are implicitly opening a Cursor. For example,\par
the function call:\par
\par
   SQLExecDirect(hstmt,"SELECT * FROM Table_1;",SQL_NTS);\par
\par
will open a Cursor.\par
\par
The reason for Cursors is that a query returns a set of rows -- a "result\par
set", as it's usually referred to in CLI contexts. But it is not possible for\par
the host language to deal with the whole result set at once -- it must deal\par
with one row at a time. The Cursor is the Object that indicates which row of\par
the result set you're currently dealing with.\par
\par
Cursor movement is just part of the story: "Get the stick, Rover!", coos the\par
hopeful master. Rover charges off, picks up the stick, and sits down. "No, I\par
mean get the stick and FETCH IT TO ME!" addends the master. So Rover trots\par
dutifully back to his caller, and sits down again -- still holding the stick\par
in his teeth. "!@###~$!!", yells the master (we've amended the wording\par
slightly as this is a family computer book). "I wanted you to get the stick,\par
then fetch it, then PUT IT IN MY HANDS!"\par
\par
Well, you know, Rover is a lot like our faithful pal SQL. The execution of an\par
SQL query (the subject of the last chapter) is analogous to a dog picking up a\par
stick. Now, in this chapter, we've reached step 2: fetch the stick. And --\par
like Rover -- that's as far as we go. Step 3, delivering the fetched stuff\par
into your hands, must wait until you have a thorough grounding in the desc\par
functions. So this chapter on "Cursors" is short. The only thing we'll worry\par
about now is the mechanics of opening, closing, fetching and naming Cursors.\par
The fun part -- doing something with the contents -- will come later.\par
\par
The following diagram shows a result set: the result of an execution of a\par
query statement, which has returned three rows. The Cursor is represented by\par
the symbol <<<. The diagram shows where the Cursor is (a) after the execution,\par
(b) after one fetch, (c) after another fetch, (d) after another fetch and (e)\par
after another fetch.\par
\par
(a)             (b)            (c)            (d)            (e)\par
            <<< \par
----------      ----------     ----------     ----------     ----------\par
- Row #1 -      - Row #1 - <<< - Row #1 -     - Row #1 -     - Row #1 -\par
----------      ----------     ----------     ----------     ----------\par
- Row #2 -      - Row #2 -     - Row #2 - <<< - Row #2 -     - Row #2 -\par
----------      ----------     ----------     ----------     ----------\par
- Row #3 -      - Row #3 -     - Row #3 -     - Row #3 - <<< - Row #3 -\par
----------      ----------     ----------     ----------     ----------\par
                                                                        <<<\par
\par
Notice that there are five possible positions of the Cursor, since it is\par
possible to be "before the first row" or "after the last row", as well as "on\par
each row".\par
\par
There are six CLI functions for creating Cursors, dropping Cursors, getting\par
Cursor attributes and fetching from Cursors. Their descriptions follow.\par
\par
SQLFetch\par
\par
Function Prototype:\par
SQLRETURN SQLFetch (\par
  SQLHSTMT hstmt                    /* input: 32-bit handle */\par
  );\par
              \par
Job:\par
Get the next row of a Cursor's result set. (Assumption: using hstmt, you've\par
already run a query which returned a result set.)\par
\par
You can use SQLFetch for one-row-at-a-time processing of a result set.\par
SQLFetch is appropriate for sequential processing, since it always gets the\par
"next" row. For random-access processing, use a different function:\par
SQLFetchScroll.\par
\par
Algorithm:\par
      If (there is no executed statement for hstmt)\par
        return error: HY010 CLI-specific condition-function sequence error\par
      If (there is no open Cursor)\par
        return error: 24000 Invalid Cursor state -\par
      If (Cursor position is not already after the last row)\par
        Set Cursor position = next Cursor position, i.e. go forward\par
      If (Cursor position is now after the last row)\par
        Return with: 02000 "Data Not found-No data"\par
      Transfer the values in the select list to bound Columns, if any.\par
      (Column-binding and transfer is the subject of the CLI desc chapter.)\par
\par
For common errors, see our descriptions of SQLSTATE codes HY010, 24000 and\par
02000 in our chapter on CLI diagnostics. Note that SQLSTATE 02000 is not an\par
exception condition -- it is a completion condition. There are also possible\par
errors -- data exceptions -- which can take place during transfers. There are\par
also possible warnings, such as 01004 "string data right truncation".\par
\par
Notes:\par
      ## SQLFetch only works if there is an open Cursor. A Cursor is\par
automatically opened as a result of executing an SQL query statement. A Cursor\par
can be explicitly closed using the CLI function SQLCloseCursor. Usually,\par
though, a Cursor is closed as a result of calling the CLI function SQLEndTran.\par
      ## There is no such Cursor position as "two places after the last row".\par
A Cursor which is "after the last row" does not move.\par
\par
Example:\par
Here's a fetch loop example:\par
\par
  #include "sqlcli.h"\par
  ...\par
  SQLHSTMT  hstmt;\par
  ...\par
  SQLExecDirect(hstmt,"SELECT * FROM Employees ORDER BY dept;",SQL_NTS);\par
  for (;;) \{\par
    sqlreturn = SQLFetch(hstmt);\par
    if (sqlreturn <> SQL_SUCCESS && sqlreturn <> SQL_SUCCESS_WITH_INFO) \{\par
      if (sqlreturn == SQL_NO_DATA) break;\par
      printf("Error!");\par
      break; \}\par
    printf("*"); \}\par
  SQLCloseCursor(hstmt);      /* "Close Cursor" -- more details soon. */\par
  ...\par
\par
Here's another example, functionally the same as the previous one, but the\par
style is different -- using names, macros and indentation a la Microsoft:\par
\par
#include "sql.h"          // "sqlcli.h" equivalent supplied with ODBC\par
SQLRETURN   rc;               // rc is an abbreviation for return code\par
#define SQL_SUCCEEDED(rc) (rc == SQL_SUCCESS || rc == SQL_SUCCESS_WITH_INFO)\par
/* sqlcli.h has this instead: #define SQL_SUCCEEDED(rc) (((rc)&(~1))==0) */\par
...\par
rc = SQLFetch(hstmt0);\par
while (SQL_SUCCEEDED(rc)) \{\par
  ...  rc = SQLFetch(hstmt0);\par
\} // while\par
\par
ODBC: All versions of ODBC support the SQLFetch function as described here,\par
but ODBC version 3.0 has an optional feature: you can fetch multiple rows with\par
one call. Logically, such a feature is unnecessary, and it makes applications\par
more complex. We assume Microsoft added the feature for performance reasons.\par
\par
Fetch Loops:\par
When dealing with a result set, the procedure is almost always to:\par
      ## 1. Make a result set.\par
      ## 2. Begin a loop which calls SQLFetch for each row; stopping when\par
there are no more rows.\par
\par
Here's what it looks like in pseudocode:\par
\par
  Make a result set.\par
  LOOP:\par
    Call SQLFetch to get the next row.\par
    Check for no more rows. If this is the end of result set, exit loop.\par
    Check for errors.\par
    Do something with the result row (for example display the contents.\par
\par
Let's explore these pseudocode statements in a little more detail.\par
\par
## Make a result set: \par
You create a result set when you execute an SQL "query". The "query"\par
statements are the ones that begin with SELECT or VALUES or TABLE. For\par
example, this CLI function call makes a result set associated with stmt:\par
\par
   sqlreturn = SQLExecDirect(hstmt,"SELECT column_1 FROM Table_1;",SQL_NTS);\par
\par
(There is also a group of CLI functions, called the Catalog functions, which\par
execute SQL queries implicitly. See our chapter on that subject.)\par
## Call SQLFetch to get the next row:\par
\par
   sqlreturn = SQLFetch(hstmt);\par
\par
## Check for end of result set.\par
Eventually, the SQLFetch function will return SQL_NO_DATA. At that point, it\par
is certain that the SQLSTATE class is '02'. SQL_NO_DATA is a completion\par
condition -- the function is completed. But there wasn't any row to fetch, so\par
no data actually moved from bound Columns into host variables. The Cursor is\par
now positioned "after the last row" and if you call SQLFetch again, it will\par
remain there. This is a cue to break out of the fetch loop:\par
\par
   if (sqlreturn == SQL_NO_DATA) break;\par
\par
## Check for errors. \par
SQLFetch functions rarely return SQL_ERROR, but we'll do some checking to be\par
on the safe side:\par
\par
  if (sqlreturn == SQL_ERROR) \{\par
    printf("Error!");\par
    break; \}\par
\par
The "break;" means that we exit the loop, just as if this were a "no data"\par
return code. Alternatively, you could continue, in the hope that the Cursor\par
has moved forward despite the error, and the next row is okay.\par
\par
## Do something with the result row. \par
The data in the fetched row will go to host variables in the program. We do\par
not show that here. We will revisit fetch loops later, after looking at desc\par
functions. Until then, remember: Rover is still holding the stick.\par
\par
SQLFetchScroll\par
\par
Function Prototype:\par
  SQLRETURN SQLFetchScroll(\par
    SQLHSTMT hstmt,                      /* 32-bit input. handle */\par
    SQLSMALLINT FetchOrientation,        /* 16-bit input. code */\par
    SQLINTEGER FetchOffset               /* 32-bit input. offset. */\par
    );\par
\par
Job:\par
Get a specified row of a Cursor's result set. (Assumption: using hstmt, you've\par
already run a query which returned a result set.)\par
\par
You can use SQLFetchScroll for one-row-at-a-time processing of a result set.\par
SQLFetchScroll is appropriate for random-order processing, since it always\par
gets the "specified" row. For sequential processing, use a different function:\par
SQLFetch.\par
\par
Algorithm:\par
      If (there is no executed statement for hstmt)\par
        return error: HY010 CLI-specific condition-function sequence error\par
      If (there is no open Cursor)\par
        return error: 24000 Invalid Cursor state -\par
      If (FetchOrientation is not a valid value)\par
        return error: HY106 CLI-specific condition-invalid fetch orientation\par
      If (Cursor is not a scroll Cursor and FetchOrientation<>SQL_FETCH_NEXT)\par
        /* scroll Cursors must be explicitly designated with SQLSetStmtAttr */\par
        return error: HY106 CLI-specific condition-invalid fetch orientation\par
      If (Cursor position is now after the last row)\par
        Return with: 02000 "Data Not found-No data"\par
      Transfer the values in the select list to bound Columns, if any.\par
      (Column-binding and transfer is the subject of the CLI desc chapter.)\par
\par
Notes:\par
      ## SQLFetchScroll works pretty much the same way as SQLFetch, except for\par
the way it positions the Cursor. There are six possible values of the\par
FetchOrientation parameter:\par
            ## If the value is 1, the #define in sqlcli.h is SQL_FETCH_NEXT\par
and the requested action is "Fetch the next row of the result set", just as\par
for SQLFetch. SQL_FETCH_NEXT is the only legal orientation if the Cursor is\par
non-scrollable.\par
            ## If the value is 2, the #define in sqlcli.h is SQL_FETCH_FIRST\par
and the requested action is "Fetch the first row of the result set".\par
            ## If the value is 3, the #define in sqlcli.h is  SQL_FETCH_LAST\par
and the requested action is "Fetch the last row of the result set".\par
            ## If the value is 4, the #define in sqlcli.h is SQL_FETCH_PRIOR\par
and the requested action is "Fetch the previous row of the result set".\par
            ## If the value is 5, the #define in sqlcli.h is \par
SQL_FETCH_ABSOLUTE and the requested action is "Fetch row#n of the result set"\par
(where n = FetchOffset -- see parameter list). The FetchOffset parameter can\par
be negative, in which case the DBMS seeks relative to the end of the result\par
set rather than relative to the beginning of the result set. If you pass\par
FetchOrientation=SQL_ABSOLUTE and FetchOffset=0, you fetch the first row in\par
the result set.\par
            ## If the value is 6, the #define in sqlcli.h is\par
SQL_FETCH_RELATIVE and the requested action is "Fetch row#n of the result set"\par
(where n = current row#-FetchOffset). Once again, the FetchOffset parameter\par
can be negative. If you pass FetchOrientation=SQL_RELATIVE and FetchOffset=0,\par
you re-fetch the same row as last time.\par
      ## The ABSOLUTE and RELATIVE fetch orientations may be thought of as\par
similar to the arguments for the C function lseek.\par
      ## By definition, the following function calls are the same:\par
SQLFetchScroll(...,NEXT,...)  = SQLFetchScroll(...,RELATIVE,+1)\par
                              or SQLFetch(...)\par
SQLFetchScroll(...,PRIOR,...) = SQLFetchScroll(...,RELATIVE,-1)\par
SQLFetchScroll(...,FIRST,...) = SQLFetchScroll(...,ABSOLUTE,+1)\par
SQLFetchScroll(...,LAST,...)  = SQLFetchScroll(...,ABSOLUTE,-1)\par
      ## If you want to do anything other than "Fetch next", the Cursor must\par
be declared "scrollable" before the query is executed. Here's how:\par
\par
   SQLSetStmtAttr(hstmt,SQL_ATTR_CURSOR_SCROLLABLE,NULL,NULL);\par
\par
If you don;t call this function, then queries executed on this stmt will be\par
non-scrollable. A non-scrollable Cursor is useful only for SQLFetch and\par
SQLFetchScroll(...SQL_FETCH_NEXT...). A non-scrollable Cursor is generally\par
slightly more efficient than a scrollable Cursor.\par
      ## It might be convenient to use SQLFetchScroll for paged-display\par
purposes. For example, start by displaying the first 20 rows on the screen. If\par
the user presses a "next page" button, fetch the next 20 rows. If the user\par
presses a "previous page" button, fetch the previous 20 rows. This process is\par
easy to keep track of with SQLFetchScroll(...,ABSOLUTE,...) using a\par
FetchOffset value to which you add or subtract 20, depending on the button\par
pushing. (In multi-user environments, paged displays might require a different\par
mechanism.)\par
      ## Fetch orientation" only works within the bounds of the result set.\par
For example, suppose that there are 3 rows in a result set. If you try to\par
fetch row number 20 -- using SQLFetchScroll(...,ABSOLUTE,20) -- the function\par
will fail with SQLSTATE 02000 "no data". The possible surprise lies in the\par
fact that the Cursor is now positioned, not at some nonexistent "row #20", but\par
just after the last row of the result set -- so if you then call\par
SQLFetchScroll(...,PRIOR,...), the DBMS will fetch row#3.\par
      ## SQLFetch and SQLFetchScroll calls can be interlaced.\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLHSTMT hstmt;\par
      ...\par
      SQLSetStmtAttribute(hstmt,SQL_ATTR_SCROLL_CURSOR,NULL,NULL);\par
      ...\par
      SQLExecDirect(hstmt,"SELECT column_1 FROM T ORDER BY column_1",SQL_NTS);\par
      ...\par
      SQLFetchScroll(hstmt,SQL_FETCH_LAST,NULL);      /* get last row */\par
      SQLFetchScroll(hstmt,SQL_FETCH_RELATIVE,-1);    /* now 2nd-last row */\par
\par
ODBC: The ODBC function is pretty much as described above, except for details\par
-- for example, "SQLFetchScroll(hstmt,SQL_ABSOLUTE,0)" will cause the Cursor\par
to be positioned before the first row (in standard SQL it would cause the\par
Cursor to be positioned at the first row). The more important difference is\par
that ODBC allows many extensions, such as multi-row retrieval and retrieval\par
using "bookmarks" (which are a special sort row address).\par
\par
SQLCloseCursor\par
\par
Function Prototype:\par
  SQLRETURN SQLCloseCursor(\par
    SQLHSTMT hstmt                        /* 32-bit input */\par
    );\par
\par
Job:\par
Close a Cursor.\par
\par
Algorithm:\par
      If (there is no executed statement associated with stmt)\par
        return error: HY010 CLI-specific condition-function sequence error\par
      If (there is no open Cursor associated with stmt)\par
        return error: 24000 Invalid Cursor state -\par
      The open Cursor is "placed in the closed state".\par
      The open Cursor's "copy of the select source is destroyed".\par
      /* That means there is no more result set to fetch from.\par
         However, the IRD is still there. */\par
\par
Notes:\par
      ## You MUST close the Cursor when you are done processing a result set.\par
Otherwise, you won't be able to re-use the stmt. SQLPrepare and SQLExecute\par
will return with an error if there is an open Cursor.\par
      ## The DBMS automatically closes the Cursor when executing any of these\par
CLI functions:\par
            ## SQLFreeStmt(...,SQL_CLOSE)\par
            ## SQLEndTran (but see later description of "held Cursors")\par
            ## SQLCancel\par
            ## SQLFreeHandle(SQL_HANDLE_STMT,...)\par
            ## SQLMoreResults\par
However, it is good style to call SQLCloseCursor explicitly, rather than\par
depending on automatic behaviour.\par
      ## SQLFreeStmt(...,SQL_CLOSE) does exactly the same thing as the\par
SQLCloseCursor function, except for one detail: if there is no Cursor\par
currently open, then SQLCloseCursor returns an error, while\par
SQLFreeStmt(...,SQL_CLOSE) does not return an error.\par
\par
Example:\par
This is a repetition of the earlier "fetch loop" example. Notice that\par
SQLCloseCursor is called at the end of the loop.\par
\par
  #include "sqlcli.h"\par
  ...\par
  SQLHSTMT  hstmt;\par
  ...\par
  SQLExecDirect(hstmt,"SELECT * FROM Employees ORDER BY dept;",SQL_NTS);\par
  for (;;) \{\par
    sqlreturn = SQLFetch(hstmt);\par
    if (sqlreturn <> SQL_SUCCESS && sqlreturn <> SQL_SUCCESS_WITH_INFO) \{\par
      if (sqlreturn == SQL_NO_DATA) break;\par
      printf("Error!");\par
      break; \}\par
    printf("*"); \}\par
  SQLCloseCursor(hstmt);      /* "Close Cursor" */\par
\par
ODBC: The SQLCloseCursor function is new in ODBC 3.0; with earlier ODBC\par
versions, the way to close Cursors was SQLFreeStmt(hstmt,SQL_CLOSE);. If\par
ODBC's "autocommit" mode is in effect, then SQLCloseCursor causes a COMMIT.\par
(In order for this to work, the DBMS must avoid performing an automatic commit\par
immediately after execution of the SELECT statement which causes the Cursor to\par
be opened.)\par
\par
SQLGetCursorName\par
\par
Function Prototype:\par
  SQLRETURN SQLGetCursorName(\par
    SQLHSTMT hstmt,           /* 32-bit input Handle*/\par
    SQLCHAR *CursorName,      /* CHAR * output: we'll put Cursor name here */\par
    SQLSMALLINT BufferLength, /* SMALLINT inputMax *Cursorname length */\par
    SQLSMALLINT *NameLength   /* SMALLINT * output returned name length*/\par
    );\par
\par
Job:\par
Retrieve the current <Cursor name> which is associated with hstmt.\par
\par
Algorithm:\par
      If (there is no Cursor name associated with hstmt)\par
        /* looks like SQLSetCursorName was never called, \par
           so the DBMS must generate an implicit Cursor name */\par
        Set the Cursor name = 'SQL_CUR' (or 'SQLCUR') plus some\par
implementation-defined characters (e.g.: 'SQL_CUR9999'). If the DBMS has to\par
make up a name like this, it will ensure that no two statements use the same\par
Cursor name.\par
      Copy the value of the Cursor name to *CursorName. This is a standard\par
case of Character String Retrieval.\par
\par
Notes:\par
      ## With embedded SQL, the <Cursor name> is important. With the CLI, the\par
<Cursor name> is not important -- we distinguish between statements using the\par
hstmt value. The only time you actually need a <Cursor name> is when you have\par
to use positioned UPDATE|DELETE statements (we'll discuss positioned\par
UPDATE|DELETE statements later in this chapter).\par
      ## The <Cursor name> exists independently of the Cursor itself. You can\par
retrieve a <Cursor name> even if the Cursor is not open.\par
      ## An implicit <Cursor name> begins with the letters SQL_CUR or SQLCUR\par
(e.g.: SQL_CUR0001). In practice, implicit <Cursor name>s are not more than 18\par
characters long. A <Cursor name> is created implicitly (if it doesn't already\par
exist) when either of these things happens: (a) SQLPrepare is called and the\par
prepared statement is a query or (b) SQLGetCursorName is called. Once an\par
implicit <Cursor name> is established, it remains until the statement is\par
freed, or until a call to SQLSetCursorName changes it explicitly.\par
\par
Example:\par
  #include "sqlcli.h"\par
  ...\par
  SQLHSTMT hstmt;\par
  SQLCHAR Cursor_name[128+1];\par
  SQLSMALLINT Cursor_name_length;\par
  ...\par
  SQLGetCursorName(hstmt,Cursor_name,sizeof(Cursor_name),&Cursor_name_length);\par
\par
ODBC: The SQLGetCursorName function has been around since ODBC 1.0. In ODBC,\par
implicit <Cursor name>s always begin with SQL_CUR (not SQLCUR).\par
\par
SQLSetCursorName\par
\par
Function Prototype:\par
  SQLRETURN SQLSetCursorName(\par
    SQLHSTMT hstmt,                 /* 32-bit input */\par
    SQLCHAR *CursorName,            /* CHAR* input */\par
    SQLSMALLINT NameLength          /* 16-bit input */\par
    );\par
\par
Job:\par
Associate a <Cursor name> with a stmt.\par
\par
Algorithm:\par
If (there is already an open Cursor associated with hstmt)\par
  return error: 24000-invalid Cursor state -\par
Get the value passed in *CursorName, with length = NameLength.\par
Trim lead or trail spaces.\par
Check that value conforms to the usual rules for <identifier>.\par
If (the value begins with the letters 'SQL_CUR' or 'SQLCUR')\par
  /* Only the DBMS can assign names that begin with 'SQL_CUR' or SQLCUR' */ \par
  return error: 34000 invalid <Cursor name> \par
If (value = <Cursor name> of another stmt in the same dbc)\par
  /* <Cursor name>s must be unique */\par
  return error: 34000 invalid <Cursor name>\par
\par
Notes:\par
      ## You only need to call SQLSetCursorName if you intend to execute\par
"positioned UPDATE|DELETE" statements.\par
      ## It is a good idea to assign your own <Cursor name>, rather than\par
depending on an implicit <Cursor name>.\par
      ## The best time to call SQLSetCursorName is immediately after calling\par
SQLAllocHandle(SQL_HANDLE_STMT,...).\par
      ## The <Cursor name> is permanent. It exists until the stmt is freed, or\par
until superseded by another call to SQLSetCursorName. Opening and closing the\par
Cursor has no effect on the name.\par
\par
Example:\par
  #include "sqlcli.h"\par
  ...\par
  SQLHSTMT hstmt;\par
  ...\par
  SQLAllocHandle(SQLHANDLE_STMT,hdbc,&hstmt);\par
  SQLSetCursorName(hstmt,"Cursor_1",sizeof("Cursor_1"));\par
\par
ODBC: The SQLSetCursorName function has been around since ODBC version 1.0. If\par
the <Cursor name> already exists, ODBC requires that the SQLSTATE should be\par
3C000 "Duplicate <Cursor name>", instead of 34000.\par
\par
Embedded SQL versus CLI\par
\par
Here is an embedded SQL example which uses a Cursor:\par
\par
  EXEC SQL DECLARE x CURSOR FOR SELECT * FROM A;\par
  EXEC SQL DECLARE y CURSOR FOR SELECT * FROM B;\par
  EXEC SQL OPEN x;\par
  EXEC SQL FETCH x;\par
  EXEC SQL CLOSE x;\par
\par
Here is a CLI example which does pretty well the same thing:\par
\par
  SQLAllocHandle(SQL_HANDLE_STMT,hdbc,&hstmt1);\par
  SQLAllocHandle(SQL_HANDLE_STMT,HDBC,&hstmt2);\par
  SQLExecDirect(hstmt1,"SELECT * FROM A",SQL_NTS);\par
  SQLFetch(hstmt1);\par
  SQLCloseCursor(hstmt1);\par
\par
Comparing these two examples, you will notice two major differences:\par
      ## In the CLI, there is no OPEN statement -- Cursors are implicitly\par
opened by execution of a SELECT statement.\par
      ## In the CLI, there is no use of <Cursor name>s -- different Cursors\par
are associated with different stmts, so hstmt alone is sufficient for unique\par
identification.\par
\par
The CLI functions SQLGetCursorName and SQLSetCursorName are unimportant. CLI\par
programmers only worry about <Cursor name>s if they have to use positioned\par
UPDATE|DELETE statements.\par
\par
Positioned UPDATE|DELETE statements:\par
In our chapter on embedded SQL, we mentioned that there are two kinds of\par
UPDATE and DELETE statements. The normal kind (called "searched UPDATE" and\par
"searched DELETE"), provide conditions for changing or removing rows in a\par
WHERE clause -- these statements are not our concern here. The Cursor-related\par
kind (called "positioned UPDATE" and "positioned DELETE") are distinguished by\par
the presence of a WHERE CURRENT OF <Cursor name> clause, rather than a\par
conditional WHERE clause. Here's an example of each:\par
\par
   UPDATE Table_1 SET column_1 = 5 WHERE CURRENT OF Cursor_1;\par
\par
   DELETE FROM Table_1 WHERE CURRENT OF Cursor_1;\par
\par
The first example will update only one row in TABLE_1: the row that underlies\par
the result-set row which is indicated by the current position of CURSOR_1. The\par
second example will delete only that single row of TABLE_1.\par
\par
With the CLI, there is one complicating factor: the positioned UPDATE|DELETE\par
statement must be executed using a different stmt than the stmt which is\par
associated with CURSOR_1. This is just a corollary of the reasonable rule that\par
"at any given time there may be only one statement associated with a stmt".\par
Since there is already an active statement -- the SELECT which caused the\par
Cursor to be opened -- the positioned UPDATE must go elsewhere. A general\par
skeleton of a positioned UPDATE|DELETE operation, then, could be:\par
\par
      Allocate stmt_1\par
      Allocate stmt_2\par
      Get or set the <Cursor name> for stmt_1\par
      Execute SELECT on stmt_1 (thus opening the Cursor)\par
      Fetch on stmt_1 (thus positioning the Cursor)\par
      Execute positioned UPDATE|DELETE on stmt_2, using the <Cursor name>\par
(If, later, the same row is re-fetched using SQLFetchScroll, then results are\par
implementation-defined.)\par
\par
Example:\par
This program uses a positioned DELETE statement. Just by the way, we'll use "A\par
delimited identifier" for our <Cursor name>. In real life the <Cursor name>\par
would be a short <regular identifier> like X or Cursor_1 or\par
SELECTION_WHERE_X_GT_0.\par
\par
  #include "sqlcli.h"\par
  SQLHENV henv;\par
  SQLHDBC hdbc;\par
  SQLHSTMT hstmt_1,hstmt_2;\par
  SQLRETURN sqlreturn;\par
  void main () \{\par
    SQLAllocHandle(SQL_HANDLE_ENV,NULL,&henv);\par
    SQLAllocHandle(SQL_HANDLE_DBC,henv,&hdbc);\par
    SQLConnect(hdbc,"OCELOT",SQL_NTS,"OCELOT",SQL_NTS,NULL,NULL);\par
    SQLAllocHandle(SQL_HANDLE_STMT,hdbc,&hstmt_1);\par
    SQLAllocHandle(SQL_HANDLE_STMT,hdbc,&hstmt_2);\par
    /* In C, the symbol \\" can be used when the symbol " is in a string.\par
       The symbol \\042 would have the same effect, since " in the ANSI\par
       repertoire the code for quote-mark is octal 042. */\par
    SQLSetCursorName(hstmt_1,"\\"A delimited identifier\\"",24);\par
    SQLExecDirect(hstmt_1,"SELECT * FROM T",16);\par
    for (;;) \{\par
      sqlreturn = SQLFetch(hstmt_1);\par
      if (SQLFetch(hstmt_1)==SQL_NO_DATA) break;\par
       /* In C, the symbol _ is used for line continuation. */\par
      SQLExecDirect(hstmt_2,"DELETE FROM T WHERE CURRENT OF _\par
      \\"A delimited identifier\\"",SQL_NTS); \}\par
    SQLCloseCursor(hstmt_1);\par
    SQLEndTran(SQL_HANDLE_DBC,hdbc,SQL_COMMIT);\par
    SQLFreeHandle(SQL_HANDLE_STMT,hstmt_2);\par
    SQLFreeHandle(SQL_HANDLE_STMT,hstmt_1);\par
    SQLDisconnect(hdbc);\par
    SQLFreeHandle(SQL_HANDLE_DBC,hdbc);\par
    SQLFreeHandle(SQL_HANDLE_ENV,henv); \}\par
\par
Singleton SELECTs:\par
In embedded SQL, there is a construct called the singleton\par
SELECT. Here's an example:\par
\par
   EXEC SQL SELECT Column_1 INTO :host_variable FROM Table_1;\par
\par
In the CLI, there is no equivalent of a singleton SELECT. All query results,\par
even ones that consist of zero rows or one row, must be processed via the\par
Cursor functions.\par
\par
Sensitive Cursors:\par
What happens if a Cursor is open on stmt_1, and a data change operation\par
happens on stmt_2? We've already noted that "positioned UPDATE|DELETE\par
statements" are possible, but here we're asking about effects in a more\par
general way -- that is, we're assuming that the SQL-data change statement is\par
INSERT, UPDATE or DELETE and that stmt_2 is associated either with the same\par
dbc, or with another dbc. For example, suppose you've executed this SQL\par
statement:\par
\par
   SELECT * FROM Table_1;\par
\par
and you are now fetching from the result. But -- after the SELECT was\par
processed and before your first FETCH, some UPDATE took place on one row of\par
TABLE_1. When you FETCH that row, will you see the new values, or the original\par
values? There are three possible answers, which depend on an attribute of the\par
stmt called the "Cursor sensitivity". Here are the options:\par
      ## If the attribute value is 0, the #define in sqlcli.h is SQL_UNDEFINED\par
and the requested action is "I don't care whether I see new or old values;\par
leave it up to the implementation".\par
      ## If the attribute value is 1, the #define in sqlcli.h is\par
SQL_INSENSITIVE and the requested action is "show me the original values".\par
      ## If the attribute value is 2, the #define in sqlcli.h is SQL_SENSITIVE\par
and the requested action is "show me the changed values".\par
\par
The default is SQL_UNDEFINED (which may be known as SQL_ASENSITIVE in ANSI\par
SQL3). Your best option is to just leave this attribute setting alone, and do\par
what you can to avoid the situation. If you must specify one of the other\par
settings, you can do so with a call to the SQLSetStmtAttr function, for\par
example:\par
\par
   SQLSetStmtAttr(hstmt,SQL_ATTR_CURSOR_SENSITIVITY,&SQL_INSENSITIVE,NULL);\par
\par
You would probably want an insensitive Cursor if the fetched rows have to be\par
consistent with each other. However, most DBMSs maintain insensitive Cursors\par
by making a copy of the Table (that is: the rows in the result set are not\par
necessarily identical to the rows of the Table you selected from). Therefore,\par
an insensitive Cursor is always a READ-ONLY Cursor. The SQLGetStmtAttr\par
function can be used to check which Cursor sensitivity option is currently in\par
effect. The SQLGetInfo function can be used to check whether a DBMS supports\par
the Cursor sensitivity options. Many DBMSs support SQL_UNSPECIFIED only.\par
\par
Holdable Cursors:\par
Another stmt attribute that affects Cursor management is "holdability". This\par
attribute, which can also be set with the SQLSetStmtAttr function, affects the\par
question: What happens to an open Cursor when we end a transaction with\par
SQLEndTran(...SQL_COMMIT)? Here are the two possible options:\par
      ## If the attribute value is 0, the #define in sqlcli.h is\par
SQL_NONHOLDABLE and the requested action is "close the Cursor".\par
      ## If the attribute value is 1, the #define in sqlcli.h is SQL_HOLDABLE\par
and the requested action is "leave the Cursor open into the next transaction".\par
\par
The default is SQL_NONHOLDABLE. In fact, for most DBMSs, holdability is not\par
yet an option (this is an SQL3 feature). It is difficult to maintain integrity\par
and concurrency if Cursors stay open over transaction boundaries. Holdable\par
Cursors are not supported in SQL-92, in ISO SQL3 or in ODBC.\par
\par
SQLMoreResults\par
\par
Function Prototype:\par
  SQLRETURN SQLMoreResults(\par
    SQLHSTMT hstmt       /* 32-bit input */\par
    );\par
\par
Job:\par
Find out if there is another result set associated with the stmt. If so,\par
position the Cursor at the start of the next result set (that is, before the\par
first row of the next result set). This is an SQL3 function.\par
\par
Only one SQL statement can produce multiple result sets:\par
\par
   CALL <procedure-name>\par
\par
That's because a "procedure" might contain multiple SELECT statements. In such\par
a case, result sets are returned in the order they were produced.\par
\par
Algorithm:\par
      If (there is no executed statement associated with stmt)\par
        return error: HY010 CLI-specific condition-function sequence error\par
      If (the executed statement did not return any result sets)\par
        return error: HY010 CLI-specific condition-function sequence error\par
      /* Presumably the first Cursor is already open and processed. */\par
      Close the Cursor associated with stmt.\par
      If (there are no more result sets)\par
        return warning: No data-no additional dynamic result sets returned\par
      Open Cursor for the new result set /* with the same <Cursor name> */\par
      Position Cursor before first row of the new result set\par
\par
Notes:\par
      ## SQLMoreResults does an implicit "close Cursor" call.\par
      ## Result sets must be processed one at a time. You cannot process them\par
in parallel (though that's a feature that's being considered for SQL4).\par
      ## Since earlier versions of the SQL Standard didn't support SQL\par
procedures, there was no need for an SQLMoreResults function until SQL3.\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLHSTMT hstmt;\par
      ...\par
      SQLExecDirect(hstmt,"CALL proc()",SQL_NTS);\par
      SQLFetch(hstmt);\par
      ...\par
      SQLMoreResults(hstmt);\par
      SQLFetch(hstmt);\par
\par
ODBC: SQLMoreResults has been around since ODBC version 1.0. That has more to\par
do with ODBC's non-standard "batching" feature than with support for\par
procedures. However, Microsoft has always assumed that DBMSs support\par
procedures.\par
\par
And that's it for the Cursor functions. In the next chapter, we'll take a look\par
at the meat of CLI -- the desc functions.\par
\page\par
Chapter 46 -- SQL/CLI: desc Functions\par
\par
** When we talk about data type correspondences, make changes according to\par
** chart in 70clig.tx2.\par
\par
In this chapter, we'll describe the fourth essential CLI resource: the desc.\par
We have much to say about:\par
      ## What is in a desc -- fields of the header and the "item descriptor areas".\par
      ## How to make a desc, or how to use an automatically-made desc.\par
      ## Similarities and differences of ARDs, APDs, IRDs and IPDs.\par
      ## Functions which attack descs directly: SQLAllocHandle,\par
SQLGetDescField, SQLSetDescField, SQLGetDescRec, SQLSetDescRec, SQLCopyDesc and others.\par
      ## Functions which attack descs indirectly: SQLBindParameter, SQLBindCol, SQLColAttribute, SQLDescribeCol and others.\par
\par
Descriptor Areas\par
\par
Here is a piece of CLI code:\par
\par
   SQLExecDirect(hstmt,"SELECT col_1,col_2 FROM T WHERE col_1=?",SQL_NTS);\par
   SQLFetch(hstmt);\par
\par
The SELECT statement in this example contains a question mark: it represents a\par
parameter marker -- that is, it means "there is an input parameter here". (An\par
input parameter is a host variable value which travels from the application to\par
the DBMS. For some CALL statements a parameter may be an output parameter, but\par
the normal case is that parameters are input parameters.) The input will\par
happen during SQLExecDirect.\par
\par
The SELECT statement also contains a two-Column select list ("col_1,col_2").\par
The existence of a select list implies "there are output rows here". (An\par
output row consists of one or more Columns in a result set, whose values\par
travel from the DBMS to the application.) The output will happen during SQLFetch.\par
\par
What are the addresses of the host variables? How will NULL values be flagged?\par
What is already known, or can be specified, about the characteristics of each\par
value: <data type>, size, precision, scale, Character set, etc.? Descriptor\par
areas -- or descs -- are available to handle such questions, for both parameters and row Columns.\par
\par
Automatic descs:\par
There are four automatic descs; here's a brief description of each:\par
      ## IRD, or Implementation Row Descriptor. Its usual use: to find out\par
what the DBMS knows about a result set. The IRD is filled in when you call\par
SQLPrepare for a SELECT statement.\par
      ## ARD, or Application Row Descriptor. Its usual use: to tell the DBMS\par
how to transfer a result set to the host. The important fields of the ARD must\par
be filled in by the host program.\par
      ## IPD, or Implementation Parameter Descriptor. Its usual use: to\par
provide information about the DBMS's view of parameters. The DBMS may be\par
capable of "populating" the IPD fields; otherwise, the programmer must take\par
some responsibility for this job.\par
      ## APD, or Application Parameter Descriptor. Its usual use: to the tell\par
the DBMS how to transfer an input parameter. (Parameters are marked in an SQL\par
statement with "?" parameter markers.)\par
\par
Here's a pseudo "struc" declaration, for future reference in this chapter's examples.\par
\par
desc struc \{\par
  SQL_DESC_ALLOC_TYPE smallint,                /* header fields ... */\par
  SQL_DESC_COUNT smallint,\par
  SQL_DESC_DYNAMIC_FUNCTION char[],\par
  SQL_DESC_DYNAMIC_FUNCTION_CODE integer,\par
  SQL_DESC_KEY_TYPE smallint,\par
  IDA struc occurs n times \{\par
    SQL_DESC_CHARACTER_SET_CATALOG varchar[],  /* IDA[n] fields ... */\par
    SQL_DESC_CHARACTER_SET_SCHEMA varchar[],\par
    SQL_DESC_CHARACTER_SET_NAME varchar[],\par
    SQL_DESC_COLLATION_CATALOG varchar[],\par
    SQL_DESC_COLLATION_SCHEMA varchar[],\par
    SQL_DESC_COLLATION_NAME varchar[],\par
    SQL_DESC_DATA_POINTER void*,\par
    SQL_DESC_DATETIME_INTERVAL_CODE smallint,\par
    SQL_DESC_DATETIME_INTERVAL_PRECISION smallint,\par
    SQL_DESC_INDICATOR_POINTER integer*,\par
    SQL_DESC_KEY_MEMBER smallint,\par
    SQL_DESC_LENGTH integer,\par
    SQL_DESC_NAME varchar[],\par
    SQL_DESC_NULLABLE smallint,\par
    SQL_DESC_OCTET_LENGTH integer,\par
    SQL_DESC_OCTET_LENGTH_POINTER integer*,\par
    SQL_DESC_PARAMETER_ORDINAL_POSITION smallint,\par
    SQL_DESC_PARAMETER_SPECIFIC_CATALOG varchar[],\par
    SQL_DESC_PARAMETER_SPECIFIC_SCHEMA varchar[],\par
    SQL_DESC_PARAMETER_SPECIFIC_NAME varchar[],\par
    SQL_DESC_PRECISION smallint,\par
    SQL_DESC_SCALE smallint,\par
    SQL_DESC_TYPE smallint,\par
    SQL_DESC_UDT_CATALOG varchar[],\par
    SQL_DESC_UDT_SCHEMA varchar[],\par
    SQL_DESC_UDT_NAME varchar[],\par
    SQL_DESC_UNNAMED smallint\par
    \}\par
  \}\par
APD = desc;\par
IPD = desc;\par
ARD = desc;\par
IRD = desc;\par
\par
Throughout this chapter, we'll replace long-winded references using\par
program-like conventions. For example, it is often necessary to make\par
statements like this: "Within the Application Parameter Descriptor, in the nth\par
occurrence of the Item Descriptor Area, set the SCALE attribute to 5." We will\par
make such statements this way:\par
\par
   "Set APD.IDA[n].SQL_DESC_SCALE = 5"\par
\par
For a programmer, the second statement is shorter, clearer and better. We'll\par
use such statements as convenient conventions, without implying that all DBMSs\par
store desc information with this structure.\par
\par
The desc Fields\par
\par
On first reading, we suggest that you skip quickly through this section. But\par
bookmark this page -- you'll have to refer to the desc field descriptions many times.\par
\par
The first entries in a descriptor area are the desc "header" fields. Then come\par
the fields of the desc "item descriptor area" (IDA), which is\par
multiple-occurrence. In our discussions of each group, entries are in\par
alphabetical order. Each entry begins with a field identifier (which is the\par
code used for identification), a <data type> and an indicator of the field's\par
importance. For example:\par
\par
   SQL_DESC_ALLOC_TYPE 1099\par
         Type: SMALLINT. Importance: Low.\par
\par
This description should be read as follows: The SQL descriptor field is\par
identified by the code SQL_DESC_ALLOC_TYPE, which is a number. The sqlcli.h\par
line for this field is:\par
\par
   #define SQL_DESC_ALLOC_TYPE 1099\par
\par
This book uses SQL_DESC_ALLOC_TYPE as both a field identifier and a field\par
name. The field's <data type> is SMALLINT (short signed integer). Relatively\par
speaking, the field is of low importance (this is our subjective estimate).\par
\par
Each field entry contains some text description, accompanied by examples if\par
the field is of high importance. Finally, each entry ends with a small chart. For example:\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  user                           SQLGetData, user\par
IRD  SQLGetData[P], user[P]         SQLPrepare\par
APD  SQLExecute, user               SQLGetDescField\par
IPD  SQLExecute, user               SQLPrepare[I], user\par
\par
This chart should be read as follows: When this field is in the ARD, it may be\par
gotten by the user (presumably with the SQLGetDescField function) and it may\par
be set by the SQLGetData function or by the user (presumably with the\par
SQLSetDescField function). And so on for the IRD, APD and IPD. In the chart,\par
the symbol "[I]" means "this function is applicable only when the AUTO\par
POPULATE flag is on" -- which usually it isn't, as you may recall from the\par
discussion of SQLSetEnvAttr. The symbol "[P]" means "this function is legal\par
only if the statement is prepared". The chart does not show functions which\par
are, in functional effect, containers of other functions. For example, many\par
fields may be affected by SQLExecDirect, but we won't show that; we only show\par
SQLPrepare and/or SQLExecute. If either "May be Gotten By" or "May be Set by"\par
is blank for a particular automatic desc, that means the field is not affected\par
by any "get" or "set" function (as appropriate) for that desc.\par
\par
The desc Header Fields:\par
There are five desc header fields: SQL_DESC_ALLOC_TYPE, SQL_DESC_COUNT, SQL_DESC_DYNAMIC_FUNCTION, SQL_DESC_DYNAMIC_FUNCTION_CODE and SQL_DESC_KEY_TYPE. Their descriptions follow.\par
\par
## SQL_DESC_ALLOC_TYPE\par
SQL_DESC_ALLOC_TYPE 1099\par
      Type: SMALLINT. Importance: Low.\par
\par
Possible values: SQL_DESC_ALLOC_AUTO (1) or SQL_DESC_ALLOC_USER (2). The value\par
is set permanently when the desc is created. Those descs which are made\par
implicitly by a call to SQLAllocHandle(SQL_HANDLE_STMT,...) are automatic\par
descs; they will have SQL_DESC_ALLOC_AUTO in this field. Those descs which are\par
made explicitly by a call to SQLAllocHandle(SQL_HANDLE_DESC,...) are user\par
descs; they will have SQL_DESC_ALLOC_USER in this field.\par
\par
     May be Gotten by ...                 May be Set by ...\par
ARD  SQLFreeHandle, user                  SQLAllocHandle\par
IRD  SQLFreeHandle, user[P]               SQLAllocHandle\par
APD  SQLFreeHandle, user                  SQLAllocHandle\par
IPD  SQLFreeHandle, user                  SQLAllocHandle\par
\par
## SQL_DESC_COUNT\par
SQL_DESC_COUNT 1001\par
      Type: SMALLINT. Importance: High\par
\par
Provides the number of item descriptor areas in the desc. Conceptually, there\par
is a correspondence between the value in SQL_DESC_COUNT and the number of\par
actual items -- the "number of parameters" (for IPDs and APDs) or "the number\par
of Columns" (for IRDs and ARDs). However, this correspondence is not\par
automatically true. You have to make it so.\par
\par
Initially, the field value is 0. The SQLPrepare function will set\par
IRD.SQL_DESC_COUNT = <the number of Columns in the select list>. If "populate\par
IPD" is true, the SQLPrepare function will set IPD.SQL_DESC_COUNT = <the\par
number of parameter markers in SQL statement>.\par
\par
If you call a function which effectively creates a new IDA, then the COUNT\par
field value may go up. For example, if ARD.SQL_DESC_COUNT=0 and you call\par
SQLBindCol for COLUMN_1, then ARD.SQL_DESC_COUNT is set to 1.\par
\par
In ODBC, the value goes down if you "unbind" the last IDA (by setting\par
desc.IDA[n].SQL_DATA_POINTER=0).\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  SQLGetData, SQLGetDescRec,     SQLBindCol, SQLSetDescRec,\par
     user                           user\par
IRD  SQLGetDescRec[P],user[P],      SQLPrepare\par
     SQLNumResultCols[P]\par
APD  SQLExecute, SQLGetDescRec,     SQLBindParameter, SQLSetDescRec,\par
     SQLGetParamData, SQLParamData, user\par
     user\par
IPD  SQLExecute, SQLGetDescRec,     SQLBindParameter, SQLPrepare[I],\par
     user                           SQLSetDescRec, user\par
\par
## SQL_DESC_DYNAMIC_FUNCTION\par
SQL_DESC_DYNAMIC_FUNCTION 1031\par
      Type: VARCHAR. Importance: Low.\par
\par
This is an SQL3 field only; it's not in ODBC. It provides an SQL_TEXT string\par
containing a copy of the prepared statement. For example, after:\par
\par
   SQLPrepare(hstmt,"INSERT INTO Table_1 VALUES (5)",SQL_NTS);\par
\par
IRD.SQL_DESC_DYNAMIC_FUNCTION will contain 'INSERT INTO Table_1 VALUES (5)'.\par
You can get the same information with the SQLGetDiagField function.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD                                                         \par
IRD  user                           SQLPrepare\par
APD  \par
IPD  user                           SQLPrepare\par
\par
## SQL_DESC_DYNAMIC_FUNCTION_CODE\par
SQL_DESC_DYNAMIC_FUNCTION_CODE 1032\par
      Data type: INTEGER. Importance: Low.\par
\par
This is an SQL3 field only; it's not in ODBC. It provides a numeric code for\par
the prepared statement. For example, after:\par
\par
   SQLPrepare(hstmt,"INSERT INTO Table_1 VALUES (5)",SQL_NTS);\par
\par
IRD.SQL_DESC_DYNAMIC_FUNCTION_CODE will contain 50 (you can find the list of\par
possible codes in our chapter on SQL/CLI diagnostics). You can get the same\par
information with the SQLGetDiagField function.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD                                                       \par
IRD  user                           SQLPrepare\par
APD  \par
IPD  user                           SQLPrepare\par
\par
## SQL_DESC_KEY_TYPE\par
SQL_DESC_KEY_TYPE 1029\par
      Type: SMALLINT. Importance: Low.\par
\par
This is an SQL3 field only; it's not in ODBC. If a SELECT statement's select\par
list contains all the Columns of the Table's primary key, the value is 2. If\par
it contains all the Columns of one of the Table's preferred candidate keys,\par
the value is 1. Otherwise, the value is 0. For example, suppose that TABLE_1\par
has two Columns, COL_1 AND COL_2, and that TABLE_1's primary key is (COL_1).\par
In that case:\par
\par
   SQLPrepare(hstmt,"SELECT * FROM Table_1",SQL_NTS);\par
\par
will set IRD.SQL_DESC_KEY_TYPE = 1, and:\par
\par
   SQLPrepare(hstmt,"SELECT COUNT(*) FROM Table_1",SQL_NTS);\par
\par
will set IRD.SQL_DESC_KEY_TYPE = 0.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD                                                           \par
IRD  user                           SQLPrepare\par
APD  \par
IPD  \par
\par
The desc Item Descriptor Area (IDA) Fields:\par
There are 28 desc IDA fields: SQL_DESC_CHARACTER_SET_CATALOG,\par
SQL_DESC_CHARACTER_SET_SCHEMA, SQL_DESC_CHARACTER_SET_NAME,\par
SQL_DESC_COLLATION_CATALOG, SQL_DESC_COLLATION_SCHEMA, SQL_DESC_COLLATION,\par
SQL_DESC_DATA_POINTER, SQL_DESC_DATETIME_INTERVAL_CODE,\par
SQL_DESC_DATETIME_INTERVAL_PRECISION, SQL_DESC_INDICATOR_POINTER,\par
SQL_DESC_KEY_MEMBER, SQL_DESC_LENGTH, SQL_DESC_NAME, SQL_DESC_NULLABLE,\par
SQL_DESC_OCTET_LENGTH, SQL_DESC_OCTET_LENGTH_POINTER, SQL_DESC_PARAMETER_MODE,\par
SQL_DESC_PARAMETER_ORDINAL_POSITION, SQL_DESC_PARAMETER_SPECIFIC_CATALOG,\par
SQL_DESC_PARAMETER_SPECIFIC_SCHEMA, SQL_DESC_PARAMETER_SPECIFIC_NAME,\par
SQL_DESC_PRECISION, SQL_DESC_SCALE, SQL_DESC_TYPE, SQL_DESC_UDT_CATALOG,\par
SQL_DESC_UDT_SCHEMA, SQL_DESC_UDT_NAME and SQL_DESC_UNNAMED. These fields are\par
also known as the "Item Fields", the "fields of the Descriptor Record" (an\par
ODBC term) and as the "detail records". Their descriptions follow.\par
\par
## Character set fields\par
SQL_DESC_CHARACTER_SET_CATALOG 1019\par
      Type: VARCHAR. Importance: Low.\par
\par
SQL_DESC_CHARACTER_SET_SCHEMA 1020\par
      Type: VARCHAR. Importance: Low.\par
\par
SQL_DESC_CHARACTER_SET_NAME 1021\par
      Type: VARCHAR. Importance: Low.\par
\par
These three fields are SQL3 fields only; they're not in ODBC. Together, they\par
make up the qualified name of a Character set and are meaningful only if the\par
item's <data type> is CHAR, VARCHAR or CLOB. Some example values are:\par
'OCELOT', 'INFORMATION_SCHEMA' and 'ISO8BIT' (for the three fields,\par
respectively).\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  SQLGetData, user               user\par
IRD  SQLGetData, user               SQLPrepare\par
APD  SQLExecute, user               user\par
IPD  SQLExecute, user               SQLPrepare[I], user\par
\par
## Collation fields\par
SQL_DESC_COLLATION_CATALOG 1016\par
      Type: VARCHAR. Importance: Low.\par
\par
SQL_DESC_COLLATION_SCHEMA 1017\par
      Type: VARCHAR. Importance: Low.\par
\par
SQL_DESC_COLLATION 1018\par
      Type: VARCHAR. Importance: Low.\par
\par
These three fields are ANSI SQL3 fields only; they're not in ISO SQL3 or ODBC.\par
Together, they make up the qualified name of a Collation and are meaningful\par
only if the item's <data type> is CHAR, VARCHAR or CLOB. The Standard says,\par
ambiguously, that this is "the Character set's Collation". Presumably it is,\par
in fact, the item's Collation.\par
\par
For a select list, a standard DBMS may set these fields to a <Collation name>\par
-- for example, 'OCELOT', 'INFORMATION_SCHEMA' and 'POLISH' (for the three\par
fields, respectively). You can change the fields, but it does not matter -- the DBMS never reads them.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  user                           user\par
IRD  user                           SQLPrepare\par
APD  user                           user\par
IPD  user                           SQLPrepare[I], user\par
\par
##SQL_DESC_DATA_POINTER \par
SQL_DESC_DATA_POINTER 1010\par
      Type: POINTER. Importance: High.\par
\par
Provides the address of a host variable. Meaningful in the APD (where it\par
points to an input parameter), or in the ARD (where it points to a target for\par
the result-set Column).\par
\par
The initial value is 0. When this field is set to a non-zero value, the item\par
is considered to be "bound" -- a "bound parameter", a "bound target".\par
Application programmers must ensure that the address is valid.\par
\par
This field is reset to 0 if a change is made to a non-pointer field in the\par
same IDA using the SQLSetDescField function. For example: if, using\par
SQLSetDescField, you set IPD.IDA[4].SQL_DESC_DATETIME_INTERVAL_CODE = 1, the\par
side effect is that IPD.IDA[4].SQL_DESC_DATA_POINTER = 0. Moral: change this field last.\par
\par
In ODBC: the name is SQL_DESC_DATA_PTR.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  SQLGetData, SQLFreeStmt,       SQLSetDescRec, user\par
     user\par
IRD                                 \par
APD  SQLExecute, SQLFreeStmt,       SQLBindParameter, SQLSetDescRec,\par
     user                           user\par
IPD                                 SQLSetDescRec, user\par
\par
## SQL_DESC_DATETIME_INTERVAL_CODE\par
SQL_DESC_DATETIME_INTERVAL_CODE 1007\par
      Type: SMALLINT. Importance: Medium.\par
\par
This field will only be meaningful if the SQL_DESC_TYPE field is 9\par
(SQL_DATETIME) or 10 (SQL_INTERVAL). It will contain a datetime subtype (a\par
number between 1 and 5) or an interval subtype (a number between 1 and 13).\par
For example: if SQL_DESC_TYPE = 9 and SQL_DESC_DATETIME_INTERVAL_CODE = 5,\par
then the item's precise <data type> is known to be TIMESTAMP WITH TIME ZONE.\par
If you change the SQL_DESC_TYPE field to 9 or 10, you must change SQL_DESC_DATETIME_INTERVAL_CODE too.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  user                           SQLSetDescRec, user\par
IRD  SQLGetData, SQLDescribeCol,    SQLPrepare\par
     user\par
APD  SQLExecute, user               SQLSetDescRec, user\par
IPD  SQLExecute, user               SQLBindParameter, SQLSetDescRec,\par
                                    SQLPrepare[I], user\par
\par
## SQL_DESC_DATETIME_INTERVAL_PRECISION\par
SQL_DESC_DATETIME_INTERVAL_PRECISION 1014\par
      Type: SMALLINT. Importance: Medium.\par
\par
This field will only be meaningful if the SQL_DESC_TYPE field is 9\par
(SQL_DATETIME) or 10 (SQL_INTERVAL). This is the precision of the leading\par
datetime field -- not the fractional-seconds precision. For example, a DATE\par
value has three fields: YEAR, MONTH and DAY. The first ("leading") datetime\par
field in a DATE is YEAR, which always has four positions: yyyy. Therefore,\par
desc.IDA[n].SQL_DESC_DATETIME_INTERVAL_PRECISION = 4.\par
\par
In ODBC, SQL_DESC_DATETIME_INTERVAL_PRECISION is 26 rather than 1014 and <data\par
type> is INTEGER rather than SMALLINT.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  user                           user\par
IRD  SQLGetData, SQLDescribeCol,    SQLPrepare\par
     user\par
APD  SQLExecute, user               user\par
IPD  SQLExecute, user               SQLBindParameter, SQLPrepare[I], user\par
\par
## SQL_DESC_INDICATOR_POINTER\par
SQL_DESC_INDICATOR_POINTER 1009\par
      Type: POINTER TO INTEGER. Importance: Medium\par
\par
Provides the address of an indicator. This field is used together with\par
SQL_DESC_DATA_POINTER. For example, suppose that you set\par
ARD.IDA[n].SQL_DESC_INDICATOR_POINTER = &indicator (where &indicator means\par
"the address of a variable named indicator in the host program"). If\par
SQLGetData retrieves a null value for the nth Column in the select list,\par
indicator is set to SQL_NULL_DATA (-1).\par
\par
The field's initial value is 0.\par
\par
In ODBC, the name is SQL_DESC_INDICATOR_PTR.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  SQLGetData, user               SQLBindCol, SQLSetDescRec,\par
                                     user\par
IRD                                 \par
APD  user                           SQLBindParameter, SQLSetDescRec,\par
                                    user\par
IPD                                 SQLSetDescRec\par
\par
## SQL_DESC_KEY_MEMBER\par
SQL_DESC_KEY_MEMBER 1030\par
      Type: INTEGER. Importance: Low.\par
\par
This field is in SQL3 only; it's not in ODBC. If a fetched item is from a\par
Column of the selected Table's primary key or a preferred candidate key, then\par
the value is 1 (true); otherwise it's 0 (false). For example:\par
\par
   SQLPrepare(hstmt,"SELECT 5 FROM t",SQL_NTS);\par
\par
will set IRD.IDA[1].SQL_DESC_KEY_MEMBER = 0. (See also the header field SQL_DESC_KEY_TYPE.)\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  \par
IRD  user                           SQLPrepare\par
APD  \par
IPD  \par
\par
## SQL_DESC_LENGTH \par
SQL_DESC_LENGTH 1003\par
      Data type: INTEGER. Importance: Medium.\par
\par
For all character string <data type>s, this is the defined length in\par
characters -- for example, it equals 12 for a Column defined as VARCHAR(12).\par
For all bit string <data type>s, this is the defined length in bits. For all\par
temporal <data type>s, this is the defined length in positions -- for example,\par
it equals 10 for a Column defined as a DATE (because 2000-01-01 is 10\par
positions). For a BLOB <data type>, this is the defined length in octets. In\par
ANSI SQL, SQL_DESC_LENGTH may be changed with the SQLSetDescField function. In ISO SQL, it may not be.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  user                           user\par
IRD  SQLGetData, SQLDescribeCol,    SQLPrepare\par
     user\par
APD  SQLExecute, user               user\par
IPD  SQLExecute, user               SQLPrepare[I], user\par
\par
## SQL_DESC_NAME\par
SQL_DESC_NAME 1011\par
      Type: VARCHAR. Importance: Low.\par
\par
This provides the derived Column name if there's a select list. For example, after:\par
\par
   SQLPrepare(hstmt,"SELECT col_1 FROM Table_1",SQL_NTS);\par
\par
the DBMS sets IRD.IDA[n].SQL_DESC_NAME = "Col_1". In ANSI SQL, SQL_DESC_NAME\par
may be changed with the SQLSetDescField function. In ISO SQL, it may not be.\par
In ODBC, named parameters are supported.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  user                           user\par
IRD  SQLDescribeCol, user           SQLPrepare\par
APD  user                           user\par
IPD  user                           user\par
\par
## SQL_DESC_NULLABLE\par
SQL_DESC_NULLABLE 1008\par
      Type: SMALLINT. Importance: Medium.\par
\par
This field is 1 (true) (SQL_NULLABLE) if the value might be NULL; otherwise\par
it's 0 (false) (SQL_NO_NULLS). For a populated IPD, SQL_DESC_NULLABLE is 1. In\par
ANSI SQL, SQL_DESC_NULLABLE may be changed with the SQLSetDescField function.\par
In ISO SQL, it may not be. In ODBC, the value might also be 2\par
(SQL_NULLABLE_UNKNOWN).\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  user                           user\par
IRD  SQLDescribeCol, user           SQLPrepare\par
APD  user                           user\par
IPD  user                           SQLPrepare[I], user\par
\par
## SQL_DESC_OCTET_LENGTH\par
SQL_DESC_OCTET_LENGTH 1013\par
      Type: INTEGER. Importance: Medium.\par
\par
For any character string, bit string or BLOB <data type>, this is the item's\par
maximum length in octets.\par
\par
This field matters for "output": if a CHAR Column is fetched, the number of\par
octets transferred will be <= SQL_DESC_OCTET_LENGTH. For example, if you\par
intend to fetch into a C host variable defined as "char[20]", then you should\par
set ARD.IDA[n].SQL_DESC_OCTET_LENGTH = 20. For "input" (SQL_PARAM_MODE_IN\par
parameters), SQL_DESC_OCTET_LENGTH is not relevant. When the DBMS inputs\par
parameters, it uses the length pointed to by the SQL_DESC_OCTET_LENGTH_POINTER field.\par
\par
Despite some contradictions in other documents, we believe that datetime or\par
interval transfers are not affected by the value in this field.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  SQLGetDescRec, user            SQLBindCol, SQLSetDescRec\par
IRD  SQLGetDescRec, user            SQLPrepare, SQLSetDescRec\par
APD  SQLGetDescRec, user            SQLBindParameter, SQLSetDescRec\par
IPD  SQLGetDescRec, user            SQLBindParameter, \par
                                    SQLPrepare[I], SQLSetDescRec, user\par
\par
## SQL_DESC_OCTET_LENGTH_POINTER\par
SQL_DESC_OCTET_LENGTH_POINTER 1004\par
      Data type: POINTER TO INTEGER. Importance: Medium.\par
\par
This field provides the address of a length in octets. Its initial value is 0\par
(ARD/APD). For VARCHAR or BIT VARYING or BLOB <data type>s, this length is the\par
actual length, which may be less than the defined length. For other character\par
string and bit string <data type>s, the actual and maximum lengths are the\par
same because size is fixed. The size of the \\0 terminator is not included in\par
the octet length. For other <data type>s, the value is implementation-defined.\par
\par
This field and the SQL_DESC_INDICATOR_POINTER field may point to the same\par
place. In ISO SQL, IPD.IDA[n].SQL_DESC_LENGTH may be changed with the\par
SQLSetDescField function. In ANSI SQL, it may not be. In ODBC, the name is SQL_DESC_OCTET_LENGTH_PTR.\par
\par
[Obscure Rule] The rules change if SQL_DESC_OCTET_LENGTH_POINTER and\par
SQL_DESC_INDICATOR_POINTER contain the same address value (this is actually\par
imprecise: the rules don't really change, but octet length is always set after\par
indicator, and we stop if indicator == SQL_NULL_DATA).\par
\par
If they're separate:\par
On Output (taking SQLFetch for our example):\par
  If fetched value IS NULL:\par
    SQLFetch sets *SQL_DESC_INDICATOR_POINTER = SQL_NULL_DATA (-1)\par
    SQLFetch does not set *SQL_DESC_OCTET_LENGTH_POINTER\par
  If fetched value IS NOT NULL:\par
    SQLFetch sets *SQL_DESC_INDICATOR_POINTER = 0\par
    SQLFetch sets *SQL_DESC_OCTET_LENGTH_POINTER = string size in octets\par
On Input:\par
  *SQL_DESC_INDICATOR_POINTER should be either 0 or -1.\par
  *SQL_DESC_OCTET_LENGTH_POINTER can be SQL_NTS, SQL_DATA_AT_EXEC or length.\par
\par
If they're the same:\par
On Output (taking SQLFetch for our example):\par
  If fetched value IS NULL:\par
    SQLFetch sets *SQL_DESC_INDICATOR_POINTER = SQL_NULL_DATA (-1)\par
  If fetched value IS NOT NULL:\par
    SQLFetch sets *SQL_DESC_INDICATOR_POINTER = 0\par
/* We've proposed a change to the ISO committee; the following is an assumption that they'll adopt it: */\par
      () if CHAR or BLOB:\par
           *SQL_DESC_OCTET_LENGTH_POINTER = length\par
      () otherwise:\par
           "implementation-dependent", but assume it's like ODBC:\par
           *SQL_DESC_OCTET_LENGTH_POINTER = length\par
           ... This "overrides the setting of *SQL_DESC_INDICATOR_POINTER=0.\par
           ... So "strlen_or_ind" is a misnomer; it's "strlen_and_ind"\par
  If (CHAR or BLOB)\par
    If (truncation would occur):\par
      SQLFetch sets *SQL_DESC_INDICATOR_POINTER = length\par
    If (truncation would not occur):\par
      SQLFetch sets *SQL_DESC_INDICATOR_POINTER = 0\par
On Input:\par
  *SQL_DESC_INDICATOR_POINTER may be 0,-1,SQL_NTS,SQL_DATA_AT_EXEC, or length.\par
\par
The rules are a little confusing, but that's the price we have to pay for\par
backward compatibility -- some of the older CLI functions allow for only one\par
pointer variable which serves for both "indicator" and "string length" information.\par
\par
     May be Gotten by ...           May be Set by ...\par
ARD  user                           SQLBindCol, SQLSetDescRec,\par
                                    user\par
IRD  \par
APD  SQLExecute, user               SQLBindParameter, SQLSetDescRec,\par
                                    user\par
IPD                                 SQLSetDescRec\par
\par
## SQL_DESC_PARAMETER_MODE\par
SQL_DESC_PARAMETER_MODE 1021\par
      Data type: SMALLINT. Importance: Low.\par
\par
This field is in SQL3 only; it's not in ODBC. Its possible values are: 1\par
(SQL_PARAM_MODE_IN), 2 (SQL_PARAM_MODE_INOUT) and 4 (SQL_PARAM_MODE_OUT). If\par
the "populate IPD" flag is true, and the SQL statement is "CALL ...", and the\par
first parameter of the called routine is input, the DBMS sets IPD.IDA[1].SQL_DESC_PARAMETER_MODE=1.\par
\par
In ANSI SQL, users may only change this field in the IPD (with the\par
SQLSetDescField function). In ISO SQL, users may change this field in the IPD,\par
the APD and the ARD. In ODBC, a field named IPD.IDA[n].SQL_DESC_PARAMETER_TYPE\par
can be set to SQL_PARAM_MODE_IN, SQL_PARAM_MODE_INOUT or SQL_PARAM_MODE_OUT.\par
The default value is SQL_PARAM_MODE_INPUT.\par
\par
     May be Gotten by ...          May be Set by ...\par
ARD \par
IRD  user\par
APD  SQLExecute                    SQLBindParameter   \par
IPD                                SQLPrepare[I], user\par
\par
## SQL_DESC_PARAMETER_ORDINAL_POSITION\par
SQL_DESC_PARAMETER_ORDINAL_POSITION 1022\par
      Type: SMALLINT. Importance: Low.\par
\par
This field is in SQL3 only; it's not in ODBC. It provides an ordinal number,\par
for SQL routine parameters. If this item corresponds to the first parameter in\par
an SQL "CALL ..." statement, the DBMS sets IPD.IDA[n].SQL_DESC_PARAMETER_ORDINAL_POSITION=1. SQLPrepare sets IPD if "populate IPD" is true.\par
\par
In ANSI SQL, users may only change this field in the IPD (with the SQLSetDescField function). In ISO SQL, users may change this field in the IPD, the APD and the ARD.\par
\par
     May be Gotten by ...          May be Set by ...\par
ARD \par
IRD  user\par
APD   \par
IPD                                SQLPrepare[I], user\par
\par
## Parameter fields\par
SQL_DESC_PARAMETER_SPECIFIC_CATALOG 1023\par
      Type: VARCHAR. Importance: Low.\par
\par
SQL_DESC_PARAMETER_SPECIFIC_SCHEMA 1024\par
      Type: VARCHAR. Importance: Low.\par
\par
SQL_DESC_PARAMETER_SPECIFIC_NAME 1025\par
      Type: VARCHAR. Importance: Low.\par
\par
These three fields are SQL3 fields only; they're not in ODBC. Together, they\par
make up the qualified name of a parameter in an SQL "CALL ..." statement.\par
SQLPrepare sets IPD if "populate IPD" is true.\par
\par
In ANSI SQL, users may only change these fields in the IPD (with the SQLSetDescField function). In ISO SQL, users may change these fields in the IPD, the APD and the ARD.\par
\par
     May be Gotten by ...          May be Set by ...\par
ARD \par
IRD  user\par
APD   \par
IPD                                SQLPrepare[I], user\par
\par
## SQL_DESC_PRECISION\par
SQL_DESC_PRECISION 1005\par
      Type: SMALLINT. Importance: Medium.\par
\par
For all numeric <data type>s, this is a precision -- that is, for DECIMAL and\par
NUMERIC, it's the number of digits both before and after the decimal point;\par
for INTEGER and SMALLINT, it's the fixed implementation-defined number of\par
decimal or binary digits; for REAL, FLOAT and DOUBLE PRECISION, it's the\par
number of bits or digits in the mantissa. For all temporal <data type>s, this\par
is the fractional seconds precision -- that is, the number of digits after the\par
decimal point in the SECOND datetime component. The default value in each case\par
is what you'd get if you used the <data type> with its default value in a CREATE TABLE statement.\par
\par
     May be Gotten by ...          May be Set by ...\par
ARD  SQLGetData, user              SQLSetDescRec, user\par
IRD  SQLGetData, SQLDescribeCol,   SQLPrepare\par
     user\par
APD  user                          SQLSetDescRec\par
IPD  SQLExecute, user              SQLBindParameter, SQLSetDescRec,\par
                                   SQLPrepare[I], user\par
\par
## SQL_DESC_SCALE\par
SQL_DESC_SCALE 1006\par
      Type: SMALLINT. Importance: Medium.\par
\par
For DECIMAL or NUMERIC <data type>s, SQL_DESC_SCALE is the number of digits\par
after the decimal point. The default value is zero -- that is, if you change\par
the SQL_DESC_TYPE to SQL_DECIMAL or SQL_NUMERIC, then the value in\par
SQL_DESC_SCALE is implicitly set to 0. For SMALLINT or INTEGER <data type>s,\par
the DBMS will set IRD.IDA[n].SQL_DESC_SCALE = 0 during SQLPrepare, and ignore\par
the field on all other occasions. For all other <data type>s, the value of\par
SQL_DESC_SCALE is irrelevant. The field's initial value is 0.\par
\par
     May be Gotten by ...          May be Set by ...\par
ARD  SQLGetData, user              SQLSetDescRec, user\par
IRD  SQLGetData, SQLDescribeCol,   SQLPrepare\par
     user[P]\par
APD  user                          SQLSetDescRec, user\par
IPD  SQLExecute, user              SQLBindParameter, SQLSetDescRec,\par
                                   SQLPrepare[I], user\par
\par
## SQL_DESC_TYPE\par
SQL_DESC_TYPE 1002\par
      Type: SMALLINT. Importance: High.\par
\par
This field provides the item's <data type>. Its possible values are: 1\par
(SQL_CHAR), 2 (SQL_NUMERIC), 3 (SQL_DECIMAL), 4 (SQL_INTEGER), 5\par
(SQL_SMALLINT), 6 (SQL_FLOAT), 7 (SQL_REAL), 8 (SQL_DOUBLE), 9 (SQL_DATETIME),\par
10 (SQL_INTERVAL), 12 (SQL_VARCHAR), 14 (SQL_BIT), 15 (SQL_BIT_VARYING), 16\par
(SQL_BOOLEAN), 17 (SQL_UDT), 18 (SQL_UDT_LOCATOR), 19 (SQL_ROW_TYPE), 20\par
(SQL_REF), 30 (SQL_BLOB), 31 (SQL_BLOB_LOCATOR), 40 (SQL_CLOB), 41\par
(SQL_CLOB_LOCATOR), 50 (SQL_ARRAY), 51 (SQL_ARRAY_LOCATOR). For datetime and\par
interval items, the subtype is in the SQL_DESC_DATETIME_INTERVAL_CODE field.\par
\par
You may set ARD.IDA[n].SQL_DESC_TYPE = SQL_C_DEFAULT. By setting SQL_DESC_TYPE\par
with SQLSetDescField, YOU CAUSE ALL OTHER FIELDS OF THE IDA TO BE RESET TO\par
IMPLEMENTATION-DEPENDENT VALUES. Moral: always set SQL_DESC_TYPE first.\par
\par
     May be Gotten by ...          May be Set by ...\par
ARD  SQLGetData, user              SQLBindCol, SQLSetDescRec,\par
                                   user\par
IRD  SQLGetData, SQLDescribeCol,   SQLPrepare\par
     user\par
APD  user                          SQLBindParameter, SQLSetDescRec,\par
                                   user\par
IPD  SQLExecute, user              SQLBindParameter, SQLSetDescRec,\par
                                   SQLPrepare[I], user\par
\par
## UDT fields\par
SQL_DESC_UDT_CATALOG 1026\par
      Type: VARCHAR. Importance: Low.\par
\par
SQL_DESC_UDT_SCHEMA 1027\par
      Type: VARCHAR. Importance: Low.\par
\par
SQL_DESC_UDT_NAME 1028\par
      Type: VARCHAR. Importance: Low.\par
\par
These three fields are SQL3 fields only; they're not in ODBC. Together, they\par
make up the qualified name of the item's user-defined type, if it has one.\par
\par
     May be Gotten by ...          May be Set by ...\par
ARD  user                          user\par
IRD  SQLGetData, user              SQLPrepare\par
APD  SQLExecute, user              user\par
IPD  SQLExecute, user              user\par
\par
## SQL_DESC_UNNAMED\par
SQL_DESC_UNNAMED 1012\par
      Type: SMALLINT. Importance: Low.\par
\par
This field has two possible values: 1 (true) (SQL_UNNAMED) or 0 (false) (SQL_NAMED).\par
\par
In the IRD: if the select list contains an initially-unnamed Column, then the\par
DBMS makes up a name, returns the made-up name to the SQL_DESC_NAME field and\par
sets the SQL_DESC_UNNAMED field to SQL_UNNAMED. For example, after:\par
\par
   SQLPrepare(hstmt,"SELECT 5+1 FROM Table_1",SQL_NTS);\par
\par
the DBMS might set IRD.IDA[n].SQL_DESC_NAME = "expr1" (this is the value an\par
Access clone would give), and then set IRD.IDA[n].SQL_DESC_UNNAMED = 1 (SQL_UNNAMED).\par
\par
In the IPD: if "auto-populate" happens, then the DBMS sets IPD.IDA[n].SQL_DESC_UNNAMED = 1 (SQL_UNNAMED).\par
\par
In ANSI SQL, users may change this field (with the SQLSetDescField function). In ISO SQL, they may not.\par
\par
     May be Gotten by ...          May be Set by ...\par
ARD  user                          user\par
IRD  user                          SQLPrepare\par
APD  user                          user\par
IPD  user                          SQLPrepare[I], user\par
\par
The desc Functions\par
\par
We are now ready to describe the individual desc functions. There is a good\par
deal of redundancy here, because several functions are available which do the\par
same thing. If you're a beginner, we suggest that you pay particular attention\par
to SQLSetDescField and SQLGetDescField, because it is possible to do nearly\par
everything with those two low-level functions alone.\par
\par
There are 14 desc functions. Their descriptions follow.\par
\par
SQLAllocHandle(SQL_HANDLE_DESC,...)\par
\par
Function Prototype:\par
  SQLRETURN SQLAllocHandle(\par
    SQLSMALLINT HandleType,     /* 16-bit input = SQL_HANDLE_DESC */\par
    SQLINTEGER InputHandle,     /* 32-bit input, must be a hdbc */\par
    SQLINTEGER *OutputHandle    /* 32-bit output, a hdesc */\par
    );\par
\par
Job:\par
Allocate a user desc. (Note: User descs are unimportant. We start off with this function for symmetry reasons.)\par
\par
Algorithm:\par
If (HandleType == SQL_HANDLE_DESC)\par
  If (InputHandle is not a valid handle of a dbc)\par
    return error: CLI-specific condition-invalid handle\par
  Empty the dbc's diagnostics area.\par
  If (dbc is not connected)\par
    Set *OutputHandle = 0\par
    return error: connection exception-connection does not exist\par
  If (the maximum number of descs has already been allocated)\par
    Set *OutputHandle = 0\par
    /* The maximum number of descs is implementor-defined */ \par
    return error: HY014 CLI-specific condition-limit on number of handles exceeded\par
  If (there's not enough memory)\par
    Set *OutputHandle = 0\par
    return error: HY001 CLI-specific condition-memory allocation error\par
  Allocate a new desc, associated with the dbc.\par
  Set desc.SQL_ALLOC_TYPE = 2 i.e. SQL_DESC_ALLOC_USER.\par
  /* Thus this desc is marked as a user desc, not an automatic desc. */\par
  *OutputHandle = handle of new desc.\par
\par
Notes:\par
      ## In early prototypes of the CLI there were separate calls for\par
different resource types (see SQLAllocEnv, SQLAllocConnect, SQLAllocStmt).\par
Eventually people realized that the number of handle types might grow\par
indefinitely, so SQLAllocHandle was defined as a generalized "allocate handle"\par
function for all current and future resource types.\par
      ## Call this function after you have allocated a dbc and after you have\par
connected, since the InputHandle parameter is a hdbc.\par
      ## This function is only for user descs. There are two kinds of descs:\par
automatic descs and user descs. The DBMS implicitly sets up 4 automatic descs\par
(ARD, APD, IRD, IPD) when SQLAllocHandle(SQL_HANDLE_STMT,...) is called, and\par
associates them with the stmt. You explicitly set up user descs with\par
SQLAllocHandle(SQL_HANDLE_DESC,...), and they are associated with the dbc.\par
      ## Using another function (SQLSetStmtAttr), you can replace one of the\par
automatic descs with a user desc. Such descs can be shared among multiple\par
stmts.\par
      ## Using another function (SQLCopyDescRec), you can save the contents of\par
an automatic desc in a user desc, for backup purposes.\par
\par
Example:\par
 #include "sqlcli.h"\par
 ...\par
 SQLHDBC hdbc;\par
 SQLHDESC hdesc;\par
 ...\par
 SQLConnect(hdbc,...);\par
 ...\par
 SQLAllocHandle(SQL_HANDLE_DESC,hdbc,&hdesc);\par
\par
ODBC: The SQLAllocHandle function is new in ODBC 3.5; in ODBC 2.0 the desc resource could not be explicitly allocated.\par
\par
SQLFreeHandle(SQL_HANDLE_DESC,...)\par
\par
Function Prototype:\par
 SQLRETURN SQLFreeHandle(     /* function returns SMALLINT */\par
      SQLSMALLINT HandleType, /* 16-bit input, = SQL_HANDLE_HDESC */\par
    SQLINTEGER Handle         /* 32-bit input, must be a hdesc */\par
    );\par
\par
Job:\par
Destroy a user desc. (Remember that the SQLFreeHandle function can be used to\par
destroy any resource: an env, a dbc, a stmt or a desc. We are treating the\par
four variants as four separate functions. In this section, our sole concern is desc.)\par
\par
Algorithm:\par
 If (HandleType == SQL_HANDLE_DESC)\par
   If (Handle is not really a handle of a desc)\par
   return error: CLI-specific condition-invalid handle\par
 Empty the desc's diagnostics area.\par
 The desc's dbc becomes the "current dbc".\par
 If (there is a deferred parameter number)\par
   return error: HY010 CLI-specific condition-function sequence error\par
 If (desc.SQL_DESC_ALLOC_TYPE == SQL_DESC_ALLOC_AUTO)\par
   /* You can't free any of the four descs (ARD IRD APD IPD) that\par
     were automatically allocated when you made a stmt. They stay\par
       around till you free the stmt. You can only free a "user"desc --\par
       a desc which you allocated explicitly with SQLAllocHandle. */\par
   return error: HY017 CLI-specific condition-invalid use of automatically-allocated descriptor\par
 /* The following cancels the effects of any SQLSetStmtAttr calls which\par
   might have made the user desc into an ARD or APD, in place of the\par
   automatic ARD or APD desc. */\par
 For (each stmt associated with dbc)\par
   If (stmt is associated with the desc)\par
    If (the desc is currently the stmt's ARD)\par
     Re-associate stmt with the automatically-allocated ARD\par
      If (the desc is currently the stmt's APD)\par
     Re-associate stmt with the automatically-allocated APD\par
 Deallocate desc.\par
 The handle becomes invalid.\par
\par
Notes:\par
      ## If SQLFreeHandle returns SQL_ERROR, then the handle is still live and you can get diagnostics.\par
      ## This function is the reverse of the SQLAllocHandle(SQL_HANDLE_DESC,...) function. Only user descs are destructible with SQLFreeHandle(SQL_HANDLE_DESC,...).\par
      ## The SQLDisconnect function will automatically destroy all descs which are associated with a dbc. So technically you don't need to call SQLFreeHandle(SQL_HANDLE_DESC...) if you are about to disconnect.\par
\par
Example:\par
 #include "sqlcli.h"\par
 SQLHDESC hdesc;\par
 ...\par
 SQLFreeHandle(SQL_HANDLE_DESC,hdesc);\par
\par
ODBC: SQLFreeHandle(SQL_HANDLE_DESC,...) is new in ODBC 3.0.\par
\par
SQLGetDescField\par
\par
Function Prototype:\par
 SQLRETURN SQLGetDescField (\par
   SQLHDESC hdesc,                       /* 32-bit input */\par
   SQLSMALLINT RecordNumber,             /* 16-bit input */\par
   SQLSMALLINT FieldIdentifier,          /* 16-bit input */\par
   SQLPOINTER Value,                     /* VOID* output */\par
   SQLINTEGER BufferLength,              /* 32-bit input */\par
   SQLINTEGER *StringLength              /* 32-bit output */\par
   );\par
\par
Job:\par
Get one field from a desc.\par
\par
Algorithm:\par
If (FieldIdentifier<> one of the FieldIdentifier codes in "The Desc Fields")\par
 return error: HY091 CLI-specific condition-invalid descriptor field identifier.\par
If (FieldIdentifier is the code for one of the IDA fields) \par
 /* The RecordNumber parameter would be irrelevant for a "header field",\par
   but IDA is multiple-occurrence so we need a valid index for IDA fields */\par
 If (RecordNumber < 1)\par
   return error: '07009': Dynamic SQL error-invalid descriptor index.\par
 If (RecordNumber > SQL_DESC_COUNT)\par
   /* Example: if the desc is an IRD, and the only SQL statement so far is\par
     INSERT, then SQL_DESC_COUNT is zero. If now you pass SQL_DESC_TYPE\par
     as the FieldIdentifier parameter and 5 as the RecordNumber parameter,\par
     then the DBMS returns with return code = SQL_NO_DATA. */\par
   Return with warning: '02000': No data.\par
If (FieldIdentifier is only applicable for a Prepared Statement, and there is no Prepared Statement)\par
 /* Example: if the desc is an IRD, and no SQLPrepare or SQLExecDirect\par
   has happened for the stmt associated with the desc, then a request\par
   for SQL_DESC_TYPE would make no sense. */\par
 Return error: HY007 CLI-specific condition-associated statement  is not prepared.\par
If (FieldIdentifier is not applicable for this type of desc)\par
 /* Example: if the desc is an IPD, then a request for\par
   SQL_DESC_INDICATOR_POINTER would make no sense. */\par
 Return with error HY091 CLI-specific condition-invalid descriptor field identifier.\par
If (the field is in its initially-undefined state)\par
 /* Example: if the desc is an IPD, and the DBMS doesn't "automatically\par
   populate" the IPD, then most fields stay in their "undefined" state. */\par
 Return with error HY091 CLI-specific condition-invalid descriptor field identifier.\par
Retrieve the value of the field indicated by the FieldIdentifier parameter,\par
and put it in the place pointed to by the Value parameter. Notice that the\par
value might be a smallint, or it might be an integer, or it might be a\par
character string. In the latter case, the rules of Character String\par
Retrieval apply.\par
\par
Notes:\par
      ## SQLGetDescField is a fundamental desc routine. There are several\par
other routines which are, conceptually, wrappers for one or more\par
SQLGetDescField calls. For example, the SQLColAttribute function will\par
implicitly call SQLGetDescField after finding the IRD; SQLGetDescRec will\par
retrieve seven desc fields at once (name, type, subtype, length, precision,\par
scale and nullable).\par
      ## In our descriptions of the desc fields, the included charts of\par
functions that affect the field use the word "user" to identify those cases\par
where SQLGetDescField may be called to retrieve a single value after\par
explicitly passing the field's numeric identifier.\par
      ## The first SQLGetDescField parameter is a hdesc. To get this handle,\par
save the handle when you call SQLAllocHandle (if it's a user desc) and call\par
SQLGetStmtAttr (if it's an automatic desc).\par
      ## The second parameter -- FieldIdentifier -- is unnecessary for a\par
header field. For an IDA, it's an index to the multiple-occurrence structure\par
and should contain a value between 1 and "count".\par
\par
Example:\par
Assume you have just called:\par
\par
   SQLExecDirect(hstmt,"SELECT * FROM Table_1",SQL_NTS);\par
\par
Since SQLExecDirect implies a "SQLPrepare" phase, the DBMS has filled in some of the IRD fields, as follows:\par
\par
---------------------------------------------------------------------------\par
-\par
--------------------\par
--SQL_DESC_COUNT -\par
- ------------------     << picture of IRD after "SELECT * FROM Table_1" >>\par
- | 00003       |\par
- ------------------\par
-\par
-------------------------------------------------------------------\par
- - SQL_DESC_NAME | SQL_DESC_PRECISION | SQL_DESC_TYPE | ... |\par
-------------------------------------------------------------------\par
-  1-'Col_1'      | 00005              | 00002         | ... |\par
-  2-'Col_2'      | 00004              | 00003         | ... |\par
-  3-'Col_3'      | ??                 | 00001         | ... |\par
-   ------------------------------------------------------------------\par
-\par
---------------------------------------------------------------------------\par
\par
For space reasons, we've shown only a few fields in this diagram. But there's\par
enough to make it clear that: (a) the DBMS found three Columns in the result\par
set (as indicated by SQL_DESC_COUNT == 3), (b) the first Column is named\par
COL_1, its <data type> is NUMERIC (as indicated by SQL_DESC_TYPE == 2) and its\par
precision is 5, (c) the second Column is named COL_2, its <data type> is\par
DECIMAL (as indicated by SQL_DESC_TYPE == 3) and its precision is 4, and (d)\par
the third Column is named COL_3, its <data type> is CHAR (as indicated by\par
SQL_DESC_TYPE == 1) and its precision is unset because CHAR Columns have no precision (they have a length instead).\par
\par
Here are some SQLGetDescField calls -- and what will be put into the value variable:\par
\par
   SQLGetDescField(hdesc,NULL,SQL_DESC_COUNT,&value,NULL,NULL);\par
    -- gets 3\par
\par
   SQLGetDescField(hdesc,1,SQL_DESC_TYPE,&value,NULL,NULL);\par
    -- gets 2\par
\par
   SQLGetDescField(hdesc,3,SQL_DESC_PRECISION,&value,NULL,NULL);\par
    -- gets 4\par
\par
And here is a larger code snippet, which finds out the hdesc value (a necessary preliminary!), then displays the name of every Column in TABLE_1:\par
\par
 #include "sqlcli.h"\par
 ...\par
 SQLHSTMT hstmt;                    /* handle of stmt */\par
 SQLHDESC hdesc;                    /* handle of IRD */\par
 SQLSMALLINT i,col_count;           /* used for a loop counter */\par
 SQLCHAR *col_name[128+1];\par
 ...\par
 SQLExecDirect(hstmt,"SELECT * FROM Table_1",SQL_NTS);\par
 SQLGetStmtAttr(hstmt,SQL_ATTR_IMP_ROW_DESC,&hdesc,NULL,NULL);\par
 SQLGetDescField(hdesc,SQL_DESC_COUNT,&col_count,NULL,NULL);\par
 printf("The Columns of Table_1 are:\\n");\par
 for (i=1; i<=col_count; ++i) \{\par
   SQLGetDescField(hdesc,i,SQL_DESC_NAME,col_name,sizeof(col_name),NULL);\par
   printf("%s\\n",col_name); \}\par
 ...\par
\par
ODBC: The SQLGetDescField function is new in ODBC 3.5. There are some\par
implementation-defined additional fields. The expected behaviour is somewhat\par
different if you ask for a field which has no defined value: a\par
standard-conformant DBMS would return SQL_ERROR, an ODBC-conformant DBMS would\par
return SQL_SUCCESS and an undefined value.\par
\par
SQLSetDescField\par
\par
Function Prototype:\par
 SQLRETURN SQLSetDescField(\par
   SQLHDESC hdesc,                  /* 32-bit input */\par
   SQLSMALLINT RecordNumber,        /* 16-bit input */\par
   SQLSMALLINT FieldIdentifier,     /* 16-bit input */\par
   SQLPOINTER Value,                /* ANY* input */\par
   SQLINTEGER BufferLength          /* 32-bit input */\par
   );\par
\par
Job:\par
Assign a value to one field in a desc.\par
\par
Algorithm:\par
If (desc is associated with a "deferred parameter")\par
 return error: HY010 CLI-specific condition-function sequence error\par
If (desc is an IRD)\par
 /* This error will appear only for ISO SQL3: */\par
 return error: HY016 CLI-specific condition-cannot modify an implementation row descriptor    \par
If (FieldIdentifier is not a code used in "The Desc Fields" list)\par
 return error: HY091 CLI-specific condition-invalid descriptor field identifier\par
If (this field cannot be set by the user)\par
 return error: HY091 CLI-specific condition-invalid descriptor field identifier \par
If (FieldIdentifier == SQL_DESC_COUNT)\par
    Set desc.SQL_DESC_COUNT = Value\par
If (this is an IDA field i.e. not a header field)\par
 If (RecordNumber < 1)\par
   return error: 07009 Dynamic SQL error-invalid descriptor index \par
 /* We have: a particular field in a particular IDA of a desc\par
    identified by FieldIdentifier/RecordNumber/hdesc respectively).\par
    We have: a new value for that field (in Value/BufferLength). */\par
If (FieldIdentifier == SQL_DESC_OCTET_LENGTH_POINTER)\par
    Set desc.IDA[RecordNumber].SQL_DESC_OCTET_LENGTH_POINTER = Value\par
If (FieldIdentifier == SQL_DESC_INDICATOR_POINTER)\par
 Set desc.IDA[RecordNumber].SQL_DESC_INDICATOR_POINTER = Value\par
If (FieldIdentifier == SQL_DESC_CHARACTER_SET_CATALOG (or SCHEMA) (or NAME))\par
 /* Value points to a string, BufferLength is string size, possibly            \par
    BufferLength == SQL_NTS */\par
 Trim lead and trail spaces from the string.\par
 Ensure that the string is a valid identifier.\par
 /* Valid identifiers may include introducers. */\par
 Copy string to desc.IDA[RecordNumber].SQL_DESC_CHARACTER_SET_CATALOG (or\par
SCHEMA) (or NAME)\par
If (RecordNumber > desc.SQL_DESC_COUNT)\par
 /* Change SQL_DESC_COUNT so it equals the maximum IDA index number */\par
 Set desc.SQL_DESC_COUNT = RecordNumber\par
If (FieldIdentifier <> SQL_DESC_COUNT)\par
 If (FieldIdentifier not\par
SQL_DESC_OCTET_LENGTH_POINTER|SQL_DESC_DATA_POINTER|INDICATOR_POINTER)\par
   Set desc.IDA[RecordNumber].SQL_DESC_DATA_POINTER = 0\par
If (FieldIdentifier == SQL_DESC_DATA_POINTER)\par
 Set desc.IDA[RecordNumber].SQL_DESC_DATA_POINTER = Value\par
 If (Value <> 0)\par
   /* The "Consistency check" is described later in this chapter.\par
     Basically, it just checks that field values aren't absurd. */\par
   If ("Consistency check" failure)\par
    /* SQL_DESC_DATA_POINTER field might be changed despite the error */\par
    return error: HY021 CLI-specific condition-inconsistent descriptor information\par
If (FieldIdentifier == SQL_DESC_TYPE)\par
    If (Value is not a valid data type, for example SQL_NUMERIC)\par
   return error: HY004 CLI-specific condition-invalid data type\par
 Set desc.IDA[RecordNumber].SQL_DESC_TYPE = Value\par
 /* See the "Default values" chart in this section */\par
    Set other fields to their "default values"\par
   If (FieldIdentifier == SQL_DATETIME_INTERVAL_CODE)\par
 If (desc.IDA[RecordNumber].SQL_DESC_TYPE is datetime (9))\par
   If (Value=1 or 2 or 4: i.e.: date or time or time with time zone)\par
      Set desc.IDA[RecordNumber].SQL_DESC_PRECISION = 0\par
   If (Value=3 or 5: i.e.: timestamp or timestamp with time zone)\par
    Set desc.IDA[RecordNumber].SQL_DESC_PRECISION = 6\par
   Set other fields to implementation-dependent values\par
 If (desc.ida[RecordNumber].SQL_DESC_TYPE is interval)\par
   Set desc.IDA[RecordNumber].SQL_DESC_DATETIME_INTERVAL_PRECISION = 2\par
   If (Value is for an interval that ends with SECOND)\par
      Set desc.IDA[RecordNumber].SQL_DESC_PRECISION = 6\par
   Else\par
    Set desc.ida[RecordNumber].SQL_DESC_PRECISION = 0\par
/* For other FieldIdentifier values, there is no standard\par
  procedure. A reasonable assumption is that the DBMS would\par
  simply copy Value to the field indicated by FieldIdentifier. */\par
\par
Notes:\par
      ## Sometimes Value is a pointer; sometimes it's an integer; sometimes\par
it's a smallint; depending on FieldIdentifier.\par
      ## If you must change multiple fields in one IDA, do them in this order:\par
            ## Change the SQL_DESC_TYPE field first.\par
            ## Change the SQL_DESC_DATETIME_INTERVAL_CODE field second. \par
            ## Change the other fields (except for SQL_DESC_DATA_POINTER) in any order.\par
            ## Change the SQL_DESC_DATA_POINTER field last.\par
If you don't set fields in this order, you'll get errors. It's deliberate.\par
      ## If an error happens, the value of the field may be changed anyway.\par
      ## If you change a header field, you should pass RecordNumber = 0 (otherwise, in theory, you could inadvertently changed the SQL_DESC_COUNT field).\par
      ## The <data type> of Value should correspond to the <data type> of the\par
field being changed. For example, if changing the SQL_DESC_SCALE field, Value\par
should contain a SMALLINT value. For a list of the <data type> correspondences\par
between the SQL predefined <data type>s and host variables, see our chapter on\par
embedded SQL.\par
      ## The SQLSetDescField function can only set one field at a time.\par
Therefore, it is a "fundamental" function. There are other functions which can\par
be used to change multiple fields (SQLSetDescRec, SQLBindParameter and SQLBindCol).\par
      ## Default Values -- A change to SQL_DESC_TYPE will cause other IDA\par
fields to be reset to their "default values". This chart shows what the\par
changes are. Any fields not shown are reset to implementation-dependent values.\par
\par
If SQL_DESC_TYPE is changed to ...  ... Then these fields change too\par
SQL_CHAR, SQL_VARCHAR, SQL_CLOB     SQL_DESC_CATALOG etc.: default set\par
                                    SQL_LENGTH: maximum length [Note 1]\par
SQL_BIT, SQL_BIT_VARYING, SQL_BLOB  SQL_LENGTH: maximum length\par
SQL_DATETIME                        SQL_PRECISION: 0\par
SQL_INTERVAL                        SQL_DATETIME_INTERVAL_PRECISION: 2\par
SQL_DECIMAL, SQL_NUMERIC            SQL_PRECISION: maximum precision [Note 2]\par
                                    SQL_SCALE: 0\par
SQL_FLOAT                           SQL_PRECISION: default precision [Note 2]\par
\par
            ## Note 1: The "maximum length" is not the usual default value for\par
a CHAR <data type>. If you say "CREATE TABLE Table_1 (col_1 CHAR);", the\par
default length is 1. That is why, in ODBC, if you set SQL_DESC_TYPE to\par
SQL_CHAR, the SQL_LENGTH field changes to 1. But in standard SQL, it becomes a\par
character string <data type>'s "maximum possible length", which is an\par
implementation-defined size.\par
            ## Note 2: The "default precision" of SQL_DECIMAL, SQL_NUMERIC and\par
SQL_FLOAT <data type>s is implementation-defined.\par
            ## The Standard has omitted mention of all other <data type>s in\par
relation to SQLSetDescField, and ends with a note that says an error will be\par
returned for any type not shown in the chart. In effect, this means that all\par
<data types> other than SQL_CHAR, SQL_VARCHAR, SQL_CLOB, SQL_BIT,\par
SQL_BIT_VARYING, SQL_BLOB, SQL_DATETIME, SQL_INTERVAL, SQL_DECIMAL,\par
SQL_NUMERIC and SQL_FLOAT are technically illegal here. The wise programmer\par
will assume that these matters will be resolved by the DBMS vendor -- not\par
being able to use SQL_INTEGER, for example, seems too severe a restriction to be followed.\par
      ## Consistency check -- While you're changing descriptor fields, you might cause temporary inconstancy. Here's how:\par
            ## [Step 1] You change SQL_DESC_TYPE to SQL_DECIMAL. Changing the\par
<data type> triggers a wholesale resetting of all other IDA fields to default\par
values. For example, the SQL_DESC_PRECISION field becomes 1 (an\par
implementation-defined default), the SQL_DESC_SCALE field becomes 0 and the\par
SQL_DESC_DATA_POINTER becomes a null pointer.\par
            ## [Step 2] You change SQL_DESC_SCALE to 5. Now the scale is\par
greater than the precision. That is inconsistent -- a DECIMAL(1,5) definition\par
is illegal. But don't worry -- the DBMS won't reject your change.\par
            ## [Step 3] You change SQL_DESC_PRECISION to 6. Now the fields are consistent again.\par
            ## [Step 4] You change SQL_DESC_DATA_POINTER to a host-variable\par
address. Changing the data pointer triggers a consistency check. The rationale\par
for delaying the consistency check until you change the data pointer is that\par
temporary inconsistencies are inevitable if you change one field at a time,\par
but don't matter as long as the data pointer is a null pointer. When you set\par
the data pointer, you "bind the Column" to the host variable. At that point\par
the DBMS cannot allow any further inconsistency. If you've read our chapters\par
about the various SQL predefined <data type>s, you'll find that the\par
consistency check is merely an enforcement of the rules you already know. And\par
there are no **GOTCHAs because the DBMS only checks what's relevant. It looks\par
for these things:\par
                  ## SQL_DESC_PRECISION, SQL_DESC_SCALE, SQL_DESC_LENGTH,\par
SQL_DESC_DESC_DATETIME_INTERVAL_CODE and SQL_DESC_DATETIME_INTERVAL_PRECISION\par
must be valid if it's possible to specify precision, scale, length and/or\par
specific datetime or interval leading-field precision when you're defining a\par
Column of the given <data type>. For example, "FLOAT(precision)" is legal in\par
definitions, therefore SQL_DESC_PRECISION must have a valid value if\par
SQL_DESC_TYPE = SQL_FLOAT. On the other hand, precision is not specifiable for\par
REAL Columns, so there is no check of SQL_DESC_PRECISION if SQL_DESC_TYPE =\par
SQL_REAL. If SQL_DESC_TYPE is NUMERIC or DECIMAL, then scale and precision\par
must be valid for the <data type> (e.g. scale cannot be greater than\par
precision). (Warning: this description is of the SQL Standard "Consistency\par
Check" definition. The ODBC "Consistency Check" is more picky.)\par
                  ## For IDAs within application descriptors (ARDs or APDs),\par
SQL_DESC_TYPE must be a <data type> that's representable in the host language.\par
In our charts of <data type> correspondences (see our chapter on embedded\par
SQL), we showed you that the SQL INTEGER <data type> translates directly to a\par
C data type: long. Easy times. Now what about the NUMERIC <data type>? Well\par
you'd have to CAST it to something that C can handle: either a floating-point\par
or a character-string. Casting is easy -- just change the <data type> as we\par
described in each <data type> chapter.\par
                  ## If the DBMS detects an inconsistency during execution of\par
SQLSetDescField or SQLSetDescRec, the SQLSTATE error return is HY021\par
CLI-specific condition-inconsistent descriptor information.\par
      ## ** TIP: even though you never need an SQL_DESC_DATA_POINTER value in\par
an IPD IDA, set it anyway. That will force a consistency check. It's better to\par
check for inconsistency in advance, rather than waiting for the consistency\par
error to happen when you try to execute the statement.\par
      ## The DBMS may also detect inconsistency during execution of\par
SQLBindParameter or SQLBindCol, but usually there is a final Consistency Check\par
during SQLExecute. If the DBMS detects an inconsistency during execution of\par
SQLExecute, the SQLSTATE error return is either 07001 Dynamic SQL error-using\par
clause does not match dynamic parameters or 07002 Dynamic SQL error-using\par
clause does not match target specifications. (There appears to be an error in\par
the Standard; this is what we believe is the intended meaning.)\par
\par
Example:\par
You have an SQL statement which uses an integer input parameter. You want to\par
tell the DBMS about it, by setting certain fields of the APD. Assume that the\par
"auto-populate IPD" flag is off, so you'll have to set some fields in the IPD\par
too. Here's how.\par
\par
 #include "sqlcli.h"\par
 SQLHSTMT hstmt;\par
 SQLHDESC hapd,hipd;          /* hapd="handle of APD"; hipd="handle of IPD" */\par
 SQLINTEGER input_variable;   /* this has the value we pass */\par
 ...\par
 SQLPrepare(hstmt,"INSERT INTO Table_1 VALUES (?)",SQL_NTS);\par
 SQLGetStmtAttr(hstmt,SQL_ATTR_AUTO_APD,\par
 SQLGetStmtAttr(hstmt, SQL_ATTR_APP_PARAM_DESC, &hapd, NULL, NULL);\par
 SQLSetDescField(hapd,1,SQL_DESC_TYPE,SQL_INTEGER,NULL);\par
 SQLSetDescField(hapd,1,SQL_DESC_DATA_POINTER,&input_variable,NULL);\par
 SQLGetStmtAttr(hstmt, SQL_ATTR_IMP_PARAM_DESC, &hipd, NULL, NULL);\par
 SQLSetDescField(hipd,1,SQL_DESC_TYPE,SQL_INTEGER,NULL);\par
 SQLSetDescField(hipd,1,SQL_DESC_DATA_POINTER,&input_variable,NULL);\par
 input_variable = 55;\par
 SQLExecute(hstmt);\par
 ...\par
\par
Here is a picture of the APD after the SQLSetDescField calls are done:\par
\par
- ----------------------- -------------------\par
--SQL_DESC_ALLOC_TYPE- - SQL_DESC_COUNT -\par
- ----------------------- ------------------\par
- | 00001              | | 00001       |\par
- ----------------------- ------------------\par
-\par
----------------------------------------------------\par
-- SQL_DESC_DATA_POINTER | SQL_DESC_TYPE | ........ |\par
-----------------------------------------------------\par
-  1-&input_variable     | 00004         | ........ |\par
- ----------------------------------------------------\par
\par
We will revisit "parameter passing" again after discussing the SQLBindCol function.\par
\par
SQLGetDescRec\par
\par
Function Prototype:\par
 SQLRETURN SQLGetDescRec(\par
   SQLHDESC hdesc,                 /* 32-bit input */\par
   SQLSMALLINT RecordNumber,       /* 16-bit input */\par
   SQLCHAR *Name,                  /* CHAR* output */\par
   SQLSMALLINT BufferLength,       /* 16-bit input */\par
   SQLSMALLINT *NameLength,        /* CHAR* output */\par
   SQLSMALLINT *Type,              /* 16-bit output */\par
   SQLSMALLINT *SubType,           /* 16-bit output */\par
   SQLINTEGER *Length,             /* 32-bit output */\par
   SQLSMALLINT *Precision,         /* 16-bit output */\par
   SQLSMALLINT *Scale,             /* 16-bit output */\par
   SQLSMALLINT *Nullable           /* 16-bit output */\par
   );\par
\par
Job:\par
Retrieve the values of several fields from one Item Descriptor Area of a desc.\par
\par
Algorithm:\par
      /* hdesc refers to a desc. */\par
      /* RecordNumber n refers to IDA[n] within the desc. */\par
      If (RecordNumber < 1)\par
     return error: 07009 dynamic SQL error-invalid descriptor index\par
      If (RecordNumber > desc.SQL_DESC_COUNT)\par
       return warning: 02000 no data -\par
      If (desc is an IRD and associated statement is not prepared)\par
       return error: HY007 CLI-specific condition-associated statement is not prepared \par
      /* Retrieve into *Name,*Type,*Subtype,etc. ... If any parameter\par
      is a null pointer (0000:0000), just ignore it. */\par
      Set *Name = desc.IDA[RecordNumber].SQL_DESC_NAME (use the\par
             usual Character String Retrieval method).\par
      Set *NameLength = desc.IDA[RecordNumber].SQL_DESC_NAME.\par
      Set *Type = desc.IDA[RecordNumber].SQL_DESC_TYPE\par
      Set *SubType = desc.IDA[RecordNumber].SQL_DESC_DATETIME_INTERVAL_CODE\par
      Set *Length = desc.IDA[RecordNumber].SQL_DESC_OCTET_LENGTH\par
      Set *Precision = desc.IDA[RecordNumber].SQL_DESC_PRECISION.\par
      Set *Scale = desc.IDA[RecordNumber].SQL_DESC_SCALE.\par
      Set *Nullable = desc.IDA[RecordNumber].SQL_DESC_NULLABLE field.\par
      \par
Notes:\par
      ## In effect, calling SQLGetDescRec is equivalent to calling\par
SQLGetDescField several times, with different field identifiers:\par
SQL_DESC_NAME, SQL_DESC_TYPE, SQL_DESC_DATETIME_INTERVAL_CODE,\par
SQL_DESC_OCTET_LENGTH, SQL_DESC_PRECISION, SQL_DESC_SCALE and SCALE_NULLABLE.\par
      ## Regarding the value of *Length, what the Standard actually says is\par
that it should be set to "the length (in octets or positions, as appropriate)"\par
... which is ambiguous. We have taken the ODBC specification as our guide here\par
-- it says *Length should be set to SQL_DESC_OCTET_LENGTH. Probably you should\par
use another function if the setting of Length is important to you.\par
      ## For fields which are "not applicable", pass null parameters. For\par
example, the SQL_DESC_NAME field is usually meaningless within an ARD or an\par
APD. So, for *Name, BufferLength and *Namelength, pass null if you're\par
retrieving from an ARD or APD. By passing null pointers, you can limit the\par
values you get, to fill only the fields you really want.\par
      ## SQLGetDescRec's BufferLength parameter is defined as SMALLINT\par
(16-bit). SQLGetDescField's BufferLength parameter in defined as INTEGER\par
(32-bit). However, the apparent inconsistency causes no problems: the length\par
of a Name string is typically only a few octets.\par
\par
Example:\par
The following code snippet is an exact copy of the example used for the SQLGetDescField function, with only one line changed:\par
\par
   SQLGetDescField(hdesc,SQL_DESC_NAME,col_name,sizeof(col_name),NULL);\par
\par
is replaced by a call to SQLGetDescRec which gets only the name.\par
\par
 #include "sqlcli.h"\par
 ...\par
 SQLHSTMT hstmt;                    /* handle of stmt */\par
 SQLHDESC hdesc;                    /* handle of IRD */\par
 SQLSMALLINT i,col_count;           /* used for a loop counter */\par
 SQLCHAR *col_name[128+1];\par
 ...\par
 SQLExecDirect(hstmt,"SELECT * FROM Table_1",SQL_NTS);\par
 SQLGetStmtAttr(hstmt,SQL_ATTR_IMP_ROW_DESC,&hdesc,NULL,NULL);\par
 SQLGetDescField(hdesc,SQL_DESC_COUNT,&col_count,NULL,NULL);\par
 printf("The Columns of Table Table_1 are:\\n");\par
 for (i=1; i<=col_count; ++i) \{\par
   SQLGetDescRec(\par
      hdesc,i,col_name,sizeof(col_name),NULL,NULL,NULL,NULL,NULL,NULL,NULL);\par
   printf("%s\\n",col_name); \}\par
 ...\par
\par
ODBC: The SQLGetDescRec function is new in ODBC 3.5. (In ODBC 2.0 the desc fields were always retrieved via other functions, such as SQLDescribeCol.)\par
SQLGetDescRec is apparently short for "Get Descriptor Record". "Descriptor\par
record" is ODBC jargon; "Item Descriptor Area" (IDA) is the standard term. The\par
fact that the name is SQLGetDescRec, rather than SQLGetIDA, illustrates the influence of ODBC over the Standard.\par
\par
SQLSetDescRec\par
\par
Function Prototype:\par
 SQLRETURN SQLSetDescRec(\par
   SQLHDESC hdesc,            /* 32-bit input */\par
   SQLSMALLINT RecordNumber,  /* 16-bit input */\par
   SQLSMALLINT Type,          /* 16-bit input */\par
   SQLSMALLINT SubType,       /* 16-bit input */\par
   SQLINTEGER Length,         /* 32-bit input */\par
   SQLSMALLINT Precision,     /* 16-bit input */\par
   SQLSMALLINT Scale,         /* 16-bit input */\par
   SQLPOINTER Data,           /* ANY* input */\par
   SQLINTEGER *StringLength,  /* 32-bit output */\par
   SQLINTEGER *Indicator      /* 32-bit output */\par
   );\par
\par
Job:\par
Set the values for several fields in one Item Descriptor Area of a desc.\par
\par
Algorithm:\par
If (desc is associated with a "deferred parameter")\par
  return error: HY010 CLI-specific condition-function sequence error\par
If (RecordNumber < 1)\par
  return error: 07009 dynamic SQL error-invalid descriptor index\par
If (desc is an IRD)\par
  /* This error will appear only for ISO SQL3: */\par
  return error: HY016 CLI-specific condition-cannot modify an implementation row descriptor \par
 Set desc.IDA[RecordNumber].SQL_DESC_TYPE = Type\par
 Set desc.IDA[RecordNumber].SQL_DESC_PRECISION = Precision\par
 Set desc.IDA[RecordNumber].SQL_DESC_SCALE = Scale\par
 Set desc.IDA[RecordNumber].SQL_DESC_DATETIME_INTERVAL_CODE = SubType\par
 if (desc is an IPD)\par
  /* for IPD: this is the length in characters / bits / positions\par
  Set desc.IDA[RecordNumber].SQL_DESC_LENGTH=Length\par
 Else\par
  /* for APD or ARD: this is the length in octets */\par
  Set desc.IDA[RecordNumber].SQL_DESC_OCTET_LENGTH=Length\par
 if (StringLength is not a null pointer)\par
  Set desc.IDA[RecordNumber].SQL_DESC_OCTET_LENGTH_POINTER=StringLength\par
  Set desc.IDA[RecordNumber].SQL_DESC_DATA = Data\par
 If (Indicator is not a null pointer)\par
  Set desc.IDA[RecordNumber].SQL_DESC_INDICATOR_POINTER=Indicator\par
 If (Data is not a null pointer)\par
  If ("Consistency Check" fails)\par
    return error: HY021 CLI-specific condition-inconsistent descriptor information\par
 If (RecordNumber > desc.SQL_DESC_COUNT)\par
  Set desc.SQL_DESC_COUNT = RecordNumber\par
 /* If any errors occur, then desc.SQL_DESC_COUNT will not be changed,\par
    but the other fields mentioned in this description may be. */\par
\par
Notes:\par
      ## In effect, calling SQLSetDescRec is equivalent to calling SQLSetDescField several times, with different field identifiers: SQL_DESC_TYPE, SQL_DESC_PRECISION, SQL_DESC_SCALE, SQL_DESC_DATETIME_INTERVAL_CODE, SQL_DESC_LENGTH or SQL_DESC_OCTET_LENGTH,SQL_DESC_OCTET_LENGTH_POINTER, SQL_DESC_DATA_POINTER and\par
SQL_DESC_DATA_POINTER.\par
      ## Using SQLSetDescRec on an ARD is somewhat similar to using SQLBindCol on the stmt which contains the ARD.\par
      ## Using SQLSetDescRec on an APD is somewhat similar to using SQLBindParameter on the stmt which contains the APD.\par
      ## The parameters of SQLGetDescRec do not correspond to the parameters\par
of SQLGetDescRec. For example, there is no way to set the SQL_DESC_NAME field.\par
      ## Because of the peculiar algorithm logic, it is impossible to set\par
SQL_DESC_OCTET_LENGTH_POINTER or SQL_DESC_INDICATOR_POINTER to null values.\par
      ## A Consistency Check always happens. Therefore, if there are other\par
fields that you want to set, you should call SQLSetDescField before you call SQLSetDescRec.\par
\par
Example:\par
This is an efficient way to execute an SQL statement many times, varying only\par
the input parameter (represented in the statement by "?"). The code will\par
insert 50 rows, with values between 1 and 50. We have deliberately varied some\par
names and parameter-declarations, to show a style preferred by other\par
programmers.\par
\par
#include "sqlcli.h"\par
SQLHSTMT hstmt;\par
SQLHDESC hdesc1,hdesc2; /* hdesc1 is APD, hdesc2 is IPD */\par
SQLINTEGER i;           /* the loop counter, and the input value */\par
...\par
/* prepare the statement -- outside the loop */\par
SQLPrepare(hstmt, "INSERT INTO Table_1 VALUES (?)", SQL_NTS);\par
/* Associate i with APD */\par
SQLGetStmtAttr(hstmt,SQL_ATTR_APP_PARAM_DESC,&hdesc1,0L,(SQLINTEGER *)NULL);\par
SQLSetDescRec(\par
   hdesc1,1,SQL_INTEGER,0,0L,0,0,(SQLPOINTER)&i,(SQLINTEGER *)NULL,\par
   (SQLINTEGER *)NULL);\par
/* Associate parameter marker with IPD */\par
SQLGetStmtAttr(hstmt,SQL_ATTR_IMP_PARAM_DESC,&hdesc2,0L,(SQLINTEGER *)NULL);\par
SQLSetDescRec(\par
   hdesc2,1,SQL_INTEGER,0,0L,0,0,(SQLPOINTER)NULL,(SQLINTEGER *)NULL,\par
   (SQLINTEGER *)NULL);\par
for (i=1; i<50; ++i)\par
    \{\par
    /* execute the statement -- inside the loop */\par
    SQLExecute(hstmt);\par
    \}\par
...\par
\par
Warning: This code is "efficient" because it calls SQLPrepare and the\par
SQLSetDescRec functions only once, for an SQL statement that is executed 50\par
times. Usually, taking code out of loops is the right thing to do. But for at\par
least one DBMS, it's better to bind i (as a deferred parameter) after the call to SQLExecute.\par
\par
ODBC: SQLSetDescRec is new in ODBC 3.0. You can set SQL_DESC_OCTET_LENGTH_POINTER or SQL_DESC_INDICATOR_POINTER to null, by passing null pointers in the StringLength or Indicator parameters. In standard SQL, the DBMS ignores null pointers in those parameters.\par
\par
SQLCopyDesc\par
\par
Function Prototype:\par
 SQLRETURN SQLCopyDesc(\par
   SQLHDESC source_hdesc,     /* 32-bit input */\par
   SQLHDESC target_hdesc      /* 32-bit input */\par
   );\par
\par
Job:\par
Copy a source desc to a target desc.\par
\par
Algorithm:\par
      If (source_hdesc is not a hdesc)\par
     return error: CLI-specific condition-invalid handle\par
    If (target_hdesc is not a hdesc)\par
     return error: CLI-specific condition-invalid handle\par
      The target desc's diagnostics area is emptied.\par
      If (source_desc is associated with a "deferred parameter")\par
       return error: HY010 CLI-specific condition-function sequence error\par
      If (target_desc is associated with a "deferred parameter")\par
       return error: HY010 CLI-specific condition-function sequence error\par
      If (Target Desc is an IRD)\par
       return error: HY016 CLI-specific condition-cannot modify an implementation row descriptor.\par
      If (Source Desc is an IRD)\par
       If (associated statement not prepared)\par
         return error: HY007 CLI-specific condition-associated statement is not prepared)\par
      Copy the contents of every field in source desc to target desc -- with\par
the exception of the SQL_DESC_ALLOC_TYPE field. SQL_DESC_ALLOC_TYPE keeps its\par
original value).\par
\par
Notes:\par
      ## There are other ways to copy an entire desc. For example, you could\par
call the SQLGetDescField and SQLSetDescField functions repeatedly. But\par
SQLCopyDesc is the easy way.\par
      ## If you're thinking of copying stmt #1's APD to stmt #2's APD, there's\par
an alternative: you can allocate a user desc and share it. Here's how:\par
            ## Make a user desc:\par
\par
   SQLAllocHandle(SQL_HANDLE_DESC,hdbc,&hdesc_user);\par
      \par
      ## Say that stmt #1's APD is the user desc:\par
 \par
  SQLSetStmtAttr(hstmt1,SQL_ATTR_APP_ROW_DESC,&hdesc_user,NULL);\par
      \par
      ## Fill in the fields of stmt #1's APD (using SQLSetDescRec etc.)\par
      \par
      ## Say that stmt #2's APD is the user desc:\par
\par
   SQLSetStmtAttr(hstmt2,SQL_ATTR_APP_ROW_DESC,&hdesc_user,NULL);\par
\par
Now there's no need to copy, because stmt #2's APD is stmt #1's APD.\par
      ## One possible use of SQLCopyDesc is to copy an IRD to an ARD. The\par
point is: the IRD and the IRD fields are supposed to be similar; the IRD is\par
set up automatically; so after the copy the ARD will have the values that the\par
DBMS thinks should be there. If you want to change these values slightly, you\par
can fine-tune using SQLSetDescField.\par
      ## Another possible use of SQLCopyDesc is to save desc information --\par
if, for example, you have a small number of queries that are executed\par
repeatedly using the same stmt. Here's how:\par
            ## Allocate a user descriptor with\par
SQLAllocHandle(SQL_HANDLE_DESC,...).\par
            ## Copy an automatic desc to the user desc, with SQLCopyDesc.\par
            ## Change the automatic desc for some temporary purpose.\par
            ## Copy the user desc back to the automatic desc, with SQLCopyDesc.\par
This is like "pushing" all the desc fields to a stack, making changes, then\par
"popping" to restore the original values.\par
      ## Some DBMSs will perform a consistency check on the target desc's IDAs\par
if any target_desc.IDA[n].SQL_DESC_DATA_POINTER is not a null pointer.\par
      ## The copy is possible even if the source and target descs are in\par
different connections.\par
\par
Example:\par
This shows how to copy values from one Table to another. The trick works like\par
this:\par
      ## Step 1: Prepare a SELECT statement from the source Table. This yields\par
the IRD of the source. Bind the result set with SQLSetDescRec. This yields the\par
ARD of the source.\par
      ## Step 2: Prepare an INSERT statement on the target Table. This yields\par
the IPD of the target.\par
      ## Step 3: Copy the source RDs to the target PDs.\par
\par
The trick would work for any pair of Tables, provided Columns have compatible\par
<data type>s.\par
\par
#include "sqlcli.h"\par
SQLCHAR   szCol_1[6];/* sz is "string, zero terminated" */\par
SQLINTEGER cbCol_1;  /* col_1's indicator */\par
SQLHSTMT    hstmt_source, hstmt_target;\par
SQLHDESC    hard_source, hird_source; /* source's ARD+IRD handles */\par
SQLHDESC    hapd_target, hipd_target; /* target's APD+IPD handles */\par
...\par
 /* Get the handles of each desc that we'll use */\par
 /* SELECT from the source. */\par
 SQLExecDirect(hstmt_source,"SELECT col_1 FROM Sources;",SQL_NTS);\par
 SQLGetStmtAttr(hstmt_source,SQL_ATTR_APP_ROW_DESC,&hard_source,0,NULL);\par
 SQLGetStmtAttr(hstmt_target,SQL_ATTR_APP_PARAM_DESC,&hapd_target,0,NULL);\par
 /* Bind source Column #1. This changes the source's ARD. */\par
 SQLSetDescRec(\par
   hard_source,1,SQL_CHAR,NULL,NULL,NULL,NULL,NULL,szCol_1,&6,&cbCol_1);\par
 /* Copy source's ARD to target's APD */\par
 SQLCopyDesc(hard_source,hapd_target);\par
 /* Copy source's IRD to target's IPD */\par
 SQLGetStmtAttr(hstmt_source,SQL_ATTR_IMP_ROW_DESC,&hird_source,0,NULL);\par
 SQLGetStmtAttr(hstmt_target,SQL_ATTR_IMP_PARAM_DESC,&hipd_target,0,NULL);\par
 SQLCopyDesc(hIrd_source, hipd_target);\par
 /* Prepare to INSERT in the target. */\par
 /* Once again, we assume "auto-populate IPD" is not true. If it were\par
   true, SQLPrepare would overwrite what we've just copied to the IPD. */\par
 SQLPrepare(hstmt_target,"INSERT INTO Targets VALUES (?)", SQL_NTS);\par
 /* Fetch loop */\par
 for (;;) \{\par
   sqlreturn = SQLFetchScroll(hstmt0, SQL_FETCH_NEXT, 0);\par
   if (sqlreturn <> SQL_SUCCESS && sqlreturn <> SQL_SUCCESS_WITH_INFO) break;\par
   /* According to the row descriptors of the SELECT: we fetched into\par
     szCol_1 and cbCol_1. According to the parameter descriptors of\par
     INSERT: we'll get our values from szCol_1 and cbCol_1. Thus the\par
     fetch's "output" is the insert's "input". */\par
   SQLExecute(hstmt_target); \}\par
 SQLCloseCursor(hstmt_source);\par
 ...\par
\par
ODBC: The SQLCopyDesc function arrived with ODBC 3.0. ODBC's Driver Manager\par
will handle copying if the source and target handles are associated with\par
different drivers.\par
\par
SQLBindCol\par
\par
Function Prototype:\par
 SQLRETURN SQLBindCol(\par
   SQLHSTMT hstmt,                  /* 32-bit input */\par
   SQLSMALLINT ColumnNumber,        /* 16-bit input */\par
   SQLSMALLINT BufferType,          /* 16-bit input */\par
   SQLPOINTER Data,                 /* ANY* input */\par
   SQLINTEGER BufferLength,         /* 32-bit input */\par
   SQLINTEGER *StrLen_or_Ind        /* 32-bit pointer to output */\par
   );\par
\par
Job:\par
Bind a Column to a host variable by setting fields in the ARD.\par
\par
Algorithm:\par
   If (ColumnNumber < 1)\par
    return error: 07009 Dynamic SQL error-invalid descriptor index\par
   If (BufferType <> SQL_C_DEFAULT and BufferType is not a valid type code)\par
    /* A "valid type code" could be one of: 1 (SQL_CHAR), 2 (SQL_NUMERIC), 3\par
(SQL_DECIMAL), 4 (SQL_INTEGER), 5 (SQL_SMALLINT), 6 (SQL_FLOAT), 7 (SQL_REAL),\par
8 (SQL_DOUBLE), 18 (SQL_UDT_LOCATOR), 20 (SQL_REF), 30 (SQL_BLOB), 31\par
(SQL_BLOB_LOCATOR), 40 (SQL_CLOB), 41 (SQL_CLOB_LOCATOR), etc. But no host\par
language has corresponding <data type>s for all of those; see the data type\par
correspondences lists in our chapter on embedded SQL. */\par
    return error: HY003 CLI-specific condition-invalid data type in application descriptor\par
   If (BufferLength <= 0)\par
    return error: HY090 CLI-specific condition-invalid string length or buffer length\par
   Set ARD.IDA[ColumnNumber].SQL_DESC_TYPE = BufferType\par
   Set ARD.IDA[ColumnNumber].SQL_DESC_OCTET_LENGTH = BufferLength \par
   Set ARD.IDA[ColumnNumber].SQL_DESC_LENGTH = maximum for this data type\par
   Set ARD.IDA[ColumnNumber].SQL_DESC_DATA_POINTER = Data\par
   Set ARD.IDA[ColumnNumber].SQL_DESC_OCTET_LENGTH_POINTER = StrLen_or_Ind\par
   Set ARD.IDA[ColumnNumber].SQL_DESC_INDICATOR_POINTER = StrLen_or_Ind\par
   If (ColumnNumber > ARD.SQL_DESC_COUNT)\par
    Set ARD.SQL_DESC_COUNT = ColumnNumber\par
   /* If an error occurs: the DBMS leaves SQL_DESC_COUNT unchanged, but may\par
     set IDA fields to implementation-dependent values. */\par
\par
Notes:\par
      ## Technically, a host variable is "bound" when it is associated with a\par
host-variable address. Since SQLBindCol causes a setting of\par
ARD.IDA[ColumnNumber].SQL_DESC_DATA_POINTER, we can describe it thus:\par
"SQLBindCol performs a binding of an output host variable for a result-set\par
Column; specifically the result-set Column indicated by the ColumnNumber parameter."\par
      ## Technically, this host variable is called a "target specification".\par
SQLBindCol is for values that flow out from the DBMS to a host variable.\par
      ## The usual idea is that what you set up with SQLBindCol will later be\par
used by SQLFetch or SQLFetchScroll. Alternatively, you could bind after\par
fetching, using the SQLGetData function.\par
      ## You need a valid hstmt, but you don't need a result set yet. That is,\par
you can SELECT either before or after you call SQLBindCol.\par
      ## Calling SQLBindCol for a stmt is conceptually similar to calling\par
SQLSetDescRec for the stmt's ARD. In fact, everything that you can do with\par
SQLBindCol, and more, can be done with SQLSetDescRec. However, SQLBindCol is\par
seen far more often than SQLSetDescRec.\par
      ## Warning: You are passing addresses. The DBMS will write to those\par
addresses. So there are two easy ways to cause GPFs:\par
            ## Pass the address of a local variable, exit from the procedure\par
that the local variable is defined in, then call SQLFetch.\par
            ## Pass a buffer which is too small to hold the result. For CHAR\par
and  BIT <data type>s there is a guard against this (you pass BufferLength to\par
tell the DBMS when it must stop). For numeric <data type>s there is also a\par
guard against this (if you say that BufferType is SQL_SMALLINT the DBMS won't\par
move a 32-bit value to it). But if you enter the wrong value for DataType ...\par
Ka-Boom! As a safeguard, some programmers deliberately "unbind" when they\par
finish fetching -- see the description of SQLFreeStmt(...SQL_UNBIND).\par
      ## SQLBindCol does not set every defined field in the ARD. You might\par
have to follow up with a call to SQLSetDescField if for some reason you have\par
to change a low-importance field, like SQL_DESC_DATETIME_INTERVAL_PRECISION.\par
      ## The value of BufferLength is irrelevant for non-string <data type>s.\par
Nevertheless, you must always pass a value greater than zero.\par
\par
Example:\par
 /* This example shows a retrieval of a CHAR string. */\par
 #include "sqlcli.h"\par
 SQLHSTMT hstmt;\par
 SQLCHAR value[128];\par
 SQLINTEGER value_indicator;\par
 ...\par
 SQLBindCol(hstmt,1,SQL_CHAR,value,sizeof(value),&value_indicator);\par
 SQLExecDirect(stmt,"SELECT 'ABCDE' FROM t",SQL_NTS);\par
 SQLFetch(hstmt);\par
 /* At this point, value has "ABCDE\\0", value_indicator has zero. */\par
 ...\par
\par
 /* This example shows a retrieval of a floating-point variable. The C data\par
type is float, but we use SQL_REAL -- for explanation, see the list of data\par
correspondences. We'd like to pass NULL as the BufferLength parameter -- it's\par
irrelevant -- but we can't. */\par
 #include "sqlcli.h"\par
 #include <math.h>\par
 SQLHSTMT hstmt;\par
 SQLREAL value;   /* sqlcli.h contains the line "typedef float SQLREAL" */\par
 SQLINTEGER value_indicator;\par
 ...\par
 SQLBindCol(hstmt,1,SQL_REAL,&value,sizeof(value),&value_indicator);\par
 SQLExecDirect(stmt,"SELECT 1.5E5 FROM t",SQL_NTS);\par
 SQLFetch(hstmt);\par
 /* At this point, value has 1.5E5, value_indicator has zero. */\par
 ...\par
\par
 /* This example shows a retrieval of two Columns from the first row of\par
TABLE_1. It displays their values, or displays "NULL". */\par
 #include "sqlcli.h"\par
 SQLINTEGER col_1;\par
 SQLCHAR   col_2[128];\par
 SQLINTEGER col_1_ind,col_2_ind;\par
 SQLHSTMT  hstmt;\par
 SQLHDESC  hdesc;\par
 ...\par
 SQLBindCol(hstmt,1,SQL_INTEGER,&col_1,sizeof(col_1),&col_1_ind);\par
 SQLBindCol(hstmt,2,SQL_CHAR,col_2,sizeof(col_2),&col_2_ind);\par
 SQLExecDirect(hstmt,"SELECT col_1,col_2 FROM Table_1",SQL_NTS);\par
 SQLFetch(hstmt);\par
 if (col_1_ind == SQL_NULL_DATA) printf("NULL\\n");\par
 else printf("%ld.\\n",col_1);\par
 if (col_2_ind == SQL_NULL_DATA) printf("NULL\\n");\par
 else printf("%s.\\n",col_2);\par
 ...\par
\par
Here is a picture of the ARD after the SQLSetDescField call is done:\par
\par
- ----------------------- -------------------\par
--SQL_DESC_ALLOC_TYPE- - SQL_DESC_COUNT -\par
- ----------------------- ------------------\par
- | 00001             | | 00002       |\par
- ----------------------- ------------------\par
-\par
-----------------------------------------------------\par
-- SQL_DESC_DATA_POINTER | SQL_DESC_TYPE | ........ |\par
-----------------------------------------------------\par
-  1-&col_1              | 00004         | ........ |\par
-----------------------------------------------------\par
-  2-col_2 (address)     | 00001         | ........ |\par
-----------------------------------------------------\par
\par
Here is a picture of the IRD after the SQLExecDirect call is done:\par
\par
- ----------------------- -------------------\par
--SQL_DESC_ALLOC_TYPE- - SQL_DESC_COUNT -\par
- ----------------------- ------------------\par
- | 00001             | | 00002       |\par
- ----------------------- ------------------\par
-\par
-----------------------------------------------------\par
-- SQL_DESC_NAME      | SQL_DESC_TYPE | ........ |\par
-----------------------------------------------------\par
-  1-'Col_1'          | 00005         | ........ |\par
-   ----------------------------------------------------\par
-  2-'Col_2'          | 00001         | ........ |\par
-----------------------------------------------------\par
\par
[Obscure Rule] In this example, COL_1 is actually a SMALLINT (SQL_DESC_TYPE ==\par
5), but it's being transferred to an INTEGER (SQL_DESC_TYPE == 4). That is not\par
a problem -- the DBMS will automatically "CAST (<smallint Column value> TO\par
INTEGER)". In fact, the DBMS will automatically cast from the IRD type to the\par
ARD type. If the cast is syntactically impossible, an SQLSTATE error appears:\par
07006 Dynamic SQL error-restricted data type attribute violation.\par
\par
ODBC: SQLBindCol always triggers a consistency check. The value of\par
BufferLength must be >= 0 (standard SQL says the value of BufferLength must be\par
> 0). The difference looks trivial, but the majority of ODBC application\par
programs would collapse tomorrow if a DBMS vendor decided to enforce the\par
standard SQL rule.\par
\par
SQL_C_DEFAULT:\par
There is a lazy way to bind numbers. Instead of passing a real <data type>,\par
pass 99 (SQL_C_DEFAULT). Here is an example using SQLBindCol -- notice that\par
the third parameter is SQL_C_DEFAULT, so, after SQLBindCol, the value in\par
ARD.IDA[n].SQL_DESC_TYPE == SQL_C_DEFAULT. When SQLFetch occurs, it handles\par
the default request like this:\par
      ## Set ARD.IDA[n].SQL_DESC_TYPE = IRD.IDA[n].SQL_DESC_TYPE.\par
      ## Set ARD.IDA[n].SQL_DESC_PRECISION = IRD.IDA[n].SQL_DESC_PRECISION.\par
      ## Set ARD.IDA[n].SQL_DESC_SCALE = IRD.IDA[n].SQL_DESC_SCALE.\par
(These are temporary settings. SQLFetch never makes permanent changes to any\par
desc fields.) Now there is enough information to continue the fetch:\par
\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  SQLSMALLINT col_1;\par
  ...\par
  SQLExecDirect(hstmt,"SELECT col_1 FROM Table_1",SQL_NTS;\par
  SQLBindCol(hstmt,1,SQL_C_DEFAULT,&col_1,1,NULL);\par
  SQLFetch(hstmt);\par
\par
And now, a few words of urgent warning:\par
      ## The only fields involved are type, precision and  scale -- not length\par
or octet_length.\par
      ## There is no check for possible overflow of the target output.\par
      ## The ODBC specification does not agree with the Standard about what\par
the default <data type> codes should be.\par
\par
Retrieving Column values:\par
Column retrieval involves executing a SELECT statement, then fetching from the\par
result set to variables defined in your host program. The Columns in the\par
select list must be "bound" to the host-variable addresses. The problems you\par
must solve -- with the DBMS's help -- are:\par
      ## The impedance mismatch between SQL <data type>s and host language types.\par
      ## Telling the DBMS where to put the data.\par
      ## Telling the DBMS how null values should be signalled to the host.\par
      ## Ensuring that the DBMS does not go beyond the host-variable buffers.\par
\par
There are two solutions to these problems:\par
      ## Call SQLBindCol, SQLSetDescField or SQLSetDescRec, then fetch using\par
SQLFetch or SQLFetchScroll.\par
      ## Fetch using SQLFetch or SQLFetchScroll, then call SQLGetData.\par
The most popular option is to call SQLBindCol, then SQLFetch.\par
\par
There are two descs involved here -- the IRD (which the DBMS sets up when the\par
SELECT statement is executed), and the ARD (which the host program sets up at\par
any time before the fetch). The programmer's job, then, can be seen as making\par
sure that the ARD matches the IRD, and setting up appropriate buffers for the\par
DBMS to fetch data into.\par
\par
Fetch Loops Revisited:\par
Once more into the "fetch", dear friends! Now that you know about binding, you\par
can fetch INTO something. Here is a program which does so. Most functions are\par
shown in skeletal form. There is a test for truncation.\par
\par
#include "sqlcli.h"\par
SQLHENV     henv;\par
SQLHDBC     hdbc;\par
SQLHSTMT    hstmt;\par
SQLCHAR   char_string[128];\par
SQLINTEGER char_string_ind;\par
SQLRETURN  sqlreturn;\par
void main ()\par
\{\par
 SQLAllocHandle(SQL_HANDLE_ENV,NULL,&henv);\par
 SQLAllocHandle(SQL_HANDLE_DBC,henv,&hdbc);\par
 SQLConnect(hdbc,...,SQL_NTS);\par
 SQLAllocHandle(SQL_HANDLE_HSTMT,hdbc,&hstmt);\par
 SQLExecDirect(hstmt,"SELECT ...",SQL_NTS);\par
 SQLBindCol(\par
   hstmt,1,SQL_CHAR,char_string,sizeof(char_string),&char_string_ind);\par
 for (;;) \{\par
   sqlreturn = SQLFetch(hstmt);\par
   if (sqlreturn == SQL_NO_DATA) break;\par
   if (sqlreturn == SQL_ERROR) \{\par
    printf("Error ... aborting\\n");\par
    break; \}\par
   if (sqlreturn == SQL_SUCCESS_WITH_WARNING) \{\par
    /* We could call SQLGetDiagnostics to find out if sqlstate == '01004'\par
        (string data right truncation), diagnostics is a later chapter.\par
      Instead, we'll see if see if the DBMS had more data than it sent. */\par
    if (char_string_ind >= sizeof(char_string) printf("[Truncated!]"); \}\par
   if (char_string_ind==SQL_NULL_DATA) printf("NULL\\n");\par
   else printf("%s.\\n",char_string); \}\par
 SQLCloseCursor(hstmt);\par
 SQLFreeHandle(SQL_HANDLE_STMT,hstmt);\par
 SQLDisconnect(hdbc);\par
 SQLFreeHandle(SQL_HANDLE_DBC,hdbc);\par
 SQLFreeHandle(SQL_HANDLE_ENV,henv); \}\par
\par
SQLGetData\par
\par
Function Prototype:\par
 SQLRETURN SQLGetData(\par
   SQLHSTMT hstmt,            /* 32-bit input */\par
   SQLSMALLINT ColumnNumber,  /* 16-bit input -- index to IDA */\par
   SQLSMALLINT TargetType,    /* 16-bit input. Concise. */\par
   SQLPOINTER TargetValue,    /* VOID* output */\par
   SQLINTEGER BufferLength,   /* 32-bit input */\par
   SQLINTEGER *StrLen_or_Ind  /* 32-bit output */\par
   );\par
\par
Job:\par
Get a value from one Column of a result set. Call SQLGetData after calling SQLFetch or SQLFetchScroll.\par
\par
Algorithm:\par
      If (there is no fetched row associated with stmt)\par
       /* Looks like somebody forgot to call SQLFetch or SQLFetchScroll */\par
       return error: HY010 CLI-specific condition-function sequence error\par
      If (the fetched row is "empty")\par
       /* Looks like somebody DELETEd the row */\par
       return warning: 02000 No data\par
      If (ColumnNumber < 1 or ColumnNumber > IRD.SQL_DESC_COUNT)\par
     /* IRD.SQL_DESC_COUNT is the number of Columns in the select list */\par
       return error: 07009 Dynamic SQL error-invalid descriptor index \par
      If (ARD.IDA[ColumnNumber].SQL_DESC_DATA_POINTER <> 0)\par
       /* It's illegal to call SQLGetdata for a "bound" Column */\par
       return error: 07009 dynamic SQL error-invalid descriptor index\par
      /* Following check is implementation-defined -- it depends whether\par
        the DBMS supports SQLGetData extensions -- see SQLGetInfo */\par
      If (ARD.IDA[x].SQL_DESC_DATA_POINTER==0 for any IDA before ColumnNumber)\par
       return error: 07009 dynamic SQL error-invalid descriptor index\par
      /* Following check is implementation-defined -- it depends whether\par
        the DBMS supports SQLGetData Extensions -- see SQLGetInfo */\par
      If (ARD.IDA[x].SQL_DESC_DATA_POINTER<>0 for any IDA after ColumnNumber)\par
       return error: 07009 dynamic SQL error-invalid descriptor index\par
      /* The rest of the SQLGetData algorithm is the same as the algorithm\par
        for fetching a "bound" Column -- see SQLBindCol for details. */\par
\par
Notes:\par
      ## SQLGetData does not make permanent changes to the ARD. But it can be\par
thought of as a function which makes a temporary binding for a specified\par
Column in a result set, and transferring the Column value to the bound target\par
variable.\par
      ## It looks like there are two possible strategies for retrieving data\par
-- with SQLBindCol or with SQLGetData. Let's compare the two:\par
\par
The SQLBindCol strategy:\par
SQLExecDirect(...,"SELECT ...",...);\par
 SQLBindCol(...,1,&var_1,...);\par
 SQLBindCol(...,2,&var_2,...);\par
 for (;;) \{\par
  if (SQLFetch(...)==100) break; \}\par
  SQLGetData(...,2,...,&var_2,...); \}\par
\par
The SQLGetData strategy:\par
SQLExecDirect(...,"SELECT ...",...);\par
for (;;) \{ \par
   if (SQLFetch(...)==100) break;\par
   SQLGetData(...,1,...,&var_1,...);\par
\par
Look hard at where the loop is. The SQLBindCol strategy is apparently more\par
efficient, because the binding happens only once. If you use SQLGetData,\par
you'll have to use it for every iteration of the SQLFetch loop. On the other\par
hand, maybe that's exactly what you want to do. There are times when you have\par
to be flexible, and change some factor (such as the variable's address) while\par
inside the loop. Then SQLGetData is the choice.\par
      ## Suppose you bind Column #1 (using SQLBindCol), then you fetch, then\par
you get Column #2 (using SQLGetData). That's legal. But it might not be legal\par
to skip Columns, to get Columns out of order or to get Columns twice. The\par
ability to get Columns in any order is called the "SQLGetData Extensions"\par
feature. You can check whether your DBMS supports it (you'll see how when we\par
describe the SQLGetInfo function). But usually there's nothing difficult about\par
getting Columns in ascending Column-number order.\par
      ## *StrLen_or_Ind points to a 32-bit integer, not a 16-bit integer. Thus\par
the final three parameters -- *TargetValue, BufferLength, *StrLen_or_Ind -- do\par
not form a typical example of Character String Retrieval parameters.\par
      ## Since SQLGetData cannot take advantage of the full set of ARD fields,\par
it only gets used for simple situations.\par
\par
Example:\par
 #include "sqlcli.h"\par
 #define CHAR_LENGTH 1000\par
 SQLHSTMT hstmt;\par
 SQLRETURN sqlreturn;\par
 SQLINTEGER sIntegerColumn;\par
 SQLINTEGER IntegerIndicator;\par
 SQLCHAR szCharColumn[CHAR_LENGTH];\par
 SQLINTEGER IntegerIndicator;\par
 ...\par
 SQLExecDirect(hstmt,"SELECT col_1,col_2 FROM Table_1",SQL_NTS);\par
 for (;;) \{\par
   sqlreturn = SQLFetch(hstmt); \par
   if (sqlreturn != SQL_SUCCESS && sqlreturn != SQL_SUCCESS_WITH_INFO) \{\par
    break; \}\par
   SQLGetData(hstmt,1,SQL_INTEGER,&sIntegerColumn,NULL,&IntegerIndicator);\par
   if (IntegerIndicator != SQL_NULL_DATA) \{\par
    if (sIntegerColumn > 0) \{\par
     SQLGetData(hstmt,2,SQL_CHAR,szCharColumn,CHAR_LENGTH,&CharIndicator);\par
     if (CharIndicator == SQL_NULL_DATA) strcpy(szCharColumn,"");\par
     printf("%s.\\n",szCharColumn); \} \} \}\par
 SQLCloseCursor(hstmt);\par
 ...\par
\par
ODBC: SQLGetData has been around since ODBC version 1.0. SQLGetData can be\par
used, with char or bit <data type>s, to get data in pieces. This is done by\par
calling SQLGetData with BufferLength == 1000 (to ask for the first 1000\par
octets), calling again -- for the same Column number with BufferLength == 1000\par
(to ask for the next 1000 octets), and so on. In the days of 16-bit operating\par
systems, this was a useful feature.\par
\par
SQLBindParameter\par
\par
Function Prototype:\par
 SQLRETURN SQLBindParameter (\par
   SQLHSTMT hstmt,                  /* 32-bit input */\par
   SQLSMALLINT ParameterNumber,     /* 16-bit input: must be > 0 */\par
   SQLSMALLINT InputOutputMode,     /* 16-bit input: must be one of:\par
                                       1 SQL_PARAM_MODE_IN,\par
                                       2 SQL_PARAM_MODE_INOUT,\par
                                       4 SQL_PARAM_MODE_OUT */\par
   SQLSMALLINT ValueType,           /* 16-bit input ... for the APD\par
                                      must be in table of host/SQL <data type>\par
                                      correspondences */\par
   SQLSMALLINT ParameterType,       /* 16-bit input ... for the IPD\par
                                      must be in table of concise types */\par
   SQLINTEGER Columnsize,           /* 32-bit input */\par
   SQLSMALLINT DecimalDigits,       /* 16-bit input */\par
   SQLPOINTER ParameterValue,       /* DEF */\par
   SQLINTEGER BufferLength,         /* 32-bit input */\par
   SQLINTEGER *StrLen_or_Ind        /* DEF */\par
   );\par
\par
Job:\par
Describe one "dynamic parameter specification" (in the IPD), and its host\par
variable (in the APD). SQLBindParameter is useful if you pass parameters from\par
the application to the DBMS. Such parameters are marked by parameter markers\par
(question marks) in SQL statements.\par
\par
Algorithm:\par
The algorithm is to complex to show in the usual manner. For this function, we\par
will have to make heavy use of texts and charts.\par
\par
What happens --\par
      ## If the function fails and returns -1 (SQL_ERROR): see 07009, HY015\par
and HY090 in our chapter on SQL/CLI diagnostics. (Note: If errors happen, some\par
of the IPD and APD fields may be garbaged, although SQL_DESC_COUNT won't\par
change.)\par
      ## If the function succeeds: some IPD and APD fields are set. The\par
precise setting depends on a combination of factors, but in general we can say\par
that:\par
            ## hstmt designates which stmt. The affected descs are the stmt's\par
IPD and APD.\par
            ## ParameterNumber designates which item descriptor area, within a\par
desc. If ParameterNumber is n, then the affected IDAs are IPD.IDA[n] and\par
APD.IDA[n].\par
            ## ParameterType, Columnsize and DecimalDigits affect IPD.IDA[n].\par
            ## ValueType, BufferLength, ParameterValue and Strlen_Or_Ind\par
affect APD.IDA[n].\par
            ## If ParameterNumber is greater than an APD or IPD's\par
SQL_DESC_COUNT field, then that SQL_DESC_COUNT field gets the value in\par
ParameterNumber.\par
            ## Sometimes passed values are ignored.\par
            ## Values should be consistent, but some DBMSs won't perform a\par
consistency check until SQLExecute happens.\par
\par
In the charts which follow, we show the effects on particular APD or IPD\par
fields. Notice that the usual effect is that the field simply receives the\par
value of a parameter that you pass, but that sometimes special calculations\par
are necessary. Particularly complex are "datetime" and "interval" settings.\par
\par
SQLBindParameter effect on APD fields:\par
Field                           gets\par
SQL_DESC_PARAMETER_MODE         InputOutputMode\par
SQL_DESC_TYPE                   ValueType\par
SQL_DESC_OCTET_LENGTH           BufferLength\par
SQL_DESC_DATA_POINTER           ParameterValue (an address)\par
SQL_DESC_INDICATOR_POINTER      StrLen_or_Ind (an address)\par
SQL_DESC_OCTET_LENGTH_POINTER   StrLen_or_Ind (an address)\par
\par
For example, if you call SQLBindParameter with ParameterNumber=2,\par
InputOutputMode = OUT, ValueType=1 (the code for CHAR <data type>),\par
BufferLength=5, ParameterValue = address of x_char_buffer and Strlen_Or_Ind =\par
address of x_char_buffer_indicator, the result is that, in the APD.IDA[2]\par
(i.e.: the second item descriptor area in the application parameter desc), the\par
settings are as follows: SQL_DESC_PARAMETER_MODE = OUT, SQL_DESC_TYPE = 1,\par
SQL_DESC_OCTET_LENGTH = BufferLength, SQL_DESC_DATA_POINTER = x_char_buffer\par
address, SQL_DESC_INDICATOR_POINTER = x_char_buffer_indicator address and\par
SQL_DESC_OCTET_LENGTH_POINTER = x_char_buffer_indicator address.\par
\par
SQLBindParameter effect on IPD.IDA fields for numeric <data type>s:\par
Field                    gets\par
SQL_DESC_TYPE            ParameterType\par
SQL_DESC_PRECISION       Columnsize  \par
SQL_DESC_SCALE           DecimalDigits\par
\par
This chart shows the effect on IPD.IDA[n] fields if the value of the passed\par
ParameterType is 2 or 3 or 4 or 5 or 6 or 7 or 8 (SQL_NUMERIC or SQL_DECIMAL\par
or SQL_INTEGER or SQL_SMALLINT or SQL_FLOAT or SQL_REAL or SQL_DOUBLE). For\par
example, if you call SQLBindParameter with ParameterNumber = 1, ParameterType\par
= 3, Columnsize=5 and DecimalDigits=4, the result is that, in the IPD.IDA[1]\par
(i.e.: the first item descriptor area in the Implementation Parameter Desc),\par
the settings are as follows: SQL_DESC_TYPE=3, SQL_DESC_PRECISION=5 and\par
SQL_DESC_SCALE=4.\par
\par
SQLBindParameter effect IPD.IDA fields for datetime <data type>s:\par
Field                            Gets for ...\par
                                 91 (date)   92 (time)      93 (timestamp)\par
SQL_DESC_TYPE                    9           9              9\par
SQL_DESC_DATETIME_INTERVAL_CODE  1           2              3\par
SQL_DESC_LENGTH (in positions)   Columnsize  Columnsize     Columnsize\par
SQL_DESC_PRECISION (frac-sec)    0           DecimalDigits  DecimalDigits\par
\par
This chart shows the effect on IPD.IDA[n] fields if the value of the passed\par
ParameterType is 91 or 92 or 93 (date or time or timestamp). SQL_DESC_LENGTH\par
is the length in "positions". SQL_DESC_PRECISION is the "fractional-seconds"\par
precision. For example, if you call SQLBindParameter with ParameterNumber = 5,\par
ParameterType=92, Columnsize=8 and DecimalDigits=0, the result is that, in the\par
IPD.IDA[5] (i.e.: the fifth item descriptor area in the Implementation\par
Parameter Desc), the settings are as follows: SQL_DESC_TYPE=9,\par
SQL_DESC_DATETIME_INTERVAL_CODE=2, SQL_DESC_LENGTH=8 and SQL_DESC_PRECISION=0.\par
\par
SQLBindParameter effect on IPD.IDA fields for interval year/month <data\par
type>s:\par
Field                                 Gets for ...\par
                                      101 (year)           102 (month)\par
SQL_DESC_TYPE                         10                   10\par
SQL_DESC_DATETIME_INTERVAL_CODE        1                    2\par
SQL_DESC_LENGTH (in positions)        Columnsize           Columnsize\par
SQL_DESC_PRECISION (frac-sec)          0                    0\par
SQL_DESC_DATETIME_INTERVAL_PRECISION  (lead) Columnsize-1  Columnsize-1\par
\par
Field                                 Gets for ...\par
                                      107 (year to month)\par
SQL_DESC_TYPE                         10\par
SQL_DESC_DATETIME_INTERVAL_CODE        7\par
SQL_DESC_LENGTH (in positions)        Columnsize\par
SQL_DESC_PRECISION (frac-sec)          0\par
SQL_DESC_DATETIME_INTERVAL_PRECISION  Columnsize-4\par
\par
The charts show the effect on IPD.IDA[n] fields if the value of the passed\par
ParameterType is 101 or 102 or 107 (interval year or interval month or\par
interval year-to-month). SQL_DESC_LENGTH is the length in "positions".\par
SQL_DESC_PRECISION is the "fractional-seconds" precision.\par
SQL_DESC_DATETIME_INTERVAL_PRECISION is the "leading field" precision. For\par
example, if you call SQLBindParameter with ParameterNumber = 2,\par
ParameterType=107, Columnsize=8 and DecimalDigits=0, the result is that, in\par
the IPD.IDA[2] (i.e.: the second item descriptor area in the Implementation\par
Parameter Desc), the settings are as follows: SQL_DESC_TYPE=10,\par
SQL_DESC_DATETIME_INTERVAL_CODE=7, SQL_DESC_LENGTH=8, SQL_DESC_PRECISION=0 and\par
SQL_DESC_DATETIME_INTERVAL_PRECISION=(8-4)=4.\par
\par
SQLBindParameter effect on IPD.IDA fields for interval day/time <data type>s\par
with no SECONDs:\par
Field                                 103 (day)            104 (hour)\par
SQL_DESC_TYPE                         10                   10\par
SQL_DESC_DATETIME_INTERVAL_CODE        3                    4\par
SQL_DESC_LENGTH (in positions)        Columnsize           Columnsize\par
SQL_DESC_PRECISION (frac-sec)          0                    0\par
SQL_DESC_DATETIME_INTERVAL_PRECISION  (lead) Columnsize-1  Columnsize-1\par
\par
Field                                 105 (minute)  108 (day to   109 (day to\par
                                                         hour)         minute)\par
SQL_DESC_TYPE                         10            10            10\par
SQL_DESC_DATETIME_INTERVAL_CODE        5             8             9\par
SQL_DESC_LENGTH (in positions)        Columnsize    Columnsize    Columnsize\par
SQL_DESC_PRECISION (frac-sec)          0             0             0\par
SQL_DESC_DATETIME_INTERVAL_PRECISION  Columnsize-1  Columnsize-4  Columnsize-7\par
\par
Field                                 111 (hour to minute)\par
SQL_DESC_TYPE                         10\par
SQL_DESC_DATETIME_INTERVAL_CODE       11\par
SQL_DESC_LENGTH (in positions)        Columnsize\par
SQL_DESC_PRECISION (frac-sec)          0\par
SQL_DESC_DATETIME_INTERVAL_PRECISION  Columnsize-4\par
\par
The charts show the effect on IPD.IDA[n] fields if the value of the passed\par
ParameterType is 103 or 104 or 105 or 108 or 109 or 111 (interval day or\par
interval hour or interval minute or interval day to hour or interval day to\par
minute or interval hour to minute). SQL_DESC_LENGTH is the length in\par
"positions". SQL_DESC_PRECISION is the "fractional-seconds" precision.\par
SQL_DESC_DATETIME_INTERVAL_PRECISION is the "leading field" precision. For\par
example, if you call SQLBindParameter with ParameterNumber = 2,\par
ParameterType=104, Columnsize=3 and DecimalDigits=0, the result is that, in\par
the IPD.IDA[2] (i.e.: the second item descriptor area in the Implementation\par
Parameter Desc), the settings are as follows: SQL_DESC_TYPE=10,\par
SQL_DESC_DATETIME_INTERVAL_CODE=4, SQL_DESC_LENGTH=3, SQL_DESC_PRECISION=0 and\par
SQL_DESC_DATETIME_INTERVAL_PRECISION=(3-1)=2.\par
\par
SQLBindParameter effect on IPD.IDA fields for interval day/time <data type>s\par
with SECONDs:\par
Field                                 Gets for ...\par
                                      106 (second)\par
SQL_DESC_TYPE                         10\par
SQL_DESC_DATETIME_INTERVAL_CODE        6\par
SQL_DESC_LENGTH (in positions)        Columnsize\par
SQL_DESC_PRECISION (frac-sec)         DecimalDigits\par
SQL_DESC_DATETIME_INTERVAL_PRECISION  (lead) Columnsize-DecimalDigits-2 or \par
                                      Columnsize-1\par
\par
Field                                 Gets for ...\par
                                      110 (day to second)\par
SQL_DESC_TYPE                         10\par
SQL_DESC_DATETIME_INTERVAL_CODE       10\par
SQL_DESC_LENGTH (in positions)        Columnsize\par
SQL_DESC_PRECISION (frac-sec)         DecimalDigits\par
SQL_DESC_DATETIME_INTERVAL_PRECISION  Columnsize-DecimalDigits-11 or \par
                                      Columnsize-10\par
\par
Field                                 Gets for ...\par
                                      112 (hour to second)\par
SQL_DESC_TYPE                         10\par
SQL_DESC_DATETIME_INTERVAL_CODE       12\par
SQL_DESC_LENGTH (in positions)        Columnsize\par
SQL_DESC_PRECISION (frac-sec)         DecimalDigits\par
SQL_DESC_DATETIME_INTERVAL_PRECISION  Columnsize-DecimalDigits-8 or \par
                                      Columnsize-7\par
\par
Field                                 Gets for ...\par
                                      113 (minute to second)\par
SQL_DESC_TYPE                         10     \par
SQL_DESC_DATETIME_INTERVAL_CODE       13      \par
SQL_DESC_LENGTH (in positions)        Columnsize \par
SQL_DESC_PRECISION (frac-sec)         DecimalDigits       \par
SQL_DESC_DATETIME_INTERVAL_PRECISION  Columnsize-DecimalDigits-5 or \par
                                      Columnsize-4\par
\par
The charts show the effect on IPD.IDA[n] fields if the value of the passed\par
ParameterType is 106 or 110 or 112 or 113 (interval second or interval\par
day-to-second or interval hour-to-second or interval minute-to-second).\par
SQL_DESC_LENGTH is the length in "positions". SQL_DESC_PRECISION is the\par
"fractional-seconds" precision. SQL_DESC_DATETIME_INTERVAL_PRECISION is the\par
"leading field" precision. The Column size must include one position for a "."\par
if there is a fractional-seconds amount -- that is, INTERVAL '+5.00' SECOND\par
has a length of 5 (Columnsize=5) and a fractional seconds precision of 2\par
(DecimalDigits=2), so the precision of the leading field is\par
(Columnsize-DecimalDigits-2) = (5-2-2) = 1. For example, if you call\par
SQLBindParameter with ParameterNumber = 1, ParameterType=110, Columnsize=12\par
and DecimalDigits=0, the result is that, in the IPD.IDA[1] (i.e.: the first\par
item descriptor area in the Implementation Parameter Desc), the settings are\par
as follows: SQL_DESC_TYPE=10, SQL_DESC_DATETIME_INTERVAL_CODE=10,\par
SQL_DESC_LENGTH=12, SQL_DESC_PRECISION=0 and SQL_DESC_DATETIME_INTERVAL_PRECISION=(12-10)=2.\par
\par
SQLBindParameter Effect on IPD.IDA fields for other <data type>s:\par
Field                               Gets \par
SQL_DESC_TYPE                       ParameterType\par
SQL_DESC_LENGTH (in chars or bits)  Columnsize\par
\par
The chart shows the effect on IPD.IDA[n] fields if the value of the passed\par
ParameterType is 1 or 12 or 14 or 15 or 30 or 40 (CHAR or CHAR VARYING or BIT\par
or BIT VARYING or BLOB or CLOB). For example, if you call SQLBindParameter\par
with ParameterNumber = 8, ParameterType = 1 and Columnsize = 50, the result is\par
that, in the IPD.IDA[8] (i.e.: the eighth item descriptor area in the\par
Implementation Parameter Desc), the settings are as follows: SQL_DESC_TYPE = 1\par
and SQL_DESC_LENGTH = 50.\par
\par
Notes:\par
      ## ValueType might be SQL_C_DEFAULT.\par
      ## *StrLen_or_Ind might be SQL_DATA_AT_EXEC.\par
      ## *StrLen_or_Ind might be SQL_DATA_NULL.\par
      ## Datetime codings are an occasional source of confusion, because the\par
specification was changed a few years ago. Make sure, especially, that\par
ParameterType is one of the "Concise Codes" for datetimes.\par
      ## The DBMS does not have to perform a consistency check at this time.\par
Contrast SQLSetDescField and SQLSetDescRec, which require a consistency check\par
as soon as SQL_DATA_POINTER contents change to a non-zero value.\par
      ## Beware if you prepare before you bind. For example:\par
\par
   SQLPrepare(hstmt,"UPDATE Table_1 SET int_column =?+5;",SQL_NTS);\par
   SQLBindParameter(hstmt,...);\par
   SQLExecute(hstmt);\par
  ...\par
\par
This sequence is okay according to standard SQL rules. But a DBMS exists which\par
evaluates input parameters while processing SQLPrepare, instead of waiting and\par
evaluating parameters while processing SQLExecute. In that case, the above\par
example won't work. Or -- even worse -- it will appear to work because\par
SQLPrepare picks up an input parameter that you made for a completely\par
different statement! It's difficult to fix this problem by changing the order\par
of the statements, but you could at least get rid of leftover bound parameters\par
by calling SQLFreeStmt(...SQL_RESET_PARAMS).\par
\par
Example:\par
...\par
SQLHSTMT hstmt;\par
SQLCHAR c[6];\par
...\par
SQLBindParameter(\par
   hstmt,1,SQL_PARAM_MODE_INPUT,SQL_C_CHAR,SQL_CHAR,5,NULL,c,NULL,NULL);\par
SQLExecDirect(hstmt,"UPDATE Table_1 SET col_1 = ?;",-3);\par
\par
This example shows how to bind a character parameter. Here, SQLExecDirect\par
contains an SQL statement with a single parameter marker (? is a parameter\par
marker). Before executing the SQL statement, we must bind that parameter.\par
Let's look at the SQLBindParameter arguments, in order:\par
      ## [hstmt] is the stmt handle -- same as in the SQLExecDirect function.\par
      ## [1] is ParameterNumber -- it's 1 because we're binding parameter number 1.\par
      ## [SQL_PARAM_MODE_INPUT] is InputOutputMode -- this is "input" (from host to DBMS).\par
      ## [SQL_C_CHAR] is ValueType -- SQL_C_CHAR = 1, that is, the input is a host 'char' field.\par
      ## [SQL_CHAR] is ParameterType -- SQL_CHAR = 1, that is, the input is an SQL CHAR field.\par
      ## [5] is Columnsize -- the input is 5 characters long.\par
      ## [NULL] is DecimalDigits -- the value here doesn't matter because we're dealing with a char field.\par
      ## [c] is ParameterValue -- what we're actually passing here is the address of c.\par
      ## [NULL] is BufferLength -- the value here doesn't matter. (Note: Many\par
programmers would pass [6] here -- i.e.: the number of octets in c. We deplore\par
this misleading practice. If the parameter mode is SQL_PARAM_MODE_INPUT, the\par
"octet length" is not determined by what is passed for BufferLength.)\par
      ## [NULL] is *StrLen_or_Ind -- in this case we won't supply an indicator pointer.\par
\par
...\par
SQLHSTMT hstmt;\par
SQLCHAR date [] = "1994-01-31";\par
...\par
SQLBindParameter(\par
   hstmt,1,SQL_PARAM_MODE_INPUT,SQL_C_CHAR,SQL_TYPE_DATE,10,0,date,11,0);\par
SQLExecDirect(hstmt,"SELECT * FROM Table_1 WHERE date_field = ?;",SQL_NTS);\par
\par
This example shows how to bind a date parameter. This is much like the\par
previous example, but this time ParameterType is SQL_TYPE_DATE. (Note:\par
ParameterType is SQL_TYPE_DATE (91) -- not SQL_DATE (9). Columnsize is 10,\par
because the number of positions in a date is 10: "yyyy-mm-dd".) In such\par
bindings, there is an implicit CAST to DATE. One of the strengths of\par
SQLBindParameter is that it makes implicit casts easy. So here's what most\par
programmers do:\par
      ## Store everything in the host program as character strings.\par
      ##  Pass ValueType = SQL_C_CHAR for every SQLBindParameter call.\par
      ## Set ParameterType = desired SQL <data type>, forcing the DBMS to perform appropriate conversions.\par
\par
...\par
SQLHSTMT    hstmt;\par
SQLINTEGER  i;                /* sqlcli.h has "typedef long SQLINTEGER" */\par
SQLINTEGER  i_indicator;\par
...\par
SQLPrepare(hstmt,"INSERT INTO Table_1 VALUES (?);",SQL_NTS);\par
SQLBindParameter(\par
      hstmt,                  /* hstmt = "handle of stmt" */\par
      1,                      /* ParameterNumber = "parameter #1" */\par
      SQL_PARAM_MODE_INPUT,   /* InputOutputType = "input" */\par
      SQL_C_LONG,             /* ValueType = "long int" (as seen from C) */\par
      SQL_INTEGER,            /* ParameterType = "int" (as seen from SQL) */\par
      NULL,                   /* Columnsize "don't care" */\par
      NULL,                   /* DecimalDigits "don't care" */\par
      &i,                     /* ParameterValue "address of input data" */\par
      NULL,                   /* BufferLength "don't care" */\par
      &i_indicator);          /* *StrLen_or_Ind "address of indicator" */\par
i_indicator=SQL_NULL_DATA;    /* sqlcli.h has "#define SQL_NULL_DATA -1" */\par
SQLExecute(hstmt);\par
\par
This example shows how to bind a nullable integer parameter. Here, the value\par
of i does not matter because the indicator variable's value is -1. Ultimately,\par
what gets inserted is a NULL value.\par
\par
#include   "sqlcli.h"\par
#include    <math.h>\par
#include    <stdio.h>\par
input_string char[20];\par
SQLHENV     henv;\par
SQLHDBC     hdbc;\par
SQLHSTMT    hstmt;\par
SQLSMALLINT experiment_number;\par
SQLREAL   measurement;\par
void main ()\par
\{\par
 SQLAllocHandle(SQL_HANDLE_ENV,NULL,&henv);\par
 SQLAllocHandle(SQL_HANDLE_DBC,henv,&hdbc);\par
 SQLConnect(hdbc,"Exp",SQL_NTS);\par
 SQLAllocHandle(SQL_HANDLE_HSTMT,hdbc,&hstmt);\par
 SQLExecDirect(\par
   hstmt,"CREATE TABLE Experiments(no INT,measurement REAL);",SQL_NTS);\par
 SQLPrepare(hstmt,"INSERT INTO Experiments VALUES (?,?);",SQL_NTS);\par
 SQLBindParameter(\par
   hstmt,1,SQL_PARAM_MODE_INPUT,SQL_C_SHORT,SQL_SMALLINT,0,0,\par
   &experiment_no,0,0);\par
SQLBindParameter(\par
   hstmt,2,SQL_PARAM_MODE_INPUT,SQL_C_FLOAT,SQL_REAL,24,0,&measurement,0,0);\par
 for (experiment_no=0; experiment_no<10; ++experiment_no) \{\par
   printf("Enter measurement:\\n");\par
   gets(input_string);\par
   measurement=atof(input_string);\par
   SQLExecute(hstmt); \}\par
 SQLEndTran(SQL_HANDLE_DBC,hdbc,SQL_COMMIT);\par
 SQLFreeHandle(SQL_HANDLE_STMT,hstmt);\par
 SQLDisconnect(hdbc);\par
 SQLFreeHandle(SQL_HANDLE_DBC,hdbc);\par
 SQLFreeHandle(SQL_HANDLE_ENV,henv);\par
\}\par
\par
This example shows how to bind two parameters in a loop: it contains calls to\par
SQLPrepare and SQLBindParameter before the loop starts. Note that, for the\par
Columnsize of the measurement parameter, we used 24. In fact, the precision of\par
a REAL is implementation-defined; for some DBMSs, the appropriate value here\par
is 7.\par
\par
ODBC: The SQLBindParameter function is new in ODBC 3.0. An ODBC 2.0 function\par
named SQLSetParam was pretty well the same except that it had no\par
InputOutputMode parameter. ODBC uses the abbreviation SQL_PARAM_INPUT rather\par
than SQL_PARAM_MODE_INPUT. ODBC, in addition to the actions described for\par
standard SQL, will change ARD.IDA[n].SQL_DESC_SCALE and ARD.IDA[n].SQL_DESC_PRECISION to "default" values if ARD.IDA[n].SQL_DESC_TYPE becomes SQL_NUMERIC.\par
\par
Who should populate the IPD?:\par
We've had to repeat, tiresomely, the phrase "if your DBMS supports\par
auto-population of the IPD ..." because this is a major factor of the CLI\par
that's implementation-defined. Let's have a last look at what it means.\par
      ## If the DBMS supports auto-population of the IPD, then:\par
            ## You can find this out by calling SQLGetConnectAttr.\par
            ## You can't change the setting by calling SQLSetConnectAttr.\par
            ## The IPD IDA fields will be populated by SQLPrepare.\par
\par
The action is analogous to what SQLPrepare does to an IRD (for a SELECT\par
statement), so what's the problem? Why don't all DBMSs support\par
auto-population? After all, in an SQL statement like this:\par
\par
   UPDATE Table_1 SET col_1 = 5.1E4 + ?\par
\par
the DBMS must know the definition of the parameter (represented by ?), because\par
it "knows" the <data type> of both TABLE_1.COL_1 and of the <literal>. Well,\par
to answer that, we must remind you that a DBMS is often two quite different\par
programs: the client (driver) and the server (data source). Now, it's true\par
that the server can figure out what a parameter must be. But the client knows\par
nothing about TABLE_1.COL_1 unless the server tells it. As Microsoft puts it:\par
"... most data sources do not provide a way for the driver to discover\par
parameter metadata."  What it comes down to, then, is: Yes, the DBMS should\par
populate the IPD. But it won't, so you should. Luckily, since you're setting\par
up the host variables anyway, you usually have all the information you need to\par
set up the IPD at the time you write your application.\par
\par
SQLColAttribute\par
\par
Function Prototype:\par
 SQLRETURN SQLColAttribute(\par
   SQLHSTMT hstmt,                  /* 32-bit input */\par
   SQLSMALLINT ColumnNumber,        /* 16-bit input, base 1, = Column # in result data corresponds to IRD.IDA[n]\par
   SQLSMALLINT FieldIdentifier,     /* 16-bit input */\par
   SQLCHAR *CharacterAttribute,     /* to char[L], where L = max VARCHAR length. field value ret'd to here if CHAR, else ignored */\par
   SQLSMALLINT BufferLength,        /* 16-bit input = sizeof(CharacterAttribute) ignored if non-CHAR */\par
   SQLSMALLINT *StringLength,       /* 16-bit output */\par
   SQLINTEGER *NumericAttribute     /* 32-bit output */\par
   );\par
\par
Job:\par
Get one field value from an IRD.\par
\par
Algorithm:\par
      If (it's an "ITEM")\par
       /* There must be an open Cursor */\par
If (FieldIdentifier is ..._CATALOG or ..._SCHEMA or ..._NAME)\par
 /* The return is a character string, it goes to CharacterAttribute */\par
 SQLGetDescField (<descriptor handle>,ColumnNumber,FieldIdentifier,\par
      CharacterAttribute,BufferLength,&StringLength);\par
Else If (FieldIdentifier is ..._TYPE)\par
 /* The return is an integer, it goes to NumericAttribute */\par
 If (datetime)\par
   NumericAttribute = "concise code value"\par
 If (interval)\par
   NumericAttribute = "concise code value"\par
 Else\par
   NumericAttribute = <data type>\par
Else\par
 SQLGetDescField(\par
   <descriptor handle>,ColumnNumber,FieldIdentifier,&NumericAttribute,\par
   BufferLength,&StringLength);\par
\par
Notes:\par
      ## SQLColAttribute stands for "[get] Column Attribute". The word\par
"attribute" here means "a field in the Implementation Row Descriptor (IRD)".\par
      ## The IRD is populated by preparing or executing a SELECT statement.\par
For example, when displaying on the screen, it is useful to know the <Column\par
name> and the <data type>. Those are two of the pieces of information that\par
SQLColAttribute will provide you.\par
      ## All of the information that SQLColAttribute returns can also be found\par
via the SQLGetDescField function.\par
      ## With some DBMSs, it is a bad idea to retrieve IRD fields after\par
SQLPrepare, but before SQLExecute. The reason, once again, is that the driver\par
may not have an easy time querying the data source for such "metadata"\par
information. In this case, the driver may actually execute a dummy SQL\par
statement merely in order to find out what fields the data source returns.\par
Such a process is inefficient. Therefore, it is commonly recommended that the\par
IRD-information functions -- SQLColAttribute, SQLDescribeCol and sometimes\par
SQLGetDescField or SQLGetDescRec -- should be deferred until the SQL statement\par
is executed. If the SQLExecute function call is in a loop, then you should set\par
flags appropriately so that the IRD-information function is only called once.\par
\par
Example:\par
      #include "sqlcli.h"\par
      ...\par
      name  char[10];\par
      SQLSMALLINT name_length;\par
      SQLRETURN sqlreturn;\par
      ...\par
      SQLExecDirect("SELECT x AS column_name FROM Table_1");\par
      ...\par
      /* We'd like to know the name. */\par
      sqlreturn=SQLColAttribute (\par
            StatementHandle,\par
            1,                    /* the Column number */\par
            SQL_DESC_NAME,        /* the field identifier, = 1011 */\par
            name,                 /* this is where the name will go */\par
            10,                   /* BufferLength -- too small! */\par
            *name_length,\par
            0);                   /* NumericAttribute doesn't matter */       \par
      /* The result is: sqlreturn==SQL_SUCCESS_WITH_INFO, and if we now got\par
        the diagnostics we would see sqlstate='01004' (truncation). The\par
        value in name is "column_NA\\0". The value in name_length is 11. */\par
\par
ODBC: SQLColAttribute arrived with ODBC 3.0. In ODBC 2.x there was a similar\par
function, SQLColAttributes, which is now deprecated. Syntactically, ODBC 3.0's\par
SQLColAttribute function is nearly standard CLI. But ODBC supports only 14 of\par
the standard FieldIdentifier values (1001 through 1013 and 1099). ODBC also\par
has 15 non-standard values in the "implementation-defined" range, for items\par
like "the name of the Base table" or "whether the Column is case sensitive".\par
In standard SQL, the fields of an IRD are still valid even after a Cursor is\par
closed -- but this is not the case with ODBC. In earlier versions, ODBC and\par
the standard CLI had different type specifications for the BufferLength and\par
StringLength parameters. These differences have now been resolved.\par
\par
SQLDescribeCol\par
\par
Function Prototype:\par
 SQLRETURN SQLDescribeCol(\par
   SQLHSTMT hstmt,                  /* 32-bit input */\par
   SQLSMALLINT ColumnNumber,        /* 16-bit input */\par
   SQLCHAR *ColumnName,             /* CHAR* output */\par
   SQLSMALLINT BufferLength,        /* 16-bit input */\par
   SQLSMALLINT *NameLength,         /* 16-bit output */\par
   SQLSMALLINT *DataType,           /* 16-bit output */\par
   SQLINTEGER *Columnsize,          /* 32-bit output */\par
   SQLSMALLINT *DecimalDigits,      /* 16-bit output */\par
   SQLSMALLINT *Nullable);          /* 16-bit output */\par
\par
Job:\par
Get the following information about one Column in a result set: the <Column\par
name>, the <data type>, the Column size, the scale and whether the Column might contain nulls.\par
\par
Algorithm:\par
      If (no statement was prepared with hstmt)\par
       return error: HY010 CLI-specific condition-function sequence error\par
      Find the IRD for hstmt.\par
      If (IRD.SQL_DESC_COUNT == 0)\par
     /* there are no "result set" Columns so last statement must have\par
       been a non-query */\par
     return error: 07005 Dynamic SQL error-prepared statement not a Cursor specification\par
    If (ColumnNumber < 1)\par
     /* in some non-standard implementations, ColumnNumber can be 0 */\par
     return error: 07009 dynamic SQL error-invalid descriptor index\par
    If (ColumnNumber > IRD.SQL_DESC_COUNT)\par
     return error: 07009 dynamic SQL error-invalid descriptor index\par
      /* Use the Character String Retrieval routine for the following: */\par
      Copy IRD.IDA[ColumnNumber].SQL_DESC_NAME to ColumnName,NameLength\par
      Switch (IRD.IDA[ColumnNumber].SQL_DESC_TYPE)\par
       case: == SQL_DATETIME\par
         /* if type = 9 and subtype = 1, return 91. and so on */\par
         Set *data type = 91, 92, 93, 94 or 95, depending on whether\par
         IRD.IDA[ColumnNumber].SQL_DESC_DATETIME_INTERVAL_CODE is 1, 2, 3, 4   \par
         or 5, respectively.\par
       case: == SQL_INTERVAL\par
         /* if type = 10 and subtype = 1, return 101, and so on */\par
         Set *data type = 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,    \par
         111, 112 or 113, depending on whether                                 \par
         IRD.IDA[ColumnNumber].SQL_DESC_DATETIME_INTERVAL_CODE is 1, 2, 3, 4,  \par
         5, 6, 7, 8, 9, 10, 11, 12 or 13, respectively. */\par
       default:\par
         Set *DataType = IRD.IDA[ColumnNumber].SQL_DESC_TYPE\par
      Switch (IRD.IDA[ColumnNumber].SQL_DESC_TYPE)\par
       case: == any "char" <data type> code\par
         Set *Columnsize = IRD.IDA[ColumnNumber].SQL_DESC_OCTET_LENGTH\par
       case: == any "numeric" <data type> code\par
         Set *Columnsize = the maximum length in decimal digits\par
       case: == any "bit" or "datetime" or "interval" <data type> code\par
         Set *Columnsize = IRD.IDA[ColumnNumber].SQL_DESC_LENGTH\par
      Switch (IRD.IDA[ColumnNumber].SQL_DESC_TYPE)\par
       case: == any "exact numeric" <data type> code\par
         Set *DecimalDigits = IRD.IDA[ColumnNumber].SQL_DESC_SCALE\par
       case: == any "datetime" or "interval" <data type> code\par
         Set *DecimalDigits = IRD.IDA[ColumnNumber].SQL_DESC_PRECISION\par
       default:\par
         Set *DecimalDigits = some implementation-dependent value\par
      Set *Nullable = IRD.IDA[ColumnNumber].SQL_DESC_NULLABLE\par
\par
Notes:\par
      ## Most of the information that SQLDescribeCol returns can  also be\par
found via the SQLGetDescField function, or via the SQLColAttribute function.\par
So SQLDescribeCol is a redundancy. It continues to be popular because it's a\par
handy wrapper: the information that SQLDescribeCol returns is what's commonly\par
needed for simple applications.\par
      ## The SQL Standard does not provide for the possibility that people may\par
wish to pass null pointers for unwanted parameters.\par
      ## Sometimes SQLDescribeCol is called in order to provide information\par
for a reporting program. In that case, ColumnName and NameLength are used for\par
the report-Column headers, DataType is used to determine whether right\par
justification is needed, ColumnLength+2 is the maximum Column width,\par
DecimalDigits helps COBOL programs decide what the totallers' PICs are and\par
Nullable, if true, may cause creation of a separate "null?" Column.\par
      ## Sometimes SQLDescribeCol is called in order to provide information\par
that can be used by SQLBindCol. In that case, DataType can be passed directly,\par
ColumnLength can be passed directly, ColumnLength can be used to decide how\par
big a buffer must be malloc'd, DecimalDigits can be passed directly and\par
Nullable can be used to decide whether an indicator is necessary.\par
However, such a scheme cannot be carried out without some advance checking.\par
For example, not all <data type>s can be passed directly -- some must be CAST\par
to a "char" with length equal to ColumnLength (usually).\par
      ## The source field for Columnsize will depend on the <data type>. This\par
chart shows what the effects are of the calculation in the "Algorithm" section:\par
\par
<data type>            field                  example             example\par
                                              definition          Columnsize\par
CHAR, VARCHAR, BLOB    SQL_DESC_OCTET_LENGTH  CHAR(18)            18\par
DECIMAL, NUMERIC       SQL_DESC_PRECISION     DECIMAL(5,3)         5\par
SMALLINT               SQL_DESC_PRECISION [1] SMALLINT             5\par
INTEGER                SQL_DESC_PRECISION [1] INTEGER             10\par
FLOAT                  SQL_DESC_PRECISION [1] FLOAT(53)           15\par
REAL                   SQL_DESC_PRECISION [1] REAL                 7\par
DOUBLE PRECISION       SQL_DESC_PRECISION [1] DOUBLE PRECISION    15\par
BIT, BIT VARYING       SQL_DESC_LENGTH        BIT(6)               6\par
DATE, TIME, TIMESTAMP  SQL_DESC_LENGTH        DATE                10\par
INTERVAL               SQL_DESC_LENGTH        INTERVAL SECOND(1)   4 [2]\par
\par
      * Note 1: This <data type> usually has a binary-radix precision, so the\par
value in SQL_DESC_PRECISION is in bits. When this is the case, the DBMS\par
converts to the number of decimal digits that would be needed to represent the\par
<data type>'s largest literal (not including space for sign, decimal point or exponent).\par
      * Note 2: The INTERVAL example is based on an assumption that the\par
leading field precision is 2; the specified fractional precision is 1, so a\par
typical <literal> would be INTERVAL '-33.5' SECOND.\par
      ## Old-timers may recognize that the fields retrieved by SQLDescribeCol\par
are analogous to the fields of IBM DB2's SQLDA (SQL descriptor area), used for\par
embedded SQL DESCRIBE statements in days of yore.\par
\par
Example:\par
 #include "sqlcli.h"\par
 #include stdlib.h\par
 SQLHSTMT hstmt;\par
 SQLCHAR column_name[128+1];\par
 SQLSMALLINT column_name_length;\par
 SQLSMALLINT data_type;\par
 SQLINTEGER column_size;\par
 SQLSMALLINT decimal_digits;\par
 SQLSMALLINT nullable;\par
 SQLCHAR *lpBuffer;\par
 ...\par
 SQLExecDirect("SELECT col_1 FROM Table_1",SQL_NTS);\par
 ...\par
 SQLDescribeCol(\par
      hstmt,                        /* handle of stmt */\par
      1,                            /* Column number */\par
      column_name,                  /* where to put Column name */\par
      sizeof(column_name),          /* = 128+1 ... allow for \\0 */\par
      &column_name_length,          /* where to put name length */\par
      &data_type,                   /* where to put <data type> */\par
      &column_size,                 /* where to put Column size */\par
      &decimal_digits,              /* where to put scale/frac precision */\par
      &nullable);                   /* where to put null/not-null flag */\par
 /* Allocate a buffer that we will fetch into. */\par
 switch (data_type) \{\par
   case SQL_BIT:              lpBuffer = malloc(column_size/8+1);\par
   case SQL_REAL:             lpBuffer = malloc(column_size+6+1);\par
   case SQL_DOUBLE_PRECISION: lpBuffer = malloc(column_size+7+1);\par
   case SQL_CHAR:             lpBuffer = malloc(column_size+1);\par
   case SQL_DECIMAL:          lpBuffer = malloc(column_size+2+1);\par
   case SQL_INTEGER:          lpBuffer = malloc(column_size+1+1);\par
   ...\par
   \}\par
\par
ODBC: The SQLDescribeCol function has been around since ODBC 1.0. The\par
differences between the ODBC and Standard's specifications are only minor.\par
Unlike Standard-conformant drivers, ODBC drivers can accept 0 for a Column\par
number, can return a blank string in ColumnName, can return\par
SQL_NULLABLE_UNKNOWN in Nullable and return SQL_DESC_OCTET_LENGTH for\par
ColumnLength of datetime, interval or bit <data type>s.\par
\par
SQLNumResultCols\par
\par
Function Prototype:\par
 SQLRETURN SQLNumResultCols(\par
   SQLHSTMT hstmt,                  /* 32-bit input */\par
   SQLSMALLINT *ColumnCount);       /* pointer to 16-bit output */\par
   );\par
\par
Job:\par
Find out how many Columns are in a result set.\par
\par
Algorithm:\par
If (there is no prepared statement associated with StatementHandle)\par
return error: HY010 CLI-specific condition-function sequence error\par
Set *ColumnCount = IRD.SQL_DESC_COUNT\par
\par
Notes:\par
      ## All this function does is retrieve the "count" field in the IRD,\par
which is zero if the last prepared/executed SQL statement was a non-query, or\par
-- if the last prepared/executed SQL statement was a query -- is the number of\par
Columns in the select list.\par
      ## SQLNumResultCols(hstmt,&column_count) is effectively the same as:\par
\par
   SQLGetStmtAttr(hstmt,SQL_ATTR_IMP_ROW_DESC,&hdesc,NULL,NULL);\par
   SQLGetDescField(hdesc,NULL,SQL_DESC_COUNT,&column_count,NULL,NULL);\par
\par
      ## Some applications call SQLNumResultCols in order to find out whether\par
the last executed statement was a query. If it was something else -- INSERT,\par
for instance -- then *ColumnCount would be 0. This is a reliable test, but\par
SQL3 programmers can use desc.SQL_DESC_DYNAMIC_FUNCTION_CODE for a slightly\par
more precise answer.\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLSMALLINT column_count;\par
      ...\par
    SQLPrepare(hstmt,...);\par
      if (SQLNumResultCols(hstmt,&column_count)<0) \{\par
     ... invalid handle, statement not prepared, etc. \}\par
      if (column_count==0) \{\par
       ... it wasn't a query expression \}\par
    if (column_count>0) \{\par
     ... now we know how many Columns we must bind \}\par
\par
ODBC: The SQLNumResultCols function has been around since ODBC 1.0.\par
\par
SQLGetParamData\par
\par
Function Prototype:\par
 SQLRETURN SQLGetParamData(\par
   SQLHSTMT StatementHandle,        /* 32-bit input */\par
   SQLSMALLINT ParameterNumber,     /* 16-bit input */\par
   SQLSMALLINT TargetType,          /* 16-bit input */\par
   SQLPOINTER TargetValue,          /* ANY* output */\par
   SQLINTEGER BufferLength,         /* 32-bit input */\par
   SQLINTEGER *StrLen_or_Ind        /* 32-bit output */\par
   );\par
\par
Job:\par
Get the value of an unbound <output parameter.\par
\par
SQLGetParamData is rare. You only need it if all these things are true:\par
      ## You have executed an SQL statement which begins with the word CALL.\par
      ## The called procedure has "output parameters" (direction of flow is from DBMS to host-language buffers).\par
      ## You did not bind the output parameters in advance with SQLBindParameter,SQLSetDescRec or SQLSetDescField.\par
\par
Algorithm:\par
If the last statement for hstmt was not a CALL statement:\par
 return error: HY010 CLI-specific condition-function sequence error\par
If the parameter referred to by ParameterNumber doesn't exist, or was bound as\par
"input" parameter, or (implementation-defined restriction) has already been\par
transferred:\par
 return error: 07009 dynamic SQL error-invalid descriptor index\par
Transfer data from DBMS internal buffers to variables in the host-language\par
program. The algorithm is the same as the SQLGetData algorithm; the only\par
important difference is that the desc is an APD rather than an ARD.\par
\par
Note:\par
      ## It is implementation-defined whether the parameters must be accessed\par
in ascending parameter-number order. You can call\par
SQLGetInfo(...SQL_GETPARAMDATA_EXTENSIONS...) to find out whether your DBMS\par
supports getting any parameter in any order.\par
      ## The "source" is already described in the IPD; you only need to pass a\par
description of the "target".\par
      ## The possible values of TargetType are:\par
SQL_C_CHARACTER    1\par
SQL_C_INTEGER      4\par
SQL_C_SMALLINT     5\par
SQL_C_REAL         7\par
SQL_C_DOUBLE       8\par
SQL_C_DEFAULT     99 (use IPD <data type>, precision, scale)\par
SQL_APD_TYPE     -99 (APD specifies <data type> already)\par
We recommend against using SQL_C_DEFAULT because "type, precision, scale" is\par
often insufficient information.\par
\par
Example:\par
Scenario: You have a procedure named Withdraw. It takes five parameters. The\par
first three parameters are input parameters. The fourth parameter is an output\par
parameter which is pre-bound with SQLBindParameter. The fifth parameter is an\par
output parameter which you will pick up with SQLGetParamData.\par
\par
SQLCHAR      amount[10];\par
SQLINTEGER   teller_id;\par
SQLINTEGER   customer_id;\par
SQLCHAR      message1[101];\par
SQLCHAR      message2[101];\par
SQLINTEGER   message2_indicator;\par
...\par
SQLBindParameter(\par
 hstmt,1,SQL_PARAM_MODE_INPUT,SQL_C_CHAR,SQL_DECIMAL,6,2,amount,0,NULL);\par
SQLBindParameter(\par
 hstmt,2,SQL_PARAM_MODE_INPUT,SQL_C_LONG,SQL_INTEGER,0,0,&teller_id,0,NULL);\par
SQLBindParameter(\par
 hstmt,3,SQL_PARAM_MODE_INPUT,SQL_C_LONG,SQL_INTEGER,0,0,&customer_id,0,NULL);\par
SQLBindParameter(\par
 hstmt,4,SQL_PARAM_MODE_OUTPUT,SQL_CHAR,SQL_C_CHAR,100,0,message1,0,NULL);\par
strcpy(amount,"15.33");\par
teller_id = 44;\par
customer_id = 90182;\par
SQLExecDirect(hstmt,"CALL Withdraw (?,?,?,?,?);",24);\par
SQLGetParamData(hstmt,5,\par
      SQL_C_DEFAULT,                /* TargetType */\par
      message2,                     /* TargetValue */\par
      100,                          /* BufferLength */\par
      &message2_indicator);         /* *StrLen_or_Ind */    \par
\par
A possible result from this code would be: message2 contains the null-terminated string "abc" and message2_indicator contains 3.\par
\par
ODBC: The SQLGetParamData function is not part of ODBC 3.0.\par
\par
And that's it for the desc functions. In the next chapter, we'll take a look\par
at the diagnostic functions.\par
\page\par
Chapter 47 -- SQL/CLI: Diagnostic Functions\par
\par
What if something goes wrong? Every env and dbc and stmt and desc has a\par
structure called the Diagnostics Area. The DBMS fills it with information\par
about what happened during the last function call. The diagnostics area has\par
one "header" and zero or more "status records". This partial illustration\par
shows only the most important fields:\par
\par
-----------------------------------------\par
- SQL_DIAG_RETURNCODE | SQL_DIAG_NUMBER -\par
- --------------------+------------------\par
- -            -1     | 00003           |\par
-----------------------------------------\par
-\par
-     ----------------------------------------------------------------------\par
-     - SQL_DIAG_SQLSTATE | SQL_DIAG_MESSAGE_TEXT                    | ... |\par
-     ---------------------------------------------------------------------\par
-   1 - 23000      | Integrity Constraint Violation - constraint <X> | ... |\par
-   2 - 01003      | Warning - null value eliminated in set function | ... |\par
-   3 - 01008      | Warning - implicit zero-bit padding             | ... |\par
-     ---------------------------------------------------------------------\par
\par
This diagram shows the diagnostics area of a stmt, just after this function call:\par
\par
   sqlreturn = SQLExecDirect(\par
      hstmt,"UPDATE T SET a=(SELECT MAX(b) FROM X),c=X'5'",SQL_NTS);\par
\par
Looking at the header, we can see that the function failed because the\par
SQL_DIAG_RETURNCODE field is -1, which is SQL_ERROR (sqlreturn will also equal\par
-1). Also, from the fact that the header's SQL_DIAG_NUMBER field is 3, we can\par
see that there are three status records. \par
\par
Looking at the status records, we can see that three different things went\par
wrong during the execution of the SQL statement. Two of them were merely\par
warnings ("completion conditions"). Probably the DBMS encountered these\par
conditions while it was setting up for the UPDATE, but it kept on going. Then\par
it hit a showstopper: an "exception condition". Although this "integrity\par
Constraint violation" error was the third condition encountered, it is the\par
first in order among the status records because an error's priority is higher than a warning's.\par
\par
The SQL_DIAG_SQLSTATE field contains a code for a reasonably precise\par
categorization of the condition. This code is called the status code, or\par
SQLSTATE value (because the DBMS always puts the status code in the\par
SQL_DIAG_SQLSTATE field). You can see what the SQLSTATE codes mean by looking\par
at the chart of codes at the end of this chapter.\par
\par
The SQL_DIAG_MESSAGE_TEXT field might be the sort of text you'd like to send\par
to the user's screen for this condition. Unlike the status code, the message\par
text is implementation-dependent: it's not standardized. It might be\par
internationalized; that is, it might not be in English. So there is a lot more\par
information here than a mere "failed" return code. And there are many more\par
fields than the ones in the picture, which can help you get an even more\par
precise diagnosis of "why didn't the SQLExecDirect function work". In order to\par
retrieve the diagnostics-area information into your application program, you\par
need to use one of these CLI functions:\par
      ## SQLGetDiagField -- You'll need this function to get any field from any part of the diagnostics area, one field at a time.\par
      ## SQLGetDiagRec -- With this function, you can pick up several of the most popular fields, including SQL_DIAG_SQLSTATE and SQL_DIAG_MESSAGE_TEXT.\par
      ## SQLError -- You'll want to know about this slightly obsolescent function because it appears frequently in legacy code.\par
      ## SQLRowCount -- This isn't exactly a diagnostics function, but it does get a value from a particular diagnostics-area field: SQL_DIAG_ROW_COUNT.\par
\par
The descriptions of these four functions follow.\par
\par
SQLGetDiagField\par
\par
Function Prototype:\par
    SQLRETURN SQLGetDiagField(\par
      SQLSMALLINT HandleType,       /* 16-bit input */\par
      SQLINTEGER Handle,            /* 32-bit input */\par
      SQLSMALLINT RecordNumber,     /* 16-bit input */\par
      SQLSMALLINT DiagIdentifier,   /* 16-bit input */\par
      SQLPOINTER DiagInfo,          /* ANY* output */\par
      SQLSMALLINT BufferLength,     /* 16-bit input */\par
      SQLSMALLINT *StringLength     /* 16-bit output */\par
      );\par
\par
Job:\par
Get one piece of information from a diagnostics area, for example, the\par
SQLSTATE of a warning that was posted for the last function call.\par
\par
There are 50 variations of SQLGetDiagField, depending on the diagnostics field\par
whose value you want to examine. Here's an example and short description of\par
each variation; each uses these shorthands:\par
      ## The words "last call" mean "the last function called using this\par
handle, other than SQLGetDiagField or SQLGetDiagRec or SQLError". The\par
principle (anti-Heisenbergian) here is that the act of observation must not\par
affect the thing observed, so the diagnostics routines don't themselves post\par
diagnostics information.\par
      ## The punctuation ...,..., at the beginning of each function example's\par
parameter list means "assume there is a valid handle type and handle here".\par
The HandleType parameter must be SQL_HANDLE_ENV, SQL_HANDLE_DBC,\par
SQL_HANDLE_STMT or SQL_HANDLE_DESC. The corresponding Handle parameter must be\par
a henv or hdbc or hstmt or hdesc. Where the only acceptable value is a hstmt,\par
the parameter list starts with SQL_HANDLE_STMT,hstmt.\par
      ## The name used for the DiagInfo parameter gives an indication of the\par
<data type> that SQLGetDiagField returns: smallint, integer or character string.\par
      ## The word NULL in a function's argument list means "doesn't matter".\par
None of the diagnostics fields contain NULL in the SQL sense.\par
      ## The four-digit number at the beginning of each paragraph is the code\par
for the DiagIdentifier parameter. We have done the same thing here that we did\par
in our chapter on the desc functions; namely, treating the name of the\par
sqlcli.h code constant as the name of the field.\par
\par
Diagnostics Fields -- Header:\par
The nine "Header" fields in a diagnostics area occur only once. It does not\par
matter what you pass for the RecordNumber parameter.\par
\par
0001\par
SQLGetDiagField(...,...,NULL,SQL_DIAG_RETURNCODE,&smallint,NULL,NULL);\par
\par
This field gives you the last call's return code: SQL_SUCCESS, SQL_ERROR,\par
SQL_SUCCESS_WITH_INFO, SQL_NEED_DATA or SQL_NO_DATA. You need to call this if\par
you failed to save the return code in an sqlreturn variable.\par
\par
0002\par
SQLGetDiagField(...,...,NULL,SQL_DIAG_NUMBER,&integer,NULL,NULL);\par
\par
This field gives you the number of Status Records (exception or completion\par
conditions) that the DBMS generated for the last call. The value will be zero\par
if the return code is SQL_SUCCESS, and will probably (but not certainly) be\par
zero if the return code is SQL_NO_DATA.\par
\par
0003\par
SQLGetDiagField(\par
   SQL_HANDLE_STMT,hstmt,NULL,SQL_DIAG_ROW_COUNT,&integer,NULL,NULL);\par
\par
If the last call was SQLExecDirect or SQLExecute for an UPDATE, DELETE or\par
INSERT statement, this field gives you the number of rows affected. Read about\par
the SQLRowCount function, which returns the same information. You must call\par
this function immediately after calling SQLExecDirect or SQLExecute.\par
\par
0007\par
SQLGetDiagField(\par
   SQL_HANDLE_STMT,hstmt,NULL,SQL_DIAG_DYNAMIC_FUNCTION,charstring,\par
   sizeof(charstring),&charstring_size);\par
\par
If the last call was SQLExecDirect or SQLExecute, this field gives you a\par
string that describes the type of SQL statement executed. Usually this is the\par
first two or three <keyword>s in the statement. The official list of SQL\par
statements and their function codes is shown at the end of this section.\par
\par
0012\par
SQLGetDiagField(\par
   SQL_HANDLE_STMT,hstmt,NULL,SQL_DIAG_DYNAMIC_FUNCTION_CODE,\par
   &integer,NULL,NULL);\par
\par
If the last call was SQLExecDirect or SQLExecute, this field gives you the\par
code value for the type of SQL statement executed; see the codes in the\par
"DYNAMIC_FUNCTION and DYNAMIC_FUNCTION_CODE" lists, above. If you allow users\par
to type in SQL statements, it's handy to call SQLPrepare and then call this\par
function, so you know what kind of SQL statement it is before you call\par
SQLExecute.\par
\par
0013\par
SQLGetDiagField(SQL_HANDLE_STMT,hstmt,NULL,SQL_DIAG_MORE,&integer,NULL,NULL);\par
\par
The return value for this field is either 1 "true" or 0 "false": if there are\par
more status records than would fit in the diagnostics area, you get a "true"\par
code here. (Actually the Standard says that the returned value is 'Y' or 'N'\par
but that must be an error.) You may or may not be able to change the maximum\par
size of the diagnostics area with SET TRANSACTION ... DIAGNOSTICS SIZE\par
statement.\par
\par
0034\par
SQLGetDiagField(\par
   ...,...,NULL,SQL_DIAG_TRANSACTIONS_COMMITTED,&integer,NULL,NULL);\par
\par
This field gives you the number of transactions committed.\par
\par
0035\par
SQLGetDiagField(\par
   ...,...,NULL,SQL_DIAG_TRANSACTIONS_ROLLED_BACK,&integer,NULL,NULL);\par
\par
This field gives you the number of transactions rolled back.\par
\par
0036\par
SQLGetDiagField(...,...,NULL,SQL_DIAG_TRANSACTION_ACTIVE,&integer,NULL,NULL);\par
\par
This field gives you a 1 "true" if a transaction is currently active. (A\par
transaction is active if a Cursor is open or the DBMS is waiting for a\par
deferred parameter.)\par
\par
## SQL_DIAG_DYNAMIC_FUNCTION codes\par
If the last call was SQLExecDirect or SQLExecute, SQLGetDiagField's\par
SQL_DIAG_DYNAMIC_FUNCTION gives you a string that describes the type of SQL\par
statement executed. As we said earlier, this is usually the first two or three\par
<keyword>s in the SQL statement. Here's the official list of SQL statements\par
and their function codes (note that not all these SQL statements are\par
executable in a CLI context; we have given a full list here so as to avoid\par
repetition elsewhere).\par
\par
List of SQL statements and codes in SQL-92, but not in CLI --\par
DYNAMIC_FUNCTION             DYNAMIC_FUNCTION_CODE\par
(string)                     (number)  (sqlcli.h definition)\par
ALLOCATE CURSOR                1       not defined\par
ALLOCATE DESCRIPTOR            2       not defined\par
CREATE TRANSLATION            79       not defined\par
DEALLOCATE DESCRIPTOR         15       not defined\par
DEALLOCATE PREPARE            16       not defined\par
DESCRIBE                      20       not defined\par
DYNAMIC CLOSE                 37       not defined\par
DYNAMIC DELETE CURSOR:        38       not defined\par
   (positioned)\par
DYNAMIC FETCH                 39       not defined\par
DYNAMIC OPEN                  40       not defined\par
DYNAMIC UPDATE CURSOR:        42       not defined\par
   (positioned)\par
EXECUTE                       44       not defined\par
EXECUTE IMMEDIATE             43       not defined\par
FETCH                         45       not defined\par
GET DESCRIPTOR                47       not defined\par
PREPARE                       56       not defined\par
SELECT (multiple row)         21       not defined\par
SET CURRENT_PATH              69       not defined\par
SET DESCRIPTOR                70       not defined\par
\par
List of additional SQL statements and codes in SQL-92 and CLI --\par
DYNAMIC_FUNCTION             DYNAMIC_FUNCTION_CODE\par
(string)                     (number)  (sqlcli.h definition)\par
''                             0       <unknown statement type>\par
ALTER DOMAIN                   3       SQL_DIAG_ALTER_DOMAIN\par
ALTER TABLE                    4       SQL_DIAG_ALTER_TABLE\par
CLOSE CURSOR                   9       SQL_DIAG_CLOSE_CURSOR\par
COMMIT WORK                   11       SQL_DIAG_COMMIT\par
CONNECT                       13       SQL_DIAG_CONNECT\par
CREATE ASSERTION               6       SQL_DIAG_CREATE_ASSERTION\par
CREATE CHARACTER SET           8       SQL_DIAG_CREATE_CHARACTER_SET\par
CREATE COLLATION              10       SQL_DIAG_CREATE_COLLATION\par
CREATE DOMAIN                 23       SQL_DIAG_CREATE_DOMAIN\par
CREATE SCHEMA                 64       SQL_DIAG_CREATE_SCHEMA\par
CREATE TABLE                  77       SQL_DIAG_CREATE_TABLE\par
CREATE VIEW                   84       SQL_DIAG_CREATE_VIEW\par
DECLARE CURSOR               101       SQL_DIAG_DECLARE_CURSOR\par
DELETE CURSOR                 18       SQL_DIAG_DELETE_CURSOR\par
DELETE WHERE                  19       SQL_DIAG_DELETE_WHERE\par
DISCONNECT                    22       SQL_DIAG_DISCONNECT\par
DROP ASSERTION                24       SQL_DIAG_DROP_ASSERTION\par
DROP CHARACTER SET            25       SQL_DIAG_DROP_CHARACTER_SET\par
DROP COLLATION                26       SQL_DIAG_DROP_COLLATION\par
DROP DOMAIN                   27       SQL_DIAG_DROP_DOMAIN\par
DROP SCHEMA                   31       SQL_DIAG_DROP_SCHEMA\par
DROP TABLE                    32       SQL_DIAG_DROP_TABLE\par
DROP TRANSLATION              33       SQL_DIAG_DROP_TRANSLATION\par
DROP VIEW                     36       SQL_DIAG_DROP_VIEW\par
DYNAMIC DELETE CURSOR:        54       SQL_DIAG_DYNAMIC_DELETE_CURSOR\par
   (preparable, positioned)\par
DYNAMIC UPDATE CURSOR         55       SQL_DIAG_DYNAMIC_UPDATE_CURSOR\par
   (preparable, positioned)\par
GRANT                         48       SQL_DIAG_GRANT\par
INSERT                        50       SQL_DIAG_INSERT\par
OPEN                          53       SQL_DIAG_OPEN\par
REVOKE                        59       SQL_DIAG_REVOKE\par
ROLLBACK WORK                 62       SQL_DIAG_ROLLBACK\par
SELECT (single row)           65       SQL_DIAG_SELECT\par
SELECT (dynamic single row)   41       SQL_DIAG_SELECT\par
SELECT CURSOR                 85       SQL_DIAG_SELECT_CURSOR\par
  (dynamic multiple row)\par
SET CATALOG                   66       SQL_DIAG_SET_CATALOG\par
SET CONNECTION                67       SQL_DIAG_SET_CONNECTION\par
SET CONSTRAINT                68       SQL_DIAG_SET_CONSTRAINT\par
SET NAMES                     72       SQL_DIAG_SET_NAMES\par
SET TIME ZONE                 71       SQL_DIAG_SET_TIME_ZONE\par
SET SESSION AUTHORIZATION     76       SQL_DIAG_SET_SESSION_AUTHORIZATION\par
SET SCHEMA                    74       SQL_DIAG_SET_SCHEMA\par
SET TRANSACTION               75       SQL_DIAG_SET_TRANSACTION\par
UPDATE CURSOR (positioned)    81       SQL_DIAG_UPDATE_CURSOR\par
UPDATE WHERE                  82       SQL_DIAG_UPDATE_WHERE\par
\par
List of additional SQL statements and codes in SQL3, but not in CLI --\par
DYNAMIC_FUNCTION             DYNAMIC_FUNCTION_CODE\par
(string)                     (number)  (sqlcli.h definition)\par
ALTER MODULE                  95       not defined\par
ALTER ROUTINE                 17       not defined\par
ALTER TYPE                    60       not defined\par
ASSIGNMENT                     5       not defined\par
BEGIN END                     12       not defined\par
CASE                          86       not defined\par
CREATE MODULE                 51       not defined\par
CREATE ORDERING              114       not defined\par
CREATE TRANSFORM             117       not defined\par
DECLARE VARIABLE              96       not defined\par
DROP MODULE                   28       not defined\par
FOR                           46       not defined\par
FREE LOCATOR                  98       not defined\par
HANDLER                       87       not defined\par
HOLD LOCATOR                  99       not defined\par
IF                            88       not defined\par
LEAVE                         89       not defined\par
LOOP                          90       not defined\par
RESIGNAL                      91       not defined\par
SET TRANSFORM GROUP          118       not defined\par
SIGNAL                        92       not defined\par
TEMPORARY TABLE               93       not defined\par
WHILE                         97       not defined\par
\par
List of additional SQL statements and codes in SQL3 and CLI --\par
DYNAMIC_FUNCTION             DYNAMIC_FUNCTION_CODE\par
(string)                     (number)  (sqlcli.h definition)\par
CALL                           7       SQL_DIAG_CALL\par
CREATE ROLE                   61       SQL_DIAG_CREATE_ROLE\par
CREATE ROUTINE                14       SQL_DIAG_CREATE_ROUTINE\par
CREATE TRIGGER                80       SQL_DIAG_CREATE_TRIGGER\par
CREATE TYPE                   83       SQL_DIAG_CREATE_TYPE\par
DROP ROLE                     29       SQL_DIAG_DROP_ROLE\par
DROP ROUTINE                  30       SQL_DIAG_DROP_ROUTINE\par
DROP TRANSFORM               116       SQL_DIAG_DROP_TRANSFORM\par
DROP TRIGGER                  34       SQL_DIAG_DROP_TRIGGER\par
DROP ORDERING                115       SQL_DIAG_DROP_ORDERING\par
DROP TYPE                     35       SQL_DIAG_DROP_TYPE\par
GRANT ROLE                    49       SQL_DIAG_GRANT_ROLE\par
RELEASE SAVEPOINT             57       SQL_DIAG_RELEASE_SAVEPOINT\par
RETURN                        58       SQL_DIAG_RETURN\par
REVOKE ROLE                   60       SQL_DIAG_REVOKE_ROLE\par
SAVEPOINT                     63       SQL_DIAG_SAVEPOINT\par
SET ROLE                      73       SQL_DIAG_SET_ROLE\par
SET SESSION CHARACTERISTICS  109       SQL_DIAG_SET_SESSION_CHARACTERISTICS\par
START TRANSACTION            111       SQL_DIAG_START_TRANSACTION\par
\par
(Note: In some contexts, the names DYNAMIC_FUNCTION and DYNAMIC_FUNCTION_CODE\par
are COMMAND_FUNCTION and COMMAND_FUNCTION_CODE, respectively.)\par
\par
Diagnostics Fields -- Status Records:\par
The 28 "status records" in a diagnostics area can occur multiple times. You\par
must pass a record number between 1 and SQL_DIAG_NUMBER (or you can pass any\par
positive number and see whether SQLGetDiagField returns SQL_NO_DATA). Other\par
terms for Status Record are: "Descriptor Record" (preferred by Microsoft) and\par
Condition Information Item (preferred by the SQL Standard in non-CLI\par
contexts). Strings are returned according to the rules of Character String\par
Retrieval.\par
\par
< 0\par
A status record with a number less than zero identifies an\par
implementation-defined diagnostics field.\par
\par
0004\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_SQLSTATE,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
This field gives you a 5-character status code -- remember to allow 6\par
characters because of the null terminator. SQLSTATE is the most important\par
diagnostics field. You'll find the complete list of SQLSTATE values, often\par
called simply status codes, at the end of this chapter. Quite often, the\par
SQLSTATE class determines whether the other diagnostics fields have meaningful\par
values.\par
\par
0005\par
SQLGetDiagField(...,...,n,SQL_DIAG_NATIVE,&integer,NULL,NULL);\par
\par
This field gives you an integer which has an implementation-defined numeric\par
code for the error type. If your DBMS has been around for a few years, this\par
will be the same as the SQLCODE value. It was once standard for DBMSs to\par
return SQLCODE, and sometimes (for instance with IBM's DB2) the SQLCODE is\par
more informative than the SQLSTATE value. But there is no standardized\par
interpretation for the codes, except that values less than zero are "errors",\par
equal to zero is "success", greater than zero are "warnings", and specifically\par
+100 is "warning-no data".\par
\par
0006\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_MESSAGE_TEXT,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
This field gives you an error message -- sometimes merely an explanation of\par
the SQLSTATE meaning, but the better DBMSs have context-sensitive tips. Useful\par
for displays. Often, due to an ODBC requirement, messages start with bracketed\par
information about the server and driver.\par
\par
0008\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_CLASS_ORIGIN,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
This field gives you the naming authority responsible for the definition of\par
the class (the first two letters of SQLSTATE). Example: 'ISO 9075' would mean\par
that the condition is documented in ISO/IEC 9075:1992 and is therefore\par
"standard".\par
\par
0009\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_SUBCLASS_ORIGIN,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
This field gives you the naming authority responsible for the definition of\par
the subclass (the last three letters of SQLSTATE). Example: 'ODBC 3.0' would\par
mean that the condition is documented in Microsoft's ODBC manual version 3.0\par
but is not in any ISO specification, and is therefore "not standard".\par
\par
0010\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_CONNECTION_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
This field gives you the <Connection name>. With the CLI this field is of\par
minor importance, because the primary identifier for an SQL-Connection is the\par
hdbc.\par
\par
0011\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_SERVER_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
If the last SQL statement was a failed CONNECT, DISCONNECT or SET CONNECTION,\par
this field gives you the server that the attempt failed with. Otherwise, you\par
get the same information that you'd get by calling\par
SQLGetInfo(...,SQL_DATA_SOURCE_NAME,...).\par
\par
0014\par
SQLGetDiagField(...,...,n,SQL_DIAG_CONDITION_NUMBER,&integer,NULL,NULL);\par
\par
This field gives you the number of the Status Record (the terms "condition\par
number" and "status record number" are synonymous). This will be the same\par
thing as the RecordNumber parameter, so you won't find out anything new here.\par
\par
0015\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_CONSTRAINT_CATALOG,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0016\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_CONSTRAINT_SCHEMA,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0017\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_CONSTRAINT_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
If SQLSTATE is '23000' (integrity constraint violation) or '27000' (triggered\par
data change violation) or '40002' (transaction rollback-integrity constraint\par
violation), then fields 0015, 0016 and 0017 give you the Catalog, Schema and\par
name of the violated Constraint.\par
\par
0018\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_CATALOG_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0019\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_SCHEMA_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0020\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_TABLE_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0021\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_COLUMN_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
Fields 0018, 0019, 0020 and 0021 give you the Catalog, Schema and Table\par
identifiers, plus the Column identifier if applicable, for what "caused" the\par
problem. If SQLSTATE = '23000' or '27000' or '40002', these fields will\par
identify the Table that the violated Constraint is associated with (assuming\par
there is one such Table). If SQLSTATE = '42000', this is the Object that\par
couldn't be found or that you lack Privileges on (the Standard contains some\par
ambiguities here, but it seems that these fields may be blank for access\par
violations). If SQLSTATE = '44000', this is the View that has a violated WITH\par
CHECK OPTION. If SQLSTATE = '09000' or '40004', this is the Table with the\par
Trigger that can't be executed. If SQLSTATE is any other value, results are\par
implementation-dependent.\par
\par
0022\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_CURSOR_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
If SQLSTATE = '01001' or '24000', this field gives you the identifier of a\par
Cursor. If SQLSTATE is anything else, results are implementation-dependent.\par
\par
0023\par
SQLGetDiagField(...,...,n,SQL_DIAG_MESSAGE_LENGTH,&integer,NULL,NULL);\par
\par
This field gives you the character length of the implementation-defined\par
message string. You can get the same information using SQL_DIAG_MESSAGE_TEXT.\par
By the way, the C include file "sqlcli.h" says "#define\par
SQL_MAXIMUM_MESSAGE_LENGTH 512" so the suggestion is that you allow 512 bytes\par
for the message -- but it's only a suggestion. It might be interesting to \par
compare SQL_MAXIMUM_MESSAGE_LENGTH with what SQLGetDiagField returns for\par
SQL_DIAG_MESSAGE_LENGTH.\par
\par
0024\par
SQLGetDiagField(...,...,n,SQL_DIAG_MESSAGE_OCTET_LENGTH,&integer,NULL,NULL);\par
\par
This field gives you the octet length of the implementation-defined message\par
string. This will be the same as the message length in characters if the\par
Character set is 8-bit.\par
\par
0025\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_CONDITION_NAME,&charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
This field gives you the name of an unhandled user-defined exception.\par
\par
0026\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_PARAMETER_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
This field gives you the name of a parameter -- presumably the parameter which\par
contained bad (input) data. Since named parameters are not a universal\par
feature, most DBMSs will not return anything here.\par
\par
0027\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_ROUTINE_CATALOG,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0028\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_ROUTINE_SCHEMA,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0029\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_ROUTINE_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0030\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_SPECIFIC_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
If the SQLSTATE error class is '38' (external routine exception) or '39'\par
(external routine invocation exception), fields 0027, 0028 and 0029 give you\par
the full identifier of the routine that "caused" the error, while field 0030\par
gives you the routine's specific name.\par
\par
0031\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_TRIGGER_CATALOG,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0032\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_TRIGGER_SCHEMA,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
0033\par
SQLGetDiagField(\par
   ...,...,n,SQL_DIAG_TRIGGER_NAME,charstring,sizeof(charstring),\par
   &charstring_size);\par
\par
If SQLSTATE='40004' or '09000', fields 0031, 0032 and 0033 give you the full\par
identifier of the Trigger that "caused" the problem.\par
\par
Algorithm:\par
If (HandleType <> SQL_HANDLE_STMT, SQL_HANDLE_ENV, SQL_HANDLE_DBC, or\par
SQL_HANDLE)DESC)\par
  return error: CLI-specific condition-invalid handle\par
If (handle isn't really the type indicated by HandleType)\par
  return error: CLI-specific condition-invalid handle\par
If (DiagIdentifier isn't a valid code)\par
  return error: HY024 CLI-specific condition-invalid attribute value\par
If (FieldIdentifier is for one of the Status Record fields)\par
  If (RecordNumber < 1)\par
    return error: 35000 invalid condition number -\par
  If (RecordNumber > actual number of status records)\par
    return warning: 01000 no data -\par
If (FieldIdentifier is for one of the Header fields)\par
  If (FieldIdentifier == SQL_DIAG_ROW_COUNT)\par
    If (last call was not SQLExecute or SQLExecDirect)\par
      return error: HY092 CLI-specific condition-invalid attribute identifier\par
      Otherwise: return a diagnostics-area field, as already described.\par
\par
Notes:\par
      ## Status Records are sorted according to the severity of the error\par
class:\par
            ## Highest: Errors that cause rollback (class '40').\par
            ## Lower: Ordinary errors (everything except '40' or '01' or\par
'02').\par
            ## Lower: No-data warning (class '02').\par
            ## Lowest: Mere warning (class '01').\par
The first Status Record is thus the most important. If the return code is\par
SQL_ERROR you can be sure that the first Status Record describes an error\par
condition.\par
      ## The SQLSTATEs associated with the possible SQLGetDiagField errors are\par
only mentioned for documentary reasons. The SQLGetDiagField function does not\par
itself post any diagnostics. The way you check for errors is: look at the\par
return code, then start guessing. These tips may be useful:\par
\par
  If (SQLGetDiagField returns SQL_SUCCESS_WITH_INFO)\par
    Probably the DiagInfo buffer is too small.\par
    Compare BufferLength (the maximum size of the DiagInfo buffer)\par
    to StringLength (the actual size of the string to be returned).\par
    If BufferLength is smaller, there's your problem.\par
  If (SQLGetDiagField returns SQL_INVALID_HANDLE)\par
    Sure, check that the handle is valid. But this problem can also occur\par
    if SQLHandleType is not SQL_HANDLE_..., so check that too.\par
  If (SQLGetDiagField returns SQL_ERROR)\par
    Check HandleType+DiagIdentifier. If the handle isn't a hstmt, then\par
    you can't ask for SQL_ROW_COUNT.\par
    Check RecordNumber. If you're looking for a header field, then it\par
    doesn't matter what you pass in RecordNumber. If you're looking for a\par
    status field, then RecordNumber must be >= 1.\par
    Check DiagIdentifier. If you use constants defined in sqlcli.h: the\par
    value here should be a constant beginning with SQL_DIAG_... -- but\par
    that's not enough. Also, make sure it's one of the values listed above.\par
    Check BufferLength. If you're looking for a numeric field, then it\par
    doesn't matter what you pass in BufferLength. If you're looking for a\par
    string field, then BufferLength must be >= 1.\par
  If (SQLGetDiagField returns SQL_NO_DATA)\par
    This always means that the value you passed in RecordNumber is greater\par
    than the value in the diagnostics area's NUMBER field.\par
    For example: you passed 1 but there are zero status records.\par
      ## Some header fields always have valid information, even if the last\par
call didn't end with an error or warning. For example, you can find out what\par
the last executed SQL statement was, and how many rows it affected, even if\par
the number of Status Records is zero.\par
      ## The great majority of diagnostics are only applicable to stmts. You\par
will only need to get a dbc's diagnostics area fields if the last call used a\par
dbc handle, which usually means if the last call was connect, disconnect,\par
endtran or some variants of allochandle and freehandle. As for envs and descs,\par
they too have diagnostics areas, but use of SQLGetDiagField with henvs and\par
hdescs is esoteric.\par
\par
Example:\par
  #include "sqlcli.h"\par
  ...\par
  SQLHSTMT     hstmt;\par
  SQLINTEGER   diag_number;         /* gets # of status records */\par
  SQLINTEGER   row_number;\par
  SQLCHAR      sqlstate[5+1];       /* gets SQLSTATE */\par
  SQLCHAR      catalog[128+1];      /* gets a catalog name */\par
  SQLSMALLINT  catalog_octet_length;/* size of catalog name */\par
  SQLCHAR      schema[128+1];       /* gets a schema name */\par
  SQLSMALLINT  schema_octet_length; /* size of schema name */\par
  SQLCHAR      name[128+1];         /* gets an object name */\par
  SQLSMALLINT  name_octet_length;   /* size of name */\par
  ...\par
  /* Make a one-Column Table, with a CHECK Constraint. */\par
  SQLExecDirect(hstmt,"CREATE TABLE Ts(col_1 INT,CHECK (col_1=7);",SQL_NTS);\par
  /* Try to violate the CHECK Constraint. */\par
  SQLExecDirect(hstmt,"INSERT INTO Ts VALUES(15);",SQL_NTS);\par
  /* Find out how many status records are in the diagnostics area. */\par
  SQLGetDiagField(SQL_HANDLE_STMT,NULL,SQL_DIAG_COUNT,&diag_count,NULL,NULL);\par
  /* Loop: For each status record ... */ \par
  for (row_number=1; row_number<=diag_number; ++row_number) \{\par
    /* Get SQLSTATE. */\par
    SQLGetDiagField(\par
      SQL_HANDLE_HSTMT,hstmt,row_number,SQL_DIAG_SQLSTATE,sizeof(sqlstate),\par
      sqlstate,NULL);\par
    /* The first two octets of SQLSTATE are the error class. */\par
    /* if class = '23' integrity constraint violation: what constraint? */ \par
    if (memcmp(sqlstate,"23",2)==0) \{\par
      /* Get Catalog . Schema . name of the Constraint */\par
      SQLGetDiagField(\par
        SQL_HANDLE_STMT,hstmt,row_number,SQL_DIAG_CONSTRAINT_CATALOG,catalog,\par
        sizeof(catalog),&catalog_size);\par
      SQLGetDiagField(\par
         SQL_HANDLE_STMT,hstmt,row_number,SQL_DIAG_CONSTRAINT_SCHEMA,\par
         schema,sizeof(schema),&schema_size);\par
      SQLGetDiagField(\par
         SQL_HANDLE_STMT,hstmt,row_number,SQL_DIAG_CONSTRAINT_NAME,\par
         name,sizeof(name),&name_size);\par
\} \}\par
\par
ODBC: The SQLGetDiagField function is new in ODBC 3.0 (older ODBC versions had\par
only SQLError for getting diagnostics fields). In addition to all the standard\par
options, ODBC has an additional useful-looking one: SQL_DIAG_CURSOR_ROW_COUNT,\par
for getting the number of rows in an open Cursor. (ODBC also gives row and\par
Column number within the result set.) ODBC, unlike standard SQL, sorts status\par
records by row number.\par
\par
SQLGetDiagRec\par
\par
Function Prototype:\par
   SQLRETURN  SQLGetDiagRec(\par
     SQLSMALLINT HandleType,              /* 16-bit input */\par
     SQLINTEGER Handle,                   /* 32-bit input */\par
     SQLSMALLINT RecordNumber,            /* 16-bit input */\par
     SQLCHAR *Sqlstate,                   /* CHAR* output */\par
     SQLINTEGER *NativeError,             /* 32-bit output */\par
     SQLCHAR *MessageText,                /* CHAR* output */\par
     SQLSMALLINT BufferLength,            /* 16-bit input */\par
     SQLSMALLINT *TextLength);            /* 16-bit output */\par
\par
Job:\par
Get SQLSTATE, sqlcode and error-message from one status record.\par
\par
Algorithm:\par
If (HandleType <> SQL_HANDLE_ENV | SQL_HANDLE_DBC | SQL_HANDLE_STMT\par
  | SQL_HANDLE_DESC)\par
Or (what handle references isn't the type that HandleType indicates)\par
  return error: CLI-specific condition-invalid handle\par
If (RecordNumber < 1)\par
  return error: 35000 invalid condition number -\par
If (RecordNumber > number of status records in diagnostics area)\par
  /* SQLGetDiagRec returns +100, but doesn't make its own diagnostics */\par
  /* In ODBC, some output parameters would be changed anyway. */\par
  return error: no data -\par
If (SqlState is not a null pointer)\par
  Set *SQLState = status record [RecordNumber] . SQL_DIAG_SQLSTATE\par
If (NativeError is not a null pointer)\par
  Set *NativeError = status record [RecordNumber] . SQL_DIAG_NATIVE_ERROR\par
If (MessageText is not a null pointer)\par
  /* ... The message text is copied in the usual Character String\par
     Retrieval way. */\par
  Set *MessageText = status record [RecordNumber ]. SQL_DIAG_MESSAGE_TEXT\par
For description of the SQL_DIAG_SQLSTATE, SQL_DIAG_NATIVE_ERROR, and\par
SQL_DIAG_MESSAGE_TEXT fields, see the SQLGetDiagField descriptions.\par
\par
Notes:\par
      ## The assumption behind SQLGetDiagRec is that, when you want\par
diagnostics information, you specifically want SQL_DIAG_SQLSTATE,\par
SQL_NATIVE_ERROR and SQL_DIAG_MESSAGE_TEXT (both contents and length). If the\par
assumption is wrong and you want only some of these fields, or you want other\par
fields, then you might find that SQLGetDiagField is all you need. We observed\par
similar assumptions at work when we looked at the desc functions,\par
SQLGetDescField and SQLGetDescRec.\par
      ## Calls to SQLGetDiagRec are frequent after a CLI function returns an\par
error. That is: \par
\par
   if (SQLfunction(...) < 0)  SQLGetDiagRec(...);\par
\par
is the normal way of calling.\par
\par
Example:\par
This example shows that SQLGetDiagRec and SQLGetDiagField may be similar. The\par
first call retrieves dbc's SQLSTATE using SQLGetDiagField -- we pass NULL for\par
the final 4 parameters because we don't care about them.\par
\par
#include "sqlcli.h"\par
SQLCHAR sqlstate[6];\par
...\par
  SQLGetDiagField(SQL_HANDLE_DBC,hdbc,1,sqlstate,sizeof(sqlstate),NULL);\par
  SQLGetDiagRec(SQL_HANDLE_DBC,hdbc,1,sqlstate,NULL,NULL,NULL,NULL);\par
\par
This example shows the minimalist error-handling procedure for applications\par
that are written in a hurry: if anything goes wrong, print a message and stop\par
the program. The symbol SQL... means "any CLI function". The "if (sqlreturn <\par
0)" test uses an assumption (true at the moment) that SQL_SUCCESS and\par
SQL_SUCCESS_WITH_INFO and SQL_NO_DATA -- the non-problems -- are all greater\par
than or equal to zero; SQL_INVALID_HANDLE and SQL_NEED_DATA and SQL_ERROR --\par
the problems -- are less than zero.\par
\par
  #include "sqlcli.h"\par
  SQLCHAR sqlstate[5+1];\par
  SQLCHAR sqlmessage[SQL_MAX_MESSAGE_LENGTH+1];\par
  SQLRETURN sqlreturn;\par
  ...\par
  sqlreturn = SQLFunc(...);\par
  if (sqlreturn < 0) \{\par
    printf("Error: \\n");\par
    if (sqlreturn==SQL_INVALID_HANDLE) \{\par
      /* For the SQL_INVALID_HANDLE return code, there are no associated\par
         status records. So we have to make up and display our own error. */\par
      printf("Invalid handle.\\n"); \}\par
    if (sqlreturn==SQL_NEED_DATA) \{\par
      /* This is shown for completeness; "need data" needs discussion later */\par
      printf("Need data.\\n"); \}\par
    if (sqlreturn==SQL_ERROR) \{\par
      if (SQLGetDiagRec(...,...,1,sqlstate,NULL,sqlmessage,NULL,NULL)\par
       == SQL_NO_DATA) \{\par
        /* Read the SQLAllocEnv description for special notes about handling\par
           errors from that function. For all other CLI functions, there\par
           will be at least one status record, so you won't get here. */\par
        printf("(No status rows).\\n"); \}\par
      else \{\par
        printf("SQLSTATE=%s.\\n",sqlstate);\par
        printf("MESSAGE_TEXT=%s.\\n",sqlmessage);\par
    exit(1); \}\par
\par
This example displays warning or error messages after an execution.\par
\par
  #include "sqlcli.h"\par
  SQLCHAR  sqlstate[6], sqlmessage[SQL_MAX_MESSAGE_LENGTH+1];\par
  SQLINTEGER sqlnative, sqlmore;\par
  SQLSMALLINT sqlrecordnumber, sqlmessagelength;\par
  SQLHSTMT hstmt;\par
  SQLRETURN sqlreturn1, sqlreturn2;\par
  ...\par
  sqlreturn1 = SQLExecDirect(hstmt,"SQL statement goes here",SQL_NTS);\par
  if (sqlreturn1 == SQL_ERROR || sqlreturn1 == SQL_SUCCESS_WITH_INFO) \{\par
    for (sqlrecordnumber=1;;++sqlrecordnumber) \{\par
      sqlreturn2=SQLGetDiagRec(\par
                    SQL_HANDLE_STMT,hstmt,sqlrecordnumber,sqlstate,&sqlnative,\par
                    sql_message,sizeof(sql_message),&sql_message_length);\par
    if (sqlreturn2 == SQL_NO_DATA || sqlreturn2 < 0) break;\par
    printf("SQLExecDirect returned: %d\\n",sqlreturn1);\par
    printf("Status code = %s\\n",sqlstate);\par
    printf("Native code or sqlcode = %ld\\n",sqlnative);\par
    printf("Error/Warning message = %s.\\n",sqlmessage);\par
    if (sqlmessagelength>sizeof(sqlmessage) printf("May be truncated."); \}\par
  SQLGetDiagField(SQL_HANDLE_STMT,hstmt,1,SQL_DIAG_MORE,&sqlmore,NULL,NULL);\par
  if (sqlmore) \{\par
    printf("Not all Error/Warning conditions have been displayed!\\n"); \}\par
\par
ODBC: The SQLGetDiagRec function is new in ODBC 3.0; applications for earlier\par
ODBC versions use SQLError, which is similar. ODBC example programs often use\par
the names "SqlState", "Msg" and "rc" where we have tended to use "SQLSTATE",\par
"sqlmessage" and "sqlreturn".\par
\par
SQLError\par
\par
Function Prototype:\par
  SQLRETURN  SQLError(\par
    SQLHENV henv,                   /* 32-bit input */\par
    SQLHDBC hdbc,                   /* 32-bit input */\par
    SQLHSTMT hstmt,                 /* 32-bit input */\par
    SQLCHAR *Sqlstate,              /* pointer to char* output -- char[5+1] */\par
    SQLINTEGER *NativeError,        /* pointer to 32-bit output */\par
    SQLCHAR *MessageText,           /* pointer to char* output */\par
    SQLSMALLINT BufferLength,       /* 16-bit input */\par
    SQLSMALLINT *TextLength         /* pointer to 16-bit output */\par
    );\par
\par
Job:\par
Return "diagnostics" -- that is, the completion conditions (warnings) and\par
exception conditions (errors) that are associated with the env or dbc or stmt.\par
\par
Although all standard DBMSs will support it, and although it is an official\par
SQL3 function, SQLError is obsolete. The modern way to get diagnostics is with\par
SQLGetDiagRec or SQLGetDiagField.\par
\par
Algorithm:\par
      /* The diagnostics come from a stmt or (if hstmt\par
      is 0) from a dbc or (if hdbc is also 0) from an env.\par
      SQLError does not get diagnostics from\par
      all three resources at once, or from a desc. */\par
      If (hstmt <> 0)\par
        Set Handle = hstmt\par
      Else\par
        /* hstmt == 0 */\par
        If (hdbc <> 0)\par
          Set Handle = hdbc\par
        Else\par
          /* hstmt == 0 and hdbc == 0 */\par
          If (henv <> 0)\par
            Set Handle = henv\par
          Else\par
            /* hstmt == 0 and hdbc == 0 and == 0 */\par
            return error: CLI-specific condition-invalid handle\par
      /* Now Handle == handle of stmt or dbc or env */ \par
      /* The diagnostics, if any, were created by the last CLI function\par
         that was called using Handle. */\par
      For (each status record generated by the last CLI function)\par
        If (we have already called SQLError and gotten this status record)\par
          continue\par
        If (there are no more status records)\par
          return SQL_NO_DATA (+100)\par
          /* ... a DBMS that follows the ODBC requirements would set\par
          sqlstate = '00000', NativeError = +100, before returning\par
          SQL_NO_DATA. This is a signal to the application program that it\par
          should break out of a loop. */\par
        Else\par
          break\par
      /* We are now looking at a status record which was generated by a\par
         previous function call using the (passed) Handle. The following\par
         is the same as if we called:\par
           SQLGetDiagRec (<handle type>, <Handle>, <# of status record>,\par
           Sqlstate,NativeError, MessageText, BufferLength, TextLength) */\par
      Return status record's SQL_DIAG_SQLSTATE value to Sqlstate.\par
      Return status record's SQL_DIAG_MESSAGE_TEXT value to MessageText\par
      (the return happens in the usual way for Character String Retrieval).\par
      Return status record's SQL_DIAG_NATIVE value, presumably SQLCODE, to\par
      NativeError.\par
\par
Notes:\par
      ## The last five parameters of SQLError are the same as the last five\par
parameters of SQLGetDiagRec. The effective difference is that, with\par
SQLGetDiagRec, you pass a "RecordNumber" parameter, while with SQLError you\par
depend on the DBMS to keep an internal counter -- SQLError will always\par
retrieve the next status record.\par
\par
Example:\par
    #include "sqlcli.h"\par
    ...\par
    SQLCHAR sqlstate[6];            /* not 5: 6!! Allow for \\0 at the end! */\par
    SQLINTEGER sqlnative;           /* this is a "long int" */\par
    SQLHSTMT hstmt;\par
    ...\par
    sqlreturn=SQLExecDirect(hstmt,"INSERT VALUES;",SQL_NTS);\par
    /* The above is illegal SQL so the return code will be negative */\par
    if (sqlreturn==SQL_ERROR) goto error_handler_for_stmt;\par
    ...\par
error_handler_for_stmt:\par
    /* **TRAP: sometimes errors happen for dbc or env functions too, each\par
       type of handle needs a separate error-handling procedure. */\par
    SQLError(0,0,hstmt,sqlstate,&sqlnative,NULL,NULL,NULL);\par
    /* sqlstate is probably '42000' */\par
    /* sqlnative is probably less than zero */\par
    ...\par
\par
ODBC: The SQLError function has been around since ODBC 1.0. In ODBC 3.0, it is\par
labelled "deprecated" and ODBC's driver manager will map it to SQLGetDiagRec.\par
\par
SQLRowCount\par
\par
Function Prototype:\par
  SQLRETURN SQLRowCount(\par
    SQLHSTMT hstmt,           /* 32-bit input -- statement handle */\par
    SQLINTEGER *RowCount      /* 32-bit output */\par
    );\par
\par
Job:\par
Find out how many rows were inserted or updated or deleted during the\par
execution of the last SQLExecute or SQLExecDirect call.\par
\par
Algorithm:\par
If (hstmt does not refer to an executed statement)\par
  return error: HY010 CLI-specific condition-function sequence error\par
Set *RowCount = stmt's diagnostics area's SQL_DIAG_ROW_COUNT value.\par
\par
Notes:\par
      ## The row count is the number of rows affected when you call SQLExecute\par
or SQLExecDirect, and the SQL statement you're executing begins with INSERT or\par
UPDATE or DELETE (the SQL-data change statements).\par
      ## Only directly affected rows matter. If you delete one primary key\par
row, and there are 10 foreign key rows that are also deleted because the\par
FOREIGN KEY Constraint definition includes ON DELETE CASCADE, then a total of\par
11 rows are deleted: 1 directly, 10 indirectly -- so the SQLRowCount function\par
returns 1.\par
      ## Only "searched UPDATE" and "searched DELETE" statements matter. The\par
UPDATE ... WHERE CURRENT OF <Cursor> and DELETE ... WHERE CURRENT OF <Cursor>\par
statements have no effect on row count.\par
      ## With some DBMSs, SQLRowCount will contain the number of rows returned\par
by the last SELECT statement. That's very useful if you want to display the\par
results on the screen along with a Windows scrollbar. If your DBMS won't give\par
you that, there are other options: (a) use a "SELECT COUNT(*)" statement (may\par
be unreliable in a multi-user environment, may fail if selection is of a\par
grouped View), (b) call SQLGetDiagField with the SQL_DIAG_CURSOR_ROW_COUNT\par
option (non-standard, works only with ODBC) or (c) call SQLFetchScroll until\par
the return is SQL_NO_DATA.\par
      ## You can get the same result by calling:\par
  \par
SQLGetDiagField(SQL_HANDLE_STMT,hstmt,SQL_DIAG_ROW_COUNT,&RowCount,NULL,NULL);\par
\par
but SQLGetDiagField only returns results for "the last function", which means\par
(for instance) that if you've fetched since you executed the UPDATE statement,\par
SQLGetDiagField can't tell you anything. SQLRowCount, which returns results\par
for "the last SQLExecute or SQLExecDirect function", is better.\par
      ## If the number of changed rows is zero, then SQLExecute and\par
SQLExecDirect both return SQL_NO_DATA (not SQL_SUCCESS or\par
SQL_SUCCESS_WITH_INFO).\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLINTEGER row_count;\par
      ...\par
      if (SQLExecDirect(hstmt,"INSERT INTO Table_1 VALUES (1);",SQL_NTS)>=0) \{\par
        if (SQLRowCount(hstmt,&row_count)>=0) \{\par
          /* The value of row_count is 1. */ \} \}\par
\par
ODBC: The SQLRowCount function has been around since ODBC 1.0.\par
\par
And that's it for the diagnostic functions. Now let's take a look at the\par
Standard's SQLSTATE codes.\par
\par
SQLSTATE Codes\par
\par
The SQL status parameter SQLSTATE is a 5-character string value, with 2 parts:\par
the first 2 characters represent a class value, the following 3 characters\par
represent a subclass value. SQLSTATE codes are limited to digits and simple\par
Latin upper-case letters.\par
\par
Class values that begin with 0, 1, 2, 3, 4, A, B, C, D, E, F, G or H are\par
called "standard-defined classes" and identify status conditions defined in\par
either the SQL Standard or some other international standard. Subclass values\par
associated with standard-defined classes that also begin with one of those 13\par
characters are called "standard-defined subclasses" and also identify status\par
conditions defined in either the SQL Standard or some other international\par
standard, while subclass values associated with standard-defined classes that\par
begin with 5, 6, 7, 8, 9, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y or\par
Z are called "implementation-defined subclasses" and identify status\par
conditions defined by DBMS vendors.\par
\par
Class values that begin with 5, 6, 7, 8, 9, I, J, K, L, M, N, O, P, Q, R, S,\par
T, U, V, W, X, Y or Z are called "implementation-defined classes" and identify\par
exception conditions defined by DBMS vendors. All subclass values except '000'\par
(no subclass) associated with implementation-defined classes are\par
implementation-defined subclasses. An implementation-defined completion\par
condition is identified by returning an implementation-defined subclass\par
together with one of the SUCCESSFUL COMPLETION, WARNING or NO DATA classes.\par
\par
If a subclass value is not specified for a condition, then either subclass\par
'000' or an implementation-defined subclass is returned.\par
\par
If multiple conditions are returned, then your DBMS decides which condition is\par
the one that will be returned in the SQLSTATE parameter. (Any number of\par
condition values, in addition to SQLSTATE, may be returned in the diagnostics\par
area.)\par
\par
Using the CLI, you can retrieve SQLSTATE with one of the diagnostics functions\par
(SQLGetDiagField, SQLGetDiagRec or SQLError). Using embedded SQL, you can\par
retrieve SQLSTATE with GET DIAGNOSTICS, or you can let the DBMS fill it in\par
automatically. Since the status codes are reasonably standard, application\par
programmers can anticipate what SQLSTATE values may crop up, and they can\par
write appropriate error-testing or descriptive routines. The rest of this\par
chapter contains detailed descriptions for all SQLSTATEs which are defined in\par
the SQL Standard, as well as summary information about some SQLSTATEs which\par
are used in common application environments, such as ODBC.\par
\par
We suggest you examine the list of SQLSTATE codes and decide which warnings\par
and errors you must take specific action for. Make a case statement which will\par
be executed after each SQL operation. If you are programming for ODBC 3.x,\par
don't worry about the obsolete ODBC 2.0 entries in the list -- Microsoft's\par
driver manager  will translate them to the current standardized value. If you\par
use the list in conjunction with some vendor manual, you will probably notice\par
that our descriptions are more specific and detailed; however, you should\par
prefer the vendor's description in case of outright contradiction. For casual\par
users, the DBMS's in-context error-message displays, accompanied by a pointer\par
to the offending SQL statement, will suffice. But that is an "after-the-fact"\par
proposition. If your job is to program for errors that haven't happened yet,\par
you need a complete list with some examples and explanations for every entry.\par
\par
Here is an example of a tiny C program (runnable in a DOS box) with one\par
embedded SQL statement, followed by a case statement that checks for an error:\par
\par
EXEC SQL INCLUDE SQLCA; /* so error message defined here? */\par
EXEC SQL BEGIN DECLARE SECTION;\par
char sqlcode[6];        /* Notice we allow 6 characters, there's a \\0 too */\par
EXEC SQL END DECLARE SECTION;\par
void main ()\par
\{\par
  EXEC SQL DROP TABLE x RESTRICT;\par
  portability(sqlstate);            /* Perhaps change the class */\par
  switch (sqlstate) \{\par
    case '.....':                   /* Okay */\par
    case '.....':                   /* Table not found */\par
    case '.....':                   /* Another table depends */\par
    default:                        /* All other errors */\par
    \} \}\par
/* In a portable program you won't know what subclasses were added by each\par
   vendor, so change all implementation-defined subclasses to '000'. NIST uses\par
   a similar technique for its compliance-test programs. */\par
void portability (char sqlstate[])\par
\{\par
  if (sqlstate[2]>='I' || (sqlstate[2]>='4' && sqlstate[0]<='9') \{\par
    /* The third character of sqlstate, which is the first byte of subclass,\par
       is a letter >= 'I' or is a digit >= '4' -- implementation-defined. */\par
    sqlstate[2]=sqlstate[3]=sqlstate[4]='0'; \} \}/* subclass = '000' */\par
\par
SUCCESSFUL COMPLETION SQLSTATEs:\par
The following SQLSTATE codes identify a successful completion condition.\par
\par
00000  successful completion\par
The "successful completion" class identifies "completion conditions" (as\par
opposed to "exception conditions", which are errors). In the case of SQLSTATE\par
00000, the last SQL operation sailed through without a problem. The 00000\par
status code is invisible to CLI programs because the Standard says: if the\par
return code = SQL_SUCCESS, then no status records are generated.\par
\par
WARNING SQLSTATEs:\par
The following SQLSTATE codes identify a successful completion condition with a\par
warning.\par
\par
01000  warning\par
The "warning" class identifies completion conditions that were processed with\par
some type of warning. They are usually associated with some DBMS-specific\par
informational message, which you can retrieve with SQLGetDiagRec or GET\par
DIAGNOSTICS. In the CLI, the existence of a warning diagnostic is signalled by\par
the SQLRETURN value SQL_SUCCESS_WITH_INFO (1). SQLSTATE 01000 is the\par
miscellaneous-warning category. For completion conditions that fit in the\par
warning class, but don't fit in one of the subclasses listed below (such as\par
01001), this is what you'll get. Suggestion for this SQLSTATE: get the message\par
with SQLGetDiagRec, display the message and continue.\par
\par
01001  warning-cursor operation conflict\par
This SQLSTATE was included in the SQL-92 Standard by mistake; the corrigendum\par
bulletin #3 says it should only be an SQL3 SQLSTATE. The NIST tests expect\par
DBMSs to return SQLSTATE=01001 if you DELETE with and without a Cursor in the\par
same transaction.\par
\par
01002  warning-disconnect error\par
There was an error during execution of the CLI function SQLDisconnect, but you\par
won't be able to see the details because the SQLDisconnect succeeded.\par
\par
01003 warning-null value eliminated in set function\par
The set function had to ignore a NULL when working on its argument. For\par
example, the SUM of 5 and NULL is 5 (not NULL), but 01003 warns you that the\par
result may be inaccurate because NULL usually means "unknown".\par
\par
01004  warning-string data, right truncation\par
Happens when you try to squeeze a 5-character (or bit) value into a\par
4-character (or bit) space (remember that "string" can be either character or\par
bit string). The truncation should happen for data outbound from the database\par
to a host variable, for example in the statement "SELECT ... INTO :x". It\par
should not happen for data inbound to the database -- that would be not a\par
warning but an error (22001).\par
\par
01005  warning-insufficient data item descriptor areas\par
Every descriptor area has multiple IDAs. You need one IDA per Column of a\par
result set, or one per parameter. Either reduce the number of Columns in the\par
select list or reduce the number of ?s in the SQL statement as a whole.\par
\par
01006  warning-privilege not revoked\par
There is no Privilege descriptor for a combination of: this grantor, this\par
grantee, this action. The DBMS does not return an error if a Privilege\par
revocation fails -- instead, it revokes whatever Privileges it can and returns\par
this warning. If an equivalent Privilege was granted by a different grantor,\par
it continues to exist, but warning 01006 does not appear.\par
\par
01007  warning-privilege not granted\par
Probably the grantor doesn't hold a Privilege WITH GRANT OPTION. For example:\par
Susan has the UPDATE Privilege on TABLE_1 (without grant option) and the\par
INSERT Privilege on TABLE_1 (WITH GRANT OPTION). She says: "GRANT SELECT,\par
INSERT, UPDATE ON Table_1 TO Joe;". Result: Joe gets the INSERT Privilege, but\par
not the SELECT or UPDATE Privileges, hence this warning (some DBMSs will\par
generate the warning twice because two Privileges are ungranted). Warning\par
01007 also appears if the grantor has zero Privileges WITH GRANT OPTION, and\par
says "GRANT ALL PRIVILEGES ...". On the other hand, if the grantor holds zero\par
Privileges period, the result is error 42000 instead of warning 01007.\par
\par
01008  warning-implicit zero-bit padding\par
Suppose you insert B'1' -- a one-bit binary <literal> -- into a two-bit\par
Column. The second bit will be a 0, and the DBMS will return this warning.\par
\par
01009  warning-search condition too long for information schema\par
Suppose you say "CREATE TABLE ... CHECK (<condition>)", and the length of\par
<condition> is larger than what can be stored in the INFORMATION_SCHEMA View,\par
CHECK_CONSTRAINTS, in its CHECK_CLAUSE Column. The Table will still be created\par
-- this warning only means you won't be able to see the entire information\par
about the Table when you look at INFORMATION_SCHEMA. See also: 0100A and\par
0100B.\par
\par
0100A  warning-query expression too long for information schema\par
This is the same as warning 01009 except that instead of a search condition\par
(as in a CHECK clause), you're using a query condition (usually SELECT). Thus,\par
if you say "CREATE VIEW ..." with a very long query, the size of Column\par
VIEW_DEFINITION in View VIEWS in INFORMATION_SCHEMA is a limiting factor.\par
\par
0100B  warning-default value too long for information schema\par
This is the same as warning 01009 except that instead of a search condition\par
(as in a CHECK clause), you're using a default value.\par
\par
0100C  warning-dynamic result sets returned\par
\par
0100D  warning-additional result sets returned\par
\par
0100E  warning-attempt to return too many result sets\par
\par
0100F  warning-fewer locators than dynamic result sets\par
\par
0102F  warning-array data, right truncation\par
\par
01Hxx  warning-external routine warning\par
The author of the external routine chooses the subclass value of xx.\par
\par
01S00  warning-invalid connection string attribute (ODBC 2+3)\par
The ODBC function SQLBrowseConnect or SQLDriverConnect requires a parameter\par
string with a certain format. Connection happens anyway.\par
\par
01S01  warning-error in row (ODBC 3)\par
With ODBC 3.x, this warning happens only for SQLExtendedFetch or for\par
SQLFetchScroll. Although an "error" has happened, this is only a warning\par
because other rows might have been returned without error.\par
\par
01S02  warning-option value changed (ODBC 3)\par
You used an ODBC function to change an option (e.g.: SQLSetEnvAttr). This\par
warns you that the change occurred.\par
\par
01S06  warning-attempt to fetch before the result set returned the first\par
rowset (ODBC 3)\par
It would be clearer to use this wording: "attempt to fetch before the first\par
row in the result set". This error would be returned if your last fetch was of\par
the first row in the result set and now you attempt to fetch PRIOR.\par
\par
01S07  warning-fractional truncation (ODBC 3)\par
You'll get this error if, for example, you assigned the value 5.432 to a\par
Column whose definition is DECIMAL(3,2) -- that is, the scale of the target is\par
2 and the scale of the source is 3, so only 5.4 is stored. A problem with the\par
non-fractional part would result in another SQLSTATE: 22003.\par
\par
01S08  warning-error saving file DSN (ODBC 3)\par
A warning from SQLDriverConnect. The Connection succeeds, but the file\par
indicated by the FILEDSN keyword was not saved.\par
\par
01S09  warning-invalid keyword (ODBC 3)\par
A warning from SQLDriverConnect. The Connection succeeds, but the SAVEFILE\par
keyword was ignored.\par
\par
NO DATA SQLSTATEs:\par
The following SQLSTATE codes identify a successful completion condition where\par
no data has been found that matches the given criteria.\par
\par
02000 no data\par
The "data not found" class identifies completion conditions that were\par
processed without any data that matched the given criteria being found. If the\par
status code is class 02, then the return code will be SQL_NO_DATA. Most\par
programs do not look for status records if the return code is SQL_NO_DATA, but\par
there is a slight chance that a warning exists. The DBMS does not make a\par
status record for SQLSTATE 02000, but it might make status records for\par
implementation-defined subclasses within class 02. SQLSTATE 02000 goes\par
together with sqlcode = +100 and return code = SQL_NO_DATA. There are several\par
scenarios which lead to SQLSTATE 02000:\par
      ## fetches -- If the Cursor position is now past the last row, or before\par
the first row in the result set -- e.g.: due to a\par
SQLFetchScroll(...,SQL_PRIOR,...) call when Cursor was on first row of the\par
result set.\par
      ## updates -- Zero rows were affected by an INSERT, UPDATE or DELETE\par
statement.\par
      ## diagnostics -- No status record corresponds to the RecordNumber\par
parameter.\par
      ## desc functions -- No item descriptor area corresponds to the\par
RecordNumber parameter\par
      ## in general -- Whenever you ask for data, and there is no data.\par
In the CLI, the DBMS does not generate status records for SQLSTATE=02000. The\par
only way to check for "no data" is to look at the return code.\par
\par
02001  no data-no additional result sets returned\par
It is possible for a CALL statement to produce multiple result sets, but in\par
this case there are no more. 02001 is possible if the function is\par
SQLMoreResults.\par
\par
ERROR SQLSTATEs:\par
The following SQLSTATE codes identify an exception condition: something is\par
preventing an SQL statement from being successfully completed.\par
\par
03000  SQL statement not yet complete\par
The "SQL statement not yet complete" class identifies exception conditions\par
that relate to incomplete processing of SQL statements.\par
\par
07000  dynamic SQL error\par
The "dynamic SQL error" class identifies exception conditions that relate to\par
dynamic SQL processing errors.\par
\par
07001  dynamic SQL error-using clause does not match dynamic parameters\par
You might encounter this error if you set the length of a descriptor, then\par
EXECUTE ... USING <descriptor>. Often this exception results from\par
consistency-check failure during SQLExecute: see SQLSTATE HY021. In ODBC, the\par
name for this subclass is "wrong number of parameters".\par
\par
07002  dynamic SQL error-using clause does not match target specifications\par
Often this exception results from consistency-check failure during SQLExecute:\par
see SQLSTATE HY021. Sometimes this exception results from an incorrect number\par
of parameters -- but see also: SQLSTATE 07008. In ODBC, the name for this\par
subclass is "COUNT field incorrect".\par
\par
07003  dynamic SQL error-cursor specification cannot be executed\par
\par
07004  dynamic SQL error-using clause required for dynamic parameters\par
You cannot simply EXECUTE an SQL statement which has dynamic parameters -- you\par
also need to use a USING clause. See also: SQLSTATE 07007.\par
\par
07005  dynamic SQL error-prepared statement not a cursor-specification\par
This results from an attempt to use ODBC function SQLColAttribute or\par
SQLDescribeCol for an SQL statement that returned no result set, or from using\par
"DECLARE CURSOR" followed by a prepare or execute of an SQL statement that\par
does not return a result set.\par
\par
07006  dynamic SQL error-restricted data type attribute violation\par
You are using a parameter whose value does not match the <data type>; the DBMS\par
cannot even try to CAST to the correct <data type> because the source and\par
target are too different. For example, you have a host variable defined as\par
SQLINTEGER, you have a Column containing a TIMESTAMP and you try to fetch that\par
Column  into the host variable. With CLI, this might mean that you forgot to\par
re-bind the parameters when you prepared a new SQL statement.\par
\par
07007  dynamic SQL error-using clause required for result fields\par
You cannot simply EXECUTE an SQL statement which has result fields -- you also\par
need to use a USING clause. See also: SQLSTATE 07004.\par
\par
07008  dynamic SQL error-invalid descriptor count\par
Using the embedded SQL ALLOCATE DESCRIPTOR statement, you allocated a 5-item\par
descriptor. Now you are trying to use the sixth item in that descriptor. See\par
also: SQLSTATE 07009.\par
\par
07009  dynamic SQL error-invalid descriptor index\par
You are using a CLI descriptor function (such as SQLBindCol or\par
SQLBindParameter) and the Column number is less than 1 or greater than the\par
maximum number of Columns. Or, you are using the embedded SQL ALLOCATE\par
DESCRIPTOR statement with a size which is less than 1 or greater than an\par
implementation-defined maximum. See also: SQLSTATE 07008.\par
\par
07S01  dynamic SQL error-invalid use of default parameter\par
You used SQLBindParameter with SQL_DEFAULT_PARAMETER, but now it turns out\par
that the parameter does not have a default value.\par
\par
08000  connection exception\par
The "connection exception" class identifies exception conditions that relate\par
to SQL-Connections.\par
\par
08001  connection exception-SQL-client unable to establish SQL-connection\par
The client could not get in touch with the server -- perhaps there is no such\par
server or perhaps the network is busy.\par
\par
08002  connection exception-connection name in use\par
The name of an SQL-Connection must be unique. With standard SQL, this would\par
happen if you said "CONNECT ... AS 'X' ..." twice (only one X at a time,\par
please).\par
\par
08003  connection exception-connection does not exist\par
You are trying to use a connection-related function (such as\par
SQLGetConnectAttr) but the SQL-Connection is not open. Or, you said\par
"DISCONNECT 'X'" and either X was never connected, or has already been\par
disconnected. If the call is SQLAllocHandle(SQL_HANDLE_STMT,...), &hstmt is\par
set to zero. You can get diagnostics from the hdbc.\par
\par
08004  connection exception-SQL-server rejected establishment of\par
SQL-connection\par
You'll get this error if, for example, the SQLConnect function was\par
unsuccessful. The server might not like the password, or it might already be\par
handling the maximum number of clients.\par
\par
08006  connection exception-connection failure\par
This occurs for a SET CONNECTION statement, where the argument is presumably a\par
dormant Connection. The failure might be due to a server failure that occurred\par
while the Connection was dormant. The SET CONNECTION might be implicit -- for\par
example, a DISCONNECT statement might result in an attempt to re-establish the\par
last dormant Connection.\par
\par
08007  connection exception-transaction resolution unknown\par
While you were trying to COMMIT, you were cut off. This is a bad one, because\par
you are not told whether the transaction finished successfully or not. The\par
ODBC manual calls this error "Connection failure during transaction" and\par
implies that it can happen for ROLLBACK too.\par
\par
08S01  connection exception-communication link failure (ODBC 2+3)\par
This can happen during execution of pretty well any ODBC function. Perhaps\par
there was a hiccup on a phone line.\par
\par
09000   triggered action exception\par
The "triggered action exception" class identifies exception conditions that\par
relate to Triggers.\par
\par
0A000  feature not supported\par
The "feature not supported" class identifies exception conditions that relate\par
to features you're trying to use, but that your DBMS hasn't implemented. The\par
Standard does not specify what will cause this SQLSTATE, possibly because the\par
expectation is that all features will be supported. If the feature is\par
ODBC-related, see also: SQLSTATE IM001, HYC00.\par
\par
0A001  feature not supported-multiple server transactions\par
The meaning is "a single transaction cannot be performed on multiple servers".\par
Such a feature is sophisticated and rare.\par
\par
0B000  invalid transaction initiation\par
The "invalid transaction initiation" class identifies exception conditions\par
that relate to beginning a transaction. \par
\par
0D000  invalid target type specification\par
The "invalid target type specification" class identifies exception conditions\par
that relate to specifying a target for data.\par
\par
0E000  invalid schema name list specification\par
The "invalid schema name list specification" class identifies exception\par
conditions that relate to specifying Schema paths.\par
\par
0F000  locator exception\par
The "locator exception" class identifies exception conditions that relate to\par
locators: BLOB and CLOB <data type>s, and their values.\par
\par
0F001  locator exception-invalid specification\par
This will be returned if a value passed for a BLOB or CLOB is invalid.\par
\par
0F002  locator exception-update attempted with non-updatable locator\par
\par
0F003  locator exception-location does not represent specified object\par
\par
0F004  locator exception-unknown native value\par
\par
0G000  reference to null table value\par
\par
0H000  invalid SQLSTATE value\par
\par
0K000  resignal when handler not active\par
\par
0K002  resignal when handler not active-modifying SQL-data not permitted\par
\par
0K003  resignal when handler not active-prohibited SQL-statement attempted\par
\par
0K005  resignal when handler not active-function executed no return statement\par
\par
0L000  invalid grantor\par
\par
0N000  most specific type mismatch in invocation of type-preserving function\par
\par
0P000  invalid role specification\par
\par
0Q000  source result set not created by current SQL-server\par
\par
0R000  cursor already allocated to result set or procedure\par
\par
20000  case not found for case statement\par
\par
21000  cardinality violation\par
Suggested error message: "subquery contained more than one row". For example,\par
suppose you have a Table T, with a Column S1 and two rows. In both rows,\par
Column S1 has the value 5. Then either "SELECT (SELECT s1 FROM T) FROM ..."\par
(scalar subquery) or "... WHERE 5 = (SELECT s1 FROM T)" (row subquery) violate\par
cardinality. Another possibility, applicable to embedded SQL only, is that you\par
are using a singleton-SELECT statement format but there are two rows returned.\par
Some cardinality violations, e.g.: OVERLAPS operand with degree greater than\par
2, cause SQLSTATE=42000 instead of SQLSTATE=21000.\par
\par
21S01  cardinality violation-insert value list does not match column list\par
(ODBC 2+3)\par
For example: the statement "INSERT INTO T (a,b) VALUES (1,2,3)" is trying to\par
insert three values into two Columns.\par
\par
21S02  cardinality violation-degree of derived table does not match column\par
list (ODBC 2+3)\par
For example: the SQL statement "CREATE VIEW (a,b) AS SELECT a,b,c FROM T;" is\par
creating a 2-Column View for a 3-Column select.\par
\par
22000  data exception\par
The "data exception" class identifies exception conditions that relate to data\par
errors.\par
\par
22001  data exception-string data, right truncation\par
Suppose you try to insert a 5-character string into a Column defined as\par
CHAR(4), or suppose you use the expression "CAST (12345 AS CHAR(4))". No\par
truncation actually occurs since the SQL statement fails. See also: SQLSTATE\par
01004.\par
\par
22002  data exception-null value, no indicator parameter\par
Suggested error message: "NULL seen, host program passed no indicator". For\par
example, you used SQLBindCol, but passed no parameter for an indicator value\par
to be returned to. This is not an error unless you fetch a NULL.\par
\par
22003  data exception-numeric value out of range\par
Suggested error message: "the numeric value <> is too big to fit in the target\par
<>". Often this is the result of an arithmetic overflow -- for example,\par
"UPDATE ... SET SMALLINT_COLUMN = 9999999999", or you're trying to retrieve a\par
value of 5 billion into a host variable defined in Pascal as "Word".\par
Fractional truncation won't cause this error, see SQLSTATE 01S07.\par
\par
22004  data exception-null value not allowed\par
\par
22005  data exception-error in assignment\par
For GET DESCRIPTOR and SET DESCRIPTOR statements, where the <data type> and\par
size indicated in the descriptor does not match the value, this error appears.\par
\par
22006  data exception-invalid interval format\par
For example, a year-month interval should contain only a year integer, a '-'\par
separator, and a month integer. See also: SQLSTATE 22015.\par
\par
22007  data exception-invalid datetime format\par
Suggested message: "For the <data type> <>, <> is not a valid value". This\par
error only occurs if there is an explicit or implicit CAST to a datetime (date\par
or time or timestamp). See also: SQLSTATE 22008, 22018.\par
\par
22008  data exception-datetime field overflow\par
Suggested message: "For the data type <>, <> is not a valid value". One thing\par
to look for: arithmetic which causes the DAY field of a date to be greater\par
than the last day of the month -- for example DATE '1994-03-31' + INTERVAL\par
'01' MONTH. See also: SQLSTATE 22007.\par
\par
22009  data exception-invalid time zone displacement value\par
Suggested message: "The time zone displacement value <> is outside the range\par
-12:59 to 13:00". This could happen for SET LOCAL TIME ZONE INTERVAL '22:00'\par
HOUR TO MINUTE;", or for TIMESTAMP '1994-01-01 02:00:00+10:00'. (In the latter\par
case, it is the result of the calculation that is a problem.)\par
\par
2200A  data exception-null value in reference target\par
\par
2200B  data exception-escape character conflict\par
\par
2200C  data exception-invalid use of escape character\par
\par
2200D  data exception-invalid escape octet\par
\par
22010  data exception-invalid indicator parameter value\par
The value of the indicator variable is less than zero but is not equal to -1\par
(SQL_NULL_DATA).\par
\par
22011  data exception-substring error\par
Suggested message: "The maximum length of SUBSTRING parameter is <>". For\par
example, "... SUBSTRING (string_column FROM 5 FOR 100) ..." when the length of\par
STRING_COLUMN is only 1.\par
\par
22012  data exception-division by zero\par
For example: "... column_name / ? ...", where ? is a parameter marker, and the\par
value of the parameter at run time is 0. If the Column contains NULL, then the\par
result is NULL -- the Standard makes it clear that dividing NULL by zero is\par
not an error.\par
\par
22014  data exception-invalid update value\par
\par
22015  data exception-interval field overflow\par
Suggested message: "The <> field contains <>, the maximum is <>". For example,\par
"... DATE '1993-01-01' + INTERVAL '1000' YEAR ..." (this is a tricky one --\par
the default size of all interval fields including year fields is only 2\par
digits). See also: SQLSTATE 22006.\par
\par
22018  data exception-invalid character value for cast\par
Suggested message: "The character <> cannot be used when CASTing to data type\par
<>". For example, if you try to cast '1994/10/10' to a date, it won't work\par
because the separator is '/' (the correct separator is '-').\par
\par
22019  data exception-invalid escape character\par
Suggested message: "The LIKE escape value <> is longer than 1 character". The\par
expression "... LIKE '...' ESCAPE 'AB' ..." would return this error.\par
\par
2201B  data exception-invalid regular expression\par
\par
2201C  data exception-null row not permitted in table\par
\par
22020  data exception-invalid limit value\par
\par
22021  data exception-character not in repertoire\par
Suggested message: "The character <> is not in the repertoire of Character set\par
<>". For example, the Character set SQL_CHARACTER does not contain the tilde\par
(~), so this <literal> is not allowed: "... _SQL_CHARACTER '~' ...".\par
\par
22022  data exception-indicator overflow\par
Suggested message: "indicator is too small for size value <>".\par
This could happen if you use embedded SQL and you define the indicator as a C\par
"short int" or Pascal "Word". If you use ODBC, then the message won't happen\par
because all indicators must be 32-bit.\par
\par
22023  data exception-invalid parameter value\par
\par
22024  data exception-unterminated C string\par
Suggested message: "the C parameter string starting with <> is too long". For\par
example, an SQL statement uses a ? parameter, for a string, but at runtime it\par
is seen that the C char-string does not have a terminating '\\0'. The DBMS can\par
only detect this error if it knows what the maximum string size is, i.e.: only\par
in embedded SQL. Usually this problem will appear as a too-long or\par
improperly-formatted string, so several other SQLSTATE error returns are\par
possible -- for example. SQLSTATE 22019.\par
\par
22025  data exception-invalid escape sequence\par
Suggested message: "LIKE pattern <> has invalid escape sequence <>". If you\par
use an escape character, it must be followed in the pattern by _ or % or\par
another escape character. If you use "... LIKE 'X%@' ESCAPE '@' ...", you'll\par
get this error.\par
\par
22026  data exception-string data, length mismatch\par
With ODBC this error should only occur for SQL_LONGVARCHAR or\par
SQL_LONGVARBINARY strings. For standard SQL, this error should only occur for\par
bit strings.\par
\par
22027  data exception-trim error\par
Suggested message: "the TRIM string <> is longer than 1 character". For\par
example, "... TRIM('AB' FROM '...') ..." results in this error.\par
\par
22028  data exception-row already exists\par
\par
2202C  data exception-sublist error\par
\par
2202D  data exception-null instance used in mutator function\par
\par
2202E  data exception-array element error\par
\par
2202F  data exception-array data, right truncation\par
\par
23000  integrity constraint violation\par
The "integrity constraint violation" class identifies exception conditions\par
that relate to Constraint violations. Suggested message for SQLSTATE 23000:\par
"Attempted violation of constraint <>". For example, Table T has a PRIMARY KEY\par
Constraint and you attempt to insert two rows into T, both with precisely the\par
same values in all Columns. For SQL-92, this SQLSTATE applies to attempted\par
violations of any kind of Constraint, including NOT NULLs and FOREIGN KEY\par
Constraints. The message can also occur if the total length of a foreign key\par
Column list is exceeded. See also: SQLSTATE 40002.\par
\par
23001  integrity constraint violation-restrict violation\par
\par
24000  invalid cursor state\par
The "invalid cursor state" class identifies exception conditions that relate\par
to Cursors. For SQLSTATE 24000, the Cursor-related operation can't happen\par
because some preliminary function hasn't been called or hasn't been completed\par
-- for example:\par
      ## OPEN <Cursor>, then immediately try to OPEN <Cursor> again.\par
      ## FETCH without opening the Cursor.\par
      ## OPEN <Cursor>, forget to FETCH, then DELETE ... WHERE CURRENT OF\par
<Cursor>.\par
For CLI programs, the DBMS returns SQLSTATE=24000 if you try to FETCH and\par
there is no result set (for example, because the previous SQL statement was\par
INSERT). However, if there was no previous SQL statement at all, then the\par
return is not 24000 but HY010 (CLI-specific error-function sequence error).\par
\par
25000  invalid transaction state\par
The "invalid transaction state" class identifies exception conditions that\par
relate to transactions. For SQLSTATE 25000, you are most likely trying to\par
execute an SQL statement that can only be executed at transaction start -- for\par
example you are issuing a SET SESSION AUTHORIZATION statement after selecting\par
something. Alternatively, you specified SET TRANSACTION READ ONLY and now you\par
are saying UPDATE, DROP, etc. Finally, it is possible you are saying INSERT\par
after a FETCH.\par
\par
25001  invalid transaction state-active SQL-transaction\par
START TRANSACTION or DISCONNECT or SET SESSION AUTHORIZATION or SET ROLE\par
statements cannot be issued if a transaction has already been started.\par
\par
25002  invalid transaction state-branch transaction already active\par
SET TRANSACTION LOCAL ..., which applies only in multiple-server contexts, is\par
illegal if a local transaction is already happening.\par
\par
25003  invalid transaction state-inappropriate access mode for branch\par
transaction\par
\par
25004  invalid transaction state-inappropriate isolation level for branch\par
transaction\par
\par
25005  invalid transaction state-no active SQL-transaction for branch\par
transaction\par
\par
25006  invalid transaction state-read-only SQL-transaction\par
\par
25007  invalid transaction state-schema and data statement mixing not\par
supported\par
Some DBMSs do not allow SQL-Schema statements (such as CREATE) to be mixed\par
with SQL-data statements (such as INSERT) in the same transaction.\par
\par
25008  invalid transaction state-held cursor requires same isolation level\par
The SET TRANSACTION statement cannot be used to change isolation level if\par
there is a held Cursor made with a different isolation level left over from\par
the last transaction.\par
\par
25S01  invalid transaction state-transaction state unknown (ODBC 3)\par
The attempt to end the transaction (with SQLEndTran) failed for at least one\par
of the environment's Connections.\par
\par
25S02  invalid transaction state-transaction is still active (ODBC 3)\par
The attempt to end the transaction (with SQLEndTran) failed; the transaction\par
did not end (that is, the transaction is not rolled back).\par
\par
25S03  invalid transaction state-transaction is rolled back (ODBC 3)\par
The attempt to end the transaction (with SQLEndTran) failed; the transaction\par
is rolled back (that is, the transaction ended).\par
\par
26000  invalid SQL statement name\par
Probable cause: you failed to PREPARE an SQL statement and now you are trying\par
to EXECUTE it.\par
\par
27000   triggered data change violation\par
With SQL-92, you can cause this error with interlocked FOREIGN KEY Constraints\par
that CASCADE ON UPDATE, so that when you UPDATE row#1 in TABLE#1, it causes an\par
UPDATE to row#2 in TABLE#2, which in turn causes an UPDATE to row#1 in TABLE#1\par
-- and that's an error because the Standard doesn't allow this kind of\par
looping. With SQL3, this error can also happen for Triggers. See also:\par
SQLSTATE 09000, 40004.\par
\par
28000  invalid authorization specification\par
This error is caused by an invalid <AuthorizationID>. For example, "SET\par
SESSION AUTHORIZATION 'PUBLIC'" is illegal because 'PUBLIC' has a special\par
significance in SQL. It's implementation-defined whether this can happen due\par
to an entry of the wrong password.\par
\par
2A000  direct SQL syntax error access or rule violation\par
This error does not appear in ordinary programs.\par
\par
2B000  dependent privilege descriptors still exist\par
You used "REVOKE GRANT OPTION FOR", but not "CASCADE".\par
\par
2C000  invalid character set name\par
Presumably an invalid <Character set name> would be one that begins with a\par
digit, contains a non-Latin letter, etc.\par
\par
2D000  invalid transaction termination\par
Has to do with savepoints and atomicity of transactions. Should not be a\par
matter of concern until SQL3 gets going.\par
\par
2E000  invalid connection name\par
For a CONNECT statement, the argument must be a valid <identifier>.\par
\par
2F000  SQL routine exception\par
An SQL routine is a procedure or function which is written in SQL. SQLSTATE\par
class 2F identifies exception conditions that relate to SQL routines.\par
(Exceptions for non-SQL routines are class 38.)\par
\par
2F002  SQL routine exception-modifying SQL-data not permitted\par
The probable cause of this error is that the CREATE PROCEDURE or CREATE\par
FUNCTION statement contained the clause: CONTAINS SQL or READS SQL, but the\par
function contains an SQL statement which can modify the database (for example,\par
an UPDATE statement). The corresponding external-routine exception is 38002.\par
\par
2F003  SQL routine exception-prohibited SQL-statement attempted\par
The prohibited procedural SQL statements are the SQL-transaction statements\par
(START TRANSACTION, SET TRANSACTION, SET CONSTRAINTS, CREATE SAVEPOINT,\par
RELEASE SAVEPOINT, COMMIT, ROLLBACK) or the SQL-Connection statements\par
(CONNECT, SET CONNECTION, DISCONNECT) or the SQL-Schema statements (CREATE,\par
DROP, ALTER, GRANT, REVOKE). The corresponding external-routine exception is\par
38003.\par
\par
2F004  SQL routine exception-reading SQL-data not permitted\par
The probable cause of this error is that the CREATE PROCEDURE or CREATE\par
FUNCTION statement contains the clause: CONTAINS SQL, but the function\par
contains an SQL statement which reads the database (for example, a SELECT\par
statement). The corresponding SQL-routine exception is 38004.\par
\par
2F005  SQL routine exception-function executed no return statement\par
\par
30000  invalid SQL statement\par
\par
31000  invalid target specification value\par
\par
33000  invalid SQL descriptor name\par
If, in embedded SQL, you use "EXECUTE ... USING DESCRIPTOR 'X';", a descriptor\par
named X must exist.\par
\par
34000  invalid cursor name\par
If the function is SQLSetCursorName, then the problem is that a <Cursor name>\par
must be a unique, valid <identifier>. If the function is SQLPrepare or\par
SQLExecDirect, the SQL statement is "UPDATE  ... WHERE CURRENT OF <Cursor>" or\par
"DELETE ... WHERE CURRENT OF <Cursor>" and <Cursor> is not the name of an open\par
Cursor.\par
\par
35000  invalid condition number\par
With embedded SQL, you get this by saying "GET DIAGNOSTICS EXCEPTION 0". With\par
the CLI, you get this by calling SQLGetDiagRec or SQLGetDiagField with a\par
RecordNumber parameter less than 1. If RecordNumber is greater than the number\par
of status records, you don't get this error. Instead, you get an SQL_NO_DATA\par
return code.\par
\par
36000  cursor sensitivity exception\par
The "cursor sensitivity exception" class identifies exception conditions that\par
relate to Cursors and their sensitivity attribute.\par
\par
36001  cursor sensitivity exception-request rejected\par
An attempt was made to open a sensitive Cursor, but the DBMS cannot guarantee\par
that data changes will be visible throughout the transaction.\par
\par
36002  cursor sensitivity exception-request failed\par
For example, an attempt was made to execute a positioned DELETE statement, but\par
there is a sensitive Cursor open, and (for some implementation-dependent\par
reason) the effects of the DELETE cannot be made visible via that Cursor.\par
\par
37000  dynamic SQL syntax error or access rule violation\par
The SQL-92 Standard originally mentioned this SQLSTATE, but according to a\par
later correction (corrigendum bulletin #3) we should use SQLSTATE = 42000\par
instead. That is what all ODBC 3.x drivers do.\par
\par
38000  external routine exception\par
An external routine is a procedure or function which is written in a language\par
other than SQL. SQLSTATE class 38 identifies exception conditions that relate\par
to external routines. (Exceptions from SQL routines are class 2F.)\par
\par
38001  external routine exception-containing SQL not permitted\par
The probable cause is that the CREATE PROCEDURE or CREATE FUNCTION statement\par
contained the clause: NO SQL, but the routine  contains an SQL statement.\par
\par
38002  external routine exception-modifying SQL-data not permitted\par
The probable cause is that the CREATE PROCEDURE or CREATE FUNCTION statement\par
contained the clause: NO SQL or CONTAINS SQL or READS SQL, but the function\par
contains an SQL statement which can modify the database (for example, an\par
UPDATE statement).\par
\par
38003  external routine exception-prohibited SQL-statement attempted\par
The prohibited procedural SQL statements are the SQL-transaction statements\par
(START TRANSACTION, SET TRANSACTION, SET CONSTRAINTS, CREATE SAVEPOINT,\par
RELEASE SAVEPOINT, COMMIT, ROLLBACK) or the SQL-Connection statements\par
(CONNECT, SET CONNECTION, DISCONNECT) or the SQL-Schema statements (CREATE,\par
DROP, ALTER, GRANT, REVOKE).\par
\par
38004  external routine exception-reading SQL-data not permitted\par
The probable cause is that the CREATE PROCEDURE or CREATE FUNCTION statement\par
contained the clause: NO SQL or CONTAINS SQL, but the function contains an SQL\par
statement which reads the database (for example, a SELECT statement).\par
\par
39000  external routine invocation exception\par
\par
39001  external routine invocation exception-invalid sqlstate returned\par
\par
39004  external routine invocation exception-null value not allowed\par
\par
3B000  savepoint exception\par
\par
3B001  savepoint exception-invalid specification\par
\par
3B002  savepoint exception-too many\par
\par
3C000  ambiguous cursor name\par
A more appropriate wording is: duplicate <Cursor name>. In ODBC you can get\par
this by calling SQLSetCursorName with an argument that is the name of an\par
already-open Cursor.\par
\par
3D000  invalid catalog name\par
Presumably a <Catalog name> could be invalid if it is used as a qualifier or\par
as the argument of SET CATALOG, and does not refer to an existing Catalog or\par
is not a valid <identifier>. However, all those situations are equally covered\par
by SQLSTATE=42000 (syntax error or access violation). For SQLSetConnectAttr,\par
the problem is with a SQL_ATTR_CURRENT_CATALOG specification.\par
\par
3F000  invalid schema name\par
Presumably a <Schema name> could be invalid if it is used as a qualifier or as\par
the argument of SET SCHEMA, and does not refer to an existing Schema or is not\par
a valid <identifier>. However, all those situations are equally covered by\par
SQLSTATE=42000 (syntax error or access violation).\par
\par
3G000  invalid UDT instance\par
\par
40000  transaction rollback\par
\par
40001  transaction rollback-serialization failure\par
Two SQL jobs are running simultaneously, and a concurrency problem arose. For\par
example, using a locking protocol, there was a deadlock or, using a timestamp\par
protocol, a younger job has read the Object.\par
\par
40002  transaction rollback-integrity constraint violation\par
This occurs for COMMIT, if there were deferred Constraints (deferred\par
Constraints aren't checked until COMMIT time unless SET CONSTRAINTS IMMEDIATE\par
is executed). So: you asked for COMMIT, and what you got was ROLLBACK. See\par
also: SQLSTATE 23000.\par
\par
40003  transaction rollback-statement completion unknown\par
The SQL-Connection was lost during execution of an SQL statement. \par
40004  transaction rollback-triggered action exception\par
This occurs for COMMIT, if there was a deferred Constraint -- presumably a\par
FOREIGN KEY Constraint unless Triggers are supported by the DBMS -- and there\par
was an attempt to violate the Constraint. See also: SQLSTATE 09000, 27000.\par
\par
42000  syntax error or access rule violation\par
The favourite exception. Syntax errors include not just grammar or spelling\par
errors, but "bind problems" such as failure to find an Object. Access\par
violations are due to lack of Privileges. A high security DBMS will try to\par
hide from the user whether the problem is "you don't have access to X" as\par
opposed to "X isn't there"; that's why these two different categories are\par
lumped together in one SQLSTATE (thus users can't discover what the <Table\par
name>s are by trying out all the possibilities).\par
\par
** TRAP: It's easy to think that a syntax violation will always be caught\par
during the prepare stage. Not so. Many DBMSs don't bind until the execution\par
stage. You have to check after both SQLPrepare and SQLExecute, and perhaps\par
even after SQLFetch (because a DBMS may evaluate expressions in the select\par
list at FETCH time, or a Column might have been dropped since the Cursor was\par
opened).\par
\par
42S01  syntax error or access rule violation-base table or view already exists\par
(ODBC 3)\par
This is caused by something like "CREATE TABLE T ..." when there's already a\par
Table named T.\par
\par
42S02  syntax error or access rule violation-base table or view not found\par
(ODBC 3)\par
This is caused by something like "SELECT * FROM T;" when there's no Table\par
named T.\par
\par
42S11  syntax error or access rule violation-index already exists (ODBC 3)\par
This is caused by something like "CREATE INDEX I ON T(c);" when there's\par
already an index named I.\par
\par
42S12  syntax error or access rule violation-index not found (ODBC 3)\par
This is caused by something like "DROP INDEX I;" when there's no index named\par
I.\par
\par
42S21  syntax error or access rule violation-column already exists (ODBC 3)\par
This is caused by something like "ALTER TABLE T ADD COLUMN c ..." when Column\par
C already exists.\par
\par
42S22  syntax error or access rule violation-column not found (ODBC 3)\par
This is caused by something like "SELECT c FROM T;" when Table T has no Column\par
named C.\par
\par
44000  with check option violation\par
This is caused by something like "CREATE VIEW V AS SELECT x FROM T WHERE x=5\par
WITH CHECK OPTION;" then "UPDATE V SET x = 6;". The View's WITH CHECK OPTION\par
clause is violated by the attempted UPDATE, which fails.\par
\par
45000  unhandled user-defined exception\par
\par
70100  operation aborted (ODBC 2)\par
Possible because tasks or threads can be destroyed in some operating systems,\par
but don't expect to see this.\par
\par
H1zzz  SQL Multimedia part 1\par
\par
H2zzz  SQL Multimedia part 2\par
\par
H3zzz  SQL Multimedia part 3\par
\par
H4zzz  SQL Multimedia part 4\par
\par
H5zzz  SQL Multimedia part 5\par
\par
H6zzz  SQL Multimedia part 6\par
\par
H7zzz  SQL Multimedia part 7\par
\par
H8zzz  SQL Multimedia part 8\par
\par
H9zzz  SQL Multimedia part 9\par
\par
HAzzz  SQL Multimedia part 10\par
\par
HBzzz  SQL Multimedia part 11\par
\par
HCzzz  SQL Multimedia part 12\par
\par
HDzzz  SQL Multimedia part 13\par
\par
HEzzz  SQL Multimedia part 14\par
\par
HFzzz  SQL Multimedia part 15\par
\par
HY000 CLI-specific condition-invalid handle\par
      CLI-specific condition-dynamic parameter value needed\par
There is no status record for the invalid-handle exception. The return from\par
the CLI function is -2 (SQL_INVALID_HANDLE), so the only test for\par
invalid-handle is:\par
\par
   if (sqlreturn == SQL_INVALID_HANDLE) ...\par
\par
The "invalid handle" exception occurs if (a) the passed hstmt or hdbc or henv\par
or hdesc is not a handle of any resource at all or (b) the passed handle\par
refers to the wrong type of resource, for example you passed a hdesc but a\par
hdbc was expected in this context.\par
\par
There is no status record for the need-data exception either. The return from\par
the CLI function is +99 (SQL_NEED_DATA), so the only test for need-data is:\par
\par
   if (sqlreturn == SQL_NEED_DATA) ...\par
\par
This exception is associated with deferred parameters.\par
\par
HY001  CLI-specific condition-memory allocation error\par
Probable cause: a malloc failure. One possible solution is to close all other\par
windows. If (SQLAllocHandle(ENVIRONMENT HANDLE ...): the DBMS returns 0 to\par
&henv. Since there is no valid handle, you can't get diagnostics. If\par
(SQLAllocHandle(CONNECTION HANDLE ...): the DBMS returns 0 to &hdbc. You can\par
get diagnostics using the henv.\par
\par
HY002  CLI-specific condition-link-to-result-sets attribute precludes using\par
this routine\par
\par
HY003  CLI-specific condition-invalid data type in application descriptor\par
Actually, the invalid <data type> is not in an application descriptor, but in\par
the parameter of a CLI function (SQLBindCol, SQLBindParameter, SQLGetData,\par
SQLGetParamData). \par
\par
HY004  CLI-specific condition-invalid data type\par
The SQLGetTypeInfo function requires a DataType parameter whose value is\par
either SQL_ALL_TYPES or one of the "concise type" codes. If the DataType\par
parameter has an invalid value, you get this error. SQLSetDescField and\par
SQLBindParameter parameters must also contain "concise type" codes.\par
\par
HY007  CLI-specific condition-associated statement is not prepared\par
A function (for example SQLGetDescField) requires a descriptor field, but the\par
SQL statement has not been prepared so no description exists.\par
\par
HY008  CLI-specific condition-operation cancelled\par
Many functions can operate asynchronously. Such operations can be cancelled\par
using the SQLCancel function. That's what happened to this one.\par
\par
HY009  CLI-specific condition-invalid use of null pointer\par
One of the parameters for a function is a pointer (address). The passed\par
pointer (address) is 0000:0000, which isn't acceptable. Some DBMSs will return\par
this error if they detect that the host language can't handle pointers.\par
\par
HY010  CLI-specific condition-function sequence error\par
Some functions won't work unless some other function has successfully\par
executed. For example, it's impossible to "fetch" if you've never connected or\par
selected. Or, an asynchronously executing function has not finished. Or, the\par
last SQLExecDirect or SQLExecDirect call returned SQL_NEED_DATA (meaning the\par
SQL statement has not finished executing), and you're trying to free the stmt.\par
See also: SQLSTATE 24000.\par
\par
HY011  CLI-specific condition-attribute cannot be set now\par
Some settings cannot be changed in the middle of a transaction. For example,\par
you can't call the function SQLSetConnectAttr to change\par
SQL_ATTR_TXN_ISOLATION, after you've already done some inserts.\par
\par
HY012  CLI-specific condition-invalid transaction operation code\par
For the function SQLEndTran, the only possible arguments are SQL_COMMIT and\par
SQL_ROLLBACK.\par
\par
HY013  CLI-specific condition-memory management error\par
Many functions can return this. Usually the reason is "low memory conditions".\par
\par
HY014  CLI-specific condition-Limit on number of handles exceeded\par
This can come from a routine that allocates a handle (env, dbc, stmt, desc)\par
such as SQLAllocHandle. The maximum number of handles is\par
implementation-defined for each type.\par
      ## If (SQLAllocHandle(SQL_HANDLE_ENV,NULL,&henv): the DBMS puts a handle\par
in &henv despite the error; however, the handle is just a skeleton -- you\par
won't be able to use it to allocate a connection handle with.\par
      ## If (SQLAllocHandle(SQL_HANDLE_DBC,henv,&hdbc): the DBMS puts 0 in\par
&hdbc (SQL_NULL_HDBC). You can get diagnostics using the henv.\par
      ## If (SQLAllocHandle(SQL_HANDLE_STMT,hdbc,&hstmt): the DBMS puts 0 in\par
&hstmt (SQL_NULL_HSTMT). You can get diagnostics using the hdbc.\par
      ## If (SQLAllocHandle(SQL_HANDLE_DESC,hdbc,&hdesc): the DBMS puts 0 in\par
&hdesc (SQL_NULL_HDESC). You can get diagnostics using the hdbc.\par
\par
HY015  CLI-specific condition-no cursor name available\par
Obsolete -- happens only for ODBC 2.x drivers, when you call SQLGetCursorName.\par
\par
HY016  CLI-specific condition-cannot modify an implementation row descriptor\par
The target of a function (for example SQLCopyDesc) was an IRD, which can't be\par
changed.\par
\par
HY017  CLI-specific condition-invalid use of an automatically allocated\par
descriptor handle\par
An attempt was made to free or change a descriptor which was not made by the\par
application program.\par
\par
HY018  CLI-specific condition-Server declined cancel request\par
The ODBC function SQLCancel was called; it's up to the data source to decide\par
whether this can be processed. For example, the data source might not be\par
responding to the driver manager's requests.\par
\par
HY019  CLI-specific condition-non-character and non-binary data sent in pieces\par
The function SQLPutData was called twice for the same parameter or Column;\par
this is only allowed for character and binary data.\par
\par
HY020  CLI-specific condition-attempt to concatenate a null value\par
The function SQLPutData was called twice for the same parameter or Column; in\par
one of the calls, the passed value was NULL.\par
\par
HY021  CLI-specific condition-Inconsistent descriptor information\par
The fields of a desc have failed the consistency check. For example, the\par
SQL_DESC_SCALE value is greater than the SQL_DESC_PRECISION value (for a\par
DECIMAL field) or the SQL_DESC_TYPE value is SQL_DATETIME but the\par
SQL_DESC_INTERVAL_CODE value is 6 (only 1 to 5 would be legal). This error\par
happens only for the function calls SQLSetDescField and SQLSetDescRec. For\par
other functions, inconsistency causes SQLSTATE 07001 or 07002.\par
\par
HY024  CLI-specific condition-invalid attribute value\par
One of the "attribute" functions was called (SQLGetEnvAttr, SQLSetEnvAttr,\par
SQLGetConnectAttr, SQLSetConnectAttr, SQLGetStmtAttr, SQLSetStmtAttr). The\par
numeric value for the attribute parameter for this function is not defined.\par
\par
HY055  CLI-specific condition-non-string data cannot be used with string\par
routine\par
\par
HY090  CLI-specific condition-invalid string length or buffer length\par
You called any CLI function that passes a string value. The size parameter for\par
this string value was less than or equal to zero, and was not equal to -3\par
(SQL_NTS).\par
\par
HY091  CLI-specific condition-invalid descriptor field identifier\par
A descriptor is a structure with information about a selected Column (in a\par
result set); a field in that descriptor is usually identified by a numeric\par
code; the number you used was out of bounds. For example, you can't call\par
SQLColAttribute with a field identifier parameter = 0.\par
\par
HY092  CLI-specific condition-invalid attribute/option identifier\par
You called any CLI function that passes an option number (for example\par
SQLGetConnectAttr). The value you passed was not one of the defined values.\par
\par
HY095  CLI-specific condition-Function type out of range (ODBC 3)\par
The SQLGetFunctions function was called, with a FunctionId parameter, the\par
value of which is not defined for ODBC. This SQLSTATE is not mentioned in the\par
SQL3 Standard.\par
\par
HY103  CLI-specific condition-invalid retrieval code (ODBC 3)\par
The ODBC function SQLDataSources or SQLDrivers was called, with a Direction\par
parameter, the value of which does not equal SQL_FETCH_FIRST SQL_FETCH_NEXT,\par
etc.\par
\par
HY104  CLI-specific condition-invalid precision or scale value\par
The maximum precision or scale for some <data type>s is up to the data source\par
(i.e. sometimes the driver can't handle big things), so the SQLBindParameter\par
function gets this return. Try querying the data source to find out what its\par
maxima are.\par
\par
HY105  CLI-specific condition-invalid parameter mode\par
The function call (e.g.: SQLBindParameter) contains an "InputOutputMode"\par
parameter, the value of which is not one of: SQL_PARAM_MODE_IN,\par
SQL_PARAM_MODE_OUT, SQL_PARAM_MODE_INOUT.\par
\par
HY106  CLI-specific condition-invalid fetch orientation\par
Only certain fetch "orientations" are allowed (e.g.: NEXT, FIRST, LAST, PRIOR,\par
ABSOLUTE, RELATIVE). The value you passed wasn't one of them, for the function\par
SQLFetchScroll. Or, if the Cursor isn't a SCROLL Cursor, the only legal\par
orientation is NEXT. ODBC variations: this could also happen for\par
SQLExtendedFetch, and the name for this SQLSTATE is: Fetch type out of range.\par
\par
HY107  CLI-specific condition-Row value out of range\par
One of the ODBC "fetch" or "set position" functions was called (e.g.:\par
SQLFetch) and the Cursor is "key set driven", but the row involved isn't in\par
the key set's range.\par
\par
HY109  CLI-specific condition-invalid cursor position\par
A row could not be fetched, probably because it has been deleted or because it\par
is now locked.\par
\par
HY110  CLI-specific condition-invalid driver completion (ODBC 3)\par
The ODBC function SQLDriverConnect contains a DriverCompletion parameter, the\par
value of which is not defined for ODBC. This SQLSTATE is not mentioned in the\par
SQL Standard.\par
\par
HY111  CLI-specific condition-invalid bookmark value (ODBC 3)\par
The ODBC function SQLExtendedFetch or SQLFetchScroll was called, with a\par
FetchOrientation parameter, the value of which was not defined for ODBC, or\par
was a null pointer. This SQLSTATE is not mentioned in the SQL Standard.\par
\par
HYC00  CLI-specific condition-optional feature not implemented (ODBC 3)\par
Many of the ODBC functions have optional features. It is unlikely that any\par
driver will support every optional feature. When the driver doesn't, this is\par
the error you'll get. See also: SQLSTATE 0A000 (which applies to unimplemented\par
features outside the CLI) and SQLSTATE IM001 (which applies to unsupported\par
ODBC functions rather than features). The ODBC manual refers to HYC00 as\par
"particularly significant".\par
\par
HYT00  CLI-specific condition-timeout expired (ODBC 3)\par
You can specify a timeout value in milliseconds (with the SQLSetStmtAttr ODBC\par
function call). If the timeout value that you set goes by and the statement is\par
unfinished, this return happens.\par
\par
HYT01  CLI-specific condition-connection timeout expired (ODBC 3)\par
This is similar to HYT00, but it applies to the connection rather than to the\par
statement.\par
\par
HZzzz  Remote Database Access\par
The Remote Database Access standard, ISO/IEC 9579-2, defines several subclass\par
code values which may be passed on via SQL, but are not defined within SQL.\par
These will all be in the class HZ.\par
\par
IM001  driver does not support this function (ODBC 2+3)\par
There are a lot of ODBC functions. Some drivers don't support them all,\par
especially since ODBC 3.x is still new (and Microsoft keeps changing it). So\par
this error comes from the driver. Compare SQLSTATE HYC00.\par
\par
IM002  Data source name not found and no default driver specified (ODBC 2+3)\par
This happens when you're connecting with ODBC, and there's no DSN registered.\par
\par
IM003  specified driver could not be loaded (ODBC 2+3)\par
Possibly the driver's DLL is missing, or is not in the directory that the\par
driver manager is searching.\par
\par
IM004  driver's SQLAllocHandle on SQL_HANDLE_ENV failed (ODBC 2+3)\par
Usually this would indicate low memory, or that the maximum number of handles\par
is exceeded, or a problem with function sequence.\par
\par
IM005  driver's SQLAllocHandle on SQL_HANDLE_DBC failed (ODBC 2+3)\par
Usually this would indicate low memory, or that the maximum number of handles\par
is exceeded, or a problem with function sequence.\par
\par
IM006  driver's SQLSetConnectAttr failed (ODBC 2+3)\par
A connection error (during SQLBrowseConnect or SQLConnect or\par
SQLDriverConnect).\par
\par
IM007  no data source or driver specified; dialog prohibited (ODBC 2+3)\par
An error return from the ODBC function call SQLDriverConnect.\par
\par
IM008  dialog failed (ODBC 2+3)\par
The SQLDriverConnect function puts up a dialog box; presumably the user did\par
not end with "OK".\par
\par
IM009  unable to load translation DLL (ODBC 2+3)\par
A failure during connect or during SQLSetConnectAttr, probably due to a\par
missing DLL, which may indicate an installation error.\par
\par
IM010  data source name too long (ODBC 3)\par
The ODBC connection functions (SQLBrowseConnect or SQLConnect or\par
SQLDriverConnect) have a maximum size for the name of the data source (DSN).\par
You've exceeded it.\par
\par
IM011  driver name too long (ODBC 3)\par
The SQLBrowseConnect and SQLDriverConnect functions have a maximum size for\par
the name of the driver. You've exceeded it.\par
\par
IM012  driver keyword syntax error (ODBC 3)\par
The SQLBrowseConnect or SQLDriverConnect functions require data in a fixed\par
format.\par
\par
IM013  trace file error (ODBC 3)\par
Couldn't perform an operation on the trace file, perhaps a failure to write\par
because of a disk-full situation.\par
\par
IM014  invalid name of file DSN (ODBC 3)\par
The SQLDriverConnect function requires a valid identifier.\par
\par
IM015  corrupt file data source (ODBC 3)\par
The SQLDriverConnect function can't read the file.\par
\par
OH000  invalid SQLSTATE value\par
\par
OK000  resignal when handler not active\par
\par
And that's it for CLI diagnostics. In the next chapter, we'll take a look at some general functions.\par
\page\par
Chapter 48 -- SQL/CLI: General Functions\par
\par
In this chapter, we discuss SQLDataSources, SQLGetFunctions and SQLGetInfo. We\par
call these the "general" functions because they are used primarily in\par
applications which are not tied to a specific DBMS or a specific database.\par
Generalized applications need to find out what is available, as part of a long\par
initialization process. Here are the descriptions of the three general functions.\par
\par
SQLDataSources\par
\par
Function Prototype:\par
  SQLRETURN SQLDataSources(\par
    SQLHENV henv,                   /* 32-bit input */\par
    SQLSMALLINT Direction,          /* 16-bit input, =\par
                                       SQL_FETCH_FIRST or SQL_FETCH_NEXT */\par
    SQLCHAR *ServerName,            /* pointer to char* output */\par
    SQLSMALLINT BufferLength1,      /* 16-bit input */\par
    SQLSMALLINT *NameLength1,       /* pointer to 16-bit output */\par
    SQLCHAR *Description,           /* pointer to char* output */\par
    SQLSMALLINT BufferLength2,      /* 16-bit input */\par
    SQLSMALLINT *NameLength2        /* pointer to 16-bit output */\par
    );\par
\par
Job:\par
Return names of data sources -- that is, servers or databases.\par
\par
Algorithm:\par
      If (henv is not really an env handle or env is skeleton)\par
        return error: CLI-specific condition-invalid handle\par
      Empty the diagnostics area associated with henv.\par
      If (Direction is not SQL_FIRST (2)or SQL_NEXT (1))\par
        return error: HY103 CLI-specific condition-invalid retrieval code\par
      If (Direction == SQL_FIRST (2))\par
        /* Cursor position is for first row of "Data Sources" Table */\par
      If (Direction is SQL_NEXT (1))\par
        /* Cursor position is for next row of "Data Sources" Table\par
           (it's 1st row if we've never called SQLDataSources before)\par
           (it's 1st row if last call to SQLDataSources returned "no data") */\par
      If (Cursor position is now past end)\par
        return with warning: 02000 no data -\par
      "Fetch" into ServerName and Description parameters\par
      /* The usual Character Set Retrieval rules apply. */\par
\par
Notes:\par
      ## The SQL Standard is firm about the meaning of the term "data source":\par
the SQLDataSources function is supposed to return names of SQL-servers. For\par
some single-tier desktop DBMSs (which are not based on a client-server\par
architecture), it is more reasonable to expect that the names returned here\par
will be names of databases. In any case, the name is something you can use in\par
a SQLConnect call.\par
      ## You would use this function for browsing ("What servers can I connect\par
to?") or for checking availability ("Is server X up yet?"). In many commercial\par
installations the application is tightly linked to a particular server, so\par
calling SQLDataSources has no point -- either you can call SQLConnect and\par
succeed, or you cannot. There is a big implementation-defined question here,\par
namely, how does anybody know what servers are out there? That depends on how\par
the system is configured, but -- sometimes -- there is a query to see what\par
names are established on the network, or a directory search for Catalog files.\par
      ## In theory, the maximum length of ServerName should be the\par
implementation-defined maximum length of a VARCHAR string. In practice, the\par
maximum length of ServerName is 128 characters.\par
      ## This is one of the very few functions for which the input handle is a\par
henv. You can call SQLGetDataSources before allocating a dbc or connecting.\par
There might be several data sources associated with an env.\par
      ## Imagine that there is a Table "Data Sources" containing two CHAR\par
Columns: "servername" or "databasename", and "description". The SQLDataSources\par
function will FETCH a single row from this Table. SQLDataSources would have\par
been implemented as a Catalog function -- that is, it would have returned a\par
result set -- if it were not for the inconvenient fact that we want to\par
retrieve data sources information before we connect.\par
\par
Example:\par
This example displays a list of available servers; assume that the "Data Sources" Table looks like this:\par
\par
"Data Sources"\par
"servername"   "description"\par
Wally          A server on the organization's main computer\par
Sammy          A local server used for test purposes\par
\par
  #include "sqlcli.h"\par
  SQLHENV henv;\par
  SQLCHAR name[128+1], description[1024];\par
  SQLSMALLINT name_length, description_length;\par
  SQLRETURN sqlreturn;\par
  ...\par
  SQLAllocHandle(SQL_HANDLE_ENV,NULL,&henv);\par
  for (;;) \{\par
    sqlreturn = SQLDataSources(\par
      henv,                         /* henv parameter */\par
      SQL_FETCH_NEXT,               /* Direction */\par
      name,                         /* *ServerName */\par
      sizeof(name),                 /* BufferLength1 */\par
      &name_length,                 /* *NameLength1 */\par
      description,                  /* *Description */\par
      sizeof(description),          /* BufferLength2 */\par
      &description_length           /* NameLength2 */\par
      );\par
    if (sqlreturn == SQL_NO_DATA) break;\par
   printf("ServerName = %s. Description = %s.\\n",name,description); \}\par
  SQLFreeHandle(SQL_HANDLE_ENV,henv);\par
\par
ODBC: This function has been available since ODBC 1.0. The Driver Manager\par
handles the call, by checking the registry of data sources which have been\par
installed using the ODBC installation program. In fact, SQLDataSources is very\par
much an ODBC sort of call, since it is difficult to see how one could find a\par
server list without using some sort of non-standard "Driver Manager".\par
\par
** TIP: With Windows 3.x the ODBC driver information is stored in an .INI\par
file, which you can query directly with GetPrivateProfileString. With\par
Windows95, the ODBC driver information is stored in the registry.\par
\par
SQLGetFunctions\par
\par
Function Prototype:\par
  SQLRETURN  SQLGetFunctions(\par
    SQLHDBC hdbc,                   /* 32-bit input */\par
    SQLSMALLINT FunctionId,         /* 32-bit input */\par
    SQLSMALLINT *Supported          /* pointer to 16-bit output */\par
    );\par
\par
Job:\par
Find out whether a specified CLI function is supported. The legal list of\par
FunctionID values, as defined (with #define) in sqlcli.h, follows -- function\par
codes are in alphabetical order; the version of standard SQL, or ODBC, which\par
requires support of the function is noted after the function's numeric code:\par
#define SQL_API_SQLALLOCCONNECT          1 SQL-92\par
#define SQL_API_SQLALLOCENV              2 SQL-92\par
#define SQL_API_SQLALLOCHANDLE        1001 SQL-92\par
#define SQL_API_SQLALLOCHANDLESTD       74 X/Open\par
#define SQL_API_SQLALLOCSTMT             3 SQL-92\par
#define SQL_API_SQLBINDCOL               4 SQL-92\par
#define SQL_API_SQLBINDPARAM          1002 ODBC 3\par
#define SQL_API_SQLBINDPARAMETER        72 SQL-92\par
#define SQL_API_SQLBROWSECONNECT        55 ODBC 3\par
#define SQL_API_SQLBULKOPERATIONS       24 ODBC 3\par
#define SQL_API_SQLCANCEL                5 SQL-92\par
#define SQL_API_SQLCLOSECURSOR        1003 SQL-92\par
#define SQL_API_SQLCOLATTRIBUTE          6 SQL-92\par
#define SQL_API_SQLCOLATTRIBUTES         6 ODBC 2\par
#define SQL_API_SQLCOLUMNPRIVILEGES     56 SQL-92\par
#define SQL_API_SQLCOLUMNS              40 SQL3\par
#define SQL_API_SQLCONNECT               7 SQL-92\par
#define SQL_API_SQLCOPYDESC           1004 SQL-92\par
#define SQL_API_SQLDATASOURCES          57 SQL-92\par
#define SQL_API_SQLDESCRIBECOL           8 SQL-92\par
#define SQL_API_SQLDESCRIBEPARAM        58 ODBC 3\par
#define SQL_API_SQLDISCONNECT            9 SQL-92\par
#define SQL_API_SQLDRIVERCONNECT        41 ODBC 3\par
#define SQL_API_SQLDRIVERS              71 ODBC 3\par
#define SQL_API_SQLENDTRAN            1005 SQL-92\par
#define SQL_API_SQLERROR                10 SQL-92\par
#define SQL_API_SQLEXECDIRECT           11 SQL-92\par
#define SQL_API_SQLEXECUTE              12 SQL-92\par
#define SQL_API_SQLEXTENDEDFETCH        59 ODBC 3\par
#define SQL_API_SQLFETCH                13 SQL-92\par
#define SQL_API_SQLFETCHSCROLL        1021 SQL-92\par
#define SQL_API_SQLFOREIGNKEYS          60 SQL-92\par
#define SQL_API_SQLFREECONNECT          14 SQL-92\par
#define SQL_API_SQLFREEENV              15 SQL-92\par
#define SQL_API_SQLFREEHANDLE         1006 SQL-92\par
#define SQL_API_SQLFREELOCATOR        1031 SQL3\par
#define SQL_API_SQLFREESTMT             16 SQL-92\par
#define SQL_API_SQLGETCONNECTATTR     1007 SQL-92\par
#define SQL_API_SQLGETCONNECTOPTION     42 ODBC 2\par
#define SQL_API_SQLGETCURSORNAME        17 SQL-92\par
#define SQL_API_SQLGETDATA              43 SQL-92\par
#define SQL_API_SQLGETDESCFIELD       1008 SQL-92\par
#define SQL_API_SQLGETDESCREC         1009 SQL-92\par
#define SQL_API_SQLGETDIAGFIELD       1010 SQL-92\par
#define SQL_API_SQLGETDIAGREC         1011 SQL-92\par
#define SQL_API_SQLGETENVATTR         1012 SQL-92\par
#define SQL_API_SQLGETFUNCTIONS         44 SQL-92\par
#define SQL_API_SQLGETINFO              45 SQL-92\par
#define SQL_API_SQLGETLENGTH          1022 SQL-92\par
#define SQL_API_SQLGETPARAMDATA       1025 SQL-92\par
#define SQL_API_SQLGETPOSITION        1023 SQL-92\par
#define SQL_API_SQLGETSTMTATTR        1014 SQL-92\par
#define SQL_API_SQLGETSTMTOPTIONS       46 ODBC 2\par
#define SQL_API_SQLGETSUBSTRING       1024 SQL3\par
#define SQL_API_SQLGETTYPEINFO          47 SQL-92\par
#define SQL_API_SQLMORERESULTS          61 SQL-92\par
#define SQL_API_SQLNATIVESQL            62 ODBC 3\par
#define SQL_API_SQLNUMPARAMS            63 ODBC 3\par
#define SQL_API_SQLNUMRESULTCOLS        18 SQL-92\par
#define SQL_API_SQLPARAMDATA            48 SQL-92\par
#define SQL_API_SQLPARAMETERS         2002 SQL-92\par
#define SQL_API_SQLPARAMOPTIONS         64 ODBC 3\par
#define SQL_API_SQLPREPARE              19 SQL-92\par
#define SQL_API_SQLPRIMARYKEYS          65 SQL-92\par
#define SQL_API_SQLPROCEDURECOLUMNS     66 ODBC 3\par
#define SQL_API_SQLPROCEDURES           67 ODBC 3\par
#define SQL_API_SQLPUTDATA              49 SQL-92\par
#define SQL_API_SQLROUTINEPRIVILEGES  1026 SQL-92\par
#define SQL_API_SQLROUTINES           2003 SQL-92\par
#define SQL_API_SQLROWCOUNT             20 SQL-92\par
#define SQL_API_SQLSETCONNECTATTR     1016 SQL-92\par
#define SQL_API_SQLSETCONNECTOPTION     50 ODBC 2\par
#define SQL_API_SQLSETCURSORNAME        21 SQL-92\par
#define SQL_API_SQLSETDESCFIELD       1017 SQL-92\par
#define SQL_API_SQLSETDESCREC         1018 SQL-92\par
#define SQL_API_SQLSETENVATTR         1019 SQL-92\par
#define SQL_API_SQLSETPARAM              2 ODBC 2\par
#define SQL_API_SQLSETPOS               68 ODBC 2\par
#define SQL_API_SQLSETSCROLLOPTIONS     69 ODBC 2\par
#define SQL_API_SQLSETSTMTATTR        1020 SQL-92\par
#define SQL_API_SQLSETSTMTOPTION        51 ODBC 2\par
#define SQL_API_SQLSPECIALCOLUMNS       52 SQL3\par
#define SQL_API_SQLSTATISTICS           53 X/Open\par
#define SQL_API_SQLTABLEPRIVILEGES      70 SQL-92\par
#define SQL_API_SQLTABLES               54 SQL3\par
#define SQL_API_SQLTRANSACT             23 ODBC 2\par
\par
Algorithm:\par
      If (hdbc is not really a handle of a dbc)\par
        return error: CLI-specific condition-invalid handle\par
      Empty the dbc's diagnostics area.\par
      If (no connection opened on hdbc)\par
        return error: 08003 connection exception-connection does not exist\par
      If (the function identified by FunctionId is supported)\par
        Set *Supported = 1 (true);\par
      Else\par
        Set *Supported = 0 (false).\par
\par
Notes:\par
      ## SQL_API_SQLCOLATTRIBUTE and SQL_API_SQLCOLATTRIBUTES have the same\par
value: 6. This error is no longer important, since SQLColAttributes was only\par
an ODBC 2.0 function.\par
      ## Calling SQLGetFunctions(...,SQL_API_SQLGETFUNCTION,...) looks a\par
little like asking a person "Are you awake?", i.e.: the answer is either "yes"\par
or you get no answer at all. But in some contexts it's a perfectly reasonable\par
question. For instance, all versions of ODBC include a Driver Manager -- a DLL\par
layer which is separate from the DBMS itself (the "driver" and the "data\par
source"). In an ODBC context, you're really asking the Driver Manager a\par
question about the driver, and that's a question you can expect either a "yes"\par
or a "no" answer for.\par
      ## It's clear from the FunctionID value chart that some CLI functions\par
are old, some are new, some are implementation-specific, some are standard.\par
That's why it makes sense to call SQLGetFunctions right after connecting, and\par
branch to an appropriate path depending on which functions are supported. The\par
SQLGetInfo function is useful for the same sort of purpose.\par
      ## If you are using MS-Windows and you are calling the DBMS directly,\par
the question you really want to ask is: is the function name exported?\par
\par
Example:\par
Although Microsoft's documentation marks the ODBC function SQLStatistics() as\par
"ISO 92", it's not an ISO Standard function. So before using it, we will ask\par
whether our DBMS supports it. Here's how.\par
\par
      #include "sqlcli.h"\par
      /* In case SQL_API_STATISTICS isn't in sqlcli.h, we define it here. */\par
      #define SQL_API_SQLSTATISTICS 53\par
      SQLHENV henv;\par
      SQLHDBC hdbc;\par
      SQLSMALLINT supported;\par
      void main ()\par
      \{\par
        SQLAllocHandle(SQL_HANDLE_ENV,...);\par
        SQLAllocConnect(SQL_HANDLE_DBC,...);\par
        SQLConnect(hdbc,...);\par
        if (SQLGetFunctions(hdbc,SQL_API_SQLSTATISTICS,&supported)<0) \{\par
          printf("SQLGetFunctions failed.\\n"); \}\par
        else \{\par
          if (!supported) \{\par
            printf("SQLStatistics is not supported.\\n"); \}\par
          else \{\par
            printf("SQLStatistics is supported.\\n");\par
        SQLDisconnect(...);\par
        SQLFreeHandle(SQL_HANDLE_DBC,...);\par
        SQLFreeHandle(SQL_HANDLE_ENV,...);\par
\par
ODBC: The SQLGetFunctions function has been around since ODBC version 1.0. The third parameter, *Supported, can be a pointer to an array.\par
\par
SQLGetInfo\par
\par
Function Prototype:\par
  SQLRETURN  SQLGetInfo(\par
    SQLHDBC hdbc,                   /* 32-bit input */\par
    SQLSMALLINT InfoType,           /* 16-bit input */\par
    SQLPOINTER InfoValue,           /* pointer to ANY* output */\par
    SQLINTEGER BufferLength,        /* 32-bit input */\par
    SQLINTEGER *StringLength        /* pointer to 32-bit output */\par
    );\par
\par
Job:\par
Ask whether a DBMS supports a specified feature, and if it does, which of several possible syntax variations the DBMS uses.\par
\par
The SQLGetInfo function's InfoType parameter has 47 possible values, which\par
we'll describe in the following paragraphs. In what follows, each paragraph\par
begins with a value (the InfoType value), a name (the #define of this value in\par
sqlcli.h) and the <data type> of the value that SQLGetInfo returns, followed by a few remarks.\par
      ## 24 SQL_ACCESSIBLE_ROUTINES -- CHAR(1)\par
The result is 'Y' if routines metadata -- such as the rows in\par
INFORMATION_SCHEMA.ROUTINES -- is accessible only to users who hold EXECUTE\par
Privileges on routines; otherwise the result is 'N'. In ODBC, this code does\par
not exist; 24 is the code for SQL_CURSOR_ROLLBACK_BEHAVIOR.\par
      ## 19 SQL_ACCESSIBLE_TABLES -- CHAR(1)\par
The result is 'Y' if Tables metadata -- such as the rows in\par
INFORMATION_SCHEMA.TABLES -- is accessible only to users who hold SELECT\par
Privileges on Tables; otherwise the result is 'N'. A standard DBMS should\par
return 'N', since access to INFORMATION_SCHEMA Views is possible if you hold\par
any Privilege, not just the SELECT Privilege. This code determines the\par
operation of the CLI Catalog functions: SQLColumnPrivileges, SQLColumns,\par
SQLForeignKeys, SQLPrimaryKeys, SQLResultSetStructure, SQLSpecialColumns,\par
SQLTablePrivileges, SQLTables. In ODBC, this code exists, but the meaning is different.\par
      ## 86 SQL_ALTER_TABLE -- INTEGER\par
The return is a bit map: one bit on for each ALTER TABLE clause the DBMS supports:\par
            ## If ALTER TABLE ... ADD COLUMN:\par
0001 hex (SQL_AT_ADD_COLUMN)\par
            ## If ALTER TABLE ... DROP COLUMN:\par
0002 hex (SQL_AT_DROP_COLUMN)\par
            ## If ALTER TABLE ... ALTER COLUMN:\par
0004 hex (SQL_AT_ALTER_COLUMN)\par
            ## If ALTER TABLE ... ADD CONSTRAINT:\par
0008 hex (SQL_AT_ADD_CONSTRAINT)\par
            ## If ALTER TABLE ... DROP CONSTRAINT:\par
0010 hex (SQL_AT_DROP_CONSTRAINT)\par
Any SQL-92 DBMS must return 001b hex (all bits except "ALTER COLUMN" on). Any\par
SQL3 DBMS must return 001f hex (all bits on). In ODBC, this code exists but the meaning is different.\par
      ## 10003 SQL_CATALOG_NAME -- CHAR(1)\par
The return is 'Y' if the DBMS supports <Catalog name>s (as qualifiers,\par
presumably); 'N' if not. Any SQL-92 DBMS must return 'Y'.\par
      ## 10004 SQL_COLLATING_SEQUENCE -- CHAR(254)\par
The return is the <identifier> of "the default Collation of [the server]" --\par
which is ambiguous. Probably it's the <identifier> of the default Collation of\par
the dbc's default Character set -- which is useless. If you want the Schema's\par
Character set, SELECT from INFORMATION_SCHEMA.SCHEMATA. If you want the\par
Collation of a Base table's Column, SELECT from INFORMATION_SCHEMA.COLUMNS. If\par
you want the Collation of a result set Column, call the SQLGetDescField\par
function. In ODBC, the designation for this code is SQL_COLLATION_SEQ, and "ISO 8859-1" or "EBCDIC" are possible returns.\par
      ## 23 SQL_CURSOR_COMMIT_BEHAVIOR -- SMALLINT\par
The return is a bit map, with one bit on, determined by what actions the DBMS takes when COMMIT happens:\par
            ## [close Cursor, delete prepared statements] DELETE:\par
0000 hex (SQL_CB_DELETE)\par
            ## [close Cursor, keep prepared statements] CLOSE:\par
0001 hex (SQL_CB_CLOSE)\par
            ## [keep Cursor open, keep prepared statements] PRESERVE:\par
0002 hex (SQL_CB_PRESERVE)\par
A standard SQL DBMS should return 0000 hex (SQL_CB_DELETE).\par
      ## XXX CURSOR HOLDABLE -- XXX\par
The return is 1 (SQL_HOLDABLE) if the DBMS supports holdable Cursors;\par
otherwise it is 0 (SQL_NONHOLDABLE).\par
      ## 10001 SQL_CURSOR_SENSITIVITY -- INTEGER\par
The return is a bit map, with zero or more bits on, determined by the DBMS's behaviour when rows are updated outside the Cursor:\par
            ## [don't see rows updated during same transaction]:\par
0001 hex (SQL_INSENSITIVE)\par
            ## [see rows updated during same transaction]:\par
0002 hex (SQL_SENSITIVE)\par
            ## [can't tell whether we see them or not]:\par
0000 hex (SQL_UNSPECIFIED) or 0000 hex (SQL_ASENSITIVE)\par
      ## 2 SQL_DATA_SOURCE_NAME -- CHAR(128)\par
The return is the name of a data source (in client/server terms: a server name). This is the name that was passed in the SQLConnect call.\par
      ## 25 SQL_DATA_SOURCE_READ_ONLY -- CHAR(1)\par
The return is 'Y' if the data source (in client/server terms: the server)\par
cannot allow data to be "modified" -- an undefined word. Presumably, the\par
meaning is: every transaction begins with the implicit statement SET TRANSACTION READ ONLY.\par
      ## 17 SQL_DBMS_NAME -- CHAR(254)\par
The return is the name of the DBMS. It's implementation-defined, but one can\par
assume that there will be a vendor name here. The sqlcli.h file does not contain SQL_DBMS_NAME.\par
      ## 18 SQL_DBMS_VERSION -- CHAR(254)\par
The return is the version number of the DBMS, in a rigid format: nn.nn.nnnn[optional description], where n is any decimal digit. Examples: "00.00.0000", "01.02.03 Vendor X's Version #1 Release #2 Patch #3". In ODBC, the name is SQL_DBMS_VER.\par
      ## 26 SQL_DEFAULT_TRANSACTION_ISOLATION -- INTEGER\par
The return is a bitmask, with one bit on for the default transaction isolation\par
level -- that is, what the transaction isolation level is if you can't execute\par
"SET TRANSACTION ISOLATION LEVEL \{READ COMMITTED | READ UNCOMMITTED | REPEATABLE READ | SERIALIZABLE\}". The possible values are:\par
            ## 0001 hex (SQL_TXN_READ_UNCOMMITTED)\par
            ## 0002 hex (SQL_TXN_READ_COMMITTED)\par
            ## 0004 hex (SQL_TXN_REPEATABLE_READ)\par
            ## 0008 hex (SQL_TXN_SERIALIZABLE)\par
A standard DBMS should return SQL_TXN_SERIALIZABLE.\par
      ## 10002 SQL_DESCRIBE_PARAMETER -- CHAR(1)\par
The return is 'Y' if the DBMS is capable of "describing dynamic parameters" --\par
which is ambiguous. Apparently, the return has nothing to do with the DBMS's\par
ability to support "auto-populate of IPD" or the non-standard\par
SQLDescribeParameter function. Apparently, all DBMSs which support the\par
embedded SQL DESCRIBE INPUT statement should return 'Y'; otherwise they should return 'N'.\par
      ## 8 SQL_FETCH_DIRECTION -- INTEGER\par
The return is a bitmask, with zero or more bits on, depending on the options\par
one can use with the SQLFetchScroll function. The possible values are:\par
            ## 0001 hex (SQL_FD_FETCH_NEXT)\par
            ## 0002 hex (SQL_FD_FETCH_FIRST)\par
            ## 0004 hex (SQL_FD_FETCH_LAST)\par
            ## 0008 hex (SQL_FD_FETCH_PRIOR)\par
            ## 0010 hex (SQL_FD_FETCH_ABSOLUTE)\par
            ## 0020 hex (SQL_FD_FETCH_RELATIVE)\par
 A standard DBMS should return 003f hex -- that is, all bits on.\par
      ## 81 SQL_GETDATA_EXTENSIONS -- INTEGER\par
The return is a bitmask, with zero or more bits on, depending on the DBMS's\par
ability to handle out-of-order SQLGetData calls. Minimally, a DBMS allows\par
SQLGetData only for Columns that were not bound with SQLBindCol, and only in\par
sequence (that is, after getting information for Column "n", you can only get\par
information for Column "n+1"). The possible options are:\par
            ## [if you can call SQLGetData for bound Columns]:\par
0001 hex (SQL_GD_ANY_COLUMN)\par
            ## [if you can call SQLGetData in any order]:\par
0002 hex (SQL_GD_ANY_ORDER)\par
      ## 20000 SQL_GETPARAMDATA_EXTENSIONS -- INTEGER\par
The return is a bitmask, with zero or more bits on, depending on the DBMS's\par
ability to handle out-of-order SQLGetParamData calls. Minimally, a DBMS allows\par
SQLGetParamData only for Columns that were not bound, and only in sequence\par
(that is, after getting information for parameter "n" you can only get\par
information for parameter "n+1"). The possible options are:\par
            ## [if you can call SQLGetParamData for bound Columns]:\par
0001 hex (SQL_GPD_ANY_COLUMN)\par
            ## [if you can call SQLGetParamData in any order]:\par
0002 hex (SQL_GPD_ANY_ORDER)\par
Compare this with SQL_GETDATA_EXTENSIONS.\par
      ## 28 SQL_<identifier>_CASE -- SMALLINT\par
Returns a number between 1 and 4, depending how the DBMS stores <regular identifier>s. The possible options are:\par
            ## [change to upper case]:\par
1 (SQL_IC_UPPER)\par
            ## [change to lower case]:\par
2 (SQL_IC_LOWER)\par
            ## [don't change case]:\par
3 (SQL_IC_SENSITIVE)\par
            ## [don't change case, but do case-insensitive searches]:\par
4 (SQL_IC_MIXED)\par
A standard DBMS should always return SQL_IC_UPPER, since only <delimited identifier>s are stored in mixed case.\par
      ## 73 SQL_INTEGRITY -- CHAR(1)\par
The return is 'Y' if the DBMS supports basic integrity Constraints: NOT NULL,\par
UNIQUE, PRIMARY KEY, FOREIGN KEY ... NO ACTION, CHECK and Column defaults.\par
Otherwise the return is 'N'. A standard DBMS should return 'Y'. In ODBC, code\par
73 is SQL_OPT_IEF, and the return is 'Y' if the DBMS supports the optional\par
integrity enhancement facility of SQL-89.\par
      ## 34 SQL_MAXIMUM_CATALOG_NAME_LENGTH -- SMALLINT\par
The return is the length, in characters, of the largest possible <Catalog\par
name>, without qualifiers or introducers. Expect 18 for an SQL-89 DBMS, 128 for a later DBMS.\par
      ## 30 SQL_MAXIMUM_COLUMN_NAME_LENGTH -- SMALLINT\par
The return is the length, in characters, of the largest possible <Column\par
name>, without qualifiers or introducers. Expect 18 for an SQL-89 DBMS, 128 for a later DBMS.\par
      ## 97 SQL_MAXIMUM_COLUMNS_IN_GROUP_BY -- SMALLINT\par
The return is the largest number of Columns that a GROUP BY clause can hold\par
(zero if that's unknown or unlimited). Expect 6 for a DBMS that meets the FIPS\par
127-2 entry-level spec, 15 for a DBMS that meets the FIPS 127-2 intermediate-level spec.\par
      ## 99 SQL_MAXIMUM_COLUMNS_IN_ORDER_BY -- SMALLINT\par
The return is the largest number of Columns that an ORDER BY clause can hold\par
(zero if that's unknown or unlimited). Expect 6 for a DBMS that meets the FIPS\par
127-2 entry-level spec, 15 for a DBMS that meets the FIPS 127-2 intermediate-level spec.\par
      ## 100 SQL_MAXIMUM_COLUMNS_IN_SELECT -- SMALLINT\par
The return is the largest number of Columns that a select list can hold (zero\par
if that's unknown or unlimited). Expect 100 for a DBMS that meets the FIPS\par
127-2 entry-level spec, 250 for a DBMS that meets the FIPS 127-2 intermediate-level spec.\par
      ## 101 SQL_MAXIMUM_COLUMNS_IN_TABLE -- SMALLINT\par
The return is the largest number of Columns that a Base table can hold (zero\par
if that's unknown or unlimited). Expect 100 for a DBMS that meets the FIPS\par
127-2 entry-level spec, 250 for a DBMS that meets the FIPS 127-2 intermediate-level spec.\par
      ## 1 SQL_MAXIMUM_CONCURRENT_ACTIVITIES -- SMALLINT\par
The return is the largest number of stmts that can be active at the same time.\par
With some implementations, it might be possible to allocate two stmts, i.e.:\par
call SQLAllocHandle(SQL_HANDLE_STMT,...) twice, but impossible to "select"\par
with both hstmt#1 and hstmt#2. The return is zero if maximum concurrent\par
activities is unknown. (A stmt is "active" if it is associated with an open Cursor or a deferred parameter.)\par
      ## 31 SQL_MAXIMUM_CURSOR_NAME_LENGTH -- SMALLINT\par
The return is the length, in characters, of the largest possible <Cursor\par
name>, without qualifiers or introducers. Expect 18 for an SQL-89 DBMS, 128 for a later DBMS.\par
      ## 0 SQL_MAXIMUM_DRIVER_CONNECTIONS -- SMALLINT\par
The return is the maximum number of connections between one driver and one\par
server, or the maximum number of connections period, or zero if the maximum is not fixed.\par
      ## 10005 SQL_MAXIMUM_<identifier>_LENGTH -- SMALLINT\par
The return is the length, in characters, of the largest possible <identifier>\par
for any kind of Object. This value won't be greater than any of the\par
SQL_MAXIMUM_..._NAME_LENGTH values. Expect 18 for an SQL-89 DBMS, 128 for a later DBMS.\par
      ## 32 SQL_MAXIMUM_SCHEMA_NAME_LENGTH -- SMALLINT\par
The return is the length, in characters, of the largest possible <Schema\par
name>, without qualifiers or introducers. Expect 18 for an SQL-89 DBMS, 128 for a later DBMS.\par
      ## 20000 SQL_MAXIMUM_STMT_OCTETS -- SMALLINT\par
<< XXX the number is wrong, 20000 is SQL_GETPARAMDATA_EXTENSIONS >>\par
The return is the maximum number of octets that can exist in any SQL\par
statement, or zero if there's no fixed limit. This is the maximum size of the\par
string parameter in an SQLPrepare or SQLExecDirect function call. In ODBC,\par
this code does not exist; the ODBC code SQL_MAXIMUM_STATEMENT_LENGTH is a different value.\par
      ## 20001 SQL_MAXIMUM_STMT_OCTETS_DATA -- SMALLINT\par
The return is the maximum number of octets that can exist in an SQL-data statement (such as INSERT), or zero if there's no fixed limit.\par
      ## 20002 SQL_MAXIMUM_STMT_OCTETS_SCHEMA -- SMALLINT\par
The return is the maximum number of octets that can exist in an SQL-Schema statement (such as CREATE SCHEMA), or zero if there's no fixed limit.\par
      ## 35 SQL_MAXIMUM_TABLE_NAME_LENGTH -- SMALLINT\par
The return is the length, in characters, of the largest possible <Table name>,\par
without qualifiers or introducers. Expect 18 for an SQL-89 DBMS, 128 for a\par
later DBMS. But don't be surprised if it's smaller: many implementations treat\par
<Table name> as "file name", and are therefore subject to whatever constraints the operating system imposes.\par
      ## 106 SQL_MAXIMUM_TABLES_IN_SELECT -- SMALLINT\par
The return is the maximum number of <Table name>s which may appear in a\par
query's FROM clause -- that is, after SELECT ... FROM. This will be less than\par
or equal to the maximum number of joins, and will be less than or equal to the\par
maximum number of <Table reference>s in an SQL statement as a whole, after\par
Views are expanded. A FIPS entry-level DBMS would return 15 for the maximum\par
number of <Table reference>s in an SQL statement, a FIPS intermediate-level DBMS would return 50.\par
      ## 107 SQL_MAXIMUM_USER_NAME_LENGTH -- SMALLINT\par
The return is the length, in characters, of the largest possible\par
<AuthorizationID>, without introducers or qualifiers. The value is the same as\par
the contents of SESSION_USER. Expect 18 from an SQL-89 or FIPS 127-2 entry\par
level DBMS, expect 128 from a more powerful DBMS -- unless the DBMS gets\par
<AuthorizationID>s from an outside source, such as the operating system's\par
login name. In that case, the limit ultimately depends on what the operating system says.\par
      ## 85 SQL_NULL_COLLATION -- SMALLINT\par
Returns a number between 1 and 2, depending on the placement of NULL values in sort sequences (ORDER BY). The possible options are:\par
            ## [treat NULLs as "greater than" all other values]:\par
1 (SQL_NC_HIGH)\par
            ## [treat NULLs as "less than" all other values]:\par
2 (SQL_NC_LOW)\par
      ## 90 SQL_ORDER_BY_COLUMNS_IN_SELECT -- CHAR(1)\par
Returns 'Y' if the DBMS allows only those ORDER BY Columns which also appear\par
in the select list; otherwise 'N'. For example: "SELECT column_1 FROM Table_1\par
ORDER BY column_2;" is illegal in SQL-92 (so an SQL-92 DBMS would return 'Y'), but is legal in SQL3.\par
      ## 115 SQL_OUTER_JOIN_CAPABILITIES -- INTEGER\par
(Not CHAR(1), there was an error in early versions of the SQL Standard.)\par
The return is a bitmask, with zero or more bits on, depending on the outer join variations that the DBMS supports. The possible options are:\par
            ## [simple LEFT OUTER JOIN]:\par
0001 hex (SQL_OUTER_JOIN_LEFT)\par
            ## [simple RIGHT OUTER JOIN]:\par
0002 hex (SQL_OUTER_JOIN_RIGHT)\par
            ## [FULL OUTER JOIN works]:\par
0004 hex(SQL_OUTER_JOIN_FULL)\par
            ## [outer joins may be nested]:\par
0008 hex(SQL_OUTER_JOIN_NESTED)\par
            ## [ON-clause Columns needn't be in Table order]:\par
0010 hex (SQL_OUTER_JOIN_NOT_ORDERED)\par
            ## [inner Table can be INNER JOIN]:\par
0020 hex (SQL_OUTER_JOIN_INNER)\par
            ## [ON predicate needn't be "=" comparison]:\par
0040 hex (SQL_OUTER_JOIN_ALL_COMPARISON_OPS)\par
      ## 20003 SQL_REF_LENGTH -- SMALLINT\par
The return is the length, in octets, of a <reference type>\par
      ## 43 SQL_SCROLL_CONCURRENCY -- INTEGER\par
The return is a bitmask, with zero or more bits on, depending on the DBMS's\par
ability to handle concurrency (multi-user) problems while dealing with scroll Cursors. The possible options are:\par
            ## [read-only scrollable Cursors are okay]:\par
0001 hex (SQL_SCCO_READ_ONLY)\par
            ## [updatable scrollable Cursors are okay in conjunction with lowest locking level]:\par
0002 hex (SQL_SCCO_LOCK)\par
            ## [updatable scrollable Cursors are okay in conjunction with optimistic concurrency -- row <identifier>s or timestamps]:\par
0004 hex SQL_SCCO_OPT_ROWVER)\par
            ## [updatable scrollable Cursors are okay in conjunction with optimistic concurrency -- comparing values]:\par
0008 hex (SQL_SCCO_OPT_VALUES)\par
      ## 14 SQL_SEARCH_PATTERN_ESCAPE -- CHAR(1)\par
The return is the fixed escape character which can be used for pattern\par
matching in some of the CLI Catalog functions (e.g.: SQLTables). Conceptually:\par
if the search-pattern-escape is '~', then the metadata search conducted for\par
such functions implicitly contains a clause "... LIKE ... ESCAPE '~' ...". In\par
ODBC, the DBMS may return '' if search-pattern escape is not supported for Catalog functions.\par
      ## 13 SQL_SERVER_NAME -- CHAR(128)\par
The return is a character string: the implementation-defined character string\par
which is the "actual name" of a server. This often will be the same as the\par
string returned for SQL_DATA_SOURCE_NAME, but some implementations make a distinction between "data source" and "server".\par
      ## 94 SQL_SPECIAL_CHARACTERS -- CHAR(254)\par
The return is a character string containing all characters "other than upper\par
case letters, lower case letters, digits and underscore" which can appear in <regular identifier>s.\par
            ## Note 1: This definition has nothing to do with the SQL Standard's definition for special characters.\par
            ## Note 2: This definition is not the same as the definition ODBC uses.\par
            ## Note 3: An SQL standard DBMS will return a blank string here.\par
If you want to use strange non-alphabetic characters in names, use <delimited identifier>s.\par
      ## 46 SQL_TRANSACTION_CAPABLE -- SMALLINT\par
The return is a number indicating what sort of SQL statements the DBMS allows within a transaction. The possible options are:\par
            ## [transactions are not supported at all]:\par
0 (SQL_TC_NONE)\par
            ## [DML only, DDL causes error]:\par
1 (SQL_TC_DML)\par
            ## [DML okay, DDL okay]:\par
2 (SQL_TC_ALL)\par
            ## [DML okay, DDL causes COMMIT]:\par
3 (SQL_TC_COMMIT)\par
            ## [DML okay, DDL is ignored]:\par
4 (SQL_TC_IGNORE)\par
DML stands for "data manipulation language" (SELECT, INSERT, etc.); DDL stands\par
for "data definition language" (ALTER, DROP, GRANT, CREATE, REVOKE). This\par
addresses one of the implementation-defined questions in standard SQL: is a\par
DDL statement just like any other or does it have to be in a transaction of\par
its own? Since many DBMSs will automatically COMMIT before and after a DDL\par
statement, you can expect the most common return to be SQL_TC_COMMIT. No\par
standard SQL DBMS will return SQL_TC_NONE. In ODBC, the code name is SQL_TXN_CAPABLE.\par
      ## 72 SQL_TRANSACTION_ISOLATION_OPTION -- INTEGER\par
The return is a bitmask, with zero or more bits on, depending on the isolation levels the DBMS supports. The possible options are:\par
            ## [supports READ UNCOMMITTED level]:\par
0001 hex (SQL_TRANSACTION_READ_UNCOMMITTED)\par
            ## [supports READ COMMITTED level]:\par
0002 hex (SQL_TRANSACTION_READ_COMMITTED)\par
            ## [supports REPEATABLE READ level]:\par
0004 hex (SQL_TRANSACTION_REPEATABLE_READ)\par
            ## [supports SERIALIZABLE level]:\par
0008 hex (SQL_TRANSACTION_SERIALIZABLE)\par
Standard SQL DBMSs will at least return SQL_TRANSACTION_SERIALIZABLE, since\par
SERIALIZABLE must be the default isolation level. Standard SQL DBMSs will\par
allow all four options in SET TRANSACTION statements, but it's\par
implementation-defined whether a DBMS can in fact go to a higher level. For\par
instance, the DBMS may respond to a "SET TRANSACTION ISOLATION LEVEL\par
REPEATABLE READ;" request by setting the isolation level to SERIALIZABLE, a\par
higher level. In ODBC, the code name is SQL_TXN_ISOLATION_OPTION.\par
      ## 47 SQL_USER_NAME -- CHAR(128)\par
The return is a character string which is the same value CURRENT_USER function.\par
\par
Algorithm:\par
      If (hdbc is not a handle of a dbc)\par
        return error: CLI-specific condition-invalid handle\par
      If (dbc is not connected)\par
        return error: 08003 connection exception-connection does not exist\par
      Empty the dbc's diagnostics area.\par
      If (InfoType not a valid code)\par
        return error: HY096 CLI-specific condition-invalid information type\par
\par
Notes:\par
      ## You want to write a portable DBMS application? Then you have to keep\par
asking yourself: does every DBMS support the feature(s) you're using, in the\par
way you use them? Hint: the answer is no. We've come a long way in the last\par
few years, and the support for "standard SQL" is a lot better than it once\par
was. But there are always DBMSs behind the curve, and always applications that\par
push the envelope. The SQLGetInfo function is designed to provide information\par
for the most common questions and unresolved issues.\par
      ## Many SQLGetInfo variants ask about non-standard features or\par
non-standard behaviour. If you know that your DBMS is completely standard,\par
then you shouldn't have to ask these questions.\par
\par
Example:\par
In this code snippet we will use the four main types of SQLGetInfo returns: to\par
a smallint, to a bitmask, to a CHAR(1) string and to a long string. We assume\par
that SQLConnect has happened already.\par
\par
#include "sqlcli.h"\par
...\par
SQLSMALLINT max_columns;\par
char  y_or_n      ## [2]:\par
;\par
SQLSMALLINT fd;\par
CHAR  server_name ## [129]:\par
;\par
SQLINTEGER server_name_size;\par
...\par
SQLGetInfo(hdbc,SQL_ORDER_BY_COLUMNS_IN_SELECT,y_or_n,2,NULL);\par
if (y_or_n  ## [0]:\par
=='Y')\par
  /* order-by Columns must be in the select list */;\par
SQLGetInfo(hdbc,SQL_MAXIMUM_COLUMNS_IN_TABLE,&max_columns,NULL,NULL);\par
if (max_columns > 10)\par
  /* more than 10 Columns are allowed in a select list * */\par
SQLGetInfo(hdbc,SQL_FETCH_DIRECTION,&fdirection,NULL,NULL);\par
if ( fetchdirection & FD_FETCH_ABSOLUTE)\par
  /* SQLFetchScroll can be done with FETCH ABSOLUTE */;\par
SQLGetInfo(hdbc,SQL_SERVER_NAME,server_name,129,&server_name_size);\par
if (server_name_size>0) \{\par
  /* server_name has the name of a server, null-terminated. */;\par
\par
ODBC: The SQLGetInfo function has been around since ODBC 1.0.\par
\par
Compare the ODBC prototype for SQLGetInfo with the standard SQL prototype:\par
\par
ODBC                          Standard SQL\par
  SQLRETURN  SQLGetInfo(        SQLRETURN SQLGetInfo(\par
    SQLHDBC hdbc,                 SQLHDBC hdbc,\par
    SQLSMALLINT InfoType,         SQLSMALLINT InfoType,\par
    SQLPOINTER InfoValue,         SQLPOINTER InfoValue,\par
    SQLSMALLINT BufferLength,     SQLINTEGER BufferLength,\par
    SQLSMALLINT *StringLength     SQLINTEGER *StringLength\par
    );                            );\par
\par
The types are incompatible! This will probably be fixed by the time you read\par
this -- check this book's web site to see how the matter was resolved.\par
\par
And that's it for the CLI general functions. In the next chapter, we'll take a look at the deferred parameter functions.\par
\page\par
Chapter 49 -- SQL/CLI: Deferred Parameter Functions\par
\par
This short chapter describes an option for passing input parameters after\par
execution begins. [Obscure Rule] applies for the whole thing.\par
\par
The concept behind deferred parameters is illustrated by these two flow\par
charts:\par
\par
Processing immediate parameters    Processing Deferred parameters\par
\par
--------------------               --------------\par
- SQLBindParameter -               - SQLExecute -\par
--------------------               --------------\par
        |                                |\par
----------------                        / \\\par
- SQLExecute  -                        /   \\\par
----------------                      /need \\ yes --------------\par
                                     / data? \\___ - SQLParam   -\par
                                     \\      /     - +          -\par
                                       \\  /       - SQLPutData -\par
                                        |         --------------\par
                                        | no\par
                                   --------------------------\par
                                   - SQLExecute (continued) -\par
                                   --------------------------\par
\par
Briefly stated: in the immediate-parameter situation all necessary information\par
is supplied before SQL statement execution begins; in the deferred-parameter\par
situation the execution is interrupted and the host supplies the missing\par
information by calling SQLParam and SQLPutData.\par
\par
Programmers can survive with immediate parameters alone. Indeed, in all the\par
previous chapters we have assumed that deferred parameters won't happen -- had\par
we allowed for them, we would have had to do some things differently.\par
\par
The reasons for use of deferred parameters are:\par
      ## Long strings can be passed a piece at a time. This was an important\par
thing in the days of 16-bit operating systems, when the maximum string size\par
was effectively limited by the segment size.\par
      ## Microsoft uses deferred parameters in ODBC examples and test\par
programs. \par
\par
These are the days of 32-bit operating systems. Passing large buffers is no\par
longer a problem. However, deferred parameters are still part of the standard\par
SQL CLI. You might see them in legacy code, or in some exotic applications\par
(for example, packet transfers). You will not see deferred parameters in\par
embedded SQL or PSM applications.\par
\par
How to pass deferred parameters\par
\par
The mechanism for passing deferred parameters involves a package of signals\par
and functions:\par
      ## Setting the last parameter = SQL_DATA_AT_EXEC (-2). Technically:\par
\par
Set *(APD.IDA[n].SQL_DESC_OCTET_LENGTH_POINTER) = -2\par
\par
For example:\par
#include "sqlcli.h"\par
SQLHSTMT hstmt;\par
SQLHDESC hdesc;\par
SQLINTEGER dp = SQL_DATA_AT_EXEC;\par
...\par
SQLGetStmtAttr(hstmt,SQL_ATTR_IMP_PARAM_DESC,&hdesc,NULL,NULL);\par
SQLSetDescField(hdesc,1,SQL_DESC_OCTET_LENGTH_POINTER,&dp,NULL);\par
\par
      ## Looking for SQL_NEED_DATA after SQLExecDirect or SQLExecDirect -- for\par
example:\par
\par
sqlreturn = SQLExecute(hstmt);\par
if (sqlreturn == SQL_NEED_DATA) /* deferred parameter seen ... */\par
\par
      ## Looping -- calling SQLParamData for each parameter and calling\par
SQLPutData for each piece of data in each parameter.\par
\par
The two CLI functions needed for deferred parameter support are SQLParamData\par
and SQLPutData; their descriptions follow. We'll also describe SQLCancel in\par
this chapter -- it might be used to cancel functions which are waiting for\par
deferred parameters (hence its inclusion here), but might have unrelated uses\par
as well.\par
\par
SQLParamData\par
\par
Function Prototype:\par
  SQLRETURN SQLParamData(\par
    SQLHSTMT hstmt,                /* 32-bit input */\par
    SQLPOINTER *Value              /* pointer to ANY* output */\par
    );\par
\par
Job:\par
Check whether a deferred parameter value is needed. If so: interrupt; if not:\par
continue with previously-interrupted statement execution.\par
\par
Algorithm:\par
  If (no deferred parameter number is associated with stmt)\par
    return error: HY010 CLI-specific condition-function sequence error\par
  /* A "deferred parameter" is an APD.IDA for which DEFERRED is true.\par
     DEFERRED is true if:\par
      *(APD.IDA[n].SQL_DESC_OCTET_POINTER) == SQL_DATA_AT_EXEC, i.e. -2. */\par
  If there is a deferred parameter, but no deferred parameter value:\par
    /* i.e.: if we have not already gotten the value in a prior call\par
       to SQLParamData */\par
    If (APD.IDA[n].SQL_DESC_DATA_POINTER is not a null pointer)\par
      return error: HY010 CLI-specific condition-function sequence error\par
    Set data-pointer value = Value (temporarily, for SQLPutData to see)\par
    return exception: HY(no subclass) CLI-specific condition-dynamic parameter\par
value needed\par
  /* Since there are no [more] deferred parameter values, execution can\par
     proceed. Restart the SQLExecute or SQLExecDirect process which was\par
     interrupted when deferred parameters were encountered. */\par
\par
Notes:\par
      ## SQLParam is needed if SQLExecute or SQLExecDirect returns\par
SQL_NEED_DATA (+99). In its turn, SQLParam causes a further generation of\par
SQL_NEED_DATA (if there are more parameters to process), or else it finishes\par
off the execution that began with SQLExecute or SQLExecDirect.\par
      ## If SQL_NEED_DATA has been returned, the deferred parameter must be\par
dealt with. You will get an error if you attempt to call any of these\par
functions -- SQLCopyDesc, SQLFreeHandle, SQLEndTran, SQLDisconnect,\par
SQLGetDescField, SQLGetDescRec, SQLSetDescField, SQLSetDescRec -- using the\par
same hstmt, or using a hdesc associated with the deferred parameter. A stmt\par
with a deferred parameter is considered to be "active". An active stmt may be\par
cancelled (with the SQLCancel function), but the only recommended action is to\par
call SQLParam.\par
      ## SQL_NEED_DATA is a positive value (+99). Therefore, if you use\par
deferred parameters, you must not use the blithe code we've used in our\par
examples so far:\par
\par
   if (sqlreturn < 0) /* error */\par
   if (sqlreturn >= 0) /* all's well, must be warning or success */\par
\par
As we said earlier, some of your operating assumptions must change if this\par
option is used.\par
      ## Do not confuse SQLParamData with SQLGetParamData.\par
\par
Example:\par
See next section, on SQLPutData.\par
\par
ODBC: SQLParamData has been around since ODBC 1.0.\par
\par
SQLPutData\par
\par
Function Prototype:\par
 SQLRETURN SQLPutData (\par
   SQLHSTMT hstmt,             /* 32-bit input */\par
   SQLPOINTER Data,            /* pointer to ANY* input */\par
   SQLINTEGER StrLen_Or_Ind     /* pointer to indicator|octet-length */\par
   );\par
\par
Algorithm: \par
  If (there is no deferred parameter associated with stmt)\par
    return error: HY010 CLI-specific condition-function sequence error\par
  If (there is no SQL_DESC_DATA_POINTER value)\par
    /* the data-pointer value should have been supplied by SQLBindParameter */\par
    return error: HY010 CLI-specific condition-function sequence error    \par
  /* At this point, we have enough data (via the current APD fields plus\par
     the Data and StrLen_Or_Ind parameters) to complete the input parameter\par
     description. For details of what input-parameter description process\par
     looks like, see SQLBindParameter. */\par
\par
Notes:\par
      ## SQLPutData is used only in association with SQLParamData.\par
      ## SQLPutData can be used repeatedly if (for a long character or binary\par
string) the data must be supplied in pieces.\par
      ## Nullness trumps deferrability. If there's an indicator and it's -1\par
(SQL_NULL_DATA), then the parameter passed is NULL -- there is no deferring.\par
\par
Example:\par
In the following example, we will pass "CHAR(4)" parameters in four separate\par
pieces, one character at a time. This is absurdly small -- usually pieces are\par
at least 2 kilobytes -- but it illustrates the method nicely. Try to imagine\par
that the data is input from some large file, or pipeline. The algorithm works\par
like this:\par
      ## Application initializes in the usual way.\par
      ## Application prepares an INSERT statement.\par
      ## Applications calls SQLBindParameter for two "SQL_DATA_AT_EXEC"\par
parameters. The application identifies the parameters as #1 and #2 -- later,\par
those values will be retrieved by SQLParamData. Thus the values identify which\par
parameter is being processed.\par
      ## Application calls SQLExecute for the prepared INSERT statement. DBMS\par
returns SQL_NEED_DATA because "SQL_DATA_AT_EXEC" parameters exist.\par
      ## Application calls SQLParamData. DBMS returns SQL_NEED_DATA because\par
"SQL_DATA_AT_EXEC" parameters exist. DBMS also fills in the parameter number\par
-- #1 -- from SQLBindParameter pass. Loop:\par
            ## Application calls SQLPutData for the next piece.\par
            ## Loop ends when the application has no more pieces.\par
      ## Application calls SQLParamdata again. DBMS returns SQL_SUCCESS\par
because there are no more parameters to process.\par
      ## Application cleans up in the usual way.\par
\par
#include <stdio.h>\par
#include <string.h>\par
#include "sqlcli.h"\par
\par
#define MAX_DATA_LENGTH 1\par
\par
void main ()\par
\{\par
SQLHENV     henv;\par
SQLHDBC     hdbc;\par
SQLHSTMT    hstmt;\par
SQLRETURN   rc;\par
SQLCHAR     OutData[1];\par
SQLCHAR     InData[]="abcd";\par
SQLSMALLINT Param1 = 1, Param2 = 2;\par
SQLINTEGER  Param1Length, Param2Length;\par
SQLPOINTER  pToken;\par
int         offset;\par
\par
  SQLAllocHandle(SQL_HANDLE_ENV,SQL_NULL_HANDLE,&henv);\par
  SQLAllocHandle(SQL_HANDLE_DBC,henv,&hdbc);\par
  rc=SQLConnect(hdbc,"OCELOT",SQL_NTS,"OCELOT",SQL_NTS,"",SQL_NTS);\par
  SQLAllocHandle(SQL_HANDLE_STMT,hdbc,&hstmt);\par
\par
  rc=SQLExecDirect(\par
   hstmt,"CREATE TABLE Tests(big_col_1 CHAR(4),big_col_2 CHAR(4))",SQL_NTS);\par
\par
  rc=SQLPrepare(\par
   hstmt,"INSERT INTO Tests(big_col_1,big_col_2) VALUES(?,?)",SQL_NTS);\par
\par
  /* There are two Columns. There are two ?s. There will be two parameters.\par
     Bind them with SQLBindParameter. Don't pass a buffer address (which is\par
     what you would usually do). Instead, pass 1 and 2 (Param1 contains 1\par
     and Param2 contains 2.) */\par
\par
  SQLBindParameter(\par
   hstmt,1,SQL_PARAM_MODE_IN,SQL_CHAR,SQL_CHAR,4,0,&Param1,\par
   MAX_DATA_LENGTH,&Param1Length);\par
  SQLBindParameter(\par
   hstmt,2,SQL_PARAM_MODE_IN,SQL_CHAR,SQL_CHAR,4,0,&Param2,\par
   MAX_DATA_LENGTH,&Param2Length);\par
\par
  /* Set Param1Length and Param2Length = SQL_DATA_AT_EXEC; the DBMS will see\par
     this because we passed addresses of Param1Length and Param2Length. */\par
\par
  Param1Length = Param2Length = SQL_DATA_AT_EXEC;\par
\par
  rc=SQLExecute(hstmt);\par
\par
  /* For data-at-execution parameters, call SQLParamData to get the */\par
  /* parameter number set by SQLBindParameter. Call InitUserData.   */\par
  /* Call GetUserData and SQLPutData repeatedly to get and put all  */\par
  /* data for the parameter. Call SQLParamData to finish processing */\par
  /* this parameter and start processing the next parameter.        */\par
\par
  while (rc ==  SQL_NEED_DATA) \{\par
    rc = SQLParamData(hstmt,&pToken);\par
    if (rc ==  SQL_NEED_DATA) \{\par
      for (offset=0;offset<=3;++offset) \{              /* "Initialize" */\par
        OutData[0] = InData[offset];                  /* "Get" */\par
        SQLPutData(hstmt,OutData,1); \} \} \}            /* "Put" */\par
\par
  SQLEndTran(SQL_HANDLE_DBC,hdbc,SQL_COMMIT);         /* commit */\par
\par
  SQLFreeHandle(SQL_HANDLE_STMT,hstmt);               /* cleanup + exit */\par
  SQLDisconnect(hdbc);\par
  SQLFreeHandle(SQL_HANDLE_DBC,hdbc);\par
  SQLFreeHandle(SQL_HANDLE_ENV,henv); \}\par
\par
ODBC: SQLPutData has been around since ODBC 1.0.\par
\par
SQLCancel\par
\par
Function Prototype:\par
  SQLRETURN SQLCancel(\par
    SQLHSTMT hstmt                        /* 32-bit input */\par
    );\par
\par
Job:\par
(Try to) stop a currently-executing function.\par
\par
There are two things that "currently-executing" might mean:\par
      ## Scenario #1: The hstmt is associated with a deferred parameter.\par
      ## Scenario #2: A routine associated with the stmt might be running\par
"concurrently". For example, in an MS-Windows environment, you might call a\par
CLI function in one thread, but now you're in another thread, and the function\par
is still running. You know what the stmt handle is and you want to stop the\par
function.\par
\par
Algorithm:\par
\par
For scenario #1\par
Clear the diagnostics area.\par
Disassociate the statement source and parameter number from the stmt.\par
It is now possible to call SQLEndTran, SQLDisconnect, SQLFreeHandle, etc. --\par
otherwise, you would have to fill in the deferred-parameter values. See the\par
description of deferred parameters.\par
\par
For scenario #2\par
The server receives the request to cancel.\par
The server tries to cancel.\par
If (cancel fails)\par
  /* Reasons for failure might be: communication problem, or the\par
     function is doing a "commit" (which can't be interrupted). */\par
  return error: HY018: CLI-Specific condition-Server declined the cancellation\par
request\par
If (cancel succeeds)\par
  The server returns: okay.\par
  The cancelled routine can leave diagnostics behind, if it was running\par
  asynchronously. (However, in ODBC, a routine which was cancelled from\par
  another thread will leave no diagnostics behind.)\par
\par
Notes:\par
      ## A "successful completion" of this function doesn't mean much; it only\par
means that the server has seen and accepted the request to cancel. More\par
significant is the return that the cancelled function returns: HY008\par
CLI-specific condition-operation cancelled.\par
      ## We believe that SQLCancel is used most frequently for the situation\par
described as "Scenario #1". For the situation described as "Scenario #2",\par
there is heavy dependence on operating-system features so it is not possible\par
to specify exactly how SQLCancel works in standard SQL.\par
      ## The cancelled routine might have already done some diagnostics and\par
the diagnostics area is not cleared. Other than that, a cancelled routine\par
leaves no effect.\par
\par
Example:\par
This example shows the use of SQLCancel against an active process with\par
deferred parameters.\par
\par
   #include "sqlcli.h"\par
   SQLHSTMT hstmt;\par
   ...\par
   if (SQLExecute(hstmt) == SQL_NEED_DATA) \{\par
     SQLCancel(hstmt); \}\par
\par
This example shows the use of SQLCancel against an asynchronous process on\par
another thread. It works like this: suppose you are shutting down, and there\par
is some asynch/other-thread function that you've given up on. To make sure you\par
are cancelling, you have to check two things: did SQLCancel work? (that tells\par
you that the server accepts the request to cancel), and did the cancelled\par
function fail? (that tells you that the server succeeded in cancelling).\par
\par
      /* Start asynch/other-thread/waiting function */\par
      ...\par
      Call <function> again, using the same hstmt.\par
      If (SQL_STILL_EXECUTING) \{\par
        Call SQLCancel.\par
        If ("00000" i.e. "successful completion") \{\par
          /* !! Do not assume the routine is cancelled !! */\par
          Call <function> again.\par
          If (SQL_STILL_EXECUTING) \{\par
            /* Cancellation request has not yet succeeded. Wait. */\par
            /* loop here */\par
          If (SQL_ERROR and "HY008" i.e. "operation cancelled") \{\par
            /* The cancellation is complete. The statement is over. */\par
          If (anything else) \{\par
            /* Probably the function finished normally, i.e. the */\par
            /* SQLCancel arrived too late. The statement is over. */\par
\par
ODBC: The SQLCancel function has been around since ODBC 1.0. In ODBC 2.x,\par
SQLCancel(StatementHandle) was precisely the same as\par
SQLFreeStmt(StatementHandle,SQL_CLOSE) if there was no asynch running. That is\par
no longer so! If you want to close a Cursor, with ODBC 3.x or with the\par
standard CLI, you must use SQLCloseCursor (hstmt).\par
\par
And that's it for the CLI deferred parameter functions. In the next chapter,\par
we'll take a look at the locator functions.\par
\page\par
Chapter 50 -- SQL/CLI: Locator Functions\par
\par
In this chapter, we'll describe the CLI locator functions: SQLGetLength,\par
SQLGetPosition and SQLGetSubstring. These functions are used with locators of\par
BLOBs and CLOBs. They are new in SQL3; as far as we know, no DBMS supports\par
them. Our description is therefore fairly brief.\par
\par
What is a Locator?\par
\par
When you assign the value of a BLOB, CLOB, NCLOB, UDT or ARRAY to an embedded\par
host language variable or a host language parameter, your DBMS generates and\par
assigns a locator to the target, to uniquely identify a value of the\par
corresponding type. The locator is a 4-octet, non-zero integer (that is,\par
locators are 32-bit INTs), and exists only until the current transaction ends\par
(unless it is held).\par
\par
Locators have certain properties.\par
      ## A locator may be either valid or invalid.\par
      ## A locator may be a holdable locator.\par
\par
When a locator is initially created, it is marked valid and (if applicable)\par
not holdable. You have to execute a HOLD LOCATOR statement before the end of\par
the transaction in which a locator is created if you want that locator to be\par
holdable. A non-holdable locator remains valid until the end of the\par
transaction in which it was generated, unless it is explicitly made invalid by\par
a FREE LOCATOR statement or a ROLLBACK WITH SAVEPOINT statement. A holdable\par
locator may remain valid beyond the end of the transaction in which it was\par
generated; it becomes invalid when you execute a FREE LOCATOR statement, a\par
ROLLBACK WITH SAVEPOINT statement with a SAVEPOINT clause or if the\par
transaction in which it is generated (or any subsequent transaction) is rolled\par
back. All locators are made invalid when the current SQL-session ends.\par
\par
The following items can have the "data type" LOCATOR: a host variable, a host\par
parameter, an SQL parameter in an external routine and a value returned by\par
external function. To specify an item as a locator, add the <keyword>s AS\par
LOCATOR to the specification. According to the SQL Standard, this then allows\par
the passing of very large data values "without transferring the entire value\par
to and from the SQL-agent". That is -- if you're dealing with an image, why do\par
this:\par
      ## DBMS reads into DBMS memory\par
      ## DBMS transfers to host language memory\par
      ## host language writes copy\par
The procedure could do it without transfers, with a locator.\par
\par
Standard SQL provides two statements for use with locators. Brief descriptions\par
of each follow.\par
\par
FREE LOCATOR statement\par
\par
The FREE LOCATOR statement removes the association between a locator variable\par
or parameter and the value represented by that locator. The required syntax\par
for the FREE LOCATOR statement is:\par
\par
FREE LOCATOR :host_parameter_name> [ \{,:host_parameter_name\}... ]\par
\par
The FREE LOCATOR statement frees one or more locators -- that is, it marks the\par
locators identified by the <host parameter name>s as invalid.\par
\par
If you want to restrict your code to Core SQL, don't use the FREE LOCATOR\par
statement.\par
\par
HOLD LOCATOR statement\par
\par
The HOLD LOCATOR statement marks a locator variable or parameter as a holdable\par
locator. The required syntax for the HOLD LOCATOR statement is:\par
\par
HOLD LOCATOR :host_parameter_name> [ \{,:host_parameter_name\}... ]\par
\par
The HOLD LOCATOR statement lets you change the status of one or more locators\par
from non-holdable to holdable. The difference between the two status has to do\par
with when a locator becomes invalid: a non-holdable locator remains valid\par
until the end of the transaction in which it was generated (unless it is\par
explicitly made invalid), while a holdable locator may remain valid beyond the\par
end of the transaction in which it was generated. All locators are made\par
invalid when the current SQL-session ends.\par
\par
If you want to restrict your code to Core SQL, don't use the HOLD LOCATOR\par
statement.\par
\par
The rest of this chapter describes the three CLI locator functions.\par
\par
SQLGetLength\par
\par
Function Prototype:\par
  SQLRETURN  SQLGetLength(\par
    SQLHSTMT hstmt,                 /* 32-bit input */\par
    SQLSMALLINT LocatorType,        /* 16-bit input */\par
    SQLINTEGER Locator,             /* 32-bit input */\par
    SQLINTEGER *StringLength,       /* pointer to 32-bit output */\par
    SQLINTEGER *IndicatorValue      /* pointer to 32-bit output */\par
    );\par
\par
Job:\par
Return the length of the value represented by a BLOB, CLOB, NCLOB, UDT or\par
ARRAY locator.\par
\par
Algorithm:\par
If (there is a prepared statement associated with hstmt)\par
  return error: HY010 CLI-specific condition-function sequence error\par
If (LocatorType is not SQL_BLOB_LOCATOR or SQL_CLOB_LOCATOR or SQL_UDT_LOCATOR\par
or SQL_ARRAY_LOCATOR)\par
  return error: CLI-specific condition-invalid argument value\par
If (Locator does not refer to a Locator)\par
  return error: 0F001 locator exception-invalid specification\par
If (LocatorType==SQL_BLOB_LOCATOR and Locator doesn't refer to a BLOB)\par
Or (LocatorType==SQL_CLOB_LOCATOR and Locator doesn't refer to a CLOB)\par
Or (LocatorType==SQL_UDT_LOCATOR and Locator doesn't refer to a UDT)\par
Or (LocatorType==SQL_ARRAY_LOCATOR and Locator doesn't refer to an ARRAY)\par
  return error: dynamic SQL error-restricted data type attribute violation     \par
  \par
Case:\par
If (the Large Object's value is NULL)\par
  If (IndicatorValue is a null pointer)\par
    return error: data exception-null value, no indicator parameter\par
    Set *IndicatorValue = SQL_NULL_DATA i.e. -1\par
Else\par
  If (IndicatorValue is not a null pointer)\par
    Set *IndicatorValue = 0\par
  If (LocatorType == SQL_BLOB_LOCATOR)\par
    Set *StringLength = length of BLOB, in octets\par
  If (LocatorType==SQL_CLOB_LOCATOR)\par
    Set *StringLength = length of CLOB, in characters \par
  If (LocatorType==SQL_UDT_LOCATOR)\par
    Set *StringLength = length of UDT, in octets\par
  If (LocatorType==SQL_ARRAY_LOCATOR)\par
    Set *StringLength = length of ARRAY, in octets\par
\par
Notes:\par
      ## The octet length and the character length will be the same value only\par
if 8-bit Character sets are in use.\par
\par
Example:\par
      #include "sqlcli.h"\par
      ...\par
      SQLINTEGER  lob;              /* large object locator */\par
      SQLINTEGER  len;              /* length */\par
      SQLINTEGER  ind;              /* indicator */\par
      ...\par
      SQLGetLength(hstmt,SQL_CLOB_LOCATOR,lob,&len,&ind);\par
\par
ODBC: Since this is an SQL3 function, it is not in ODBC 3.0.\par
\par
SQLGetPosition\par
\par
Function Prototype:\par
  SQLRETURN SQLGetPosition(\par
    SQLHSTMT StatementHandle,         /* 32-bit input */\par
    SQLSMALLINT LocatorType,          /* 16-bit input */\par
    SQLINTEGER SourceLocator,         /* 32-bit input */\par
    SQLINTEGER SearchLocator,         /* 32-bit input */\par
    SQLCHAR *SearchLiteral,           /* pointer to *ANY */\par
    SQLINTEGER SearchLiteralLength,    /* 32-bit input */\par
    SQLINTEGER FromPosition,          /* 32-bit input */\par
    SQLINTEGER *LocatedAt,            /* pointer to 32-bit integer */\par
    SQLINTEGER *IndicatorValue        /* pointer to 32-bit integer */\par
    );\par
\par
Job:\par
Return the position of a passed string within a BLOB, CLOB, NCLOB, UDT or\par
ARRAY.\par
\par
Algorithm:\par
  if (stmt is associated with a prepared or executed statement)\par
    return error: HY010 CLI-specific condition-function sequence error\par
      If (LocatorType is not SQL_BLOB_LOCATOR or SQL_CLOB_LOCATOR or\par
SQL_UDT_LOCATOR or SQL_ARRAY_LOCATOR)\par
    return error: CLI-specific condition-invalid argument value\par
  If (Locator does not refer to a Locator)\par
    return error: 0F001 locator exception-invalid specification\par
  If (LocatorType==SQL_BLOB_LOCATOR and Locator doesn't refer to a BLOB)\par
  Or (LocatorType==SQL_CLOB_LOCATOR and Locator doesn't refer to a CLOB)\par
  Or (LocatorType==SQL_UDT_LOCATOR and Locator doesn't refer to a UDT)\par
  Or (LocatorType==SQL_ARRAY_LOCATOR and Locator doesn't refer to an ARRAY)\par
    return error: dynamic SQL error-restricted data type attribute violation\par
  If (the Large Object's value is NULL)\par
    If (IndicatorValue is a null pointer)\par
      return error: data exception-null value, no indicator parameter\par
    Set *IndicatorValue = SQL_NULL_DATA i.e. -1\par
  Else\par
    If (IndicatorValue is not a null pointer)\par
      Set *IndicatorValue = 0;\par
  Set *LocatedAt = position of string within the BLOB or CLOB or NCLOB or UDT\par
or ARRAY.\par
\par
ODBC: Since this is an SQL3 function, it is not in ODBC 3.0.\par
\par
SQLGetSubstring\par
\par
Function Prototype\par
  SQLRETURN  SQLGetSubString(\par
    SQLHSTMT StatementHandle,             /* 32-bit input */\par
    SQLSMALLINT LocatorType,              /* 16-bit input */\par
    SQLINTEGER SourceLocator,             /* 32-bit input */\par
    SQLINTEGER FromPosition,              /* 32-bit input */\par
    SQLINTEGER ForLength,                 /* 32-bit input */\par
    SQLSMALLINT TargetType,               /* 16-bit input */\par
    SQLPOINTER TargetValue                /* pointer to output */\par
    SQLINTEGER BufferLength,              /* 32-bit input */\par
    SQLINTEGER *StringLength,             /* pointer to integer output */\par
    SQLINTEGER *IndicatorValue);          /* pointer to integer output */\par
\par
Job:\par
Extract a portion of a BLOB, CLOB, NCLOB, UDT or ARRAY, returning the result\par
as a string or, alternatively, as a new BLOB, CLOB, NCLOB, UDT or ARRAY.\par
\par
Algorithm:\par
  if (stmt is associated with a prepared or executed statement)\par
    return error: HY010 CLI-specific condition-function sequence error\par
  If (LocatorType is not SQL_BLOB_LOCATOR or SQL_CLOB_LOCATOR or\par
SQL_UDT_LOCATOR or SQL_ARRAY_LOCATOR)\par
    return error: CLI-specific condition-invalid argument value\par
  If (Locator does not refer to a Locator)\par
    return error: 0F001 locator exception-invalid specification\par
  If (LocatorType==SQL_BLOB_LOCATOR and Locator doesn't refer to a BLOB)\par
  Or (LocatorType==SQL_CLOB_LOCATOR and Locator doesn't refer to a CLOB)\par
  Or (LocatorType==SQL_UDT_LOCATOR and Locator doesn't refer to a UDT)\par
  Or (LocatorType==SQL_ARRAY_LOCATOR and Locator doesn't refer to an ARRAY)\par
    return error: dynamic SQL error-restricted data type attribute violation\par
  If (the Large Object's value is NULL)\par
    If (IndicatorValue is a null pointer)\par
      return error: data exception-null value, no indicator parameter\par
    Set *IndicatorValue = SQL_NULL_DATA i.e. -1\par
  Else\par
    If (IndicatorValue is not a null pointer)\par
      Set *IndicatorValue = 0;\par
  Transfer the substring from the BLOB, CLOB, NCLOB, UDT or ARRAY to\par
TargetValue, using a procedure analogous to Character Retrieval Procedure.\par
\par
ODBC: Since this is an SQL3 function, it is not in ODBC 3.0.\par
\par
And that's it for the CLI locator functions. In the next (and final) chapter\par
on the CLI, we'll take a look at the Catalog functions.\par
\page\par
Chapter 51 -- SQL/CLI: Catalog Functions\par
\par
The CLI Catalog functions are so called because they involve implicit searches\par
of the metadata -- what in pre-SQL-92 days was known as the system catalog.\par
Nowadays the metadata is in INFORMATION_SCHEMA. The functions, and the\par
INFORMATION_SCHEMA Views which provides most of the information for them, are:\par
\par
Function             Related INFORMATION_SCHEMA View(s)\par
SQLColumnPrivileges  COLUMN_PRIVILEGES\par
SQLColumns           COLUMNS\par
SQLForeignKeys       KEY_COLUMN_USAGE, REFERENTIAL_CONSTRAINTS, \par
                     TABLE_CONSTRAINTS\par
SQLGetTypeInfo\par
SQLParameters        PARAMETERS\par
SQLPrimaryKeys       KEY_COLUMN_USAGE, TABLE_CONSTRAINTS\par
SQLRoutinePrivileges ROUTINE_PRIVILEGES\par
SQLRoutines          ROUTINES\par
SQLSpecialColumns    COLUMNS\par
SQLTablePrivileges   TABLES, TABLE_PRIVILEGES\par
SQLTables            TABLES\par
\par
You should study Catalog functions if:\par
      ## Your problem matches the limited range of ad-hoc solutions offered\par
here.\par
      ## They're the standard in your shop.\par
      ## You're maintaining an old ODBC program.\par
      ## Your DBMS doesn't support INFORMATION_SCHEMA.\par
      ## You want to see what extremely long SELECT statements look like.\par
Otherwise, study the description of the INFORMATION_SCHEMA in our chapter on\par
Catalogs and use the simple mechanisms you already know. It's cleaner to\par
SELECT from a View in INFORMATION_SCHEMA.\par
\par
Some necessary preliminaries\par
\par
Calling a Catalog function is equivalent to calling SQLExecDirect with an\par
argument containing a SELECT statement. That means that data is returned in a\par
result set. You may traverse the rows in the result set using SQLFetch or\par
SQLFetchScroll. You should call SQLCloseCursor when there is nothing more to\par
fetch.\par
\par
For most Catalog functions, you pass (character string) input parameters to\par
specify which rows should be selected for the result set. There are several\par
rules concerning these input parameters. There is no use trying to figure out\par
what the rationale is behind these rules. You'll simply have to learn them if\par
you want Catalog functions to work reliably. Here they are:\par
      ## Accessible tables. You may recall that there is an option to the\par
SQLGetInfo function, namely SQL_ACCESSIBLE_TABLES, which returns as follows:\par
            ## 'Y': the DBMS only returns information about Tables to users\par
who have SELECT Privileges on the Tables.\par
            ## 'N': the DBMS returns information about Tables based on some\par
other, implementation-defined, criterion.\par
In fact, all standard DBMSs should return 'N' because information is available\par
to users who have any Privileges on the Tables, not necessarily just SELECT\par
Privileges. In all that follows, we will just assume that the\par
INFORMATION_SCHEMA rows are the rows that would be available in standard SQL.\par
      ## Catalogs. Not every DBMS supports Catalogs. For the cases where we\par
say that a <Catalog name> is retrieved, it is possible that the actual\par
retrieval will be NULL. Once again, this is a case where NULL means "not\par
applicable".\par
      ## Length. All input-string parameters are accompanied by a SMALLINT\par
parameter -- the "length". This length should be the number of octets in the\par
input string. The special value SQL_NTS is permissible. The special value 0\par
(zero) is permissible, and a zero-length string means "don't care" -- for\par
example, if you pass a zero-length string for a parameter named *SchemaName,\par
the DBMS will accept all <Schema name>s in the Catalog.\par
      ## Metadata ID. You may recall that there is an option to the\par
SQLGetStmtAttr function, namely SQL_ATTR_METADATA_ID, which returns either\par
TRUE (the METADATA ID attribute is TRUE) or FALSE (the METADATA ID attribute\par
is FALSE).\par
            ## If METADATA ID is TRUE:\par
                  ## If there is such a thing as a <Catalog name> (which is\par
the case in all standard DBMSs), then you must not pass a null pointer for any\par
Catalog function parameter which is labelled *CatalogName. Passing a null\par
pointer will result in the error: HY009 CLI-specific condition-invalid use of\par
null pointer.\par
                  ## You must not pass a null pointer for any Catalog function\par
parameter which is labelled *SchemaName. Passing a null pointer will result in\par
the error: HY009 CLI-specific condition-invalid use of null pointer.\par
                  ## You may pass a string which begins and ends with quotes,\par
as is the custom for <delimited identifier>s. If you do pass a quoted string,\par
the quotes are stripped and the string is not converted to upper case. If you\par
don't pass a quoted string, the string is converted to upper case.\par
            ## If METADATA ID is FALSE:\par
                  ## You may pass a null pointer for any string parameter.\par
Doing so is equivalent to passing a string with zero length.\par
                  ## The string may be treated as a search pattern; that is,\par
wild cards are allowed as they are in LIKE predicates. If you need to find out\par
what the value is for the escape character, call\par
SQLGetInfo(hstmt,SQL_SEARCH_PATTERN_ESCAPE,...).\par
\par
** TIP: you'll only have to learn one set of rules if METADATA ID is always\par
TRUE. Therefore, as soon as you allocate a stmt, execute this function:\par
\par
   SQLSetStmtAttr(hstmt,SQL_ATTR_METADATA_ID,&1,NULL);\par
\par
and leave it that way. Henceforward, we'll forget about the possibility that\par
METADATA ID could be FALSE.\par
\par
In ODBC, searching is different in significant ways: quotes are not stripped,\par
<identifier>s are always converted to upper case, regardless of the value of\par
METADATA ID. If quotes are not present, then trail spaces are trimmed. The\par
character used for <delimited identifier>s may be something other than a quote\par
mark.\par
\par
** TIP: There's no way to remove the incompatibilities between standard SQL\par
and ODBC here, but they won't matter if you follow two policies. One: avoid\par
<delimited identifier>s. Two: pass all string values in upper case.\par
\par
SQLColumnPrivileges\par
\par
Function Prototype:\par
  SQLRETURN SQLColumnPrivileges(\par
    SQLHSTMT hstmt,                 /* 32-bit input */\par
    SQLCHAR *CatalogName,           /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength1,        /* 16-bit input */\par
    SQLCHAR *SchemaName,            /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength2,        /* 16-bit input */\par
    SQLCHAR *TableName,             /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength3,        /* 16-bit input */\par
    SQLCHAR *ColumnName,            /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength4         /* 16-bit input */\par
    );\par
\par
Job:\par
Get metadata concerning Column Privileges.\par
\par
Algorithm:\par
  Execute the following SELECT statement and return a result set.\par
\par
         SELECT\par
          TABLE_CATALOG AS table_cat,   /* VARCHAR(128) */\par
          TABLE_SCHEMA AS table_schem,  /* VARCHAR(128) NOT NULL */\par
          TABLE_NAME,                   /* VARCHAR(128) NOT NULL */\par
          COLUMN_NAME,                 /* VARCHAR(128) NOT NULL */\par
          GRANTOR,                      /* VARCHAR(128) */\par
          GRANTEE,                      /* VARCHAR(128) NOT NULL */\par
          PRIVILEGE_TYPE AS privilege,  /* VARCHAR(128) NOT NULL */\par
          IS_GRANTABLE                  /* VARCHAR(3) */\par
         FROM INFORMATION_SCHEMA.COLUMN_PRIVILEGES\par
         WHERE\par
          CATALOG_NAME = ?              /* use CatalogName parameter */\par
          AND SCHEMA_NAME = ?           /* use SchemaName parameter */\par
          AND TABLE_NAME = ?            /* use TableName parameter */\par
          AND COLUMN_NAME = ?           /* use ColumnName parameter */\par
         ORDER BY table_cat,table_schem,TABLE_NAME,COLUMN_NAME,privilege;\par
\par
Notes:\par
      ## The algorithm's SELECT statement does not reflect some minor matters.\par
See the earlier section titled "Some Necessary Preliminaries".\par
\par
Example\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  SQLCHAR CatalogName[128+1],SchemaName[128+1],TableName[128+1];\par
  SQLCHAR ColumnName[128+1];\par
  SQLRETURN sqlreturn;\par
  ...\par
  sqlreturn = SQLColumnPrivileges(\par
    hstmt,CatalogName,SQL_NTS,SchemaName,SQL_NTS,TableName,\par
    SQL_NTS,ColumnName,SQL_NTS);\par
\par
ODBC: SQLColumnPrivileges has been around since ODBC 1.0. However, searching\par
is significantly different: see the earlier section titled "Some Necessary\par
Preliminaries".\par
\par
SQLColumns\par
\par
Function Prototype:\par
  SQLRETURN SQLColumns(\par
    SQLHSTMT hstmt,                 /* 32-bit input */\par
    SQLCHAR *CatalogName,           /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength1,        /* 32-bit input */\par
    SQLCHAR *SchemaName,            /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength2,        /* 32-bit input */\par
    SQLCHAR *TableName,             /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength3,        /* 32-bit input */\par
    SQLCHAR *ColumnName,            /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength4         /* 16-bit input */\par
    );\par
\par
Job:\par
Get metadata concerning Columns.\par
\par
Algorithm:\par
  Execute the following SELECT statement and return a result set.\par
\par
      SELECT\par
      TABLE_CATALOG AS table_cat,            /* VARCHAR(128) */\par
      TABLE_SCHEMA  AS table_schem,          /* VARCHAR(128) NOT NULL */\par
      TABLE_NAME,                            /* VARCHAR(128) NOT NULL */\par
      COLUMN_NAME,                           /* VARCHAR(128) NOT NULL */\par
      CASE DATA_TYPE\par
        WHEN 'CHARACTER' THEN 1\par
        WHEN 'NUMERIC' THEN 2\par
        WHEN 'DECIMAL' THEN 3\par
        WHEN 'INTEGER' THEN 4\par
        WHEN 'SMALLINT' THEN 5\par
        WHEN 'FLOAT' THEN 6\par
        WHEN 'REAL' THEN 7\par
        WHEN 'DOUBLE PRECISION' THEN 8\par
        WHEN 'VARCHAR' THEN 12\par
        WHEN 'BIT' THEN 14\par
        WHEN 'BIT VARYING' THEN 15\par
        WHEN 'REF' THEN 20\par
        WHEN 'DATE' THEN 91\par
        WHEN 'TIME' THEN 92\par
        WHEN 'TIMESTAMP' THEN 93\par
        WHEN 'TIME WITH TIME ZONE' THEN 94\par
        WHEN 'TIMESTAMP WITH TIME ZONE' THEN 95\par
        WHEN 'INTERVAL' THEN\par
          CASE INTERVAL_TYPE\par
            WHEN 'YEAR' THEN 101\par
            WHEN 'MONTH' THEN 102\par
            WHEN 'DAY' THEN 103\par
            WHEN 'HOUR' THEN 104\par
            WHEN 'MINUTE' THEN 105\par
            WHEN 'SECOND' THEN 106\par
            WHEN 'YEAR TO MONTH' THEN 107\par
            WHEN 'DAY TO HOUR' THEN 108\par
            WHEN 'DAY TO MINUTE' THEN 109\par
            WHEN 'DAY TO SECOND' THEN 110\par
            WHEN 'HOUR TO MINUTE' THEN 111\par
            WHEN 'HOUR TO SECOND' THEN 112\par
            WHEN 'MINUTE TO SECOND' THEN 113\par
            END\par
        END AS DATA_TYPE,                        /* SMALLINT */\par
      DATA_TYPE     AS TYPE_NAME,                /* VARCHAR(128) NOT NULL */\par
      CASE \par
        WHEN DATA_TYPE = 'CHARACTER'\par
          OR DATA_TYPE = 'VARCHAR'\par
          OR DATA_TYPE = 'CLOB'\par
          OR DATA_TYPE = 'BLOB'\par
          OR DATA_TYPE = 'BIT'\par
          OR DATA_TYPE = 'BIT VARYING'\par
          THEN CHARACTER_MAXIMUM_LENGTH\par
        WHEN DATA_TYPE = 'NUMERIC'\par
          OR DATA_TYPE = 'DECIMAL'\par
          OR DATA_TYPE = 'SMALLINT'\par
          OR DATA_TYPE = 'INTEGER'\par
          OR DATA_TYPE = 'REAL'\par
          OR DATA_TYPE = 'FLOAT'\par
          OR DATA_TYPE = 'DOUBLE PRECISION'\par
          THEN NUMERIC_PRECISION\par
        WHEN DATA_TYPE = 'DATE' THEN 10\par
        WHEN DATA_TYPE = 'TIME' THEN\par
          CASE\par
            WHEN DATETIME_PRECISION > 0 THEN 9+DATETIME_PRECISION\par
            ELSE 8\par
            END\par
          END\par
        WHEN DATA_TYPE = 'TIMESTAMP' THEN\par
          CASE\par
            WHEN DATETIME_PRECISION > 0 THEN 20+DATETIME_PRECISION\par
            ELSE 19\par
            END\par
          END\par
        WHEN DATA_TYPE = 'TIME WITH TIME ZONE' THEN\par
          CASE\par
            WHEN DATETIME_PRECISION > 0 THEN 15+DATETIME_PRECISION\par
            ELSE 14\par
            END\par
          END\par
        WHEN DATA_TYPE = 'TIMESTAMP WITH TIME ZONE' THEN\par
          CASE\par
            WHEN DATETIME_PRECISION > 0 THEN 26+DATETIME_PRECISION\par
            ELSE 25\par
            END\par
          END\par
        END AS COLUMN_SIZE,                            /* INTEGER */\par
      CHARACTER_OCTET_LENGTH AS BUFFER_LENGTH,         /* INTEGER */\par
      CASE\par
        WHEN DATA_TYPE = 'DATE'\par
          OR DATA_TYPE = 'TIME'\par
          OR DATA_TYPE = 'TIMESTAMP'\par
          OR DATA_TYPE = 'TIME WITH TIME ZONE'\par
          OR DATA_TYPE = 'TIMESTAMP WITH TIME ZONE'\par
          THEN DATETIME_PRECISION\par
        WHEN DATA_TYPE = 'NUMERIC'\par
          OR DATA_TYPE = 'DECIMAL'\par
          OR DATA_TYPE = 'SMALLINT'\par
          OR DATA_TYPE = 'INTEGER'\par
          THEN NUMERIC_SCALE\par
        ELSE NULL\par
        END AS DECIMAL_DIGITS,                     /* SMALLINT */\par
      NUMERIC_PRECISION_RADIX AS num_prec_radix,   /* SMALLINT */\par
      CASE\par
        WHEN IS_NULLABLE='NO' THEN 0\par
        ELSE 1\par
        END AS  nullable,                         /* SMALLINT NOT NULL */\par
      '' AS remarks,                            /* VARCHAR(254) */\par
      COLUMN_DEFAULT AS COLUMN_DEF,             /* VARCHAR(254) */\par
      CASE DATA_TYPE\par
        WHEN 'CHARACTER' THEN 1\par
        WHEN 'NUMERIC' THEN 2\par
        WHEN 'DECIMAL' THEN 3\par
        WHEN 'INTEGER' THEN 4\par
        WHEN 'SMALLINT' THEN 5\par
        WHEN 'FLOAT' THEN 6\par
        WHEN 'REAL' THEN 7\par
        WHEN 'DOUBLE PRECISION' THEN 8\par
        WHEN 'VARCHAR' THEN 12\par
        WHEN 'BIT' THEN 14\par
        WHEN 'BIT VARYING' THEN 15\par
        WHEN 'REF' THEN 20\par
        WHEN 'DATE' THEN 9\par
        WHEN 'TIME' THEN 9\par
        WHEN 'TIMESTAMP' THEN 9\par
        WHEN 'TIME WITH TIME ZONE' THEN 9\par
        WHEN 'TIMESTAMP WITH TIME ZONE' THEN 9\par
        WHEN 'INTERVAL' THEN 10\par
        END AS sql_data_type,                        /* SMALLINT */\par
      CASE DATA_TYPE\par
        WHEN 'DATE' THEN 1\par
        WHEN 'TIME' THEN 2\par
        WHEN 'TIMESTAMP' THEN 3\par
        WHEN 'TIME WITH TIME ZONE' THEN 4\par
        WHEN 'TIMESTAMP WITH TIME ZONE' THEN 5\par
        WHEN 'INTERVAL' THEN \par
          CASE INTERVAL_TYPE\par
            WHEN 'YEAR' THEN 1\par
            WHEN 'MONTH' THEN 2\par
            WHEN 'DAY' THEN 3\par
            WHEN 'HOUR' THEN 4\par
            WHEN 'MINUTE' THEN 5\par
            WHEN 'SECOND' THEN 6\par
            WHEN 'YEAR TO MONTH' THEN 7\par
            WHEN 'DAY TO HOUR' THEN 8\par
            WHEN 'DAY TO MINUTE' THEN 9\par
            WHEN 'DAY TO SECOND' THEN 100\par
            WHEN 'HOUR TO MINUTE' THEN 11\par
            WHEN 'HOUR TO SECOND' THEN 12\par
            WHEN 'MINUTE TO SECOND' THEN 13\par
            END\par
        ELSE NULL AS sql_datetime_sub,             /* INTEGER */\par
       CHARACTER_OCTET_LENGTH AS char_octet_length,/* INTEGER */\par
       ORDINAL_POSITION,                           /* INTEGER NOT NULL */\par
       IS_NULLABLE,                                /* VARCHAR(254) */\par
       CHARACTER_SET_CATALOG AS char_set_cat,      /* VARCHAR(128) */\par
       CHARACTER_SET_SCHEMA  AS char_set_schem,    /* VARCHAR(128) */\par
       CHARACTER_SET_NAME    AS char_set_name,     /* VARCHAR(128) */\par
       COLLATION_CATALOG     AS collation_cat,     /* VARCHAR(128) */\par
       COLLATION_SCHEMA      AS collation_schem,   /* VARCHAR(128) */\par
       COLLATION_NAME,                             /* VARCHAR(128) */\par
       USER_DEFINED_TYPE_CATALOG AS udt_cat,       /* VARCHAR(128) */\par
       USER_DEFINED_TYPE_SCHEMA AS udt_schem,      /* VARCHAR(128) */\par
       USER_DEFINED_TYPE_NAME AS udt_name          /* VARCHAR(128) */\par
      FROM INFORMATION_SCHEMA.COLUMNS\par
      WHERE\par
            CATALOG_NAME = ?             /* From CatalogName parameter */\par
            AND SCHEMA_NAME = ?          /* From SchemaName parameter */\par
            AND TABLE_NAME = ?           /* From TableName parameter */\par
            AND COLUMN_NAME = ?         /* From ColumnName parameter */\par
      ORDER BY table_cat,table_schem,TABLE_NAME,ORDINAL_POSITION;\par
\par
Notes:\par
      ## The algorithm's SELECT statement does not reflect some minor matters.\par
See the earlier section titled "Some Necessary Preliminaries".\par
      ## Some of the newer SQL3 <data type>s, for instance BOOLEAN, are not\par
yet representable by a numeric DATA_TYPE code.\par
      ## TYPE_NAME is implementation-defined. This field is supposed to\par
accommodate DBMSs which use non-standard <data type> names.\par
      ## COLUMN_SIZE is implementation-defined when the <data type> is\par
SMALLINT, INTEGER, REAL, FLOAT or DOUBLE PRECISION. For what's above, we\par
assumed that the DBMS will return NUMERIC_PRECISION.\par
      ## What's above does not show all the calculations required for INTERVAL\par
<data type>s. Put simply, the rule is that COLUMN_SIZE is the number of\par
positions.\par
      ## BUFFER_LENGTH is implementation-defined. The intent is that the value\par
should be the number of octets transferred during SQLFetch or SQLFetchScroll,\par
so for character string <data type>s the source would be the\par
CHARACTER_OCTET_LENGTH Column in INFORMATION_SCHEMA.COLUMNS.\par
      ## REMARKS is implementation-defined.\par
      ## SQL_DATA_TYPE is not defined at all. What's above is what we believe\par
was the intention.\par
      ## For SQL_DATETIME_SUB, the Standard contains errors. What's above is\par
what we believe was the intention.\par
      ## SQL_DATA_TYPE, CHAR_OCTET_LENGTH, ORDINAL_POSITION and IS_NULLABLE\par
are not defined in the Standard. What's above is what we believe was the\par
intention.\par
      ## The Columns UDT_CAT, UDT_SCHEM and UDT_NAME are strictly SQL3 (for\par
user-defined types). To run the query with an SQL-92 DBMS, remove the\par
references to those fields.\par
\par
Example:\par
Given <Table name> T, make an SQL statement which selects all the Columns in T\par
without using the "*" shorthand. For example: if T has two Columns -- COLUMN_1\par
and COLUMN_2 -- the output string will be:\par
\par
   SELECT COLUMN_1,COLUMN_2 FROM T;\par
\par
Use this only with <regular identifier>s.\par
\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  SQLCHAR select_statement[1024];\par
  SQLCHAR column_name[128+1];\par
  ...\par
  sqlreturn = SQLColumns(\par
    hstmt,"OCELOT",SQL_NTS,"OCELOT",SQL_NTS,"T",SQL_NTS,NULL,0);\par
  /* Take column_name from the fourth Column in the result: COLUMN_NAME. */\par
  SQLBindCol(hstmt,4,SQL_CHAR,column_name,128+1,NULL);\par
  strcpy(select_statement,"SELECT ");\par
  for (;;) \{\par
    sqlreturn = SQLFetch(hstmt);\par
    if (sqlreturn == SQL_NO_DATA) break;\par
    strcat(select_statement,column_name);\par
    strcat(select_statement,","); \}\par
  SQLCloseCursor(hstmt);    \par
  select_statement[strlen(select_statement)-1]='\\0'; /* elim final "," */\par
  strcat(select_statement," FROM T");\par
  SQLExecDirect(hstmt,select_statement,SQL_NTS);\par
\par
ODBC: SQLColumns has been around since ODBC 1.0. The final three\par
Columns (UDT_CAT, UDT_SCHEM, UDT_NAME) do not appear in ODBC.\par
\par
SQLForeignKeys\par
\par
Function Prototype:\par
  SQLRETURN SQLForeignKeys(\par
    SQLHSTMT hstmt,              /* 32-bit input */\par
    SQLCHAR *PKCatalogName,       /* pointer to CHAR * input */\par
    SQLSMALLINT NameLength1,      /* 16-bit input */\par
    SQLCHAR *PKSchemaName,        /* pointer to CHAR * input */    \par
    SQLSMALLINT NameLength2,      /* 16-bit input */\par
    SQLCHAR *PKTableName,         /* pointer to CHAR * input */\par
    SQLSMALLINT NameLength3,      /* 16-bit input */\par
    SQLCHAR *FKCatalogName,       /* pointer to CHAR * input */\par
    SQLSMALLINT NameLength4,      /* 16-bit input */\par
    SQLCHAR *FKSchemaName,        /* pointer to CHAR * input */\par
    SQLSMALLINT NameLength5,      /* 16-bit input */\par
    SQLCHAR *FKTableName,         /* pointer to CHAR * input */\par
    SQLSMALLINT NameLength6       /* 16-bit input */\par
    );\par
\par
Job:\par
Depending on the input parameters,SQLForeignKeys will either (a) return a\par
result set with information about a referenced Table, (b) return a result set\par
with information about a referencing Table or (c) both (a) and (b). By\par
definition, every foreign key is associated with one referencing Table, one\par
referenced Table and one primary or unique key. The returned result set will\par
contain information about them too.\par
\par
Algorithm:\par
To visualize how the DBMS gets the result set and what it will contain, assume\par
that the DBMS makes a View and then SELECTS from it. We are trying, in the\par
following CREATE VIEW statement, to make it clear what each <Column name> will\par
be (that's why there are AS clauses) and what each Column <data type> will be\par
(that's why there are /* comments */). The View we're creating is a join of\par
three INFORMATION_SCHEMA Views: KEY_COLUMN_USAGE, REFERENTIAL_CONSTRAINTS and\par
TABLE_CONSTRAINTS.\par
\par
   CREATE VIEW TEMPORARY_VIEW AS SELECT\par
      UK.TABLE_CATALOG    AS UK_table_cat,    /* VARCHAR(128) */\par
      UK.TABLE_SCHEMA     AS UK_table_schem,  /* VARCHAR(128) NOT NULL */\par
      UK.TABLE_NAME       AS UK_TABLE_NAME,   /* VARCHAR(128) NOT NULL */\par
      UK.COLUMN_NAME      AS UK_COLUMN_NAME,  /* VARCHAR(128) NOT NULL */\par
      FK.TABLE_CATALOG    AS FK_table_cat,    /* VARCHAR(128) */\par
      FK.TABLE_SCHEMA     AS FK_table_schem,  /* VARCHAR(128) NOT NULL */\par
      FK.TABLE_NAME       AS FK_TABLE_NAME,   /* VARCHAR(128) NOT NULL */\par
      FK.COLUMN_NAME      AS FK_COLUMN_NAME,  /* VARCHAR(128) NOT NULL */\par
      CO.ORDINAL_POSITION AS ORDINAL_POSITION,/* SMALLINT NOT NULL */\par
      CASE FK.UPDATE_RULE\par
        WHEN 'CASCADE'     0\par
        WHEN 'SET NULL'    2\par
        WHEN 'NO ACTION'   3\par
        WHEN 'SET DEFAULT' 4\par
        END                AS UPDATE_RULE,     /* SMALLINT */\par
      CASE FK.DELETE_RULE\par
        WHEN 'CASCADE'     0\par
        WHEN 'SET NULL'    2\par
        WHEN 'NO ACTION'   3\par
        WHEN 'SET DEFAULT' 4\par
        END                AS DELETE_RULE,     /* SMALLINT */\par
      FK.CONSTRAINT_NAME   AS FK_NAME,         /* VARCHAR(128) */\par
      UK.CONSTRAINT_NAME   AS UK_NAME,         /* VARCHAR(128) */\par
      CASE UK.CONSTRAINT_TYPE\par
        WHEN 'PRIMARY KEY' 'PRIMARY'\par
        WHEN 'UNIQUE KEY'  'UNIQUE '\par
        END                AS UNIQUE_OR_PRIMARY /* CHAR(7) */\par
      FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE AS CO,\par
           INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS AS FK,\par
           INFORMATION_SCHEMA.TABLE_CONSTRAINTS AS UK\par
      WHERE\par
            CO.CONSTRAINT_NAME = FK.CONSTRAINT_NAME          /* see note */\par
            AND\par
            FK.UNIQUE_CONSTRAINT_NAME = UK.CONSTRAINT_NAME   /* see note */\par
\par
Incidentally, the Standard needs 15 pages to express the above, so this is a\par
tribute to the expressive power of the SELECT statement. To get our result\par
set, we will SELECT from this View. For the sake of an example, assume there\par
are three Tables, with these definitions:\par
\par
   CREATE TABLE T1 ( \par
      t1_col_1 ... PRIMARY KEY);\par
\par
   CREATE TABLE T2 ( \par
      t2_col_1 ... PRIMARY KEY, \par
      t2_col_2 ... REFERENCES T1);\par
\par
   CREATE TABLE T3 ( \par
      t3_col_1 ... REFERENCES T1, \par
      t3_col_2 ... REFERENCES T2);\par
\par
In the following, we use the words "is passed" to mean "is not a null pointer\par
and does not contain all spaces".\par
\par
[1] If the PKTableName parameter is passed, search the temporary  View,\par
looking for primary key:\par
\par
   SELECT * FROM TEMPORARY_VIEW\par
   WHERE UK_TABLE_NAME = ?   /* ? is for the *PKTableName parameter */\par
   AND UK_SCHEMA_NAME = ?    /* included if *PKSchemaName is passed */\par
   AND UK_CATALOG_NAME = ?   /* included if *PKCatalogName is passed */\par
   ORDER BY FK_table_cat,FK_table_schem,FK_TABLE_NAME,ORDINAL_POSITION;\par
\par
What this means is: if you pass PKTableName = 'T2', you get a result set with\par
information about every FOREIGN KEY Constraint that references T2. Given the\par
above example Tables, the result of this call:\par
\par
   SQLForeignKeys(StatementHandle,NULL,0,NULL,0,"T2",2,NULL,0,NULL,0,NULL,0);\par
\par
is:\par
UK_TABLE_NAME  UK_COLUMN_NAME  FK_TABLE_NAME  FK_COLUMN_NAME\par
T2             T2_COL_1        T3             T3_COL_1\par
\par
[2] If the *FKTableName parameter is passed, search the temporary View looking\par
for foreign key:\par
\par
    SELECT * FROM TEMPORARY_VIEW\par
    WHERE FK_TABLE_NAME = ?      /* ? is for the *FKTableName parameter */\par
    AND FK_SCHEMA_NAME = ?       /* included if FKSchemaName is passed */\par
    AND FK_CATALOG_NAME = ?      /* included if FKCatalogName is passed */\par
    ORDER BY FK_table_cat,FK_table_schem,FK_TABLE_NAME,ORDINAL_POSITION;\par
\par
What this means is: if you pass FKTableName = 'T2', you get a result set with\par
information about all the foreign keys defined in T2. Given the above example\par
Tables, the result of this call:\par
\par
   SQLForeignKeys(StatementHandle,NULL,0,NULL,0,NULL,0,NULL,0,NULL,0,"T2",2);\par
\par
is:\par
UK_TABLE_NAME  UK_COLUMN_NAME  FK_TABLE_NAME  FK_COLUMN_NAME\par
T1             T1_COL_1        T2             T2_COL_1\par
\par
[3] If both the *PKTableName and *FKTableName parameters are passed, then\par
search the temporary View looking for both primary and foreign key:\par
\par
    SELECT * FROM TEMPORARY_VIEW\par
    WHERE UK_TABLE_NAME = ?   /* ? is for the *PKTableName parameter */\par
    AND UK_SCHEMA_NAME = ?    /* included if *PKSchemaName is passed */\par
    AND UK_CATALOG_NAME = ?   /* included if *PKCatalogName is passed */\par
    AND FK_TABLE_NAME = ?        /* ? is for the *FKTableName parameter */\par
    AND FK_SCHEMA_NAME = ?       /* included if FKSchemaName is passed */\par
    AND FK_CATALOG_NAME = ?      /* included if FKCatalogName is passed */\par
    ORDER BY FK_table_cat,FK_table_schem,FK_TABLE_NAME,ORDINAL_POSITION;\par
\par
What this means is: if you pass PKTableName = 'T1' and FKTableName = 'T3', you\par
get a result set with information about one of the foreign keys that's in T3.\par
Given the above example Tables, the result of this call:\par
\par
   SQLForeignKeys(StatementHandle,NULL,0,NULL,0,"T1",2,NULL,0,NULL,0,"T3",2);\par
\par
is:\par
UK_TABLE_NAME  UK_COLUMN_NAME  FK_TABLE_NAME  FK_COLUMN_NAME\par
T1             T1_COL_1        T3             T3_COL_1\par
\par
Notes:\par
      ## The above SELECT statements do not reflect some minor matters. See\par
the earlier section titled "Some Necessary Preliminaries".\par
      ## For readability, this example only shows the joins on "name" Columns\par
-- it omits the joins on "Schema" and "Catalog" Columns.\par
\par
Example:\par
This function call might put several rows in the result set, since we are\par
asking for "any Catalog", "any Schema".\par
\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  SQLRETURN sqlreturn;\par
  ...\par
  sqlreturn = SQLForeignKeys(hstmt,\par
            "",0,        /* Primary Catalog */\par
            "",0,        /* Primary Schema */\par
            "T",SQL_NTS, /* Primary Table  */\par
            "",0,        /* Foreign Catalog*/\par
            "",0,        /* Foreign Schema */\par
            "",0);       /* Foreign Table  */\par
\par
ODBC: The SQLForeignKeys function has been around since ODBC 1.0. Most of the\par
<Column name>s are different in ODBC. That's partly because ODBC only\par
recognizes references to primary keys, it doesn't expect that foreign keys\par
could reference unique keys.\par
\par
SQLGetTypeInfo\par
\par
Function Prototype:\par
  SQLRETURN SQLGetTypeInfo(\par
    SQLHSTMT hstmt,                 /* 32-bit input */\par
    SQLSMALLINT DataType            /* 16-bit input */\par
    );\par
\par
Job:\par
Return a result set, with one row for each <data type> that the DBMS supports.\par
It is possible to select a particular <data type>.\par
\par
Algorithm:\par
The SQL Standard asks us to pretend that there is a TYPE_INFO Table containing\par
information about the <data type>: its name, whether there is a scale, the SQL\par
<data type> code and so on. To help the pretense, we have actually made an\par
INFORMATION_SCHEMA View which is defined according to the Standard's\par
specification. PLEASE SEE THE DESCRIPTION OF THE TYPE_INFO VIEW IN OUR CHAPTER\par
ON CATALOGS FOR A COMPLETE DESCRIPTION.\par
\par
Assuming that such a View exists, the DBMS algorithm is simple:\par
\par
If (DataType==SQL_ALL_TYPES i.e. 0) then in effect this search happens:\par
      SELECT *\par
      FROM   INFORMATION_SCHEMA.TYPE_INFO;\par
\par
If the DataType parameter contains a value other than SQL_ALL_TYPES (0),\par
then in effect this search happens:\par
      SELECT *\par
      FROM   INFORMATION_SCHEMA.TYPE_INFO\par
      WHERE  DATA_TYPE = ?;\par
where the parameter marker ? stands for "the value of the DataType parameter".\par
\par
Notes:\par
      ## Much of the information returned by SQLGetTypeInfo is stuff you\par
already know, because it's standard. What you should worry about is the parts\par
labelled "implementation-defined". For example, the maximum size of a CHAR\par
Column varies from DBMS to DBMS. Unfortunately, the TYPE_INFO View lacks a few\par
items which might be useful -- such as the Character set.\par
      ## A typical application: if you allow the user to create Tables, it's\par
handy to call SQLGetTypeInfo and display list boxes (showing the localized\par
<data type> names) or explanatory notes based on implementation-defined\par
maxima.\par
\par
Example:\par
This Column will display "10", because the third Column in\par
INFORMATION_SCHEMA.TYPE_INFO is COLUMN_SIZE and the Column size for a DATE\par
<data type> is always 10 positions. The value of SQL_TYPE_DATE is 91.\par
\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  SQLINTEGER column_size;\par
  ...\par
  SQLGetTypeInfo(hstmt,SQL_TYPE_DATE);\par
  SQLBindCol(hstmt,3,SQL_INTEGER,&column_size,NULL,NULL);\par
  SQLFetch(hstmt);\par
  SQLCloseCursor;\par
  printf("column size = %d\\n",column_size);\par
\par
ODBC: SQLGetTypeInfo has been around since ODBC 1.0, but many of the Columns\par
are new in ODBC 3.0. The implicit SELECT statements contain the clause "ORDER\par
BY DATA_TYPE".\par
\par
SQLParameters\par
\par
Function Prototype:\par
  SQLRETURN SQLParameters (\par
    SQLHSTMT      hstmt,                 /* 32-bit input */\par
    SQLCHAR*      CatalogName,           /* CHAR* input */\par
    SQLSMALLINT   NameLength1,            /* 16-bit input */\par
    SQLCHAR*      SchemaName,             /* CHAR* input */\par
    SQLSMALLINT   NameLength2,            /* 16-bit input */\par
    SQLCHAR*      RoutineName,            /* CHAR* input */\par
    SQLSMALLINT   NameLength3,            /* 16-bit input */\par
    SQLCHAR*      ParameterName,          /* CHAR* input */\par
    SQLSMALLINT   NameLength4             /* 16-bit input */\par
    );\par
\par
Job:\par
Get metadata concerning parameters.\par
\par
Algorithm:\par
      Execute the following SELECT statement and return a result set.\par
\par
        SELECT\par
          SPECIFIC_CATALOG AS routine_cat,  /* VARCHAR(128) */\par
          SPECIFIC_SCHEMA AS routine_schem, /* VARCHAR(128) NOT NULL */\par
          SPECIFIC_NAME AS routine_name,    /* VARCHAR(128) NOT NULL */\par
          PARAMETER_NAME,                   /* VARCHAR(128) NOT NULL */\par
          PARAMETER_MODE,                   /* VARCHAR(254) NOT NULL */\par
          (see notes) AS DATA_TYPE,         /* INTEGER NOT NULL */\par
          DATA_TYPE AS TYPE_NAME,           /* VARCHAR(128) NOT NULL */\par
          (see notes) AS PARAMETER_SIZE,               /* INTEGER */\par
          (see notes) AS BUFFER_LENGTH,                /* INTEGER */\par
          (see notes) AS DECIMAL_DIGITS,               /* SMALLINT */\par
          NUMERIC_PRECISION_RADIX AS num_prec_radix,   /* SMALLINT */\par
          (see notes) AS sql_datetime_sub,             /* SMALLINT */\par
          CHARACTER_OCTET_LENGTH AS char_octet_length, /* INTEGER */\par
          ORDINAL_POSITION,                            /* INTEGER NOT NULL */\par
          CHARACTER_SET_CATALOG AS char_set_cat,  /* VARCHAR(128) */\par
          CHARACTER_SET_SCHEMA AS char_set_schem, /* VARCHAR(128) */\par
          CHARACTER_SET_NAME AS char_set_name,    /* VARCHAR(128) */\par
          COLLATION_CATALOG AS collation_cat,     /* VARCHAR(128) */\par
          COLLATION_SCHEMA AS collation_schem,    /* VARCHAR(128) */\par
          COLLATION_NAME,                         /* VARCHAR(128) */\par
          USER_DEFINED_TYPE_CATALOG AS udt_cat,   /* VARCHAR(128) */\par
          USER_DEFINED_TYPE_SCHEMA AS udt_schem,  /* VARCHAR(128) */\par
          USER_DEFINED_TYPE_NAME AS udt_name,     /* VARCHAR(128) */\par
          <implementation-defined> AS REMARKS     /* VARCHAR(254) */\par
         FROM INFORMATION_SCHEMA.PARAMETERS\par
         WHERE\par
          CATALOG_NAME LIKE ?\par
          AND SCHEMA_NAME LIKE ?\par
          AND ROUTINE_NAME LIKE ?\par
          AND PARAMETER_NAME LIKE ?\par
         ORDER BY routine_cat,routine_schem,routine_name,PARAMETER_NAME;\par
      \par
      Where the four ? parameters are CatalogName, SchemaName,\par
      RoutineName and ParameterName, in that order.\par
\par
Notes:\par
      ## The algorithm's SELECT statement does not reflect some minor matters.\par
See the earlier section titled "Some Necessary Preliminaries".\par
      ## For the result set's DATA_TYPE, BUFFER_LENGTH, DECIMAL_DIGITS and\par
SQL_DATA_TYPE Columns, the DBMS uses the same calculations that it uses for\par
the SQLColumns function -- see the long CASE expressions in the SQLColumns\par
description.\par
      ## The value in TYPE_NAME is implementation-defined; in our\par
implementation we defined that it's the same as PARAMETERS.DATA_TYPE.\par
      ## The value in the result set's PARAMETER_SIZE Column is the same as\par
the value in the BUFFER_SIZE Column. (Although PARAMETER_SIZE and BUFFER_SIZE\par
depend on several implementation-defined rules, we believe that any practical\par
DBMS will employ the same rules for both Columns.)\par
      ## The DBMS will only return rows for routines that you have EXECUTE\par
Privileges on.\par
\par
Example:\par
      /* This shows every parameter in routine X. */\par
      #include "sqlcli.h"\par
      ...\par
      SQLParameters(hstmt,"",0,"",0,"X",1,"",0);\par
      ...\par
\par
ODBC: There is no ODBC equivalent of SQLParameters.\par
\par
SQLPrimaryKeys\par
\par
Function Prototype:\par
  SQLRETURN SQLPrimaryKeys(\par
    SQLHSTMT hstmt,                 /* 32-bit input */\par
    SQLCHAR *CatalogName,           /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength1,        /* 16-bit input */\par
    SQLCHAR *SchemaName,            /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength2,        /* 16-bit input */\par
    SQLCHAR *TableName,             /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength3         /* 16-bit input */\par
    );\par
\par
Job:\par
Given a <Table name>, return a list of the Columns in the Table's primary key.\par
The return is a result set.\par
\par
Algorithm:\par
      If values are passed in the CatalogName and SchemaName and TableName\par
      parameters, the main rule is that this query is effectively executed:\par
\par
      SELECT\par
            K.TABLE_CATALOG AS table_cat,\par
            K.TABLE_SCHEMA AS table_schem,\par
            K.TABLE_NAME,\par
            K.COLUMN_NAME,\par
            K.ORDINAL_POSITION,\par
            K.CONSTRAINT_NAME AS pk_name\par
            FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE AS K,\par
                 INFORMATION_SCHEMA.TABLE_CONSTRAINTS AS P \par
            WHERE K.CONSTRAINT_CATALOG = P.CONSTRAINT_CATALOG\par
            AND   K.CONSTRAINT_SCHEMA = P.CONSTRAINT_SCHEMA\par
            AND   K.CONSTRAINT_NAME = P.CONSTRAINT_NAME\par
            AND   K.TABLE_CATALOG = ?\par
            AND   K.TABLE_SCHEMA = ?\par
            AND   K.TABLE_NAME = ?\par
            AND   P.CONSTRAINT_TYPE = 'PRIMARY KEY'\par
            ORDER BY table_cat,table_schem,TABLE_NAME,ORDINAL_POSITION;\par
      \par
      Where the three ? parameter markers are for CatalogName, SchemaName and\par
      TableName, respectively.\par
\par
Notes:\par
      ## The only returned rows are for PRIMARY KEY Constraints. If there is a\par
UNIQUE Constraint -- even a UNIQUE Constraint that is referenced by a foreign\par
key -- SQLPrimaryKeys will not see it.\par
\par
Example:\par
/* The result set will contain all primary keys from Tables in Schema OCELOT\par
in Catalog OCELOT. */\par
\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  ...\par
  SQLPrimaryKeys(\par
    hstmt,"OCELOT",sizeof("OCELOT"),"OCELOT",sizeof("OCELOT"),"",0);\par
\par
ODBC: The SQLPrimaryKeys function has been around since ODBC 1.0. The name of\par
the fifth returned Column is KEY_SEQ instead of ORDINAL_POSITION.\par
\par
SQLRoutinePrivileges\par
\par
Function Prototype:\par
  SQLRETURN SQLRoutinePrivileges(\par
    SQLHSTMT hstmt,           /* 32-bit input */\par
    SQLCHAR *CatalogName,     /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength1,  /* 16-bit input */\par
    SQLCHAR *SchemaName,      /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength2,  /* 16-bit input */\par
    SQLCHAR *RoutineName,     /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength3   /* 16-bit input */\par
    );\par
\par
Job:\par
Get information about Privileges on routines.\par
\par
Algorithm:\par
      Produce a result set using this query:\par
\par
      SELECT\par
        ROUTINE_CATALOG AS routine_cat,   /* VARCHAR(128) */\par
        ROUTINE_SCHEMA AS routine_schem,  /* VARCHAR(128) NOT NULL */\par
        ROUTINE_NAME AS routine_name,     /* VARCHAR(128) NOT NULL */\par
        SPECIFIC_NAME AS specific_name,   /* VARCHAR(128) NOT NULL */\par
        GRANTOR AS GRANTOR,               /* VARCHAR(128) */\par
        GRANTEE AS GRANTEE,               /* VARCHAR(128) NOT NULL */\par
        PRIVILEGE_TYPE AS privilege,      /* VARCHAR(128) NOT NULL */\par
        IS_GRANTABLE AS IS_GRANTABLE       /* VARCHAR(3) */\par
      FROM INFORMATION_SCHEMA.ROUTINE_PRIVILEGES\par
      WHERE ROUTINE_CATALOG = ?\par
      AND   ROUTINE_SCHEMA = ?\par
      AND   ROUTINE_NAME = ?\par
      ORDER BY routine_name,routine_cat,routine_schem;\par
\par
      ... where the three ? parameter markers are replaced by the string\par
      values in, respectively, the CatalogName and SchemaName and\par
      RoutineName parameters.\par
\par
Notes:\par
      ## In SQL-92, there is no such thing as a routine. Therefore\par
SQLRoutinePrivileges is supported only by SQL3 DBMSs.\par
      ## The value in the RoutineName parameter is matched against\par
ROUTINE_NAME, not SPECIFIC_NAME.\par
\par
Example:\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  ...\par
  /* any Catalog, any Schema, any name */\par
  SQLRoutinePrivileges(hstmt,"",0,"",0,"",0);\par
  ...\par
  /* Catalog A, any Schema, any name */\par
  SQLRoutinePrivileges(hstmt,"A",1,"",0,"",0);\par
  ...\par
  /* Catalog A,Schema B, any name */\par
  SQLRoutinePRivileges(hstmt,"A",1,"B",1,"",0);\par
  ...\par
  /* Catalog A,Schema B,name C */\par
  SQLRoutinePrivileges(hstmt,"A",1,"B",1,"C",1);\par
\par
ODBC: SQLRoutinePrivileges is not in ODBC 3.0.\par
\par
SQLRoutines\par
\par
Function Prototype:\par
  SQLRETURN SQLRoutines(\par
    SQLHSTMT StatementHandle,       /* 32-bit input */\par
    SQLCHAR *CatalogName,           /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength1,        /* 16-bit input */\par
    SQLCHAR *SchemaName,            /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength2,        /* 16-bit input */\par
    SQLCHAR *RoutineName,           /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength3,        /* 16-bit input */\par
    SQLCHAR *RoutineType,           /* pointer to CHAR* input */\par
    SQLSMALLINT NameLength4         /* 16-bit input */\par
    );\par
\par
Job:\par
Retrieve information about functions and procedures.\par
\par
Algorithm:\par
      Produce a result set using this query:\par
      SELECT\par
        ROUTINE_CATALOG AS routine_cat,   /* VARCHAR(128) */\par
        ROUTINE_SCHEMA AS routine_schem,  /* VARCHAR(128) NOT NULL */\par
        ROUTINE_NAME,                     /* VARCHAR(128) NOT NULL */\par
        SPECIFIC_NAME,                    /* VARCHAR(128) NOT NULL */\par
        ROUTINE_TYPE,                     /* VARCHAR(254) NOT NULL */\par
        DATA_TYPE,                        /* INTEGER */\par
        TYPE_NAME,                        /* VARCHAR(128) */\par
        PARAMETER_SIZE,                   /* INTEGER */\par
        DECIMAL_DIGITS,                   /* SMALLINT */\par
        NUM_PREC_RADIX,                   /* SMALLINT */\par
        SQL_DATA_TYPE,                    /* SMALLINT */\par
        SQL_DATETIME_SUB,                 /* SMALLINT */\par
        CHAR_OCTET_LENGTH,                /* INTEGER */\par
        CHAR_SET_CAT,                     /* VARCHAR(128) */\par
        CHAR_SET_SCHEM,                   /* VARCHAR(128) */\par
        CHAR_SET_NAME,                    /* VARCHAR(128) */\par
        COLLATION_CATALOG AS collation_cat,/* VARCHAR(128) */\par
        COLLATION_SCHEMA AS collation_schem,/* VARCHAR(128) */\par
        COLLATION_NAME,                   /* VARCHAR(128) */\par
        UDT_CATALOG AS udt_cat,           /* VARCHAR(128) */\par
        UDT_SCHEMA AS udt_schem,          /* VARCHAR(128) */\par
        UDT_NAME,                         /* VARCHAR(254) */\par
        LANGUAGE,                         /* VARCHAR(128) */\par
        IS_DETERMINISTIC,                 /* VARCHAR(254) */\par
        SQL_DATA_ACCESS,                  /* VARCHAR(254) */\par
        MAX_DYNAMIC_RESULT_SETS,          /* INTEGER */\par
        REMARKS                           /* VARCHAR(254) */\par
      FROM INFORMATION_SCHEMA.ROUTINES\par
      WHERE ROUTINE_CATALOG = ?\par
      AND   ROUTINE_SCHEMA = ?\par
      AND   ROUTINE_NAME = ?\par
      AND   ROUTINE_TYPE = ?\par
      ORDER BY ROUTINE_NAME,routine_cat,routine_schem;\par
\par
      ... where the three ? parameter markers stand for the values passed in\par
      the CatalogName, SchemaName, RoutineName and RoutineType parameters.\par
\par
Notes:\par
      ## We have made liberal use of "<name>" as a shorthand in the select\par
list in the algorithm. The meaning, in each case, is: "the input for this\par
value, and the attendant calculations, are the same as for the Column of the\par
same name in the result set of SQLColumns."\par
      ## REMARKS is implementation-defined.\par
      ## [Obscure Rule] There are three variants of SQLRoutines which are so\par
different, they should be regarded as different functions. These variants are\par
easily recognized by the arguments: one argument is always "%" and the others\par
are always "" (blank strings). The variants always return result sets with\par
five Columns.\par
            ## The first variant is:\par
\par
   SQLRoutines(hstmt,"%",1,"",0,"",0,"",0);\par
\par
This is effectively equivalent to:\par
\par
   SELECT DISTINCT ROUTINE_CATALOG AS routine_cat,\par
                    CAST(NULL AS VARCHAR(128)),\par
                    CAST(NULL AS VARCHAR(128)),\par
                    CAST(NULL AS VARCHAR(254)),\par
                    CAST(NULL AS VARCHAR(254))\par
   FROM INFORMATION_SCHEMA.ROUTINES;\par
\par
            ## The second variant is:\par
\par
   SQLRoutines(hstmt,"",0,"%",1,"",0,"",0);\par
\par
This is effectively equivalent to:\par
\par
   SELECT DISTINCT CAST(NULL AS VARCHAR(128)),\par
                    ROUTINE_SCHEMA AS ROUTINE_SCHEM,\par
                    CAST(NULL AS VARCHAR(128)),\par
                    CAST(NULL AS VARCHAR(254)),\par
                    CAST(NULL AS VARCHAR(254))\par
   FROM INFORMATION_SCHEMA.ROUTINES;\par
\par
            ## The third variant is:\par
\par
   SQLRoutines(hstmt,"",0,"",0,"",0,"%",1);\par
\par
This is effectively equivalent to:\par
\par
   SELECT DISTINCT CAST(NULL AS VARCHAR(128)),\par
                    CAST(NULL AS VARCHAR(128)),\par
                    CAST(NULL AS VARCHAR(128)),\par
                    ROUTINE_TYPE,\par
                    CAST(NULL AS VARCHAR(254))\par
   FROM INFORMATION_SCHEMA.ROUTINES;\par
\par
Example:\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  ...\par
  SQLRoutines(hstmt,\par
      "CATALOG_1",sizeof("CATALOG_1"),\par
      "SCHEMA_1",sizeof("SCHEMA_1"),\par
      "ROUTINE_1",sizeof("ROUTINE_1"),\par
      "",0);\par
\par
ODBC: SQLRoutines is not in ODBC 3.0.\par
\par
SQLSpecialColumns\par
\par
Function Prototype:\par
  SQLRETURN SQLSpecialColumns(\par
    SQLHSTMT hstmt,                 /* 32-bit input */\par
    SQLSMALLINT IdentifierType,     /* 16-bit input */\par
    SQLCHAR *CatalogName,           /* CHAR* input */\par
    SQLSMALLINT NameLength1,        /* 16-bit input */\par
    SQLCHAR *SchemaName,            /* CHAR* input */\par
    SQLSMALLINT NameLength2,        /* 16-bit input */\par
    SQLCHAR *TableName,             /* CHAR* input */\par
    SQLSMALLINT NameLength3,        /* 16-bit input */\par
    SQLSMALLINT Scope,              /* 16-bit input */\par
    SQLSMALLINT Nullable            /* 16-bit input */\par
    );\par
\par
Job:\par
Show the Columns that can be used for uniquely identifying a row in a given\par
Table.\par
\par
Algorithm:\par
      If (IdentifierType <> SQL_BEST_ROWID)\par
        return error: HY097 CLI-specific condition-column type out of range\par
      If (Scope not SCOPE_CURRENT_ROW or SCOPE_TRANSACTION or SCOPE_SESSION)\par
        return error: HY098 CLI-specific condition-scope type out of range\par
      If (Nullable not SQL_NO_NULLS or NULLABLE)\par
        return error: HY099 CLI-specific condition-nullable type out of range\par
      Produce a result set using this query:\par
\par
      SELECT\par
      SCOPE,                          /* SMALLINT */\par
      COLUMN_NAME,                    /* VARCHAR(128) NOT NULL */\par
      ... AS DATA_TYPE,               /* SMALLINT NOT NULL */\par
     ... AS TYPE_NAME,                /* VARCHAR(128) NOT NULL */\par
     ... AS COLUMN_SIZE,              /* INTEGER */\par
     ... AS BUFFER_LENGTH,            /* INTEGER */\par
     ... AS DECIMAL_DIGITS,           /* INTEGER */\par
     ... AS pseudocolumn              /* INTEGER */\par
      FROM INFORMATION_SCHEMA.COLUMNS\par
      WHERE <column "is special" i.e. "is the best rowid">\par
      AND   scope = ?\par
      AND   catalog_name = ?\par
      AND   schema_name = ?\par
      AND   table_name = ?\par
      AND  NOT EXISTS <any nullable Column in the set of Columns>\par
      ORDER BY SCOPE;\par
\par
      ... where the four ? parameters are Scope, CatalogName, SchemaName and\par
      TableName, in that order.\par
\par
Notes:\par
      ## We have used ... in the algorithm's select list as a shorthand. The\par
meaning of this shorthand is that the same inputs and calculations should be\par
used as were used in the lengthy CASE expressions for the SQLColumns function.\par
      ## Don't worry about the outre' select list in the algorithm. The only\par
thing that you really need is the <Column name> and the scope. All the rest\par
can be found using straightforward selections from INFORMATION_SCHEMA Views.\par
      ## It's implementation-defined which Columns make the "best rowid" and\par
have a particular "scope".\par
      ## The Special Column Type can be:\par
            ## 1  SQL_BEST_ROWID\par
      ## The Scope of Row Id can be:\par
            ## 0  SQL_SCOPE_CURRENT_ROW (valid while Cursor is positioned on\par
that row -- the ODBC name is SQL_SCOPE_CURROW)\par
            ## 1  SQL_SCOPE_TRANSACTION (valid until transaction ends)\par
            ## 2  SQL_SCOPE_SESSION (valid until SQL-session ends)\par
      ## How does the DBMS pick what Columns are special?\par
            ## First choice: the "rowid".\par
            ## Second choice: a single Column which is defined as UNIQUE or\par
PRIMARY KEY.\par
            ## Third choice: a combination of Columns which make up a UNIQUE\par
or PRIMARY KEY.\par
            ## Fourth choice: a "serial number" Column.\par
            ## Fifth choice: a "timestamp" Column (the Sybase way).\par
Columns lose points if nullable; gain points if short, numeric, constrained.\par
      ## What's a pseudo-column? Perhaps it's called the ROWID (Oracle),\par
perhaps it's Ingres's TID. Sometimes a TIMESTAMP is also a pseudo-column, but\par
that's not relevant here. For purposes of illustration, we have had to pretend\par
that pseudo-columns exist in the COLUMNS View.\par
      ## The Pseudo Column Flag can be:\par
            ## 0  SQL_PSEUDO_UNKNOWN\par
            ## 1  SQL_PSEUDO_NOT_PSEUDO\par
            ## 2  SQL_PSEUDO_PSEUDO\par
      ## Many DBMSs support "rowid" as a unique identifier. The rowid is often\par
directly translatable to a physical address in the Table's underlying file, so\par
searches by rowid tend to be fast. Some disadvantages of rowid: addresses can\par
change; format differs between DBMSs.\par
      ## What good is the SQLSpecialColumns function? Assume there's a Table\par
that you're navigating one screenload at a time. You want to allow the user to\par
edit each row, or even delete it. But you don't want to lock all the rows in\par
the result set. By finding and storing the Column values that constitute the\par
unique identifiers of the result set rows, you can do these things with\par
separate selections. The big problem is concurrency. If you want to do your\par
own multi-user scheming, this is the function for you.\par
      ## Our description ignores some obvious and minor errors in the SQL\par
Standard.\par
      ## If speed is not a major concern and portability is a major concern,\par
do not use SQLSpecialColumns with its heavily implementation-dependent\par
assumptions. Instead, find out what the unique key Columns are by searching\par
the INFORMATION_SCHEMA.KEY_COLUMN_USAGE View.\par
      ## It is often a bad idea to pass SQL_NO_NULLS in the Nullable\par
parameter. By insisting that nullable Columns are unacceptable, you are\par
interfering with the DBMS's algorithm for choosing the "best" row id.\par
      ## There might be no rows returned. But if you define every Table with a\par
primary or unique key, SQLSpecialColumns can't fail.\par
      ## Because calculation happens a` la SQLColumns, the COLUMN_SIZE for BIT\par
and BIT VARYING <data type>s is a length in bits.\par
\par
Example:\par
  #include "sqlcli.h"\par
  SQLHSTMT hstmt;\par
  ...\par
  SQLSpecialColumns(\par
      hstmt,                       /* hstmt */\par
      SQL_BEST_ROWID,              /* IdentifierType */\par
      "OCELOT",sizeof("OCELOT"),   /* CatalogName,NameLength1 */\par
      "OCELOT",sizeof("OCELOT"),   /* SchemaName,NameLength2 */\par
      "T",sizeof("T"),             /* TableName,NameLength3 */\par
      SQL_SCOPE_TRANSACTION,       /* Scope */\par
      SQL_PSEUDO_UNKNOWN);         /* Nullable */\par
\par
ODBC: The SQLSpecialColumns function has been in ODBC since version 1.0.\par
Perhaps because it depends on non-standard features, SQLSpecialColumns wasn't\par
in the SQL-92 CLI (but was in X/Open). Besides the "best rowid" option, one\par
can ask about Columns which are automatically changed whenever there is an\par
update (e.g.: Sybase's TIMESTAMP Column).\par
\par
SQLTablePrivileges\par
\par
Function Prototype:\par
  SQLRETURN SQLTablePrivileges(\par
    SQLHSTMT      hstmt,            /* 32-bit input */\par
    SQLCHAR *     CatalogName,      /* CHAR* input */\par
    SQLSMALLINT   NameLength1,      /* 16-bit input */\par
    SQLCHAR *     SchemaName,       /* CHAR* input */\par
    SQLSMALLINT   NameLength2,      /* 16-bit input */\par
    SQLCHAR *     TableName,        /* CHAR* input */\par
    SQLSMALLINT   NameLength3       /* 16-bit input */\par
    );\par
\par
Job:\par
Show what Privileges the user holds, given <Table name>(s).\par
\par
Algorithm:\par
      Produce a result set using this query:\par
\par
         SELECT\par
          TABLE_CATALOG AS table_cat,   /* VARCHAR(128) */\par
          TABLE_SCHEMA AS  table_schem, /* VARCHAR(128) NOT NULL */\par
          TABLE_NAME,                  /* VARCHAR(128) NOT NULL */\par
          GRANTOR,                      /* VARCHAR(128) */\par
          GRANTEE,                      /* VARCHAR(128) NOT NULL */\par
          PRIVILEGE_TYPE AS privilege,  /* VARCHAR(128) NOT NULL */\par
          IS_GRANTABLE                  /* VARCHAR(3) */\par
         FROM INFORMATION_SCHEMA.TABLE_PRIVILEGES\par
         WHERE\par
          CATALOG_NAME LIKE ?\par
          AND SCHEMA_NAME LIKE ?\par
          AND TABLE_NAME LIKE ?\par
         ORDER BY table_cat,table_schem,TABLE_NAME,privilege;\par
      \par
      Where the three ? parameters are CatalogName, SchemaName, TableName, in\par
      that order.\par
\par
Notes:\par
      ## The algorithm's SELECT statement does not reflect some minor matters.\par
See the earlier section titled "Some Necessary Preliminaries".\par
      ## If you lack the UPDATE Privilege on a Table T, that does not prove\par
that this SQL statement:\par
\par
   UPDATE T SET column_1 = 5;\par
\par
is illegal for you. You might have a Column UPDATE Privilege on COLUMN_1 only\par
(Column Privileges are discovered by calling SQLColumnPrivileges or selecting\par
from INFORMATION_SCHEMA.COLUMN_PRIVILEGES). You might hold a Role or an\par
implementation-defined "super user" Privilege. So the only guaranteed proof\par
is: try it and see. Seriously:\par
\par
    x=SQLExecDirect(hstmt,"UPDATE T SET column_1=5 WHERE 1=2;",SQL_NTS);\par
    if (x<0) \{\par
      SQLGetDiagField(...<sqlstate>)\par
      if ('42000')\par
        /* UPDATE failed. SQLSTATE='42000' access/syntax error.\par
           Most likely the problem is that you lack Privileges. */\par
      else\par
        /* UPDATE failed but for some other reason. Test is no good. */ \}\par
    else \{\par
      /* UPDATE succeeded, so you have the right Privileges. */  \}\par
\par
The key for this tip is to use an always-FALSE condition in the WHERE clause\par
-- do not try setting the Column to itself and do not depend on ROLLBACK.\par
\par
Example:\par
      /* This shows every Table you have Privileges on. */\par
      #include "sqlcli.h"\par
      ...\par
      SQLTablePrivileges(hstmt,"",0,"",0,"",0);\par
      ...\par
\par
ODBC: The SQLTablePrivileges function has been around since ODBC version 1.0.\par
\par
SQLTables                           \par
\par
Function Prototype:                  /* not in SQL-92, but in SQL3 */\par
  SQLRETURN SQLTables(\par
    SQLHSTMT hstmt,                 /* 32-bit input */\par
    SQLCHAR *CatalogName,           /* CHAR* input */\par
    SQLSMALLINT NameLength1,        /* 16-bit input */\par
    SQLCHAR *SchemaName,            /* CHAR* input */\par
    SQLSMALLINT NameLength2,        /* 16-bit input */\par
    SQLCHAR *TableName,             /* CHAR* input */\par
    SQLSMALLINT NameLength3,        /* 16-bit input */\par
    SQLCHAR *TableType,             /* CHAR* input */\par
    SQLSMALLINT NameLength4         /* 16-bit input */\par
    );\par
\par
Job:\par
Show information about specified Table(s).\par
\par
Algorithm:\par
      For a moment let us ignore the *TableType parameter. Now,\par
      the SQLTables function is effectively the same as this query:\par
\par
      SELECT\par
        TABLE_CATALOG AS table_cat,       /* VARCHAR(128),\par
        TABLE_SCHEMA AS table_schem,      /* VARCHAR(128),\par
        TABLE_NAME,                       /* VARCHAR(128),\par
        CASE TABLE_TYPE\par
          WHEN 'VIEW' THEN\par
            CASE TABLE_SCHEMA\par
              WHEN 'INFORMATION_SCHEMA' THEN\par
                'SYSTEM TABLE'\par
              ELSE\par
                'VIEW'\par
              END\par
          WHEN 'BASE TABLE' THEN\par
            'TABLE'\par
          ELSE\par
            TABLE_TYPE\par
          END\par
          AS TABLE_TYPE,                      /* VARCHAR(254),\par
        CAST('' AS VARCHAR(254)) AS remarks   /* VARCHAR(254)\par
      FROM INFORMATION_SCHEMA.TABLES\par
      WHERE TABLE_CATALOG = ?\par
      AND   TABLE_SCHEMA = ?\par
      AND   TABLE_NAME = ?;\par
      \par
      Where the three ? parameters are filled in by CatalogName\par
      SchemaName and TableName in that order -- but see notes\par
      regarding TABLE_TYPE.\par
\par
Notes:\par
      ## The *TableType parameter is a wrinkle which is hard to show in an SQL\par
statement but it's reasonably straightforward. The idea is that there are five\par
general categories of Tables: the INFORMATION_SCHEMA Views ('SYSTEM TABLE'),\par
all other Views ('VIEW'), ordinary Base tables ('TABLE') and the two kinds of\par
temporary Tables ('GLOBAL TEMPORARY' or 'LOCAL TEMPORARY'). To restrict to the\par
categories you want, pass a commalist in *TableType -- for example: 'SYSTEM\par
TABLE','VIEW'. Or pass SYSTEM TABLE,VIEW (the quote marks are optional). Or\par
pass nothing (if you pass a blank string, the DBMS returns Tables in all\par
categories).\par
      ## The algorithm's SELECT statement does not reflect some minor matters.\par
See the earlier section titled "Some Necessary Preliminaries".\par
      ## The REMARKS Column is supposed to contain an implementation-defined\par
description of the Table. For IBM's DB2 this would be the value that you enter\par
with a COMMENT statement.\par
      ## Many Windows applications have a "File" menu item and within that an\par
"Open..." menu item, for putting a dialog box on the screen. Your database\par
application doesn't have files -- it has Tables -- but the dialog box should\par
look similar.\par
      ## SQLTables was not available in SQL-92; it is new to SQL with SQL3.\par
      ## [Obscure Rule] There are three variants of SQLTables which are so\par
different, they should be regarded as different functions. These variants are\par
easily recognized by the arguments: one argument is always "%" and the others\par
are always "" (blank strings). The variants always return result sets with\par
five Columns.\par
            ## The first variant is:\par
\par
   SQLTables(hstmt,"%",1,"",0,"",0,"",0);\par
\par
This is effectively equivalent to:\par
\par
   SELECT DISTINCT TABLE_CATALOG AS table_cat,\par
                   CAST(NULL AS VARCHAR(128)),\par
                   CAST(NULL AS VARCHAR(128)),\par
                   CAST(NULL AS VARCHAR(254)),\par
                   CAST(NULL AS VARCHAR(254))\par
   FROM INFORMATION_SCHEMA.TABLES;\par
      \par
      ## The second variant is:\par
 \par
  SQLTables(hstmt,"",0,"%",1,"",0,"",0);\par
\par
This is effectively equivalent to:\par
\par
   SELECT DISTINCT CAST(NULL AS VARCHAR(128)),\par
                   TABLE_SCHEMA AS table_schem,\par
                   CAST(NULL AS VARCHAR(128)),\par
                   CAST(NULL AS VARCHAR(254)),\par
                   CAST(NULL AS VARCHAR(254))\par
   FROM INFORMATION_SCHEMA.TABLES;\par
      \par
      ## The third variant is:\par
  \par
 SQLTables(hstmt,"",0,"",0,"",0,"%",1);\par
\par
This is effectively equivalent to:\par
 \par
  SELECT DISTINCT CAST(NULL AS VARCHAR(128)),\par
                   CAST(NULL AS VARCHAR(128)),\par
                   CAST(NULL AS VARCHAR(128)),\par
                   CASE TABLE_TYPE\par
                    WHEN 'VIEW' THEN\par
                       CASE TABLE_SCHEMA\par
                       WHEN 'INFORMATION_SCHEMA' THEN\par
                          'SYSTEM TABLE'\par
                        ELSE 'VIEW'\par
                        END\par
                       WHEN 'BASE TABLE' THEN 'TABLE'\par
                       ELSE TABLE_TYPE\par
                       END\par
                   AS TABLE_TYPE,\par
                  CAST(NULL AS VARCHAR(254))\par
   FROM INFORMATION_SCHEMA.TABLES;\par
\par
There are no Privilege checks: with variant SQLTables functions, you can find\par
Tables that you have no Privileges on. Compare the variant SQLRoutines\par
functions.\par
\par
Example:\par
      #include "sqlcli.h"\par
      SQLHSTMT hstmt;\par
      ...\par
      /* In CATALOG_1, in SCHEMA_1, find Table T, which may be either a Base\par
         table or a View. */\par
      SQLTables(\par
        hstmt,"CATALOG_1",SQL_NTS,"SCHEMA_1",SQL_NTS,"T",SQL_NTS,"",SQL_NTS);\par
\par
      /* The following example is derived from an example supplied\par
         by Microsoft for SQL Server 6.0. Notice these subtleties:\par
         (a) the catalog and schema parameters are passed\par
         with NULL,0 -- passing NULL,0 is legal only if METADATA is FALSE,\par
         if METADATA were TRUE the parameters would have to be passed as "",0\par
         (b) "q%" is a search pattern i.e. we are looking for <Table name>s\par
         which begin with the letter q -- again, this is only legal if\par
         METADATA ID is FALSE\par
         (c) the search should be case sensitive (Microsoft suggests the\par
         opposite, so some caution is necessary here)\par
         (d) the search will only find Base tables -- not Views. */\par
      SQLTables(hstmt,NULL,0,NULL,0,TEXT("q%"),SQL_NTS,\par
      TEXT("'TABLE'"),SQL_NTS);\par
\par
ODBC: The SQLTables function has been around since ODBC version 1.0. In ODBC,\par
the result set is guaranteed to be in order by TABLE_CAT, TABLE_SCHEM,\par
TABLE_NAME ... -- this order is not specified in the Standard but it will\par
probably be the case.\par
\par
THE END\par
\par
The description of SQL/CLI is -- at long last -- finished. Here's a summary of\par
some of the good and the bad and the ugly points that we've talked about in\par
the past several chapters:\par
      ## The impedance-mismatch problem is solved. It's considerably easier,\par
for the vendor especially, to supply a library of functions rather than to\par
allow mixing of host language code with SQL code. Since most programmers are\par
well acquainted with the concept of a function library, there are no strong\par
objections to the practice.\par
      ## The CLI's functionality is analogous to that of "dynamic SQL" in the\par
embedded SQL specification. The absence of "static SQL" does entail that there\par
will have to be some parsing and binding at runtime which, in theory, could\par
have been done once and for all when the program was produced.\par
      ## A considerable debt is owed by the programming community to SAG,\par
X/Open and Microsoft. Before the CLI came along, SQL was a much smaller deal.\par
The use of the CLI has opened up the power of database programming to a much\par
wider audience than the embedded SQL and PSM styles were ever likely to\par
produce. Particularly this is true for shrink-wrapped software.\par
      ## The CLI contains many redundancies.\par
      ## The CLI specifications often appear to be influenced by ideas which run counter to the general spirit of SQL.\par
      ## The CLI is much more complex than it would have been if a single design team had started with standard SQL-92 as a base.\par
\page\par
Chapter 52 -- Module Binding Style\par
\par
SQL DBMSs communicate with SQL applications through a common programming\par
language interface that is invoked through one of the SQL Standard-defined\par
binding styles, or interface options. There are three main approaches to writing complete programs with SQL:\par
      ## With embedded SQL, you can put SQL statements directly into host programs. We described this binding style earlier.\par
      ## With SQL/CLI, you can call a SQL DBMS's library from a host program. This binding style was the subject of the last several chapters.\par
      ## With the Module language, you can dispense with host programs and write entire Modules in SQL. You'll still have to call these Modules from one of the standard host languages though.\par
The Module language binding style is the subject of this  chapter.\par
\par
Because we believe that SQL/CLI will quickly become the SQL interface of choice, this chapter omits large amounts of detail, in favour of providing the necessary detail in our chapters on SQL/CLI.\par
\par
Note: The SQL Standard actually describes three kinds of SQL Module, each of\par
which has certain characteristics and contains various kinds of Module Objects\par
(principally, routines). An SQL-client Module contains only externally-invoked\par
procedures, an SQL-session Module contains only SQL statements prepared in\par
that SQL-session and an SQL-server Module -- the SQL/PSM type -- is a Schema Object that contains only SQL-invoked routines.\par
\par
SQL-client Modules\par
\par
SQL-client Modules are programming modules that contain externally-invoked\par
procedures -- that is, SQL procedures that are invoked by a host language.\par
Generally speaking, this methodology is really the basic SQL binding style:\par
all of the binding styles -- direct SQL, embedded SQL, CLI or SQL-client\par
Modules -- at least conceptually, involve a program module. Before SQL/PSM\par
came on the scene, SQL "module language" was the only way to identify SQL\par
Modules. But now, with the advent of SQL/PSM and (far better) of SQL/CLI, we\par
believe this method of utilizing SQL will rapidly become obsolete and so we give only a brief description here.\par
\par
An SQL-client Module is an Object -- a programming module -- that you define\par
with SQL's module language: a subset of SQL that allows you to write database\par
routines in pure SQL. It contains SQL statements that will operate on your\par
SQL-data, and you link it (in some implementation-defined way) with modules of\par
code in one or more of the Standard's host languages. The database routines\par
are called externally-invoked procedures because they are invoked by the host language program to which you link the Module they belong to.\par
\par
MODULE statement\par
\par
The MODULE statement defines an SQL-client Module. The required syntax for the MODULE statement is:\par
\par
<SQL-client Module definition> ::=\par
MODULE [ <SQL-client Module name> ]\par
 NAMES ARE <Character set name>\par
 LANGUAGE \{ADA | C |COBOL | FORTRAN | MUMPS | PASCAL | PLI\}\par
 <Module authorization clause>\par
 [ PATH <Schema name> \{,<Schema name>\}... ]\par
 [ TRANSFORM GROUP \{<group name> | \{<group name> FOR TYPE <UDT name>\} , ...\} ]\par
 [ DECLARE TABLE statement(s) ]\par
 <Module contents>...\par
\par
      <Module authorization clause> ::=\par
      SCHEMA <Schema name> |\par
      AUTHORIZATION <AuthorizationID> |\par
      SCHEMA <Schema name> AUTHORIZATION <AuthorizationID>\par
\par
      <Module contents> ::=\par
      DECLARE CURSOR statement(s) |\par
      PROCEDURE statement(s)\par
\par
An SQL-client Module doesn't have to be named (unless the Module's LANGUAGE\par
clause specifies ADA, in which case you must give the Module a valid Ada\par
library unit name); your SQL-environment can contain multiple unnamed SQL-\par
client Modules. If you do name an SQL-client Module, though, you must give it\par
a unique name (for all SQL-client Modules) in your SQL-environment. A <SQL-client Module name> is a <regular identifier> or a <delimited identifier>.\par
\par
The optional NAMES ARE clause provides the name of the Module's default\par
Character set: the Character set that your DBMS will use for any character\par
strings in the Module that don't include an explicit Character set\par
specification. If you omit this clause, the Module's default Character set is\par
chosen by your DBMS, and must contain at least every <SQL language character>.\par
\par
The LANGUAGE clause provides the name of the host language that will invoke the routines this Module contains.\par
\par
The Module authorization clause provides either the Module's default Schema,\par
the Module's <AuthorizationID> or both (at least one must be included).\par
      ## SCHEMA <Schema name> provides an explicit <Schema name> -- this will\par
be the default <Schema name> qualifier for any Objects referred to in the\par
Module without explicit qualifiers. If you omit this clause, the default\par
<Schema name> defaults to the value in the AUTHORIZATION clause.\par
      ## AUTHORIZATION <AuthorizationID> provides an explicit\par
<AuthorizationID> to be the owner of the Module -- this will be the\par
<AuthorizationID> whose Privileges will be checked when the Module's SQL\par
statements are executed. If you omit this clause, your DBMS will treat the\par
SQL-session <AuthorizationID> as the Module's owner at runtime.\par
\par
The optional PATH clause provides a list of <Schema name>s that will be used\par
as the Module's default path -- that is, the qualifying <Schema name>s that\par
will be used for any unqualified <Routine name>s in this Module. You can name\par
zero or more Schemas in this clause (your DBMS will pick the one that matches\par
the unqualified routine best at runtime); each Schema in the list must belong\par
to the same Catalog that this Module's default Schema belongs to. If you omit\par
this clause, it will default to a list of Schemas, containing at least this Module's default Schema, chosen by your DBMS.\par
\par
The optional TRANSFORM GROUP clause provides a <group name> for each UDT parameter that has no locator; see our chapter on UDTs.\par
\par
You can declare zero or more temporary Tables for the Module. Each will be visible only to the Module you declare them in.\par
\par
The <Module contents> clause is the meat of the Module -- it contains the SQL\par
statements that do the work you need done on your SQL-data. You can declare\par
zero or more Cursors here (see our chapter on embedded SQL), as well as one or\par
more externally-invoked procedures (with the PROCEDURE statement, see below).\par
\par
If you want to restrict your code to Core SQL, don't use the NAMES ARE clause, the PATH clause, the TRANSFORM GROUP clause or any DECLARE TABLE statements in a MODULE statement.\par
\par
PROCEDURE statement\par
\par
The PROCEDURE statement defines an externally-invoked procedure. The required syntax for the PROCEDURE statement is:\par
\par
PROCEDURE <procedure name>\par
\{(<host parameter declaration> [ \{,<host parameter declaration>\}... ] ) |\par
<host parameter declaration>...\};\par
SQL procedure statement;\par
\par
   <host parameter declaration> ::=\par
   :<host parameter name> <data type> [ AS LOCATOR ] |\par
   SQLSTATE\par
\par
An externally-invoked procedure is an SQL procedure that is called from a host\par
language program. It belongs to an SQL-client Module, and must have a\par
<procedure name> that is unique (for all procedures) within that Module. A\par
<procedure name> is a <regular identifier> or a <delimited identifier> and\par
should conform to the host language you'll be calling it from.\par
\par
Each procedure has to contain a list of one or more parameter declarations,\par
terminated with a semicolon: SQLSTATE is always mandatory. Your list should be\par
enclosed in parentheses, with each parameter declaration separated from the\par
next by a comma (though our syntax diagram shows that both the parentheses and\par
the commas are currently optional, this is a deprecated feature in the\par
Standard, so avoid it). Other than SQLSTATE, each parameter has a name\par
(preceded by a colon), a <data type> and -- if it is a BLOB, CLOB, NCLOB, UDT\par
or ARRAY, an optional AS LOCATOR indicator. A call of an externally-invoked\par
procedure has to supply the same number of arguments as the parameter declarations in the procedure.\par
\par
Each procedure has to contain exactly one SQL procedure statement, terminated\par
with a semicolon. This is the SQL statement that gets executed when the\par
procedure is called. An SQL procedure statement is any executable SQL\par
statement -- this includes all the SQL-Schema statements, the SQL-data\par
statements, the SQL-control statements, the SQL-transaction statements, the\par
SQL-Connection statements, the SQL-session statements and the SQL diagnostics statement.\par
\par
If you calling the procedure from:\par
      ## Ada -- then use only these <data type>s in your <host parameter\par
declaration>s: CHARACTER, BIT, SMALLINT, INTEGER, REAL, DOUBLE PRECISION,\par
declare SQLSTATE's base type as SQL_STANDARD.SQLSTATE_TYPE, and identify the\par
procedure by its <procedure name>, as if it was declared within an Ada library\par
unit specification that has a name equal to the name of the SQL-client Module that contains the procedure.\par
      ## C -- then use only these <data type>s in your <host parameter declaration>s: CHARACTER, CHARACTER VARYING, BIT, INTEGER, SMALLINT, REAL, DOUBLE PRECISION, and declare SQLSTATE as a C char with length 6.\par
      ## COBOL -- then use only these <data type>s in your <host parameter declaration>s: CHARACTER, BIT, NUMERIC, INTEGER, SMALLINT, and declare SQLSTATE as a COBOL PICTURE X(5).\par
      ## Fortran -- then use only these <data type>s in your <host parameter declaration>s: CHARACTER, BIT, INTEGER, REAL, DOUBLE PRECISION, and declare SQLSTATE as a Fortran CHARACTER with length 5.\par
      ## MUMPS -- then use only these <data type>s in your <host parameter declaration>s: CHARACTER VARYING, INTEGER, DECIMAL, REAL, and declare SQLSTATE as a MUMPS character with maximum length greater than or equal to 5.\par
      ## Pascal -- then use only these <data type>s in your <host parameter declaration>s: CHARACTER, BIT, INTEGER, REAL, and declare SQLSTATE as a Pascal PACKED ARRAY [1..5] OF CHAR.\par
      ## PL/I -- then use only these <data type>s in your <host parameter declaration>s: CHARACTER, CHARACTER VARYING, BIT, BIT VARYING, DECIMAL, INTEGER, SMALLINT, FLOAT, and declare SQLSTATE as a PL/I CHARACTER(5).\par
For a list of the correspondences between SQL <data type>s and host data types, see "Host Variables" in our chapter on embedded SQL.\par
\par
Here's an example of an SQL-client Module:\par
\par
   MODULE module_1\par
      NAMES ARE ASCII_FULL\par
      LANGUAGE C\par
      SCHEMA catalog_1.schema_1 AUTHORIZATION bob\par
      DECLARE LOCAL TEMPORARY TABLE Table_1 (\par
         COLUMN_1 INTEGER, COLUMN_2 CHARACTER VARYING(25))\par
         ON COMMIT DELETE ROWS;\par
      PROCEDURE proc_1 (\par
         :var_1 INTEGER, :var_2 CHARACTER VARYING(25));\par
         INSERT INTO Table_1 (column_1, column_2)\par
            VALUES (:var_1, :var_2);\par
      PROCEDURE proc_2 (\par
         :var_1 INTEGER);\par
         UPDATE Table_2 SET\par
            column_3 = column_3*:var_1 WHERE column_3 IN\par
              (SELECT column_1 FROM Table_1;\par
\page\par
Chapter 53 -- Style \par
\par
Here is one SQL operation, written in two contrasting styles. Notice the different names, spacing, indentation and choice of optional keywords: [CASUAL] SELECT * FROM T WHERE C1>5 ORDER BY 1 ASC; [FORMAL] SELECT package_id, special_handling_code, buy_date FROM Packages WHERE package_id > 1.0 ORDER BY package_id; Casual style is better for notes, examples, blackboard discussions and prototypes. We use it in this book whenever we enclose an SQL statement in an illustrative sentence, as when we say that "SELECT * FROM T WHERE C1>5 ORDER BY 1 ASC" is an example of casual style. We don't wear suits on beaches and we believe that casual style is appropriate for our purposes. On the other hand, a serious program demands some formality. There is one good reason and one bad reason. ## Appearance. Okay, this is the bad reason. Formal style persuades others, perhaps even yourself, that you used some sort of organization and design. ## Coherence. You can read statements more easily if you know in advance the shape, order and vocabulary. More time is spent "reading" code than "writing" it, so you will save time by investing time at the start. Besides, maybe you do wear suits on beaches. A true story There once was a clever DBMS named O_____ (tm). The people who program O_____ were mulling in their tall building in Redwood Shores CA one day. "Sometimes we have to run the same SQL statements twice", they mulled. "So why should we parse the same statement again when we already know what the Access Plan is from the first time we ran it?" And they came up with a clever plan. They put the first SQL statement in a cache! Then, when the second SQL statement came along, they had a clever way of telling that it was really something they'd done before (maybe with a parameter or two different but that doesn't affect the story). And they just re-used the same Access Plan and saved oodles of time. They even used this clever plan for Views. Which was great. Except that their way of comparing the new SQL statement with the cached SQL statement was, well, simple. What they did was: they compared every byte in the cached statement with every byte in the new statement. That's it. No lower-to-upper conversions, no lead-space trimming, nothing but a REP CMPSB (that's "strcmp" to you C fans). What happened next? Well, in all the good-doobie programming shops, where everybody wrote every detail according to the same style rules ... why, the programs ran faster. But in all the other programming shops, where freedom and creativity ruled, nothing happened. The moral of the story is: choose a common style, then STICK TO YOUR STYLE. Authority To get the rules of good SQL style for you, we culled them from actual rules of large programmer shops, or by just looking at what rules are implicit in code written by experts (for example, the sample code in vendors' manuals). Where we had to note inconsistencies -- and there are several -- we've made no attempt to clean them up. Where we are aware of minority views, we've reported them. And where we saw opportunities to improve things by adding some new reasonable rule, we didn't -- on the grounds that anything which is really reasonable would already be common practice. Having said that we are following common practice, we must also say that no single person or organization actually obeys all these prescriptions. About half of the world's database programmers obey about half of the style rules, sometimes. We've organized the style rules into two general classes: layout rules and naming rules. Within the classes, the rules are in no particular order. The numbers are arbitrary. Layout Rules 1. Capitals. Write SQL s in upper case. Write \par
s with an initial capital, small letters after that; when a \par
has two parts, use an initial capital for each part. Write s in lower case. For example: CREATE TABLE Widgets ( width SMALLINT); UPDATE Temporary_Personnel SET discharge_date = CURRENT_DATE; Names of other, non-Column, Objects should also have an initial capital. For example: GRANT UPDATE ON Widgets TO Sandra, Maria; Exception: If a name is an acronym -- e.g.: NATO or SQL or NIST -- use all capital letters. Alternative: Some write everything in lower case -- it's easier to remember. And we've seen examples written entirely in upper case -- but not recent examples. You should remember that are stored in upper case, but it's been a long time since any DBMS insisted that Object names must be entered in upper case in the first place. 2. Spaces. Put a single space after every SQL -- that is, after every and after s and after operators such as * or + or =. For example: SELECT width * 5 ... Exception: There need be no spaces after scalar or set function names, or within parentheses. For example: SELECT MAX(width) ... Exception: There should be no space before comma (,) or semicolon (;). There should, however, be a space after the comma. For example: SELECT width, length ... ... DECIMAL (7, 2) ... Exception: There should be no space at the end of a line. Exception: In a qualified name, there should be no space before or after the period (.). Alternative: Some would omit spaces around comparison operators or arithmetic operators. For example: ... (a=b) OR (b=c) ... 3. Line Breaks. [ Skip this rule if you use SQL/CLI or direct SQL ] There are alternate rules for "when to switch to a new line", usually called "breaking". The common rule is to break on every clause-start . In a SELECT statement, the clause-start s are: SELECT itself, FROM, ON, WHERE, GROUP, HAVING, ORDER; the Boolean operators AND / OR are usually considered to be equivalent to clause-start s. Additionally, some prescribe a break after every full expression. For example: SELECT width, length+5 FROM Widgets, Foobars WHERE width > 5 AND length >= 5 ORDER BY width; Others will place multiple items on a line if there aren't too many to fit. For example: SELECT width, length + 5 FROM Widgets, Foobars WHERE width > 5 AND length >= 5 ORDER BY width; Notice the indentation at the start of each line -- or lack thereof! It is rare to find, say, a SELECT statement starting on Column #1 but all subsequent clauses starting on Column #3. In any case, to accomplish the lined-up effect, one uses spaces rather than tab characters. The indentation seen in the above SELECT statements is to Column position 10 to accommodate "ORDER BY "; with non-SELECT statements indent is random. Exception: One group prefers to right-justify the main s. For example: SELECT width, length + 5 FROM Widgets, Foobars WHERE width > 5 AND length >= 5 ORDER BY width; There is a universal rule in all languages: if it's nested, indent. So further indentation will be necessary for subqueries. For example: SELECT width, length, width + 10 FROM Widgets WHERE width <> 7 AND length = (SELECT expression FROM t); Notice the position of the ( preceding the word SELECT. Alternative: Put the ( at the end of the previous line. However, placing a closing ) on the same line as the end of the statement is normal -- even though this differs from the way many C programmers use \{\} braces and differs from the way many Pascal programmers write begin ... end blocks. Alternative: Put the initial of a major clause on a line of its own, as is done with WHERE and AND in this example: SELECT length FROM widgets WHERE (rowid = 5) AND (specialty = 'FUN'); Note also the different indentation of the conditional clauses. Alternative: Put ORed conditions on the same line, but break for AND. For example: SELECT length FROM widgets WHERE (rowid = 5 OR rowid = 6 OR rowid = 7) AND width > 1; Alternative: Add line breaks for each level of a nested function. For example: SELECT SUBSTRING( UPPER(title) FROM 1 TO 5) FROM Books; Make a new line for UNION. Treat AND NOT as a single operator. 3a. Continuation Lines. When room is unavailable on a line, break if possible at a comma or equal sign or other operator . If there are too many s to fit in one line, break thus: SELECT Column_1, Column_2, Column_3, Column_4, Column_5, Column_6, Column_7, Column_8, Column_9, Column_10 ... Alternative: There is a minority view that commas should be shifted. For example: SELECT Column_1, Column_2, Column_3, Column_4, Column_5 ,Column_6, Column_7, Column_8, Column_9, Column_10 ... 3b. Indenting CREATEs. In a CREATE TABLE statement, every new Column goes on a new line. When it helps, you may indent so that each part of the is at the same position on the line -- but nobody does that all the time. Here's an example: CREATE TABLE Transactions (transactionid INTEGER NOT NULL, amount DECIMAL(7, 2), partid INTEGER, comments VARCHAR(3000)); Usually CREATE TABLE statements will also have Constraint clauses. We have split them out here, adding the Constraints in later ALTER TABLE statements. Constraints are in fact separate from Tables, but if you find that splitting up the Table definition into separate statements is unacceptable, you're not alone. The other part of this illustration shows our preference for giving names to everything, including Constraints -- see Rule 16. Here's an example: ALTER Table Transactions ADD CONSTRAINT transaction_primary_key PRIMARY KEY (transactionid); ALTER Table Transactions ADD CONSTRAINT transaction_references_inventory FOREIGN KEY partid REFERENCES Inventory(partid) ON UPDATE CASCADE ON DELETE CASCADE; 3c. Indenting INSERTs. Here is an INSERT statement formed according to the same rules as discussed. Notice that the SELECT in the example is not indented like a subquery would be. INSERT INTO Recreation_players (playerno, name, town, phoneno) SELECT playerno, name, town, phoneno FROM Players WHERE leagueno IS NULL; For streams of INSERT statements, one relaxes the rules to squeeze to one line. For example: INSERT INTO Personnel VALUES (1, 2, 3, 'Maximum'); INSERT INTO Personnel VALUES (7, 4, 166, 'Minimum'); INSERT INTO Personnel VALUES (15, -6, 0, NULL); It might appear nice to line up the values in this example, but that's not what people do. 3d. Indenting UPDATEs. If we apply the rules consistently, then an UPDATE statement should look like this: UPDATE Contacts SET first_grade = 'A', second_grade = 'B', third_grade = 'C'; Alternative: The more common style is to break for each assignment. For example: UPDATE Contacts SET first_grade = 'A', second_grade = 'B', third_grade = 'C'; 4. Statement end. End statements with a semicolon without a preceding space. For example: COMMIT; Exception: Where the semicolon is inappropriate, omit it (for example, in COBOL shops or where the vendor won't accept it). 5. Comments. A simple comment begins with a double minus sign (--) and ends at the next line. Unfortunately, if an SQL statement comes from keyboard input, then the dialog manager will strip the line breaks. And, OSs disagree whether a line break is one character (LF) or two (CR+LF). Because of the danger that presents to the parser, many eschew all comments in the SQL statement and put them in the host language code. For example: /* Here is a C comment preceding an embedded SQL statement */ EXEC SQL SELECT width, length FROM Widgets; /* Here is a C comment following an embedded SQL statement */ The problem disappears if your DBMS supports SQL3, which allows C-like comments -- i.e.: comments that begin with /* and end with */. Although C-like comments are far from universal, they are the preferred style among Microsoft SQL Server users. Occasionally they are even used for section headings, thus: /************************************* The Table creations *************************************/ CREATE Table ... CREATE Table ... /************************************* The procedure definitions *************************************/ CREATE PROCEDURE ... CREATE PROCEDURE ... Speaking of comments, Weinberg (The Psychology of Computer Programming) suggested that code and comments should be written in separate columns. This would make it easier to focus on the code when debugging (if a program has bugs then the comments are probably lies). 6. Qualifiers. When an SQL statement contains references to more than one Table, use s rather than s. This is particularly true for joins. For example: SELECT Widgets.length, Foobars.width FROM Widgets, Foobars WHERE Widgets.length = Foobars.width; Not only does the qualification of a help the reader see which Table a Column belongs to, it guards against later breakage of the code (if, for instance, a new Column named WIDTH is someday added to FOOBARS). Sometimes the qualification may have to include Schema and s too. If qualification starts to get at all lengthy, use s. 7. Shorthands. 7a. Shorthands for lists. Do not use "SELECT * ..." to mean "SELECT all Columns ...". List the Columns you want by name. For example: SELECT length, width FROM Widgets; Exception: In the set function COUNT(*), the asterisk is necessary and in "EXISTS (SELECT * ..." the asterisk is preferred. Do not use an INSERT statement without a Column list. List the Columns you want by name. For example: INSERT INTO Widgets (length, width) VALUES (1, 2); Exception: Streams of INSERT statements contain no Column list, see rule 3c. Do not use GRANT ALL PRIVILEGES or REVOKE ALL PRIVILEGES for a Privilege list. List the Privileges you want by name. For example: GRANT SELECT, UPDATE ON TABLE Widgets TO Sandra, Joan; 7b. Shorthands for expressions. Usually, expression shorthands involve learning new syntax. For example, "COALESCE(a,b)" is short for "CASE WHEN a IS NOT NULL THEN a ELSE b END". But we'd guess that some people would have to look up COALESCE to find out what it means. On the other hand, they might be able to puzzle out the longer CASE expression, because they've seen similar constructs in most other computer languages. The consensus seems to be to use the longer expression, rather than the shorthand -- unless the shorthand itself is a common and well-understood construct. 8. Short forms. For s, use short forms: CHAR rather than CHARACTER, VARCHAR rather than CHARACTER VARYING, INT rather than INTEGER, BLOB rather than BINARY LARGE OBJECT. Speaking of shortness -- though this has nothing to do with Rule 8 -- a too-long name is: Parts_Which_Have_No_Serial_Numbers. 9. Redundancy. 9a. Noise s. Where a is optional and eliminating it would cause no change in meaning, eliminate it. One example: GRANT UPDATE, INSERT ON Widgets ... instead of: GRANT UPDATE, INSERT ON TABLE Widgets ... Another example: SELECT width FROM Widgets ORDER BY width; instead of: SELECT width FROM Widgets ORDER BY width ASC; Another example: COMMIT; instead of: COMMIT WORK; Another example: SELECT width FROM Widgets; instead of: SELECT ALL width FROM Widgets; Remember Shannon and information theory: when a word adds nothing to the meaning, it is not information. It is noise. Exception: It's never bad to add unnecessary parentheses if there is any chance that a reader might not guess what the precedence of operators might be. For example: SELECT (width * 5) + 4 FROM Widgets; Exception: Although UNION DISTINCT is not in common use, it is clear that SQL3's designers believe that explicitly saying DISTINCT is good. 9b. Superfluous clauses. Most SQL programmers are willing to say the same thing twice "to make the meaning clearer". We give two examples of this bad but normal practice. The first shows a superfluous NOT NULL clause: CREATE TABLE Widgets (width INT NOT NULL, CONSTRAINT widget_pkey PRIMARY KEY(width)); In SQL-92 and SQL3, a primary key is automatically NOT NULL. The second example shows a superfluous predicate: SELECT width FROM Widgets WHERE spoffo BETWEEN 'A' AND 'AZZZ' AND spoffo LIKE 'A%'; The BETWEEN clause is unnecessary. It's probably there for "optimization" reasons which are outside the scope of this chapter. 9c. Explicitizing. You don't need to start any program with the SQL statement: CONNECT TO DEFAULT; because the DBMS would "CONNECT TO DEFAULT" anyway. So should you bother? According to one DBMS expert: yes. In general, if some critical process is "implicit" (performed automatically as default behaviour), you might do good by making it "explicit" (specified in the instruction). You're making your intentions clear not only to the reader, but also to the DBMS, so this act is more than a mere comment. In this view, the first SQL executed statement should be CONNECT. 10. Literals. Enter s using maximum scale but without lead zeros and without leading + signs. For example: UPDATE Widgets SET maximality = 10.00; Exception: When using s in arithmetic expressions, use the scale that you want to the result to have. (Note: If you want to be emphatic about what specific numeric you are using, consider using CAST.) Even if a search of a character string Column is probably case-insensitive, use both upper and lower case as you would if you were inserting. For example: SELECT surname FROM Widgets WHERE surname = 'Smith'; Do not put trailing spaces in s unless they are necessary for comparisons with PAD SPACE Collations. For binary items, use X'....' rather than B'....' notation. For example: INSERT INTO Widgets (bobbet) VALUES (X'427A'); 11. Specify Character sets. We can't call this "common practice" because we haven't seen much of _introducer use, but it would be consistent with the preceding to say that if a character string has, or will have, non-Latin letters, and the default Character set is not obvious, specify the Character set. 12. Statement splitting. Most SQL programmers are willing to write very long SQL statements. There is some practical justification for this tendency: (a) if any form of "auto-commit" is in effect, then splitting up SQL statements could leave the database in an inconsistent state and (b) most DBMSs optimize at the statement level, so putting everything in one statement might provide useful information to the optimizer. Alternative: A minority view (which we espouse) holds that separate thoughts belong in separate sentences, as in any ordinary language. For example, we've suggested before that it's a good idea to add Constraints later (with ALTER TABLE), rather than mix all Constraints with s in the original CREATE TABLE statement. 13. Impossibilities Consider this example of a CASE expression: CASE Column_of_doom WHEN > 5 THEN '>5' WHEN <= 5 THEN '<=5' END It's hard to be sure, but it looks like the writers didn't ask "what if COLUMN_OF_DOOM is NULL?". There should be an explicit ELSE clause, here to allow for that. Defensive programmers code for the "default" or "otherwise" case, even if the case can't possibly happen. 14. Precise comparisons Comparisons with ">" and "<" operators are sometimes vaguer than they need be. For example: name > 'X' /* what if somebody is named 'X'? */ position < 1 /* you mean position <= 0? */ By rephrasing the comparison with a ">=" or "<=" operator, you can sometimes catch such problems. 15. Distributing NOTs "Neither a borrower nor a lender be." -- Polonius Instead of saying "be not a borrower or a lender" Polonius said "neither a borrower nor a lender be" -- using a separate negation word for each negated thing. This was an application of one of DeMorgan's Rules: NOT (A OR B) can be changed to NOT(A) AND NOT(B) NOT (A AND B) can be changed to NOT(A) OR NOT(B) Since the changed form is closer to the way that people actually talk, it is easier to read. Naming Rules Everyone says that onomatopoeia is the oldest profession. Or, at least, they would say that, if they knew that onomatopoeia originally meant "the making of names", and that Adam's first job was to name all the beasts in the Garden of Eden. 16. Give everything a name. The DBMS often lets you skip giving an Object a name: it just assigns a default name. But this default name is arbitrary. And besides, no two DBMSs use the same rules for default names. So, give explicit names to expressions in select lists. For example: SELECT (length + width) AS length_and_width FROM Widgets; Consider giving explicit names to Constraints in CREATE TABLE, ALTER TABLE, CREATE DOMAIN and ALTER DOMAIN statements. If you don't, how will you drop the Constraints later? And how will you interpret the diagnostics, which include s? Here's an example: CREATE TABLE Widgets (length INT, CONSTRAINT Widgets_Length_Checker CHECK (length > 0)); Exception: Usually one does not give names to simple Column Constraints like NOT NULL or PRIMARY KEY. Actually, naming is just one prominent example of a case where the DBMS will assign some "implementation-dependent" value if you don't specify one yourself. In all such cases, it's probably safer to specify. 17. When a name has two parts, separate the parts with the underscore character (_). For example: ytd_sales, initial_extent. Alternative: For \par
s especially, you can keep the parts unseparated but capitalize the second word. For example: OrderItems, DepartmentNumbers. 18. Avoid names that might be reserved words in some SQL dialect. The way to do this is to use names that refer to objects in the real world that you're modelling with your database. You can be fairly sure that names like CandyStores, book_title or swather are not names that the DBMS needs for its own purposes. If you must be absolutely sure, you can take further measures -- but there are problems with all of them. ## You can use the list of s, in our chapter on general SQL concept. This list includes reserved words used in major SQL dialects, as well as reserved words used in all standard SQL variations at the time of printing. It's better to look it up here rather than depend on a vendor's manual. But it's impossible to keep such a list up to date. ## You can check by passing to your DBMS an SQL statement containing the and looking for an error message. For example, try to execute something like "CREATE TABLE ( INT);" If the SQL statement works, is not a reserved word. However, this won't tell you if some other DBMS reserves that word, or if the next version of your DBMS will reserve it. ## You can put underscores (_) in names. This is unpopular. The SQL Standards committee doesn't intend to add s containing underscores in any future SQL version. However, there are some exceptions: words that begin with CURRENT_ or SESSION_ or SYSTEM_, or words that end with _LENGTH. Underscores have special meanings when used with introducers, with LIKE predicates and with SIMILAR predicates. The SQL Standards committee will also avoid s containing digits in all future versions. So try Mussels4. But first read Rule 25. ## You can enclose all names with quotes (""). But s cause their own problems: see Rule 19. 19. Avoid s. The troubles with them are, first, that double quote marks are false signals to many people who are used to thinking that quote marks appear around strings instead of names. Second, there's case sensitivity -- "X" is not the same as "x". Third, quote marks are ugly. Exception: \par
s might require s, because some DBMSs use files for Tables. File names include special characters -- . or / or \\ or : -- that are illegal in regular s. Exception: Microsoft Access programmers often use s for \par
s (Access is a non-standard SQL which uses []s instead of ""s to mark the delimitation). Exception: Applications which generate SQL statements, such as user interfaces, might automatically enclose all s inside ""s. Exception: Of course, if you use SQL s in your names, you must use s. With all these exceptions, you might decide to take the minority line and use s regularly. If you do, at least avoid names that have lead or trailing spaces. Some DBMSs' processes include an automatic TRIM. 20. Names of Tables are plural; names of all other Objects are singular. Thus, in the INFORMATION_SCHEMA, we have a View named SCHEMATA and the Columns of this View are: CATALOG_NAME, SCHEMA_NAME and so on. Often a plural is a collective noun, for example: INVENTORY. Admittedly, this means that \par
s will be longer (at least in English), but it's a subtle signal that distinguishes \par
s from other s. Alternative: The dissenting minority points out that the English phrases for many tabular items are singular: "ADDRESS BOOK" (not "ADDRESSES BOOK"), "PHONE BOOK", "INVESTMENT PORTFOLIO", "RESTAURANT LIST", etc. 21. Use words in your national language. The fact that SQL s look like English is irrelevant. For example, this sample SQL statement appeared in an article in a Polish magazine: UPDATE studenci SET nazwisko='Kowalski'; This does mean that names will sometimes include characters outside the regular English alphabet. Obviously the effect on portability is unfortunate, but if your DBMS doesn't support accented characters in names then it doubtless won't properly support them in data values either, so why would you use such a DBMS anyway? Precisely because you don't know what a nazwisko is, you can see that a Pole would have trouble understanding the word that you use instead of nazwisko. 22. Don't worry about how s appear when a Table is displayed on the screen. That's something that changes anyway (use AS clauses). Instead, worry about how names appear if you print out a program. Remember: The goal is long-term comprehension, so ephemeral considerations such as screen-display deserve low priority. 23. Names should be descriptive, but not too descriptive. Minimally, you should avoid algebra like "UPDATE k SET k1=4" -- where no one could possibly guess what k and k1 are supposed to represent. Medianly, you should avoid non-specific descriptors like PHONE_NUMBER -- where no one can be sure whether the referent is a home- or office- or general-contact- telephone number. But stop there! Avoid names like SOLDIERS_IN_THE_ARMY because (presumably) all the soldiers in the database are in the army; the "in the army" bit is only helpful if you also have soldiers in the navy and you have to distinguish between them. This part of the rule -- avoid making accidents part of the identification -- is analogous to one of the normalization rules. 24. If two Columns from different Tables are based on the same Domain, they should have the same name. In fact, they should have the Domain's name. For example: CREATE DOMAIN surname VARCHAR(25); CREATE TABLE Students (surname surname, ...); CREATE TABLE Professors (surname surname, ...); This rule would apply even if your DBMS doesn't support explicit creation of Domains, or if you use SQL3's user-defined type feature -- you're still using the concept of Domains. Exception: This rule does not apply for two Columns in the same Table. Incidentally, when s are the same, NATURAL JOIN is easier. That's usually a blessing, but some caution is required -- you certainly don't want to cause a join over two Columns which have the same name by accident. 25. Digits are a bad sign. Too often we use digits as arbitrary distinguishers -- e.g.: Lines_1 / Lines_2 -- when there is some intrinsic difference between Lines_1 and Lines_2 that could be expressed in the names, for example, Lines_Freshwater and Lines_Longitude. Particularly bad are the digits '0' and '1', which look too much like the letters 'O' and 'l'. 26. Try to stop a name at 18 characters: that was the maximum length allowed in SQL-89. Mainly, it's hard to remember a long name. For example, do you remember if the name mentioned in rule 8 was Parts_Which_Have_No_Serial_Numbers? Or was it Parts_Which_Have_No_Serialnumber? 27. Repeat the \par
in the ... not. Firstly, you'd end up violating rule 24. Secondly, if you make a View of the Table you'll have to either violate this rule, or make View s not equal to Table s. For example, the INFORMATION_SCHEMA View called GRANTS has a Column called IS_GRANTABLE instead of GRANT_IS_GRANTABLE. Remember, if you really need to make it clear what Table the Column is in, you can use a : GRANTS.IS_GRANTABLE. Exception: A Column which is part of the primary key of the Table could include the \par
, in the singular. For example, the INFORMATION_SCHEMA View called SCHEMATA has a Column called SCHEMA_NAME -- and any foreign keys that reference SCHEMATA would be Columns called SCHEMA_NAME too (assuming that Views could have such Constraints). There are several conflicting conventions for foreign keys. In any case, though, it is not part of your mandate to ensure that all s in the database must be unique. 28. Depend on a dialect ... not. This can be subtle, e.g.: UCASE is a function name that some people seem to think is standard SQL (in fact it's ODBC). Write with lowest-common-denominator syntax when you can, but test it first with an SQL3 parser to make sure you're not going to violate a rule when you upgrade. 29. Sometimes s (or aliases) are simply necessary because the actual \par
is unwieldy, containing qualifiers or lengthy path names. In Oracle, use of s actually helps the optimizer. But should you always use s? No -- they're most appropriate in SELECT statements where s must be qualified. 30. Abbreviations. Legacy SQL code has frequent abbreviations: PROV for PROVINCE, DEPT for DEPARTMENT, LEN for LENGTH, FNAME for FIRST NAME and so on. Judging from trends in other computer languages, this taste will become obsolete. At this moment it's still a matter of taste. A few abbreviated prefixes/suffixes are used for some common Domains: _id for single-Column candidate key (e.g.: author_id, program_id), _no for ordinal number (e.g.: player_no, receipt_no), qty_ for quantity (e.g.: qty_of_goods_sold), avg_ for average (e.g.: avg_qty_of_goods_sold), min_ for minimum (e.g.: min_weight), max_ for maximum (e.g.: max_length) and sum_ for total (e.g.: sum_balance). Notice that some of the prefixes are derived from SQL s. ## Examples of s/s Some names that we have seen in use in databases for banking/libraries /retail shops/government include: firstname, lastname or surname, street, houseno, aptno or unitno or suiteno, city, state or province, country, phoneno or email, sex, birth_date, account_id, balance, account_open_date, account_close_date, transaction_code, author_firstname, author_lastname, title, callno, isbn, year_published, checkout_date, loan_type, amount, itemno, transaction_time, transaction_code. Certainly we've seen many other names too, in many styles. We picked ones that generally fit the criteria that we've described heretofore. 31. Host language conventions. There is certainly an argument that this C code snippet looks fine: EXEC SQL INSERT INTO Recordings (szRecording) VALUES (:szRecording); The point here is that the C host variable szRecording associates with the SQL Column szRecording. Hence the same name. In general we could say that SQL Object names are often influenced by conventions used in the most common host language, such as C in this case. We don't condemn this practice, we just ignore it, since our concern is SQL conventions rather than host language conventions. One detail about the szRecording in the preceding example: it's in a Polish notation, that is, the sz in the name indicates the data type (string zero). We will concern ourselves solely with the question: is it good SQL to embed information in names, for example szrecording or name_char or (more subtly) namestring? The answer, judging as usual from what seems to be common practice, is yes that's okay, but nobody is doing so systematically. Sometimes we do see s that end in _date or num[eric], but we don't see consistency. For the narrower concept -- Domains -- we have Rule 24. 32. User Names If you have control over user names, prefer first names: Ralph, Mike, Lucien. Where necessary add the first letter of the last name: JeanC, RalphK, LucienB. This convention appears to derive from names on the Internet. Often there is no choice in this regard, because the operating system feeds user names to the DBMS. 33. Comma Lists Whenever a list is disordered, people wonder why. For example, these SQL statements look a trifle curious: SELECT firstname, travel_allowance, surname FROM SalesPersons; SELECT * FROM States WHERE state_abbreviation IN('WY','MI','AK','CO'); If there is some hidden order, add a note explaining what it is. Otherwise, change to a natural or alphabetical order. Examples of statements in formal style Here are some actual SQL statement examples. We have not edited them to fit all the rules in this chapter. ALTER Table Countries ADD gnp DECIMAL(8, 2); COMMIT; CONNECT TO 'c:\\db'; CREATE TABLE players (playerno SMALLINT NOT NULL PRIMARY KEY, name CHAR(15) NOT NULL , leagueno SMALLINT DEFAULT 99); ALTER Table players ADD Constraint check_playerno CHECK (playerno BETWEEN 00 AND 99); CREATE VIEW ages (playerno, age) AS SELECT playerno, 1986 - YEAR_OF_BIRTH FROM Players; DELETE FROM Order_Items WHERE partid IN ( SELECT partid FROM Inventory WHERE description LIKE 'd%'); GRANT SELECT, UPDATE ON Jackets TO Carol, Kathleen; INSERT INTO Gradings (gradeno, inspectorid, description) VALUES (3, ?, 'Prime'); INSERT INTO Temporary_Workers (workerid, name, town, phoneno) SELECT workerid, name, town, phoneno FROM Workers WHERE benefit IS NULL; SELECT title FROM Videos WHERE out_date > DATE '1994-07-06' GROUP BY title HAVING COUNT(*) > 1 ORDER BY title; SELECT accountid, balance FROM Accounts WHERE (town = 'Amesville' OR balance < 0) AND NOT (town = 'Amityville' AND balance < 0); SELECT NAME, TOWN FROM PLAYERS WHERE TOWN IN ('Inglewood', 'Stratford') SELECT first_name, last_name FROM Students WHERE studentno IN (SELECT studentno FROM Delinquent_Students WHERE excuse IN ('sick','unhappy','deprived')) UNION SELECT first_name, last_name FROM Teachers WHERE teacher_status = 'sick'; SELECT Realtors.name AS realtor_name, Vendors.name AS vendor_name FROM Members_Of_Real_Estate_Board Realtors, Sellers_Of_Farm_Land Vendors WHERE Realtors.name = Vendors.contact_name; UPDATE Addresses SET street = ?, houseno = ?, town = ?, state_or_province = ?, zip_or_postal_code = ?, country = ? WHERE CURRENT OF Selection; SELECT title, release, censorrtg, runtime FROM title WHERE runtime BETWEEN 120 AND 231 ORDER BY release DESC Host Language Programs Some programmers keep SQL statements apart from host language statements, in separate procedures (or even separate modules). Others allow mixing, as in this (embedded Pascal SQL) example: EXEC SQL SELECT COUNT(*) INTO :counter FROM Specifiers; if (counter=0) Writeln('Empty Table!'); if (counter>0) begin EXEC SQL UPDATE Specifiers SET process_count = process_count + 1; end; The following style notes apply to either SQL/CLI or to embedded SQL. 34. Host language variable names should be similar to corresponding SQL s, but not identical. 35. Put comments in the host program (not inside the SQL statement), using the host program's comment style. 36. Employ assertions (here we use the word "assertion" in the non-SQL sense: a conditional statement that you'd like to have in the debug version but not in the production version.) SQL is interpretive, so all "asserting" has to take place at runtime. In programs, the best method is to add executable SQL statements with #if/#endif host language directives. ** Warning: Some SQL precompilers ignore #if and #endif. For example, this assertion example checks that Column PROGRAMS.SUMMARY has matching definitions in both C and SQL. The format of the SQLExecDirect call is not a common style; you should take it merely as a suggestion. ... #define SUMMARY_LENGTH [500] SQLCHAR summary[SUMMARY_LENGTH+1]; #if DEBUG_ON SQLINTEGER character_maximum_length; #endif ... /* assertion start */ #if DEBUG_ON character_maximum_length = 0; SQLExecDirect(hstmt,"SELECT CHARACTER_MAXIMUM_LENGTH\\ FROM INFORMATION_SCHEMA.COLUMNS\\ WHERE TABLE_NAME = 'PROGRAMS'\\ AND COLUMN_NAME = 'SUMMARY'", SQL_NTS); SQLFetch(hstmt); SQLGetData(hstmt,1,SQL_INTEGER,&character_maximum_length,NULL,NULL); if (character_maximum_length <> SUMMARY_LENGTH) exit(1); if (SQLFetch(hstmt) != SQL_NO_DATA) exit(1); #endif /* assertion end -- if you survive to here, things are all right */ SQLExecDirect(hstmt,"SELECT summary FROM Programs",SQL_NTS); The following style notes apply only to SQL/CLI. 37. Use conventional names. For example, resource handles are henv, hdbc, hstmt and hdesc. When there is more than one stmt, use ordinals: hstmt1, hstmt2 and so on. 38. Declare variables with constants or macros, supplied in sqlcli.h. For example: #include "sqlcli.h" #define NAMELEN 50 ... SQLCHAR name[NAMELEN]; SQLCHAR create[] = "CREATE TABLE NameID (\\ id INT,name CHAR(50))"; ... 39. If an SQL statement contains constants which are also used in the host program, check or edit the statement at runtime. For example, add this to the last example: ... sprintf(create,"CREATE TABLE NameID(id INT,name CHAR(%d))",NAMELEN); ... 40. When testing a function's return values, programmers use various styles. For example: if (SQL_ERROR == SQLAllocStmt (hdbc,&hstmt)) goto error; if (sqlreturn = (SQLExecute(hstmt)) < 0) \{ printf("sqlreturn = %ld\\n",sqlreturn); exit(1); \} Summary Whatever you write, may later be read. Whatever style you choose for serious programs, stick with it consistently. \par
}
 